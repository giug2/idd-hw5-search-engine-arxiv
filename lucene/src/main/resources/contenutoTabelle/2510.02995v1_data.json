{
    "S4.T1": {
        "source_file": "AudioToolAgent: An Agentic Framework for Audio-Language Models",
        "caption": "Table 1: Comparison of AudioToolAgent with baseline models on MMAU, MMAR, and MMAU-Pro benchmarks. AudioToolAgent achieves state-of-the-art performance across all evaluation metrics. All baseline model scores are copied from their respective original works and/or benchmark evaluations. †Self-proposed, no code or API available to verify.",
        "body": "Dataset\nModels\nResults\n\n\n\n\nMMAU test-mini [14]\n\nSound || Music || Speech || Average\n\n\nClosed Source\n\n\nGPT-4o Audio [21]\n\n64.56 || 56.29 || 66.67 || 62.50\n\n\nGemini 2.5 Pro [5]\n\n75.08 || 68.26 || 71.47 || 71.60\n\n\nOmni-R1† [26]\n\n81.70 || 73.40 || 76.00 || 77.00\n\n\nStep-Audio 2† [10]\n\n\n83.48 || 73.65 || 76.88 || 78.00\n\n\n\nAudioToolAgent\n73.57 || 69.16 || 79.57 || 74.10\n\n\nOpen Source\n\n\nAudio Reasoner [27]\n\n67.87 || 69.16 || 66.07 || 67.70\n\n\nKimi-Audio [8]\n\n75.68 || 66.77 || 62.16 || 68.20\n\n\nQwen2.5-Omni [6]\n\n78.10 || 65.90 || 70.60 || 71.50\n\n\nStep-Audio 2 mini [10]\n\n76.28 || 71.56 || 71.47 || 73.20\n\n\nAudio Flamingo 3 [11]\n\n\n79.58 || 66.77 || 66.37 || 73.30\n\n\nAudioToolAgent-Open\n78.08 || 69.67 || 75.08 || 74.20\n\n\n\n\n\nMMAR [16]\n\nSound || Music || Speech || Sound-Music ||\nSound-Speech || Music-Speech ||\nSound-Music-Speech || Average\n\n\nClosed Source\n\n\nGPT-4o Audio [21]\n\n53.94 || 50.97 || 70.41 || 63.64 || 72.48 || 62.20 || 75.00 || 63.50\n\n\nGemini 2.0 Flash [28]\n\n61.21 || 50.97 || 72.11 || 81.82 || 72.48 || 65.85 || 70.83 || 65.60\n\n\nOmni-R1† [26]\n\n\n67.30 || 51.50 || 64.30 || 45.50 || 70.20 || 64.60 || 70.80 || 63.40\n\n\nAudioToolAgent\n61.81 || 51.94 || 77.55 || 72.72 || 76.61 || 71.96 || 70.83 || 68.80\n\n\n\nOpen Source\n\n\nAudio Reasoner [27]\n\n43.64 || 33.50 || 32.99 || 45.45 || 42.66 || 31.71 || 25.00 || 36.80\n\n\nQwen2.5-Omni [6]\n\n58.79 || 40.78 || 59.86 || 54.55 || 61.93 || 67.07 || 58.33 || 56.70\n\n\nAudioToolAgent-Open\n\n59.39 || 45.63 || 67.34 || 54.55 || 70.64 || 59.76 || 70.83 || 61.70\n\n\n\n\n\nMMAU-Pro [15]\n\nSound || Music || Speech || Sound-Music ||\nSpeech-Music || Speech-Sound ||\n\nSound-Music-Speech || Spatial || Voice ||\n\nMulti-Audio || Open-ended ||\n\nInstruction-Following || Average\n\n\nClosed Source\n\n\nGPT4o Audio [21]\n\n44.70 || 63.10 || 68.20 || 40.40 || 43.50 || 62.50 || 57.10 || 21.40 || 57.50 || 32.60 || 43.20 || 82.50 || 52.50\n\n\nGemini-2.5 Flash [5]\n\n\n51.90 || 64.90 || 73.40 || 42.80 || 58.70 || 61.30 || 42.80 || 36.30 || 71.70 || 21.20 || 67.50 || 95.10 || 59.20\n\n\n\nAudioToolAgent\n33.14 || 63.47 || 73.74 || 26.00 || 50.00 || 54.55 || 57.14 || 30.15 || 70.69 || 57.21 || 73.31 || 86.21 || 57.96\n\n\nOpen Source\n\n\nAudio-Reasoner [27]\n\n34.20 || 50.10 || 44.00 || 26.00 || 36.90 || 43.20 || 28.60 || 20.30 || 43.40 || 22.60 || 38.60 || 43.40 || 39.50\n\n\nKimi-Audio [8]\n\n46.00 || 57.60 || 52.20 || 46.00 || 54.30 || 48.90 || 42.80 || 43.70 || 50.60 || 17.20 || 34.50 || 42.30 || 46.60\n\n\nAudio Flamingo 3 [11]\n\n\n55.90 || 61.70 || 58.80 || 40.00 || 41.30 || 47.70 || 57.10 || 26.80 || 58.60 || 26.00 || 44.20 || 33.30 || 51.70\n\n\nQwen2.5-Omni [6]\n\n47.60 || 61.50 || 57.40 || 40.00 || 53.20 || 60.20 || 28.50 || 41.20 || 60.00 || 24.30 || 52.30 || 61.30 || 52.20\n\n\nAudioToolAgent-Open\n42.79 || 64.39 || 67.90 || 36.00 || 45.65 || 54.55 || 57.14 || 33.54 || 61.72 || 23.49 || 72.17 || 64.37 || 55.68",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Models</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Results</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"13\">\n<span class=\"ltx_inline-block ltx_align_left\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">MMAU test-mini</span> <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib14\" title=\"\">14</a>]</cite></span>\n<span class=\"ltx_p\">\n<span class=\"ltx_text ltx_font_italic\">Sound <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m1\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Music <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m2\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Speech <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m3\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Average</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"2\"><span class=\"ltx_text ltx_font_italic\">Closed Source</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">GPT-4o Audio <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib21\" title=\"\">21</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">64.56 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m4\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 56.29 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m5\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 66.67 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m6\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 62.50</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Gemini 2.5 Pro <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib5\" title=\"\">5</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">75.08 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m7\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 68.26 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m8\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 71.47 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m9\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 71.60</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Omni-R1<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">&#8224;</span></sup> <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib26\" title=\"\">26</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">81.70 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m11\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 73.40 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m12\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 76.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m13\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 77.00</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Step-Audio 2<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">&#8224;</span></sup> <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib10\" title=\"\">10</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">\n<span class=\"ltx_text ltx_font_bold\">83.48</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m15\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">73.65</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m16\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 76.88 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m17\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">78.00</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">AudioToolAgent</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">73.57 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m18\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 69.16 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m19\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">79.57</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m20\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 74.10</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"2\"><span class=\"ltx_text ltx_font_italic\">Open Source</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Audio Reasoner <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib27\" title=\"\">27</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">67.87 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m21\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 69.16 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m22\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 66.07 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m23\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 67.70</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Kimi-Audio <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib8\" title=\"\">8</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">75.68 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m24\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 66.77 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m25\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 62.16 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m26\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 68.20</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Qwen2.5-Omni <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib6\" title=\"\">6</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">78.10 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m27\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 65.90 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m28\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 70.60 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m29\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 71.50</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Step-Audio 2 mini <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib10\" title=\"\">10</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">76.28 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m30\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">71.56</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m31\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 71.47 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m32\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 73.20</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Audio Flamingo 3 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib11\" title=\"\">11</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">\n<span class=\"ltx_text ltx_font_bold\">79.58</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m33\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 66.77 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m34\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 66.37 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m35\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 73.30</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">AudioToolAgent-Open</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">78.08 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m36\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 69.67 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m37\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">75.08</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m38\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">74.20</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"9\">\n<span class=\"ltx_inline-block ltx_align_left\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">MMAR</span> <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib16\" title=\"\">16</a>]</cite></span>\n<span class=\"ltx_p\">\n<span class=\"ltx_text ltx_font_italic\">Sound <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m39\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Music <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m40\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Speech <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m41\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Sound-Music <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m42\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math></span></span>\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_italic\">Sound-Speech <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m43\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Music-Speech <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m44\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math></span></span>\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_italic\">Sound-Music-Speech <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m45\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Average</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"2\"><span class=\"ltx_text ltx_font_italic\">Closed Source</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">GPT-4o Audio <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib21\" title=\"\">21</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">53.94 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m46\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 50.97 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m47\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 70.41 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m48\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 63.64 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m49\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 72.48 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m50\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 62.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m51\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">75.00</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m52\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 63.50</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Gemini 2.0 Flash <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib28\" title=\"\">28</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">61.21 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m53\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 50.97 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m54\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 72.11 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m55\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">81.82</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m56\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 72.48 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m57\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 65.85 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m58\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 70.83 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m59\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 65.60</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Omni-R1<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">&#8224;</span></sup> <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib26\" title=\"\">26</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">\n<span class=\"ltx_text ltx_font_bold\">67.30</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m61\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 51.50 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m62\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 64.30 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m63\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 45.50 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m64\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 70.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m65\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 64.60 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m66\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 70.80 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m67\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 63.40</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">AudioToolAgent</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">61.81 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m68\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">51.94</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m69\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">77.55</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m70\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 72.72 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m71\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">76.61</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m72\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">71.96</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m73\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 70.83 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m74\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">68.80</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"2\"><span class=\"ltx_text ltx_font_italic\">Open Source</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Audio Reasoner <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib27\" title=\"\">27</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">43.64 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m75\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 33.50 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m76\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 32.99 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m77\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 45.45 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m78\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 42.66 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m79\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 31.71 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m80\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 25.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m81\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 36.80</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Qwen2.5-Omni <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib6\" title=\"\">6</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">58.79 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m82\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 40.78 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m83\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 59.86 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m84\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">54.55</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m85\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 61.93 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m86\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">67.07</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m87\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 58.33 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m88\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 56.70</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">AudioToolAgent-Open</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">\n<span class=\"ltx_text ltx_font_bold\">59.39</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m89\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">45.63</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m90\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">67.34</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m91\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">54.55</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m92\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">70.64</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m93\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 59.76 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m94\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">70.83</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m95\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">61.70</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" rowspan=\"12\">\n<span class=\"ltx_inline-block ltx_align_left\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">MMAU-Pro</span> <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib15\" title=\"\">15</a>]</cite></span>\n<span class=\"ltx_p\">\n<span class=\"ltx_text ltx_font_italic\">Sound <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m96\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Music <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m97\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Speech <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m98\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Sound-Music <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m99\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math></span></span>\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_italic\">Speech-Music <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m100\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Speech-Sound <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m101\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math></span></span>\n<span class=\"ltx_p\">\n<span class=\"ltx_text ltx_font_italic\">Sound-Music-Speech <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m102\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Spatial <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m103\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Voice <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m104\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math></span></span>\n<span class=\"ltx_p\">\n<span class=\"ltx_text ltx_font_italic\">Multi-Audio <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m105\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Open-ended <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m106\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math></span></span>\n<span class=\"ltx_p\">\n<span class=\"ltx_text ltx_font_italic\">Instruction-Following <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m107\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> Average</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"2\"><span class=\"ltx_text ltx_font_italic\">Closed Source</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">GPT4o Audio <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib21\" title=\"\">21</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">44.70 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m108\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 63.10 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m109\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 68.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m110\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 40.40 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m111\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 43.50 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m112\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 62.50 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m113\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 57.10 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m114\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 21.40 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m115\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 57.50 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m116\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 32.60 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m117\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 43.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m118\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 82.50 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m119\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 52.50</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Gemini-2.5 Flash <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib5\" title=\"\">5</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">\n<span class=\"ltx_text ltx_font_bold\">51.90</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m120\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">64.90</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m121\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 73.40 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m122\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">42.80</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m123\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">58.70</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m124\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 61.30 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m125\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 42.80 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m126\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">36.30</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m127\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">71.70</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m128\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 21.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m129\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 67.50 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m130\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">95.10</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m131\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">59.20</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">AudioToolAgent</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">33.14 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m132\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 63.47 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m133\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">73.74</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m134\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 26.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m135\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 50.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m136\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 54.55 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m137\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">57.14</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m138\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 30.15 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m139\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 70.69 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m140\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">57.21</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m141\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">73.31</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m142\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 86.21 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m143\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 57.96</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"2\"><span class=\"ltx_text ltx_font_italic\">Open Source</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Audio-Reasoner <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib27\" title=\"\">27</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">34.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m144\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 50.10 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m145\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 44.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m146\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 26.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m147\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 36.90 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m148\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 43.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m149\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 28.60 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m150\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 20.30 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m151\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 43.40 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m152\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 22.60 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m153\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 38.60 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m154\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 43.40 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m155\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 39.50</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Kimi-Audio <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib8\" title=\"\">8</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">46.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m156\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 57.60 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m157\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 52.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m158\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">46.00</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m159\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">54.30</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m160\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 48.90 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m161\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 42.80 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m162\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">43.70</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m163\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 50.60 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m164\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 17.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m165\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 34.50 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m166\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 42.30 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m167\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 46.60</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Audio Flamingo 3 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib11\" title=\"\">11</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">\n<span class=\"ltx_text ltx_font_bold\">55.90</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m168\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">61.70</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m169\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 58.80 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m170\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 40.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m171\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 41.30 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m172\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 47.70 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m173\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 57.10 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m174\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 26.80 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m175\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 58.60 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m176\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 26.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m177\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 44.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m178\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 33.30 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m179\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 51.70</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Qwen2.5-Omni <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib6\" title=\"\">6</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">47.60 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m180\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 61.50 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m181\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 57.40 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m182\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 40.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m183\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 53.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m184\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">60.20</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m185\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 28.50 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m186\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 41.20 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m187\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 60.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m188\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 24.30 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m189\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 52.30 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m190\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 61.30 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m191\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 52.20</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">AudioToolAgent-Open</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">42.79 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m192\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">64.39</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m193\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">67.90</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m194\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 36.00 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m195\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 45.65 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m196\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 54.55 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m197\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">57.14</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m198\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 33.54 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m199\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">61.72</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m200\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> 23.49 <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m201\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">72.17</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m202\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">64.37</span> <math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m203\" intent=\":literal\"><semantics><mo fence=\"false\" stretchy=\"false\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math> <span class=\"ltx_text ltx_font_bold\">55.68</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "reasoner",
            "multiaudio",
            "source",
            "closed",
            "flamingo",
            "available",
            "gpt4o",
            "mmau",
            "stateoftheart",
            "qwen25omni",
            "benchmark",
            "audioreasoner",
            "speech",
            "gemini",
            "musicspeech",
            "achieves",
            "evaluations",
            "openended",
            "across",
            "voice",
            "all",
            "metrics",
            "copied",
            "from",
            "baseline",
            "open",
            "original",
            "api",
            "audiotoolagent",
            "mmar",
            "results",
            "soundmusic",
            "benchmarks",
            "model",
            "audiotoolagentopen",
            "speechsound",
            "spatial",
            "their",
            "speechmusic",
            "evaluation",
            "andor",
            "dataset",
            "soundspeech",
            "soundmusicspeech",
            "testmini",
            "flash",
            "mmaupro",
            "†selfproposed",
            "kimiaudio",
            "average",
            "instructionfollowing",
            "performance",
            "code",
            "mini",
            "models",
            "omnir1†",
            "gemini25",
            "scores",
            "sound",
            "music",
            "stepaudio",
            "respective",
            "verify",
            "works",
            "pro",
            "comparison",
            "audio"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S4.T1\" title=\"Table 1 &#8227; 4 Results &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> summarizes the results. AudioToolAgent-Open outperforms all open-source models on average across the three benchmarks, including the individual tools it uses. AudioToolAgent outperforms most closed-source models on average, even when some models could not be used as the tools of AudioToolAgent due to no API availability.</p>\n\n",
            "<p class=\"ltx_p\">Performance gains appear most pronounced in the <span class=\"ltx_text ltx_font_italic\">Speech</span> portions of the benchmarks (see Speech columns in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S4.T1\" title=\"Table 1 &#8227; 4 Results &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>). The automatic speech recognition tools in both AudioToolAgent and AudioToolAgent-Open explain this improvement. While other approaches use a single multimodal model trained for both speech recognition and audio understanding, AudioToolAgent invokes ASR models like Whisper <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib13\" title=\"\">13</a>]</cite> and Voxtral <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib12\" title=\"\">12</a>]</cite> for accurate transcription.</p>\n\n",
            "<p class=\"ltx_p\">Our evaluation approach uses existing benchmark results from model authors and benchmark maintainers (see Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S4.T1\" title=\"Table 1 &#8227; 4 Results &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>) rather than reproducing all baseline numbers independently. This decision was made based on practical factors: high inference costs, API availability limitations, and the need for model-specific optimization to achieve peak performance. The unverified entries are marked where applicable.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Large Audio-Language Models (LALMs) perform well on audio understanding tasks but lack multi-step reasoning and tool-calling found in recent Large Language Models (LLMs). This paper presents AudioToolAgent, a framework that coordinates audio-language models as tools via a central LLM agent that accesses tool adapters for audio question answering and speech-to-text. The agent selects tools, asks follow-up questions, and compares outputs for verification. Experiments with MMAU, MMAR, and MMAU-Pro show state-of-the-art accuracy: up to 74.10% on MMAU, 68.80% on MMAR, and 57.96% on MMAU-Pro. Monte Carlo sampling for shapley values across 374 configurations identifies effective agent-tool combinations. The modular design allows integration of new tools and eliminates the use of data and training costs. Code and reproduction materials are available at: <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/GLJS/AudioToolAgent\" title=\"\">https://github.com/GLJS/AudioToolAgent</a>.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "across",
                    "models",
                    "available",
                    "mmaupro",
                    "mmau",
                    "stateoftheart",
                    "code",
                    "audiotoolagent",
                    "mmar"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold ltx_font_italic\">Index Terms<span class=\"ltx_text ltx_font_upright\">&#8212;&#8201;</span></span>\nAudio-Language Models, Agentic Framework, Multi-Modal Audio Understanding, Reasoning, Tool-Calling</p>\n\n",
                "matched_terms": [
                    "models",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Understanding and reasoning about audio is central to human cognition. Recent progress in transferring this capability to machines spans two areas: the advancement of Large Language Models (LLMs) with reasoning and tool-calling capabilities <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib4\" title=\"\">4</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib5\" title=\"\">5</a>]</cite>, and the development of Large Audio-Language Models (LALMs) for tasks such as audio captioning, audio question answering, and speech recognition <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib6\" title=\"\">6</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib7\" title=\"\">7</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib8\" title=\"\">8</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib9\" title=\"\">9</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib10\" title=\"\">10</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib11\" title=\"\">11</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib12\" title=\"\">12</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib13\" title=\"\">13</a>]</cite>.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "models",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While recent LALMs perform well on audio benchmarks <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib15\" title=\"\">15</a>]</cite>, few can call multiple tools <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib10\" title=\"\">10</a>]</cite>, whereas general LLMs excel at reasoning and using external tools but lack direct audio processing. This paper combines these strengths by enabling an LLM agent to use audio models as tools. This approach achieves more adaptive audio understanding than LALMs while maintaining the deeper reasoning capabilities of general LLMs.</p>\n\n",
                "matched_terms": [
                    "models",
                    "benchmarks",
                    "achieves",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This paper introduces <span class=\"ltx_text ltx_font_bold\">AudioToolAgent</span>, a framework that treats audio-language models as tools and uses a central agent to coordinate them. The agent, a text-only LLM, cannot process audio directly. Instead, the LLM receives the audio file path with a question or prompt and possible answers and delegates new instructions to LALMs (tools) to be able to understand the audio. The system prompt of the LLM contains instructions for the agent on how to use the tools. Because the framework reuses pretrained state-of-the-art models, the proposed framework needs no new datasets or training. Researchers can add both new public and local tools without architectural changes.</p>\n\n",
                "matched_terms": [
                    "models",
                    "stateoftheart",
                    "audiotoolagent",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The agent receives an audio input, a question, and answer choices. The agent uses this information to reason about the task, upon which it calls tools to be able to answer the question or prompt. For speech, the agent prioritizes speech-to-text tools to transcribe the audio. For environmental sounds or music, the agent uses general audio models to gather information. AudioToolAgent asks follow-up questions, invokes tools iteratively, compares outputs, and verifies disagreements by continuing to call tools with different inputs to increase reliability. Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> shows an example of the framework in a chatbot.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "models",
                    "music",
                    "audiotoolagent",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">A modular architecture with an agent that coordinates audio-language tools through tool adapters. By utilizing pretrained foundational models without data or finetuning, this provides a cost-effective approach for state-of-the-art performance. Experiments on MMAU <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib14\" title=\"\">14</a>]</cite>, MMAR <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib16\" title=\"\">16</a>]</cite> and MMAR-Pro <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib15\" title=\"\">15</a>]</cite> show that both closed-source and open-source versions of AudioToolAgent outperform prior models in several domains.</p>\n\n",
                "matched_terms": [
                    "performance",
                    "models",
                    "mmau",
                    "stateoftheart",
                    "audiotoolagent",
                    "mmar"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">A benchmark that evaluates the effectiveness of different LLMs for reasoning on audio tasks and a benchmark that evaluates the effectiveness of different audio-language models as tools.</p>\n\n",
                "matched_terms": [
                    "models",
                    "audio",
                    "benchmark"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent advances in large language models (LLMs) have resulted in agents that perform tool calling to solve tasks <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib17\" title=\"\">17</a>]</cite>. This began with GPT-3.5&#8217;s function calling <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib18\" title=\"\">18</a>]</cite> and includes the Model Context Protocol (MCP) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib19\" title=\"\">19</a>]</cite>, which standardizes interactions with external tools. This work uses the ReAct framework <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib20\" title=\"\">20</a>]</cite>. In ReAct, the agent first reasons about the task and then performs actions to solve it. The agent selects appropriate tools to answer the question. After receiving tool responses, the agent decides whether to make additional tool calls or answer the question with the information already gathered.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent developments include large multimodal models that integrate audio processing and agentic capabilities within a single architecture. Models such as Gemini 2.5 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib5\" title=\"\">5</a>]</cite> and GPT-4o <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib21\" title=\"\">21</a>]</cite> handle both audio understanding and speech recognition while performing tool calling. These models can generate audio output, enabling real-time, end-to-end speech-to-speech interactions with tool use. Training these models costs substantial resources, and they remain closed-source, accessible only through API endpoints.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "speech",
                    "models",
                    "gpt4o",
                    "api",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Another relevant work, StepAudio 2 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib10\" title=\"\">10</a>]</cite>, received explicit training for tool calling and benchmarking on four specific tools: audio search with multimodal RAG, date and time retrieval, weather search, and web search. This model processes audio input, performs tool calls, understands audio content, and generates speech output. Training this integrated model consumed 1.356 trillion tokens over 21 days <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib10\" title=\"\">10</a>]</cite>. In contrast, the AudioToolAgent framework eliminates this training cost by coordinating existing pre-trained models.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "model",
                    "models",
                    "stepaudio",
                    "audiotoolagent",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Similarly, other works with the same name include AudioAgent <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib22\" title=\"\">22</a>]</cite>, which uses audio attributes to optimize prompts via a fine-tuned LLM for audio tools, and the Audio-Agent framework <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib23\" title=\"\">23</a>]</cite>, which uses an LLM to orchestrate audio generation and editing.\nThe current work differs by using a text-only agent that delegates audio understanding to specialized tools without fine-tuning. Instead of using fixed classifiers, AudioToolAgent queries multiple interchangeable tools and cross-checks their outputs for verification.</p>\n\n",
                "matched_terms": [
                    "their",
                    "audiotoolagent",
                    "audio",
                    "works"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The agent, a reasoning model, receives an audio file path and task description and selects tools to produce the output. It accesses audio signals only through tools. The agent identifies suitable tool calls for the task, then invokes them through structured tags: <span class=\"ltx_text ltx_font_typewriter\">&lt;tool_call&gt;</span> to initiate a request and <span class=\"ltx_text ltx_font_typewriter\">&lt;/tool_call&gt;</span> to conclude it. Within these tags, the agent specifies the target tool, audio file path, and prompt. Each tool&#8217;s output enters the agent&#8217;s context, enabling it to reason and invoke additional tools as needed. The tool set includes audio understanding and speech recognition tools. Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S1.F2\" title=\"Figure 2 &#8227; 1 Introduction &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> shows a schematic visualization. To prevent runaway loops, each agent can invoke a maximum of 20 tool calls. In AudioToolAgent, the agent typically makes 5-10 calls, depending on the configuration.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "model",
                    "audiotoolagent",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this framework, all tools connect via HTTP API tool adapters for modularity. This includes public endpoints for proprietary models and self-hosted endpoints for open-source models, running on either vLLM <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib24\" title=\"\">24</a>]</cite> or Transformers <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib25\" title=\"\">25</a>]</cite>. To demonstrate the framework&#8217;s versatility, the implementation offers two configurations:</p>\n\n",
                "matched_terms": [
                    "api",
                    "models",
                    "all"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">AudioToolAgent</span>: This configuration uses a proprietary agent and closed-source tools, accessed through public API endpoints to maximize performance. The agent is the GPT5 model <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib4\" title=\"\">4</a>]</cite>, and the tool suite includes GPT-4o <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib21\" title=\"\">21</a>]</cite>, Gemini 2.5 Flash <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib5\" title=\"\">5</a>]</cite>, Voxtral <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib12\" title=\"\">12</a>]</cite>, Qwen2.5 Omni <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib6\" title=\"\">6</a>]</cite>, and Audio Flamingo 3 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib11\" title=\"\">11</a>]</cite>.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "model",
                    "flamingo",
                    "performance",
                    "flash",
                    "gpt4o",
                    "api",
                    "audiotoolagent",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">AudioToolAgent-Open</span>: As the primary model, this configuration uses an open-source agent with high-performing open-source audio tools to balance performance with self-hosting capabilities. The agent is DeepSeek V3.1 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib1\" title=\"\">1</a>]</cite>, and the tool suite includes Whisper <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib13\" title=\"\">13</a>]</cite>, Voxtral <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib12\" title=\"\">12</a>]</cite>, Qwen2.5 Omni <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib6\" title=\"\">6</a>]</cite>, Audio Flamingo 3 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib11\" title=\"\">11</a>]</cite>, and DeSTA 2.5 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib9\" title=\"\">9</a>]</cite>.</p>\n\n",
                "matched_terms": [
                    "model",
                    "audiotoolagentopen",
                    "flamingo",
                    "performance",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The study evaluated AudioToolAgent and AudioToolAgent-Open on three benchmarks: Massive Multi-Task Audio Understanding (MMAU) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib14\" title=\"\">14</a>]</cite>, MMAR <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib16\" title=\"\">16</a>]</cite> and MMAR-Pro <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib15\" title=\"\">15</a>]</cite>. The MMAU benchmark includes 10,000 audio clips for multi-task audio understanding and reasoning, with 1,000 in the test-mini split and 9,000 in the test split. The experiments used only the test-mini split to reduce costs. The MMAR benchmark tests deep reasoning capabilities with 1,000 audio-question-answer triplets requiring multi-step reasoning across modalities. The MMAU-Pro benchmark measures audio intelligence using 5,304 instances (one audio example was broken) containing human expert-generated question-answer pairs across speech, sound, music, and combinations.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "audio",
                    "benchmarks",
                    "audiotoolagentopen",
                    "across",
                    "sound",
                    "music",
                    "testmini",
                    "mmaupro",
                    "mmar",
                    "mmau",
                    "audiotoolagent",
                    "benchmark"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To identify the most effective configuration for AudioToolAgent, an ablation study examined 10% of the MMAU test-mini split (100 examples), analyzing agents and tools separately.</p>\n\n",
                "matched_terms": [
                    "mmau",
                    "testmini",
                    "audiotoolagent"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To evaluate the LLMs capable of tool calling, the experiments used a fixed set of tools - the same tools from the open-source AudioToolAgent configuration (see Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S3.SS1\" title=\"3.1 Framework Overview &#8227; 3 Methodology and Experimental Setup &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">3.1</span></a>). Each evaluation ran five independent tests per agent with different random seeds and reported the mean. This approach accounts for accuracy variations from non-deterministic inference even with fixed seeds, partly due to vendor-recommended decoding defaults such as nonzero temperature. Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S4.F3\" title=\"Figure 3 &#8227; 4.1.1 Agents &#8227; 4.1 Ablation Study &#8227; 4 Results &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> shows the tested tools on the y-axis.</p>\n\n",
                "matched_terms": [
                    "from",
                    "audiotoolagent",
                    "evaluation"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S4.F3\" title=\"Figure 3 &#8227; 4.1.1 Agents &#8227; 4.1 Ablation Study &#8227; 4 Results &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> visualizes the agent ablation. Inspired by Omni-R1 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib26\" title=\"\">26</a>]</cite>, which showed that text-only models perform well on audio reasoning tasks, the black vertical tick on the bar plot shows each LLM&#8217;s performance without audio capabilities, which still scores well on the benchmark. The dots represent individual evaluations, with the horizontal colored bar showing the average across 5 runs.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "evaluations",
                    "across",
                    "models",
                    "scores",
                    "average",
                    "performance",
                    "benchmark"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Deepseek V3.1 outperforms all other LLMs with a mean accuracy of 0.784, followed by Kimi K2 (0.766), Claude Sonnet 4 (0.762) and GPT-5 (0.748). Based on these results, AudioToolAgent-Open uses Deepseek V3.1 and AudioToolAgent uses GPT-5. GPT-5 was chosen over Claude Sonnet 4 because it costs less in the configuration: low settings for reasoning effort and verbosity were maintained to reduce costs.</p>\n\n",
                "matched_terms": [
                    "all",
                    "audiotoolagent",
                    "audiotoolagentopen",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To quantify each tool&#8217;s contribution to system performance, this work estimates Shapley values using a two-stage, Monte Carlo approximation. In the first stage, the method generates multiple sampled permutations of the available tools. For each permutation, the system evaluates performance on the 100 examples from the MMAU subset. In the second stage, the approach calculates the final Shapley values by considering only combinations of two or more tools to determine each tool&#8217;s marginal contribution. The final Shapley value for each tool represents the average of these marginal contributions across all sampled permutations. Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S4.F4\" title=\"Figure 4 &#8227; 4.1.2 Tools &#8227; 4.1 Ablation Study &#8227; 4 Results &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> displays these values. The analysis clusters the tested tools into 4 categories, shown on the y-axis of Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S4.F4\" title=\"Figure 4 &#8227; 4.1.2 Tools &#8227; 4.1 Ablation Study &#8227; 4 Results &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>.</p>\n\n",
                "matched_terms": [
                    "across",
                    "all",
                    "available",
                    "from",
                    "average",
                    "mmau",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Qwen2.5 Omni <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib6\" title=\"\">6</a>]</cite> provides the highest contribution, followed by Audio Flamingo 3 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib11\" title=\"\">11</a>]</cite> and Gemini 2.5 Flash <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib5\" title=\"\">5</a>]</cite>. The top-performing tools were incorporated in the configurations of this work (see Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S3.SS1\" title=\"3.1 Framework Overview &#8227; 3 Methodology and Experimental Setup &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">3.1</span></a>) with two exceptions: Qwen2Audio <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib7\" title=\"\">7</a>]</cite> processes only 30 seconds of audio and audios in benchmarks are often longer, and AudSemThinker <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#bib.bib40\" title=\"\">40</a>]</cite> shares its architecture with Qwen2.5 Omni.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "benchmarks",
                    "flamingo",
                    "flash",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">AudioToolAgent&#8217;s performance depends on its underlying audio tools, creating both opportunities and challenges for future development. When tools produce inaccurate outputs, the agent may propagate these errors. To mitigate this, the agent uses a cross-validation approach, verifying information across multiple tools. By comparing answers to direct questions, the agent reduces reliance on single tool responses. Future work should explore advanced consensus mechanisms and uncertainty quantification to improve robustness against tool errors.</p>\n\n",
                "matched_terms": [
                    "performance",
                    "audio",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">A practical limitation of AudioToolAgent is speed. Using multiple separate tools creates longer processing times than a single audio model. The agent calls tools sequentially and waits for each result, adding overhead. Running AudioToolAgent on separate machines mitigates this issue. Future research should focus on training agents to select optimal tool subsets for specific tasks, improving efficiency.</p>\n\n",
                "matched_terms": [
                    "model",
                    "audiotoolagent",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We tested the framework with web search integration using both DuckDuckGo API and Tavily&#8217;s proprietary search API (see Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02995v1#S4.F4\" title=\"Figure 4 &#8227; 4.1.2 Tools &#8227; 4.1 Ablation Study &#8227; 4 Results &#8227; AudioToolAgent: An Agentic Framework for Audio-Language Models\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>). Ablation studies revealed no consistent improvements, likely because the benchmarks focus on audio content and general information. These benchmarks mostly require historical information and common knowledge facts. Nevertheless, web search integration remains promising for real-world applications where external knowledge retrieval enhances performance. The tests also included the ability to extract parts of the audio and use them as input to the tools, but this did not improve performance. Future work should explore this approach.\nExpanding the tool ecosystem to include audio retrieval, audio generation, and analysis tools offers another valuable research direction.</p>\n\n",
                "matched_terms": [
                    "performance",
                    "api",
                    "benchmarks",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This paper introduced AudioToolAgent, a framework for multimodal audio understanding and reasoning where a central agent coordinates audio-language models as tools. The combination of GPT-4o, Gemini 2.5 Flash, Voxtral, Qwen2.5 Omni and Audio Flamingo 3 orchestrated by GPT-5 outperforms prior models on the MMAU, MMAR and MMAR-Pro benchmarks.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "audio",
                    "benchmarks",
                    "flamingo",
                    "models",
                    "flash",
                    "gpt4o",
                    "mmau",
                    "audiotoolagent",
                    "mmar"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This framework establishes a new paradigm that combines the strengths of ALMs and LLMs. The ablation studies identified Qwen2.5 Omni and AudioFlamingo 3 as the most effective audio tools. Among LLMs, DeepSeek V3.1 and Kimi K2 demonstrated superior performance as orchestrating agents. This hybrid approach combines the audio processing of ALMs with the reasoning strengths of LLMs, creating a more flexible and powerful system than either model type could achieve alone.</p>\n\n",
                "matched_terms": [
                    "performance",
                    "model",
                    "audio"
                ]
            }
        ]
    }
}