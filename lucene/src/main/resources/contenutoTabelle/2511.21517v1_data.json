{
    "p3": {
        "source_file": "Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation",
        "caption": "",
        "body": "Lina Conti,\nDennis Fucci,\nMarco Gaido,\nMatteo Negri,\n\n\n\nGuillaume Wisniewski,\nLuisa Bentivogli\n\n\n\n\n\nFondazione Bruno Kessler, Italy\n\n\n{lvarellaconti,dfucci,mgaido,negri,bentivo}@fbk.eu\n\n\nUniversity of Trento, Italy\n\n\nLaboratoire de Linguistique Formelle, Université Paris Cité, CNRS, Paris, France\n\n\nguillaume.wisniewski@u-paris.fr",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_top\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">\nLina Conti,\nDennis Fucci,\nMarco Gaido,\nMatteo Negri,</span></th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">Guillaume Wisniewski</span>,\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">Luisa Bentivogli</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\">Fondazione Bruno Kessler, Italy</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\">{lvarellaconti,dfucci,mgaido,negri,bentivo}@fbk.eu</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\">University of Trento, Italy</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\">Laboratoire de Linguistique Formelle, Universit&#233; Paris Cit&#233;, CNRS, Paris, France</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\">guillaume.wisniewski@u-paris.fr</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "lvarellacontidfuccimgaidonegribentivofbkeu",
            "fondazione",
            "trento",
            "guillaume",
            "marco",
            "luisa",
            "france",
            "guillaumewisniewskiuparisfr",
            "paris",
            "gaido",
            "université",
            "conti",
            "italy",
            "negri",
            "laboratoire",
            "kessler",
            "university",
            "cnrs",
            "bentivogli",
            "bruno",
            "dennis",
            "fucci",
            "wisniewski",
            "lina",
            "matteo",
            "linguistique",
            "cité",
            "formelle"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": []
    },
    "S6.T1.st1": {
        "source_file": "Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation",
        "caption": "(a) Spanish",
        "body": "More Freq.\nLess Freq.\n\n\n\n\nF\n24\n173\n\n\nM\n221\n22",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">More Freq.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Less Freq.</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">F</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">24</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">173</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">M</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">221</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">22</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "less",
            "freq",
            "more",
            "spanish"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6.T1\" title=\"Table 1 &#8227; 6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> shows that the Transformer model does not simply replicate training data patterns when assigning gender.\nThe table categorizes each predicted gendered term by whether the predicted gender (F or M) is the more or less prevalent form in the training data for that specific term. If models followed the heuristic of generating each term in its most frequent training data gender, predictions should consistently fall in the &#8220;More Freq.&#8221; column.\nInstead, the model frequently predicts genders that are less prevalent for that specific term: 87.8&#8201;% of feminine generated terms in Spanish (173 of 197), 85.5&#8201;% in French (130 of 152), and 92.1&#8201;% in Italian (140 of&#160;152) correspond to the less prevalent form in the training data. For masculine predictions, the model does tend to predict the more prevalent form (221 of 243 in Spanish, 187 of 203 in French, 192 of 205 in Italian). However, given the overall masculine skew, this reflects the general pattern in the training data rather than term-specific memorization. The Conformers show a similar pattern: the distribution of predictions relative to prevalence resembles Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6.T1\" title=\"Table 1 &#8227; 6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, although with slightly more predictions aligning with the more prevalent form.\nCrucially, none of the models closely follow term-by-term gender associations from the training data.</p>\n\n",
                "matched_terms": [
                    "less",
                    "more",
                    "spanish"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Beyond architectural differences, models&#8217; reliance on input features also differs between feminine and masculine predictions. For the Transformer, the percentage of examples whose gender prediction we can flip by occluding salient features in the input spectrogram is 60.8&#8201;% vs. 19.2&#8201;% for Spanish, 66.7&#8201;% vs. 24.9&#8201;% for French, and 52.2&#8201;% vs. 21.1&#8201;% for Italian (feminine vs. masculine respectively). The Conformers show the same pattern with a narrower gap (es: 47.5&#8201;% vs. 33.6&#8201;%; fr: 51.0&#8201;% vs. 37.6&#8201;%; it: 44.7&#8201;% vs. 41.3&#8201;%). This asymmetry suggests that the mechanism of accessing acoustic gender cues through first-person pronouns plays a more critical role for feminine predictions, while masculine predictions rely more heavily on the model&#8217;s internal biases. This asymmetry aligns with prior work showing that language models and MT systems use masculine as a default, requiring strong feminine signals to generate feminine forms <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">jumelet2019analysing</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">manna-etal-2025-paying</span></cite>, which they slowly and imperfectly learn to use during training <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">savoldi2022dynamics</span></cite>.</p>\n\n",
                "matched_terms": [
                    "more",
                    "spanish"
                ]
            }
        ]
    },
    "S6.T1.st2": {
        "source_file": "Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation",
        "caption": "(b) French",
        "body": "More Freq.\nLess Freq.\n\n\n\n\nF\n22\n130\n\n\nM\n187\n16",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">More Freq.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Less Freq.</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">F</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">22</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">130</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">M</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">187</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">16</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "french",
            "less",
            "freq",
            "more"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6.T1\" title=\"Table 1 &#8227; 6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> shows that the Transformer model does not simply replicate training data patterns when assigning gender.\nThe table categorizes each predicted gendered term by whether the predicted gender (F or M) is the more or less prevalent form in the training data for that specific term. If models followed the heuristic of generating each term in its most frequent training data gender, predictions should consistently fall in the &#8220;More Freq.&#8221; column.\nInstead, the model frequently predicts genders that are less prevalent for that specific term: 87.8&#8201;% of feminine generated terms in Spanish (173 of 197), 85.5&#8201;% in French (130 of 152), and 92.1&#8201;% in Italian (140 of&#160;152) correspond to the less prevalent form in the training data. For masculine predictions, the model does tend to predict the more prevalent form (221 of 243 in Spanish, 187 of 203 in French, 192 of 205 in Italian). However, given the overall masculine skew, this reflects the general pattern in the training data rather than term-specific memorization. The Conformers show a similar pattern: the distribution of predictions relative to prevalence resembles Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6.T1\" title=\"Table 1 &#8227; 6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, although with slightly more predictions aligning with the more prevalent form.\nCrucially, none of the models closely follow term-by-term gender associations from the training data.</p>\n\n",
                "matched_terms": [
                    "french",
                    "less",
                    "more"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Beyond architectural differences, models&#8217; reliance on input features also differs between feminine and masculine predictions. For the Transformer, the percentage of examples whose gender prediction we can flip by occluding salient features in the input spectrogram is 60.8&#8201;% vs. 19.2&#8201;% for Spanish, 66.7&#8201;% vs. 24.9&#8201;% for French, and 52.2&#8201;% vs. 21.1&#8201;% for Italian (feminine vs. masculine respectively). The Conformers show the same pattern with a narrower gap (es: 47.5&#8201;% vs. 33.6&#8201;%; fr: 51.0&#8201;% vs. 37.6&#8201;%; it: 44.7&#8201;% vs. 41.3&#8201;%). This asymmetry suggests that the mechanism of accessing acoustic gender cues through first-person pronouns plays a more critical role for feminine predictions, while masculine predictions rely more heavily on the model&#8217;s internal biases. This asymmetry aligns with prior work showing that language models and MT systems use masculine as a default, requiring strong feminine signals to generate feminine forms <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">jumelet2019analysing</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">manna-etal-2025-paying</span></cite>, which they slowly and imperfectly learn to use during training <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">savoldi2022dynamics</span></cite>.</p>\n\n",
                "matched_terms": [
                    "french",
                    "more"
                ]
            }
        ]
    },
    "S6.T1.st3": {
        "source_file": "Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation",
        "caption": "(c) Italian",
        "body": "More Freq.\nLess Freq.\n\n\n\n\nF\n12\n140\n\n\nM\n192\n13",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">More Freq.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Less Freq.</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">F</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">12</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">140</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">M</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">192</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">13</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "italian",
            "less",
            "freq",
            "more"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6.T1\" title=\"Table 1 &#8227; 6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> shows that the Transformer model does not simply replicate training data patterns when assigning gender.\nThe table categorizes each predicted gendered term by whether the predicted gender (F or M) is the more or less prevalent form in the training data for that specific term. If models followed the heuristic of generating each term in its most frequent training data gender, predictions should consistently fall in the &#8220;More Freq.&#8221; column.\nInstead, the model frequently predicts genders that are less prevalent for that specific term: 87.8&#8201;% of feminine generated terms in Spanish (173 of 197), 85.5&#8201;% in French (130 of 152), and 92.1&#8201;% in Italian (140 of&#160;152) correspond to the less prevalent form in the training data. For masculine predictions, the model does tend to predict the more prevalent form (221 of 243 in Spanish, 187 of 203 in French, 192 of 205 in Italian). However, given the overall masculine skew, this reflects the general pattern in the training data rather than term-specific memorization. The Conformers show a similar pattern: the distribution of predictions relative to prevalence resembles Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6.T1\" title=\"Table 1 &#8227; 6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, although with slightly more predictions aligning with the more prevalent form.\nCrucially, none of the models closely follow term-by-term gender associations from the training data.</p>\n\n",
                "matched_terms": [
                    "italian",
                    "less",
                    "more"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Beyond architectural differences, models&#8217; reliance on input features also differs between feminine and masculine predictions. For the Transformer, the percentage of examples whose gender prediction we can flip by occluding salient features in the input spectrogram is 60.8&#8201;% vs. 19.2&#8201;% for Spanish, 66.7&#8201;% vs. 24.9&#8201;% for French, and 52.2&#8201;% vs. 21.1&#8201;% for Italian (feminine vs. masculine respectively). The Conformers show the same pattern with a narrower gap (es: 47.5&#8201;% vs. 33.6&#8201;%; fr: 51.0&#8201;% vs. 37.6&#8201;%; it: 44.7&#8201;% vs. 41.3&#8201;%). This asymmetry suggests that the mechanism of accessing acoustic gender cues through first-person pronouns plays a more critical role for feminine predictions, while masculine predictions rely more heavily on the model&#8217;s internal biases. This asymmetry aligns with prior work showing that language models and MT systems use masculine as a default, requiring strong feminine signals to generate feminine forms <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">jumelet2019analysing</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">manna-etal-2025-paying</span></cite>, which they slowly and imperfectly learn to use during training <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">savoldi2022dynamics</span></cite>.</p>\n\n",
                "matched_terms": [
                    "italian",
                    "more"
                ]
            }
        ]
    },
    "S7.T2.st1": {
        "source_file": "Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation",
        "caption": "(a) Spanish",
        "body": "Higher Prob.\nLower Prob.\n\n\n\n\nF\n52\n145\n\n\nM\n225\n18",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Higher Prob.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Lower Prob.</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">F</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">52</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">145</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">M</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">225</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">18</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "lower",
            "prob",
            "higher",
            "spanish"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Pitch is the perceptual correlate of the fundamental frequency F<sub class=\"ltx_sub\">0</sub> <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">dan2009speech</span></cite>: utterances with higher F<sub class=\"ltx_sub\">0</sub> sound higher pitched and more feminine, whereas male speech typically has lower F<sub class=\"ltx_sub\">0</sub> <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">simpson2009phonetic</span></cite>. To determine whether the model relies on pitch, we examine the intensity with which the pitch region (80-350&#8201;Hz, where the fundamental frequency lies) is highlighted in our heatmaps. We aggregate each gender term&#8217;s explanation by taking the max score for each frequency bin over the time dimension, then average across all gender terms.</p>\n\n",
                "matched_terms": [
                    "lower",
                    "higher"
                ]
            }
        ]
    },
    "S7.T2.st2": {
        "source_file": "Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation",
        "caption": "(b) French",
        "body": "Higher Prob.\nLower Prob.\n\n\n\n\nF\n33\n119\n\n\nM\n195\n8",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Higher Prob.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Lower Prob.</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">F</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">33</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">119</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">M</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">195</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">8</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "french",
            "lower",
            "prob",
            "higher"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Pitch is the perceptual correlate of the fundamental frequency F<sub class=\"ltx_sub\">0</sub> <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">dan2009speech</span></cite>: utterances with higher F<sub class=\"ltx_sub\">0</sub> sound higher pitched and more feminine, whereas male speech typically has lower F<sub class=\"ltx_sub\">0</sub> <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">simpson2009phonetic</span></cite>. To determine whether the model relies on pitch, we examine the intensity with which the pitch region (80-350&#8201;Hz, where the fundamental frequency lies) is highlighted in our heatmaps. We aggregate each gender term&#8217;s explanation by taking the max score for each frequency bin over the time dimension, then average across all gender terms.</p>\n\n",
                "matched_terms": [
                    "lower",
                    "higher"
                ]
            }
        ]
    },
    "S7.T2.st3": {
        "source_file": "Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation",
        "caption": "(c) Italian",
        "body": "Higher Prob.\nLower Prob.\n\n\n\n\nF\n46\n106\n\n\nM\n195\n10",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Higher Prob.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Lower Prob.</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">F</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">46</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">106</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">M</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">195</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">10</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "italian",
            "lower",
            "prob",
            "higher"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Pitch is the perceptual correlate of the fundamental frequency F<sub class=\"ltx_sub\">0</sub> <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">dan2009speech</span></cite>: utterances with higher F<sub class=\"ltx_sub\">0</sub> sound higher pitched and more feminine, whereas male speech typically has lower F<sub class=\"ltx_sub\">0</sub> <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">simpson2009phonetic</span></cite>. To determine whether the model relies on pitch, we examine the intensity with which the pitch region (80-350&#8201;Hz, where the fundamental frequency lies) is highlighted in our heatmaps. We aggregate each gender term&#8217;s explanation by taking the max score for each frequency bin over the time dimension, then average across all gender terms.</p>\n\n",
                "matched_terms": [
                    "lower",
                    "higher"
                ]
            }
        ]
    },
    "S8.T3": {
        "source_file": "Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation",
        "caption": "Table 3: Percentage of examples where the top-scoring source word is “I” or a self-referential word, for examples that flip and for all examples. Results for the Transformer model wang2020fairseq.",
        "body": "‘I’\n\nSelf-referential\n\n\n\nes\nfr\nit\nes\nfr\nit\n\n\n\n\nFlip\n16.9\n21.7\n25.8\n23.7\n28.0\n35.1\n\n\nAll\n25.4\n28.4\n33.3\n32.5\n35.2\n42.0",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"3\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">&#8216;</span><span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">I</span><span class=\"ltx_text\" style=\"font-size:90%;\">&#8217;</span>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"3\"><span class=\"ltx_text\" style=\"font-size:90%;\">Self-referential</span></th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">es</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">fr</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">it</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">es</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">fr</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">it</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Flip</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">16.9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">21.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">25.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">23.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">28.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">35.1</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">All</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">25.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">28.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">33.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">32.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">35.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">42.0</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "model",
            "flip",
            "source",
            "“i”",
            "selfreferential",
            "all",
            "percentage",
            "‘i’",
            "topscoring",
            "where",
            "examples",
            "word",
            "transformer",
            "wang2020fairseq",
            "results"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Analyzing which source words drive gender assignment reveals a surprising pattern: models rely primarily on first-person pronouns and determiners that refer to the speaker.\nManual investigation of the contrastive heatmaps has revealed that &#8220;<span class=\"ltx_text ltx_font_italic\">I</span>&#8221; is the word most frequently highlighted to explain gender choice. To validate this observation quantitatively, we extract word-level scores from the spectrogram heatmaps by using Gentle<span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>https://github.com/strob/gentle</span></span></span> to obtain each source word&#8217;s time range and selecting the highest feature score within that range as the word&#8217;s score. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.T3\" title=\"Table 3 &#8227; 8.2. Time Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> shows that, for the Transformer model, &#8220;<span class=\"ltx_text ltx_font_italic\">I</span>&#8221; is the top-scoring word in 16.9&#8211;25.8&#8201;% of examples, depending on the language. Including other self-referential expressions (&#8220;<span class=\"ltx_text ltx_font_italic\">I</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">I&#8217;d</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">I&#8217;ve</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">I&#8217;m</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">my</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">me</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">myself</span>&#8221;) raises these percentages to 23.7&#8211;35.1&#8201;%.\nThese percentages are even higher when considering all examples in our dataset rather than just those that flip (second row of Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.T3\" title=\"Table 3 &#8227; 8.2. Time Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>).\nBesides these first-person words, Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.T4\" title=\"Table 4 &#8227; 8.2. Time Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> shows that words like &#8220;<span class=\"ltx_text ltx_font_italic\">and</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">was</span>&#8221;, and &#8220;<span class=\"ltx_text ltx_font_italic\">when</span>&#8221; also frequently receive high attribution scores. However, manual inspection reveals these words appear next to &#8220;<span class=\"ltx_text ltx_font_italic\">I</span>&#8221; in the source sentence (&#8220;<span class=\"ltx_text ltx_font_italic\">and I&#8230;</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">I was&#8230;</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">when I&#8230;</span>&#8221;) and likely score highest due to imprecisions in Gentle&#8217;s word-level alignments, suggesting the actual prevalence of first-person words is even greater.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Unlike text, speech conveys information about the speaker, such as gender, through acoustic cues like pitch. This gives rise to modality-specific bias concerns.\nFor example, in speech translation (ST), when translating from languages with notional gender, such as English, into languages where gender-ambiguous terms referring to the speaker are assigned grammatical gender, the speaker&#8217;s vocal characteristics may play a role in gender assignment.\nThis risks misgendering speakers&#8212;whether through masculine defaults or vocal-based assumptions&#8212;yet how ST models make these decisions remains poorly understood.\nWe investigate the mechanisms ST models use to assign gender to speaker-referring terms across three language pairs (enes/fr/it), examining how training data patterns, internal language model (ILM) biases, and acoustic information interact. We find that models do not simply replicate term-specific gender associations from training data, but learn broader patterns of masculine prevalence. While the ILM exhibits strong masculine bias, models can override these preferences based on acoustic input. Using contrastive feature attribution on spectrograms, we reveal that the model with higher gender accuracy relies on a previously unknown mechanism: using first-person pronouns to link gendered terms back to the speaker, accessing gender information distributed across the frequency spectrum rather than concentrated in pitch.\n\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>\n<span class=\"ltx_text ltx_font_bold\">Keywords:&#8201;</span>gender bias, speech translation, interpretability, XAI</p>\n\n",
                "matched_terms": [
                    "model",
                    "where"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To investigate the mechanisms ST models use to assign gender to speaker-referring terms, we start from the common assumption that attributes gender bias to training data imbalances <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">tatman2017gender</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">garnerin2019gender</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">iluz-etal-2023-exploring</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mastromichalakis2025assumed</span></cite>. This leads to our first research question: (i) <span class=\"ltx_text ltx_font_bold\">What is the influence of gender associations learned from the training data?</span> We address this by comparing model predictions with gender frequencies in the training corpus (&#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6\" title=\"6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>). Finding that models do not simply replicate term-specific patterns motivates us to investigate the broader factors driving gender assignment in ST models.\nFor this, we conceptually divide the ST model into two components: the encoder, which processes the input audio and may extract acoustic cues from it, and the decoder, which autoregressively predicts the next token based on both the encoder&#8217;s representation of the audio and the previously generated tokens.\nFirst, we study the decoder&#8217;s contribution by removing encoder information, thus isolating the ST system&#8217;s internal language model (ILM) <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">variani2020hybrid</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">meng2021internal</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">zeineldeen2021investigating</span></cite>. Through this, we aim to answer the question (ii) <span class=\"ltx_text ltx_font_bold\">What is the impact of the model&#8217;s learned knowledge of the target language and a priori assumptions about gender on predictions?</span> Following this analysis (&#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S7\" title=\"7. Internal Language Model Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">7</span></a>), we turn to assessing the role of the source audio: (iii) <span class=\"ltx_text ltx_font_bold\">What aspects of the input audio does the model use to assign gender to speaker-referring terms?</span> Does it rely primarily on pitch, a key acoustic correlate of perceived gender? We study this with contrastive feature attribution over input spectrograms (&#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8\" title=\"8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>).</p>\n\n",
                "matched_terms": [
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"\\#w\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m3\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">#</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">\\#w</annotation></semantics></math> denotes the number of occurrences of word form <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m4\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> in the training data.\nWe then compare the prevalence of term <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m5\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> in gender <math alttext=\"g_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m6\" intent=\":literal\"><semantics><msub><mi>g</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">g_{1}</annotation></semantics></math> with the model&#8217;s preference for that gender when generating <math alttext=\"w_{g_{1}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m7\" intent=\":literal\"><semantics><msub><mi>w</mi><msub><mi>g</mi><mn>1</mn></msub></msub><annotation encoding=\"application/x-tex\">w_{g_{1}}</annotation></semantics></math>. We quantify this preference by computing the relative probabilities between gendered alternatives:</p>\n\n",
                "matched_terms": [
                    "word",
                    "where"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"p(w)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m8\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">p(w)</annotation></semantics></math> is the probability assigned by a given model to word <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m9\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> in the translation hypothesis.\nThis can be calculated as either the predicted gender preference (comparing the generated form against its ungenerated alternative) or the masculine preference (comparing masculine versus feminine forms regardless of which was generated).\nBy comparing prevalences with the model&#8217;s gender preferences, we can distinguish predictions that replicate term-specific training patterns (where the higher-probability gender matches the more prevalent one in training data) from those based on acoustic or content-based source information, or other sources of bias.</p>\n\n",
                "matched_terms": [
                    "word",
                    "model",
                    "where",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While training data patterns provide one source of gender bias, the model&#8217;s entrenched biases encompass more than only term-specific associations.\nThe decoder&#8217;s behavior also reflects its learned understanding of target language structure, general patterns of gender marking, and how previously generated tokens constrain subsequent predictions. As the decoder autoregressively predicts tokens based on both encoder input and previously generated tokens, it develops these broader linguistic patterns, forming an internal language model.</p>\n\n",
                "matched_terms": [
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To capture all aspects of these ingrained preferences that exist independently of the source audio, we analyze the ILM. Methods for its estimation have initially been developed for domain adaptation in ASR models <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">variani2020hybrid</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">meng2021internal</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">zeineldeen2021investigating</span></cite>.\nWe adopt the ILM estimation method of <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">variani2020hybrid</span></cite> and <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">meng2021internal</span></cite>, which replaces the encoder output with a dummy zero vector and has been shown to perform on par with more complex methods <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">zeineldeen2021investigating</span></cite>.\nWhile <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">fucci2023integrating</span></cite> used the ILM to nudge ST models toward specific gender forms, here we analyze it to understand the decoder&#8217;s inherent biases.</p>\n\n",
                "matched_terms": [
                    "all",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Understanding how models use input audio requires dedicated interpretability methods. Existing approaches for speech-to-text models <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">trinh2020directly</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">markertvisualizing</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mohebbi2023homophone</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">wu2023explanations</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">fucci2024spes</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">wu2024can</span></cite> primarily use perturbation techniques that mask input portions and measure the effect on model output.\nHowever, these methods generate holistic explanations that highlight features relevant for all aspects of word generation. Since our goal is to identify which input features drive gender assignment specifically, we employ the contrastive feature attribution method of <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">conti2025unheard</span></cite>.</p>\n\n",
                "matched_terms": [
                    "word",
                    "all",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Following <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">conti2025unheard</span></cite>, we validate that the highlighted features are causally involved in gender assignment by testing whether occluding them changes the model&#8217;s gender prediction. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S4.F1\" title=\"Figure 1 &#8227; 4.3. Feature Attribution &#8227; 4. Method &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>.c shows the top 2&#8201;% of salient features that, when masked, successfully flip the prediction in this example.\n<span class=\"ltx_text\" style=\"--ltx-fg-color:#000000;\">By occluding 1&#8211;20&#8201;% of the most salient features, we can flip the predicted gender in 37&#8211;47&#8201;% of examples across languages and models. </span>\nWe focus our analysis on such flipped examples, where causal links between input features and gender assignment are established.\nFrom these validated explanations, we can analyze which regions of the input spectrogram drive gender assignment: along the frequency dimension to identify relevant acoustic features, and along the time dimension to identify relevant words.</p>\n\n",
                "matched_terms": [
                    "examples",
                    "flip",
                    "where"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use MuST-SHE <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">bentivogli-etal-2020-gender</span></cite>, a benchmark containing annotations for gender-neutral English terms in natural speech that require gender marking when translated to Spanish, French, or Italian.\nWe focus on the subset containing terms referring to the speaker, as these are cases where acoustic gender cues could influence gender assignment. Unlike sentences with gendered pronouns like &#8220;<span class=\"ltx_text ltx_font_italic\">She is a student</span>,&#8221; where gender is explicitly marked in the source, speaker-referential sentences like &#8220;<span class=\"ltx_text ltx_font_italic\">I am a student</span>&#8221; contain no linguistic gender information, making acoustic cues potentially relevant.\nFor each term, the dataset provides correct and incorrect gender translations, e.g., &#8220;<span class=\"ltx_text ltx_font_italic\">diventata</span>&#8221;<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">F</span></sup> vs. &#8220;<span class=\"ltx_text ltx_font_italic\">diventato</span>&#8221;<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">M</span></sup> as Italian translations of &#8220;<span class=\"ltx_text ltx_font_italic\">become</span>,&#8221; which we use as contrastive pairs for our analysis. Following <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">savoldi-etal-2022-morphosyntactic</span></cite>, we exclude gender articles, as their high frequency in both genders across sentences makes it difficult to identify instances specifically referring to the speaker. We analyze only terms where the ST model generates one of the MuST-SHE annotated forms. Depending on the model used to translate, this yields between 309 and 453 gender terms per target language.</p>\n\n",
                "matched_terms": [
                    "model",
                    "where",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We select models trained exclusively on a single open-source dataset to enable our training data analysis in &#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6\" title=\"6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>. We therefore focus on two model architectures trained on MuST-C <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cattoni2021must</span></cite>: the multilingual Transformer encoder-decoder model by <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">wang2020fairseq</span></cite>, and the monolingual Conformer encoder-Transformer decoder models from <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">papi2024good</span></cite>. More recent ST systems and\nspeech-enhanced large language models are typically trained on massive datasets that are not publicly released, making it difficult to establish connections between training data patterns and model behavior.</p>\n\n",
                "matched_terms": [
                    "wang2020fairseq",
                    "model",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We primarily focus on the Transformer model for our analyses, as it demonstrates strong gender accuracy<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>The proportion of correct gender realizations among terms where the model generates one of the MuST-SHE annotated forms <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">gaido-etal-2020-breeding</span></cite>.</span></span></span>\nfor speaker-referential terms: 77.1&#8201;% to 80.6&#8201;% for feminine terms and 91.4&#8201;% to 94.4&#8201;% for masculine terms across target languages.\nThis suggests that the Transformer is well positioned to leverage vocal cues for gender disambiguation, a phenomenon we aim to investigate further, both in terms of relevant features and its relation to the ILM.\nBy comparing these results with Conformer models, which achieve lower accuracy (39.2-49.8% for feminine terms and 72.5-76.7% for masculine terms across the three language pairs), we assess whether gender assignment strategies are model-dependent.\nThese models provide architectural (Transformer vs. Conformer encoders) and scope (multilingual vs. monolingual) diversity, enabling us to examine how gender assignment strategies vary across different ST system configurations.</p>\n\n",
                "matched_terms": [
                    "transformer",
                    "model",
                    "results",
                    "where"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The first thing we observe is that the training data shows a clear masculine skew for the gender terms we study.\nIf we compute the average prevalence in the training data of the masculine form over the feminine one for all speaker-referring gendered terms in the translation hypotheses of the Transformer model, this average ranges from 0.68 to 0.71 depending on the languages, with nearly identical values for the Conformer models.</p>\n\n",
                "matched_terms": [
                    "all",
                    "model",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6.T1\" title=\"Table 1 &#8227; 6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> shows that the Transformer model does not simply replicate training data patterns when assigning gender.\nThe table categorizes each predicted gendered term by whether the predicted gender (F or M) is the more or less prevalent form in the training data for that specific term. If models followed the heuristic of generating each term in its most frequent training data gender, predictions should consistently fall in the &#8220;More Freq.&#8221; column.\nInstead, the model frequently predicts genders that are less prevalent for that specific term: 87.8&#8201;% of feminine generated terms in Spanish (173 of 197), 85.5&#8201;% in French (130 of 152), and 92.1&#8201;% in Italian (140 of&#160;152) correspond to the less prevalent form in the training data. For masculine predictions, the model does tend to predict the more prevalent form (221 of 243 in Spanish, 187 of 203 in French, 192 of 205 in Italian). However, given the overall masculine skew, this reflects the general pattern in the training data rather than term-specific memorization. The Conformers show a similar pattern: the distribution of predictions relative to prevalence resembles Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6.T1\" title=\"Table 1 &#8227; 6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, although with slightly more predictions aligning with the more prevalent form.\nCrucially, none of the models closely follow term-by-term gender associations from the training data.</p>\n\n",
                "matched_terms": [
                    "model",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In summary, our results challenge the assumption that gender bias in ST simply reflects the training data distribution <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">tatman2017gender</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">garnerin2019gender</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">iluz-etal-2023-exploring</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mastromichalakis2025assumed</span></cite>.\nOur findings align with <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">conti2023using</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">elghazaly2025exploring</span></cite>, suggesting that gender bias cannot be exclusively reduced to training data imbalances.\nThe data&#8217;s masculine skew clearly influences model behavior, but not through simple memorization&#8212;rather, models internalize broader biases that we investigate through the ILM.</p>\n\n",
                "matched_terms": [
                    "model",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While the training data analysis has revealed that models do not simply memorize term-specific associations, gender assignment must still be driven by some combination of learned decoder preferences and input audio features.\nWe first investigate whether the decoder has internalized broader biases beyond individual term associations by addressing our second research question: &#8220;What is the impact of the model&#8217;s learned knowledge of the target language and a priori assumptions about gender on predictions?&#8221;\nThe ILM analysis isolates these entrenched preferences by removing encoder information, measuring what the decoder learned independently of source audio. Comparing ILM with full model predictions then reveals when and how the audio input overrides these biases.</p>\n\n",
                "matched_terms": [
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The ILM reflects and amplifies the masculine skew observed in the training data. Averaging over all gender terms, the ILM&#8217;s preference for masculine over feminine ranges from 0.74 to 0.81 for the Transformer, depending on language&#8212;higher than the training data prevalence of 0.68&#8211;0.71.\nWhen we separate by the gender that is ultimately generated by the full model, the ILM&#8217;s masculine preference is 0.85&#8211;0.88 for masculine predictions and 0.58&#8211;0.71 for feminine ones (always above 0.5, even when generating feminine forms).\nFor the Conformer models, average masculine preference is 0.63&#8211;0.64 (0.71&#8211;0.74 for masculine predictions, 0.48&#8211;0.49 for feminine ones). While the Conformers&#8217; masculine preference drops just below 0.5 for feminine predictions, for masculine ones it remains well above 0.5, suggesting some masculine bias, though weaker than for the Transformer.</p>\n\n",
                "matched_terms": [
                    "all",
                    "model",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">However, the full model frequently overrides these entrenched biases. In the example in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S4.F1\" title=\"Figure 1 &#8227; 4.3. Feature Attribution &#8227; 4. Method &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, the prevalence in training data for masculine &#8220;<span class=\"ltx_text ltx_font_italic\">diventato</span>&#8221; is 0.57, and the ILM preference is 0.85, yet the full model&#8217;s preference for the predicted feminine form &#8220;<span class=\"ltx_text ltx_font_italic\">diventata</span>&#8221; is 0.99, illustrating how acoustic input can supersede learned biases and training data statistics.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S7.T2\" title=\"Table 2 &#8227; 7. Internal Language Model Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> shows this is common: the Transformer frequently predicts genders to which the ILM assigns lower probability, particularly for feminine predictions. Instead, the Conformers seem to rely more on their ILM: the Pearson correlation between ILM and full model masculine preference is strong for Conformers (es: 0.65; fr: 0.62; it: 0.62), but weak to moderate for the Transformer (es: 0.45; fr: 0.38; it: 0.47).</p>\n\n",
                "matched_terms": [
                    "model",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section has shown that the ILM exhibits a masculine-as-norm bias across our models, but ST systems vary in how much they rely on these entrenched preferences versus input audio. The Transformer&#8217;s ILM is strongly biased toward masculine, yet the full model frequently overrides these preferences based on acoustic information. The Conformers show weaker ILM masculine bias but rely more on it, struggling to leverage source audio effectively. This analysis demonstrates that ST models combine acoustic gender cues with language model preferences to varying degrees.\nThese findings demonstrate that acoustic input can play a substantial role in gender assignment, motivating us to investigate which specific aspects of the audio our models exploit for this.</p>\n\n",
                "matched_terms": [
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section addresses our third research question: &#8220;What aspects of the input audio does the model use to assign gender to terms referring to the speaker?&#8221;\nFor this, we apply the feature attribution method from &#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S4.SS3\" title=\"4.3. Feature Attribution &#8227; 4. Method &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">4.3</span></a>.\nOccluding 1&#8211;20&#8201;% of the most salient features highlighted by the saliency map flips the predicted gender in 40.7&#8201;% of Spanish examples, 46.8&#8201;% of French examples, and 37.0&#8201;% of Italian examples for the Transformer model, with comparable rates for the Conformers.\nFor these flipped examples, we have a guarantee that the highlighted features are causally involved in gender assignment, since if we occlude them, the model&#8217;s prediction changes.\nWe analyze these saliency maps to identify which words and acoustic cues in the source audio influence gender assignment.</p>\n\n",
                "matched_terms": [
                    "transformer",
                    "examples",
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Pitch is the perceptual correlate of the fundamental frequency F<sub class=\"ltx_sub\">0</sub> <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">dan2009speech</span></cite>: utterances with higher F<sub class=\"ltx_sub\">0</sub> sound higher pitched and more feminine, whereas male speech typically has lower F<sub class=\"ltx_sub\">0</sub> <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">simpson2009phonetic</span></cite>. To determine whether the model relies on pitch, we examine the intensity with which the pitch region (80-350&#8201;Hz, where the fundamental frequency lies) is highlighted in our heatmaps. We aggregate each gender term&#8217;s explanation by taking the max score for each frequency bin over the time dimension, then average across all gender terms.</p>\n\n",
                "matched_terms": [
                    "all",
                    "model",
                    "where"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Surprisingly, the pitch range does not show the highest scores, suggesting it is not the most important region driving the choice of gender to refer to the speaker for the models we study. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.F2\" title=\"Figure 2 &#8227; 8.1. Frequency Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> shows the average score across the frequency range for the Transformer model on the enit split, with the same pattern holding for other languages and for the Conformer models.\nInstead, the formant range (350&#8211;2,500&#8201;Hz) displays the highest scores, with two peaks corresponding to the first and second formants (F<sub class=\"ltx_sub\">1</sub> and F<sub class=\"ltx_sub\">2</sub>). These formants are important for identifying the word being uttered, especially vowels <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">dan2009speech</span></cite>, but their exact frequency also varies by speaker and, notably, depending on the speaker&#8217;s gender <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">simpson2009phonetic</span></cite>. This is visible in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.F2\" title=\"Figure 2 &#8227; 8.1. Frequency Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, where peaks in saliency scores corresponding to F<sub class=\"ltx_sub\">1</sub> and F<sub class=\"ltx_sub\">2</sub> for feminine terms (uttered by female speakers) appear at higher frequencies than for masculine terms. This suggests that the assumption that ST models should leverage pitch information to disambiguate the gender of terms referring to the speaker does not fully correspond to our model&#8217;s behavior.</p>\n\n",
                "matched_terms": [
                    "word",
                    "transformer",
                    "model",
                    "where"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Still, while not the dominant feature, we cannot exclude that pitch plays a role in the model&#8217;s decision process.\nIn the example in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S4.F1\" title=\"Figure 1 &#8227; 4.3. Feature Attribution &#8227; 4. Method &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, occluding the top 2&#8201;% of features with the highest scores flips the gender of the translation of &#8220;<span class=\"ltx_text ltx_font_italic\">become</span>&#8221; from feminine to masculine. These features are concentrated along the time axis but spread across most of the frequency range and, crucially, they include the pitch region. This pattern holds for all our samples: 99.9&#8201;% of examples that flip contain at least one feature in the pitch region among those occluded for flipping (99.8&#8201;% for the Conformers).</p>\n\n",
                "matched_terms": [
                    "all",
                    "flip",
                    "examples"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Overall, we can conclude that the information the model uses is distributed across the frequency range rather than concentrated in pitch alone, with particular emphasis on F<sub class=\"ltx_sub\">1</sub> and F<sub class=\"ltx_sub\">2</sub>. This has implications for interventions to mitigate gender bias or neutralize the gender of audio samples, suggesting that approaches acting solely on pitch would be insufficient.\nMoreover, since salient features for gender disambiguation are concentrated along the time dimension but distributed along the frequency dimension, this suggests that <span class=\"ltx_text ltx_font_italic\">when</span> acoustic cues occur may be particularly important. We now turn to analyzing which source words correspond to these temporally concentrated features.</p>\n\n",
                "matched_terms": [
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The reliance on first-person pronouns differs across model architectures. For the Conformers, self-referential words are top-scoring in only 14.3&#8211;14.8&#8201;% of flipped examples, compared to 23.7&#8211;35.1&#8201;% for the Transformer. Despite this quantitative difference, the same set of words consistently appears at the top across all models and languages, indicating that this strategy is learnable by different architectures but exploited with varying effectiveness. The Transformer, which achieves higher gender translation accuracy, relies on this mechanism more frequently than the Conformers. This pattern corroborates <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">fucci-etal-2025-different</span></cite>, which finds that models with higher gender translation accuracy for speaker-referring terms also encode more gender information in their representations (measured via probing). Our contrastive analysis goes further by revealing the mechanism through which models access this information: via self-referential words that establish coreference with the speaker.</p>\n\n",
                "matched_terms": [
                    "model",
                    "selfreferential",
                    "all",
                    "examples",
                    "topscoring",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Beyond architectural differences, models&#8217; reliance on input features also differs between feminine and masculine predictions. For the Transformer, the percentage of examples whose gender prediction we can flip by occluding salient features in the input spectrogram is 60.8&#8201;% vs. 19.2&#8201;% for Spanish, 66.7&#8201;% vs. 24.9&#8201;% for French, and 52.2&#8201;% vs. 21.1&#8201;% for Italian (feminine vs. masculine respectively). The Conformers show the same pattern with a narrower gap (es: 47.5&#8201;% vs. 33.6&#8201;%; fr: 51.0&#8201;% vs. 37.6&#8201;%; it: 44.7&#8201;% vs. 41.3&#8201;%). This asymmetry suggests that the mechanism of accessing acoustic gender cues through first-person pronouns plays a more critical role for feminine predictions, while masculine predictions rely more heavily on the model&#8217;s internal biases. This asymmetry aligns with prior work showing that language models and MT systems use masculine as a default, requiring strong feminine signals to generate feminine forms <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">jumelet2019analysing</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">manna-etal-2025-paying</span></cite>, which they slowly and imperfectly learn to use during training <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">savoldi2022dynamics</span></cite>.</p>\n\n",
                "matched_terms": [
                    "percentage",
                    "transformer",
                    "flip",
                    "examples"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Besides first-person pronouns, models sometimes assign high salience to the source words corresponding to the gendered target terms.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.T4\" title=\"Table 4 &#8227; 8.2. Time Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> contains examples of this phenomenon: words like &#8220;<span class=\"ltx_text ltx_font_italic\">scientist</span>&#8221;, which translates to &#8220;<span class=\"ltx_text ltx_font_italic\">scienziato</span>&#8221;<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">M</span></sup> or &#8220;<span class=\"ltx_text ltx_font_italic\">scienziata</span>&#8221;<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">F</span></sup> in Italian. These words are directly relevant for translating the gendered term itself and, like all words in the utterance, carry acoustic gender cues that models can access.</p>\n\n",
                "matched_terms": [
                    "examples",
                    "all",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In summary, the contrastive saliency maps reveal that ST models frequently rely on self-referential words like &#8220;<span class=\"ltx_text ltx_font_italic\">I</span>&#8221; to establish coreference with the speaker, enabling access to acoustic gender cues.\nThese cues are distributed across the frequency spectrum rather than concentrated in pitch, with <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S8.SS2.p6.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> and <math alttext=\"F_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S8.SS2.p6.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">F_{2}</annotation></semantics></math> showing higher importance.</p>\n\n",
                "matched_terms": [
                    "selfreferential",
                    "“i”"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our analysis focuses on two model architectures trained on the MuST-C dataset <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cattoni2021must</span></cite>. While these models are not state-of-the-art in terms of overall speech translation performance, we selected them for specific methodological reasons. The Transformer model <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">wang2020fairseq</span></cite> demonstrates notably higher accuracy on gender assignment compared to more recent systems like SeamlessM4T <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">seamless2025joint</span></cite>, making it better positioned to reveal how models successfully leverage acoustic cues for gender disambiguation. Additionally, both models are trained exclusively on MuST-C, which enables the training data analysis in &#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6\" title=\"6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>. In contrast, modern speech translation systems and speech-enhanced large language models are typically trained on multiple large-scale datasets without transparent documentation, making it difficult to establish connections between training data patterns and model behavior. The models we analyze provide architectural diversity (Transformer versus Conformer encoders) and scope differences (multilingual versus monolingual), allowing us to examine how gender assignment strategies vary across different system configurations. However, they are trained with the same objective (supervised training with cross entropy) and we do not cover different training regimes such as non-autoregressive or self-supervised trainings. Additionally, our analysis does not extend to speech-enhanced large language models (SpeechLLMs) <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">rubenstein2023audiopalm</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">wu2023decoder</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">tang2024salmonn</span></cite>, which represent an emerging paradigm for speech translation with potentially different mechanisms for processing acoustic information and assigning gender. Future work should investigate whether the patterns we identified&#8212;particularly the use of first-person pronouns for coreference resolution, the distribution of salient features across the frequency spectrum rather than concentration in pitch, and the relationship between internal language model biases and full model predictions&#8212;generalize to recent models trained on large-scale data, to models trained with different objectives, and to SpeechLLMs.</p>\n\n",
                "matched_terms": [
                    "wang2020fairseq",
                    "model",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our analysis uses the MuST-SHE benchmark <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">bentivogli-etal-2020-gender</span></cite>, which covers the translation from English into three Romance languages (Spanish, French, and Italian). Since gender cues may manifest differently in other languages, this may influence how models learn gender assignment patterns. For this reason, future work should extend our analysis to typologically diverse language pairs, including languages with different gender marking strategies or non-gendered source languages. This would help determine whether the mechanisms we identify represent general model strategies or language-specific patterns.</p>\n\n",
                "matched_terms": [
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The benchmark also constrains our dataset size. After filtering as described in &#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S5\" title=\"5. Experimental Setup &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, we obtain 440 gender terms for Spanish, 355 for French, and 357 for Italian for the Transformer model, and 453 gender terms for Spanish, 379 for French, and 309 for Italian for the Conformer models. While this represents a relatively small dataset, MuST-SHE is currently the only available resource for speech translation that provides the fine-grained annotations required for our interpretability methods: gender terms referring to the speaker that are gender-neutral in English but gendered in the target language, gold-standard gender labels reflecting speakers&#8217; self-identified gender, and contrastive gender alternatives for each term. These annotations are essential for the contrastive feature attribution method <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">conti2025unheard</span></cite> we employ. The consistency of findings across three language pairs strengthens confidence in our results despite the dataset size.</p>\n\n",
                "matched_terms": [
                    "model",
                    "results",
                    "transformer"
                ]
            }
        ]
    },
    "S8.T4": {
        "source_file": "Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation",
        "caption": "Table 4: Most frequent top-scoring source words for examples that flip, with the number of examples in the receive the highest saliency score. Results for the Transformer model wang2020fairseq.",
        "body": "es\nfr\nit\n\n\n\n\nI\n\n\n22\n\n\nI\n\n\n28\n\n\nI\n\n\n33\n\n\n\n\nI’m\n\n\n13\n\n\nand\n\n\n5\n\n\nmyself\n\n\n9\n\n\n\n\nsure\n\n\n9\n\n\nwas\n\n\n5\n\n\nI’m\n\n\n8\n\n\n\n\nmyself\n\n\n9\n\n\nI’m\n\n\n4\n\n\nas\n\n\n7\n\n\n\n\nas\n\n\n8\n\n\nmusician\n\n\n4\n\n\nI’ve\n\n\n6\n\n\n\n\nscientist\n\n\n7\n\n\nme\n\n\n3\n\n\nscientist\n\n\n6\n\n\n\n\nkid\n\n\n6\n\n\nwhen\n\n\n3\n\n\nwas\n\n\n5\n\n\n\n\nand\n\n\n6\n\n\nhappy\n\n\n2\n\n\nand\n\n\n4\n\n\n\n\nchild\n\n\n6\n\n\nserious\n\n\n2\n\n\nprofessor\n\n\n3\n\n\n\n\nus\n\n\n4\n\n\nlawyer\n\n\n2\n\n\nsure\n\n\n3",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">es</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" colspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">fr</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">it</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">I</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">22</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">I</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">28</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">I</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">33</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\"><span class=\"ltx_text\" style=\"font-size:90%;\">I&#8217;m</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">13</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">and</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">5</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">myself</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">9</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\"><span class=\"ltx_text\" style=\"font-size:90%;\">sure</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">9</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">was</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">5</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">I&#8217;m</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">8</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\"><span class=\"ltx_text\" style=\"font-size:90%;\">myself</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">9</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">I&#8217;m</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">4</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">as</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">7</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\"><span class=\"ltx_text\" style=\"font-size:90%;\">as</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">8</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">musician</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">4</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">I&#8217;ve</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">6</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\"><span class=\"ltx_text\" style=\"font-size:90%;\">scientist</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">7</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">me</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">3</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">scientist</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">6</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\"><span class=\"ltx_text\" style=\"font-size:90%;\">kid</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">6</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">when</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">3</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">was</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">5</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\"><span class=\"ltx_text\" style=\"font-size:90%;\">and</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">6</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">happy</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">2</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">and</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">4</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l\"><span class=\"ltx_text\" style=\"font-size:90%;\">child</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">6</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">serious</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">2</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">professor</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">3</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l\"><span class=\"ltx_text\" style=\"font-size:90%;\">us</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">4</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">lawyer</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">2</span></span>\n</span>\n</td>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">sure</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text\" style=\"font-size:90%;\">3</span></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "flip",
            "source",
            "professor",
            "i’m",
            "sure",
            "receive",
            "score",
            "words",
            "transformer",
            "musician",
            "happy",
            "highest",
            "most",
            "scientist",
            "topscoring",
            "kid",
            "frequent",
            "results",
            "model",
            "myself",
            "examples",
            "number",
            "serious",
            "lawyer",
            "i’ve",
            "child",
            "when",
            "wang2020fairseq",
            "saliency"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Analyzing which source words drive gender assignment reveals a surprising pattern: models rely primarily on first-person pronouns and determiners that refer to the speaker.\nManual investigation of the contrastive heatmaps has revealed that &#8220;<span class=\"ltx_text ltx_font_italic\">I</span>&#8221; is the word most frequently highlighted to explain gender choice. To validate this observation quantitatively, we extract word-level scores from the spectrogram heatmaps by using Gentle<span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>https://github.com/strob/gentle</span></span></span> to obtain each source word&#8217;s time range and selecting the highest feature score within that range as the word&#8217;s score. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.T3\" title=\"Table 3 &#8227; 8.2. Time Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> shows that, for the Transformer model, &#8220;<span class=\"ltx_text ltx_font_italic\">I</span>&#8221; is the top-scoring word in 16.9&#8211;25.8&#8201;% of examples, depending on the language. Including other self-referential expressions (&#8220;<span class=\"ltx_text ltx_font_italic\">I</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">I&#8217;d</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">I&#8217;ve</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">I&#8217;m</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">my</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">me</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">myself</span>&#8221;) raises these percentages to 23.7&#8211;35.1&#8201;%.\nThese percentages are even higher when considering all examples in our dataset rather than just those that flip (second row of Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.T3\" title=\"Table 3 &#8227; 8.2. Time Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>).\nBesides these first-person words, Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.T4\" title=\"Table 4 &#8227; 8.2. Time Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> shows that words like &#8220;<span class=\"ltx_text ltx_font_italic\">and</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">was</span>&#8221;, and &#8220;<span class=\"ltx_text ltx_font_italic\">when</span>&#8221; also frequently receive high attribution scores. However, manual inspection reveals these words appear next to &#8220;<span class=\"ltx_text ltx_font_italic\">I</span>&#8221; in the source sentence (&#8220;<span class=\"ltx_text ltx_font_italic\">and I&#8230;</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">I was&#8230;</span>&#8221;, &#8220;<span class=\"ltx_text ltx_font_italic\">when I&#8230;</span>&#8221;) and likely score highest due to imprecisions in Gentle&#8217;s word-level alignments, suggesting the actual prevalence of first-person words is even greater.</p>\n\n",
            "<p class=\"ltx_p\">Besides first-person pronouns, models sometimes assign high salience to the source words corresponding to the gendered target terms.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.T4\" title=\"Table 4 &#8227; 8.2. Time Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> contains examples of this phenomenon: words like &#8220;<span class=\"ltx_text ltx_font_italic\">scientist</span>&#8221;, which translates to &#8220;<span class=\"ltx_text ltx_font_italic\">scienziato</span>&#8221;<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">M</span></sup> or &#8220;<span class=\"ltx_text ltx_font_italic\">scienziata</span>&#8221;<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">F</span></sup> in Italian. These words are directly relevant for translating the gendered term itself and, like all words in the utterance, carry acoustic gender cues that models can access.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Unlike text, speech conveys information about the speaker, such as gender, through acoustic cues like pitch. This gives rise to modality-specific bias concerns.\nFor example, in speech translation (ST), when translating from languages with notional gender, such as English, into languages where gender-ambiguous terms referring to the speaker are assigned grammatical gender, the speaker&#8217;s vocal characteristics may play a role in gender assignment.\nThis risks misgendering speakers&#8212;whether through masculine defaults or vocal-based assumptions&#8212;yet how ST models make these decisions remains poorly understood.\nWe investigate the mechanisms ST models use to assign gender to speaker-referring terms across three language pairs (enes/fr/it), examining how training data patterns, internal language model (ILM) biases, and acoustic information interact. We find that models do not simply replicate term-specific gender associations from training data, but learn broader patterns of masculine prevalence. While the ILM exhibits strong masculine bias, models can override these preferences based on acoustic input. Using contrastive feature attribution on spectrograms, we reveal that the model with higher gender accuracy relies on a previously unknown mechanism: using first-person pronouns to link gendered terms back to the speaker, accessing gender information distributed across the frequency spectrum rather than concentrated in pitch.\n\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>\n<span class=\"ltx_text ltx_font_bold\">Keywords:&#8201;</span>gender bias, speech translation, interpretability, XAI</p>\n\n",
                "matched_terms": [
                    "when",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">One example of these modality-specific concerns is the manifestation of gender bias when translating speech input compared to text input.\nWhen translating from languages with limited gender marking like English to languages with overt gender distinctions like Spanish, French, and Italian, systems assign grammatical gender to ambiguous terms.\nFor example, when translating &#8220;<span class=\"ltx_text ltx_font_italic\">I have become a student</span>&#8221; to Italian, the verb form for &#8220;<span class=\"ltx_text ltx_font_italic\">become</span>&#8221; is grammatically gendered, leading the model to choose between &#8220;<span class=\"ltx_text ltx_font_italic\">diventata</span>&#8221;<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">F</span></sup> (feminine) and &#8220;<span class=\"ltx_text ltx_font_italic\">diventato</span>&#8221;<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">M</span></sup> (masculine).\nIn text-based machine translation (MT), systems typically default to masculine forms or make assumptions based on gender stereotypes <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">Prates2018AssessingGBA</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">stanovsky-etal-2019-evaluating</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mastromichalakis2025assumed</span></cite>.\nSpeech translation (ST) systems can exhibit similar patterns, but they also have access to vocal characteristics, such as pitch, that could be used as proxies for the speaker&#8217;s gender when translating terms that refer to them <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">bentivogli-etal-2020-gender</span></cite>, as in the example above.</p>\n\n",
                "matched_terms": [
                    "when",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To investigate the mechanisms ST models use to assign gender to speaker-referring terms, we start from the common assumption that attributes gender bias to training data imbalances <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">tatman2017gender</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">garnerin2019gender</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">iluz-etal-2023-exploring</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mastromichalakis2025assumed</span></cite>. This leads to our first research question: (i) <span class=\"ltx_text ltx_font_bold\">What is the influence of gender associations learned from the training data?</span> We address this by comparing model predictions with gender frequencies in the training corpus (&#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6\" title=\"6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>). Finding that models do not simply replicate term-specific patterns motivates us to investigate the broader factors driving gender assignment in ST models.\nFor this, we conceptually divide the ST model into two components: the encoder, which processes the input audio and may extract acoustic cues from it, and the decoder, which autoregressively predicts the next token based on both the encoder&#8217;s representation of the audio and the previously generated tokens.\nFirst, we study the decoder&#8217;s contribution by removing encoder information, thus isolating the ST system&#8217;s internal language model (ILM) <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">variani2020hybrid</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">meng2021internal</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">zeineldeen2021investigating</span></cite>. Through this, we aim to answer the question (ii) <span class=\"ltx_text ltx_font_bold\">What is the impact of the model&#8217;s learned knowledge of the target language and a priori assumptions about gender on predictions?</span> Following this analysis (&#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S7\" title=\"7. Internal Language Model Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">7</span></a>), we turn to assessing the role of the source audio: (iii) <span class=\"ltx_text ltx_font_bold\">What aspects of the input audio does the model use to assign gender to speaker-referring terms?</span> Does it rely primarily on pitch, a key acoustic correlate of perceived gender? We study this with contrastive feature attribution over input spectrograms (&#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8\" title=\"8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>).</p>\n\n",
                "matched_terms": [
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"\\#w\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m3\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">#</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">\\#w</annotation></semantics></math> denotes the number of occurrences of word form <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m4\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> in the training data.\nWe then compare the prevalence of term <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m5\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> in gender <math alttext=\"g_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m6\" intent=\":literal\"><semantics><msub><mi>g</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">g_{1}</annotation></semantics></math> with the model&#8217;s preference for that gender when generating <math alttext=\"w_{g_{1}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m7\" intent=\":literal\"><semantics><msub><mi>w</mi><msub><mi>g</mi><mn>1</mn></msub></msub><annotation encoding=\"application/x-tex\">w_{g_{1}}</annotation></semantics></math>. We quantify this preference by computing the relative probabilities between gendered alternatives:</p>\n\n",
                "matched_terms": [
                    "number",
                    "when"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"p(w)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m8\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">p(w)</annotation></semantics></math> is the probability assigned by a given model to word <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m9\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> in the translation hypothesis.\nThis can be calculated as either the predicted gender preference (comparing the generated form against its ungenerated alternative) or the masculine preference (comparing masculine versus feminine forms regardless of which was generated).\nBy comparing prevalences with the model&#8217;s gender preferences, we can distinguish predictions that replicate term-specific training patterns (where the higher-probability gender matches the more prevalent one in training data) from those based on acoustic or content-based source information, or other sources of bias.</p>\n\n",
                "matched_terms": [
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While training data patterns provide one source of gender bias, the model&#8217;s entrenched biases encompass more than only term-specific associations.\nThe decoder&#8217;s behavior also reflects its learned understanding of target language structure, general patterns of gender marking, and how previously generated tokens constrain subsequent predictions. As the decoder autoregressively predicts tokens based on both encoder input and previously generated tokens, it develops these broader linguistic patterns, forming an internal language model.</p>\n\n",
                "matched_terms": [
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We compute the preference metric (Eq.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S4.E2\" title=\"In 4.1. Training Data Prevalence &#8227; 4. Method &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>) for the ILM and compare it with the full model&#8217;s preferences. Contrasting ILM and full model preferences reveals to what extent models follow these entrenched biases and when, conversely, the audio input overrides them.</p>\n\n",
                "matched_terms": [
                    "when",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This approach identifies why the model generates one gendered form instead of its alternative by computing relative probability changes between the two options when different parts of the input are masked.\nSpecifically, it automatically segments the input spectrogram (Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S4.F1\" title=\"Figure 1 &#8227; 4.3. Feature Attribution &#8227; 4. Method &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>.a) into acoustically meaningful regions and performs multiple inference passes with random perturbations to each segment. It assigns each segment a score based on how its perturbation affects the probability of one gendered form versus the other, producing saliency maps (Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S4.F1\" title=\"Figure 1 &#8227; 4.3. Feature Attribution &#8227; 4. Method &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>.b) that highlight the spectrogram regions most responsible for the model&#8217;s gender choice.</p>\n\n",
                "matched_terms": [
                    "model",
                    "most",
                    "score",
                    "when",
                    "saliency"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Following <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">conti2025unheard</span></cite>, we validate that the highlighted features are causally involved in gender assignment by testing whether occluding them changes the model&#8217;s gender prediction. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S4.F1\" title=\"Figure 1 &#8227; 4.3. Feature Attribution &#8227; 4. Method &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>.c shows the top 2&#8201;% of salient features that, when masked, successfully flip the prediction in this example.\n<span class=\"ltx_text\" style=\"--ltx-fg-color:#000000;\">By occluding 1&#8211;20&#8201;% of the most salient features, we can flip the predicted gender in 37&#8211;47&#8201;% of examples across languages and models. </span>\nWe focus our analysis on such flipped examples, where causal links between input features and gender assignment are established.\nFrom these validated explanations, we can analyze which regions of the input spectrogram drive gender assignment: along the frequency dimension to identify relevant acoustic features, and along the time dimension to identify relevant words.</p>\n\n",
                "matched_terms": [
                    "flip",
                    "most",
                    "examples",
                    "words",
                    "when"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use MuST-SHE <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">bentivogli-etal-2020-gender</span></cite>, a benchmark containing annotations for gender-neutral English terms in natural speech that require gender marking when translated to Spanish, French, or Italian.\nWe focus on the subset containing terms referring to the speaker, as these are cases where acoustic gender cues could influence gender assignment. Unlike sentences with gendered pronouns like &#8220;<span class=\"ltx_text ltx_font_italic\">She is a student</span>,&#8221; where gender is explicitly marked in the source, speaker-referential sentences like &#8220;<span class=\"ltx_text ltx_font_italic\">I am a student</span>&#8221; contain no linguistic gender information, making acoustic cues potentially relevant.\nFor each term, the dataset provides correct and incorrect gender translations, e.g., &#8220;<span class=\"ltx_text ltx_font_italic\">diventata</span>&#8221;<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">F</span></sup> vs. &#8220;<span class=\"ltx_text ltx_font_italic\">diventato</span>&#8221;<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_italic\">M</span></sup> as Italian translations of &#8220;<span class=\"ltx_text ltx_font_italic\">become</span>,&#8221; which we use as contrastive pairs for our analysis. Following <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">savoldi-etal-2022-morphosyntactic</span></cite>, we exclude gender articles, as their high frequency in both genders across sentences makes it difficult to identify instances specifically referring to the speaker. We analyze only terms where the ST model generates one of the MuST-SHE annotated forms. Depending on the model used to translate, this yields between 309 and 453 gender terms per target language.</p>\n\n",
                "matched_terms": [
                    "when",
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We select models trained exclusively on a single open-source dataset to enable our training data analysis in &#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6\" title=\"6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>. We therefore focus on two model architectures trained on MuST-C <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cattoni2021must</span></cite>: the multilingual Transformer encoder-decoder model by <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">wang2020fairseq</span></cite>, and the monolingual Conformer encoder-Transformer decoder models from <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">papi2024good</span></cite>. More recent ST systems and\nspeech-enhanced large language models are typically trained on massive datasets that are not publicly released, making it difficult to establish connections between training data patterns and model behavior.</p>\n\n",
                "matched_terms": [
                    "wang2020fairseq",
                    "model",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We primarily focus on the Transformer model for our analyses, as it demonstrates strong gender accuracy<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>The proportion of correct gender realizations among terms where the model generates one of the MuST-SHE annotated forms <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">gaido-etal-2020-breeding</span></cite>.</span></span></span>\nfor speaker-referential terms: 77.1&#8201;% to 80.6&#8201;% for feminine terms and 91.4&#8201;% to 94.4&#8201;% for masculine terms across target languages.\nThis suggests that the Transformer is well positioned to leverage vocal cues for gender disambiguation, a phenomenon we aim to investigate further, both in terms of relevant features and its relation to the ILM.\nBy comparing these results with Conformer models, which achieve lower accuracy (39.2-49.8% for feminine terms and 72.5-76.7% for masculine terms across the three language pairs), we assess whether gender assignment strategies are model-dependent.\nThese models provide architectural (Transformer vs. Conformer encoders) and scope (multilingual vs. monolingual) diversity, enabling us to examine how gender assignment strategies vary across different ST system configurations.</p>\n\n",
                "matched_terms": [
                    "model",
                    "results",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The first thing we observe is that the training data shows a clear masculine skew for the gender terms we study.\nIf we compute the average prevalence in the training data of the masculine form over the feminine one for all speaker-referring gendered terms in the translation hypotheses of the Transformer model, this average ranges from 0.68 to 0.71 depending on the languages, with nearly identical values for the Conformer models.</p>\n\n",
                "matched_terms": [
                    "model",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6.T1\" title=\"Table 1 &#8227; 6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> shows that the Transformer model does not simply replicate training data patterns when assigning gender.\nThe table categorizes each predicted gendered term by whether the predicted gender (F or M) is the more or less prevalent form in the training data for that specific term. If models followed the heuristic of generating each term in its most frequent training data gender, predictions should consistently fall in the &#8220;More Freq.&#8221; column.\nInstead, the model frequently predicts genders that are less prevalent for that specific term: 87.8&#8201;% of feminine generated terms in Spanish (173 of 197), 85.5&#8201;% in French (130 of 152), and 92.1&#8201;% in Italian (140 of&#160;152) correspond to the less prevalent form in the training data. For masculine predictions, the model does tend to predict the more prevalent form (221 of 243 in Spanish, 187 of 203 in French, 192 of 205 in Italian). However, given the overall masculine skew, this reflects the general pattern in the training data rather than term-specific memorization. The Conformers show a similar pattern: the distribution of predictions relative to prevalence resembles Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6.T1\" title=\"Table 1 &#8227; 6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, although with slightly more predictions aligning with the more prevalent form.\nCrucially, none of the models closely follow term-by-term gender associations from the training data.</p>\n\n",
                "matched_terms": [
                    "model",
                    "most",
                    "transformer",
                    "frequent",
                    "when"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In summary, our results challenge the assumption that gender bias in ST simply reflects the training data distribution <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">tatman2017gender</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">garnerin2019gender</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">iluz-etal-2023-exploring</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mastromichalakis2025assumed</span></cite>.\nOur findings align with <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">conti2023using</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">elghazaly2025exploring</span></cite>, suggesting that gender bias cannot be exclusively reduced to training data imbalances.\nThe data&#8217;s masculine skew clearly influences model behavior, but not through simple memorization&#8212;rather, models internalize broader biases that we investigate through the ILM.</p>\n\n",
                "matched_terms": [
                    "model",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While the training data analysis has revealed that models do not simply memorize term-specific associations, gender assignment must still be driven by some combination of learned decoder preferences and input audio features.\nWe first investigate whether the decoder has internalized broader biases beyond individual term associations by addressing our second research question: &#8220;What is the impact of the model&#8217;s learned knowledge of the target language and a priori assumptions about gender on predictions?&#8221;\nThe ILM analysis isolates these entrenched preferences by removing encoder information, measuring what the decoder learned independently of source audio. Comparing ILM with full model predictions then reveals when and how the audio input overrides these biases.</p>\n\n",
                "matched_terms": [
                    "when",
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The ILM reflects and amplifies the masculine skew observed in the training data. Averaging over all gender terms, the ILM&#8217;s preference for masculine over feminine ranges from 0.74 to 0.81 for the Transformer, depending on language&#8212;higher than the training data prevalence of 0.68&#8211;0.71.\nWhen we separate by the gender that is ultimately generated by the full model, the ILM&#8217;s masculine preference is 0.85&#8211;0.88 for masculine predictions and 0.58&#8211;0.71 for feminine ones (always above 0.5, even when generating feminine forms).\nFor the Conformer models, average masculine preference is 0.63&#8211;0.64 (0.71&#8211;0.74 for masculine predictions, 0.48&#8211;0.49 for feminine ones). While the Conformers&#8217; masculine preference drops just below 0.5 for feminine predictions, for masculine ones it remains well above 0.5, suggesting some masculine bias, though weaker than for the Transformer.</p>\n\n",
                "matched_terms": [
                    "when",
                    "model",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">However, the full model frequently overrides these entrenched biases. In the example in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S4.F1\" title=\"Figure 1 &#8227; 4.3. Feature Attribution &#8227; 4. Method &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, the prevalence in training data for masculine &#8220;<span class=\"ltx_text ltx_font_italic\">diventato</span>&#8221; is 0.57, and the ILM preference is 0.85, yet the full model&#8217;s preference for the predicted feminine form &#8220;<span class=\"ltx_text ltx_font_italic\">diventata</span>&#8221; is 0.99, illustrating how acoustic input can supersede learned biases and training data statistics.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S7.T2\" title=\"Table 2 &#8227; 7. Internal Language Model Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> shows this is common: the Transformer frequently predicts genders to which the ILM assigns lower probability, particularly for feminine predictions. Instead, the Conformers seem to rely more on their ILM: the Pearson correlation between ILM and full model masculine preference is strong for Conformers (es: 0.65; fr: 0.62; it: 0.62), but weak to moderate for the Transformer (es: 0.45; fr: 0.38; it: 0.47).</p>\n\n",
                "matched_terms": [
                    "model",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section has shown that the ILM exhibits a masculine-as-norm bias across our models, but ST systems vary in how much they rely on these entrenched preferences versus input audio. The Transformer&#8217;s ILM is strongly biased toward masculine, yet the full model frequently overrides these preferences based on acoustic information. The Conformers show weaker ILM masculine bias but rely more on it, struggling to leverage source audio effectively. This analysis demonstrates that ST models combine acoustic gender cues with language model preferences to varying degrees.\nThese findings demonstrate that acoustic input can play a substantial role in gender assignment, motivating us to investigate which specific aspects of the audio our models exploit for this.</p>\n\n",
                "matched_terms": [
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section addresses our third research question: &#8220;What aspects of the input audio does the model use to assign gender to terms referring to the speaker?&#8221;\nFor this, we apply the feature attribution method from &#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S4.SS3\" title=\"4.3. Feature Attribution &#8227; 4. Method &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">4.3</span></a>.\nOccluding 1&#8211;20&#8201;% of the most salient features highlighted by the saliency map flips the predicted gender in 40.7&#8201;% of Spanish examples, 46.8&#8201;% of French examples, and 37.0&#8201;% of Italian examples for the Transformer model, with comparable rates for the Conformers.\nFor these flipped examples, we have a guarantee that the highlighted features are causally involved in gender assignment, since if we occlude them, the model&#8217;s prediction changes.\nWe analyze these saliency maps to identify which words and acoustic cues in the source audio influence gender assignment.</p>\n\n",
                "matched_terms": [
                    "model",
                    "most",
                    "source",
                    "saliency",
                    "examples",
                    "words",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Pitch is the perceptual correlate of the fundamental frequency F<sub class=\"ltx_sub\">0</sub> <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">dan2009speech</span></cite>: utterances with higher F<sub class=\"ltx_sub\">0</sub> sound higher pitched and more feminine, whereas male speech typically has lower F<sub class=\"ltx_sub\">0</sub> <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">simpson2009phonetic</span></cite>. To determine whether the model relies on pitch, we examine the intensity with which the pitch region (80-350&#8201;Hz, where the fundamental frequency lies) is highlighted in our heatmaps. We aggregate each gender term&#8217;s explanation by taking the max score for each frequency bin over the time dimension, then average across all gender terms.</p>\n\n",
                "matched_terms": [
                    "model",
                    "score"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Surprisingly, the pitch range does not show the highest scores, suggesting it is not the most important region driving the choice of gender to refer to the speaker for the models we study. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.F2\" title=\"Figure 2 &#8227; 8.1. Frequency Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> shows the average score across the frequency range for the Transformer model on the enit split, with the same pattern holding for other languages and for the Conformer models.\nInstead, the formant range (350&#8211;2,500&#8201;Hz) displays the highest scores, with two peaks corresponding to the first and second formants (F<sub class=\"ltx_sub\">1</sub> and F<sub class=\"ltx_sub\">2</sub>). These formants are important for identifying the word being uttered, especially vowels <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">dan2009speech</span></cite>, but their exact frequency also varies by speaker and, notably, depending on the speaker&#8217;s gender <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">simpson2009phonetic</span></cite>. This is visible in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S8.F2\" title=\"Figure 2 &#8227; 8.1. Frequency Dimension &#8227; 8. The Role of Input Audio &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, where peaks in saliency scores corresponding to F<sub class=\"ltx_sub\">1</sub> and F<sub class=\"ltx_sub\">2</sub> for feminine terms (uttered by female speakers) appear at higher frequencies than for masculine terms. This suggests that the assumption that ST models should leverage pitch information to disambiguate the gender of terms referring to the speaker does not fully correspond to our model&#8217;s behavior.</p>\n\n",
                "matched_terms": [
                    "model",
                    "highest",
                    "most",
                    "score",
                    "transformer",
                    "saliency"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Still, while not the dominant feature, we cannot exclude that pitch plays a role in the model&#8217;s decision process.\nIn the example in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S4.F1\" title=\"Figure 1 &#8227; 4.3. Feature Attribution &#8227; 4. Method &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, occluding the top 2&#8201;% of features with the highest scores flips the gender of the translation of &#8220;<span class=\"ltx_text ltx_font_italic\">become</span>&#8221; from feminine to masculine. These features are concentrated along the time axis but spread across most of the frequency range and, crucially, they include the pitch region. This pattern holds for all our samples: 99.9&#8201;% of examples that flip contain at least one feature in the pitch region among those occluded for flipping (99.8&#8201;% for the Conformers).</p>\n\n",
                "matched_terms": [
                    "examples",
                    "highest",
                    "flip",
                    "most"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Overall, we can conclude that the information the model uses is distributed across the frequency range rather than concentrated in pitch alone, with particular emphasis on F<sub class=\"ltx_sub\">1</sub> and F<sub class=\"ltx_sub\">2</sub>. This has implications for interventions to mitigate gender bias or neutralize the gender of audio samples, suggesting that approaches acting solely on pitch would be insufficient.\nMoreover, since salient features for gender disambiguation are concentrated along the time dimension but distributed along the frequency dimension, this suggests that <span class=\"ltx_text ltx_font_italic\">when</span> acoustic cues occur may be particularly important. We now turn to analyzing which source words correspond to these temporally concentrated features.</p>\n\n",
                "matched_terms": [
                    "words",
                    "when",
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The reliance on first-person pronouns differs across model architectures. For the Conformers, self-referential words are top-scoring in only 14.3&#8211;14.8&#8201;% of flipped examples, compared to 23.7&#8211;35.1&#8201;% for the Transformer. Despite this quantitative difference, the same set of words consistently appears at the top across all models and languages, indicating that this strategy is learnable by different architectures but exploited with varying effectiveness. The Transformer, which achieves higher gender translation accuracy, relies on this mechanism more frequently than the Conformers. This pattern corroborates <cite class=\"ltx_cite ltx_citemacro_citet\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">fucci-etal-2025-different</span></cite>, which finds that models with higher gender translation accuracy for speaker-referring terms also encode more gender information in their representations (measured via probing). Our contrastive analysis goes further by revealing the mechanism through which models access this information: via self-referential words that establish coreference with the speaker.</p>\n\n",
                "matched_terms": [
                    "model",
                    "topscoring",
                    "examples",
                    "words",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Beyond architectural differences, models&#8217; reliance on input features also differs between feminine and masculine predictions. For the Transformer, the percentage of examples whose gender prediction we can flip by occluding salient features in the input spectrogram is 60.8&#8201;% vs. 19.2&#8201;% for Spanish, 66.7&#8201;% vs. 24.9&#8201;% for French, and 52.2&#8201;% vs. 21.1&#8201;% for Italian (feminine vs. masculine respectively). The Conformers show the same pattern with a narrower gap (es: 47.5&#8201;% vs. 33.6&#8201;%; fr: 51.0&#8201;% vs. 37.6&#8201;%; it: 44.7&#8201;% vs. 41.3&#8201;%). This asymmetry suggests that the mechanism of accessing acoustic gender cues through first-person pronouns plays a more critical role for feminine predictions, while masculine predictions rely more heavily on the model&#8217;s internal biases. This asymmetry aligns with prior work showing that language models and MT systems use masculine as a default, requiring strong feminine signals to generate feminine forms <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">jumelet2019analysing</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">manna-etal-2025-paying</span></cite>, which they slowly and imperfectly learn to use during training <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">savoldi2022dynamics</span></cite>.</p>\n\n",
                "matched_terms": [
                    "examples",
                    "flip",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In summary, the contrastive saliency maps reveal that ST models frequently rely on self-referential words like &#8220;<span class=\"ltx_text ltx_font_italic\">I</span>&#8221; to establish coreference with the speaker, enabling access to acoustic gender cues.\nThese cues are distributed across the frequency spectrum rather than concentrated in pitch, with <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S8.SS2.p6.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> and <math alttext=\"F_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S8.SS2.p6.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">F_{2}</annotation></semantics></math> showing higher importance.</p>\n\n",
                "matched_terms": [
                    "saliency",
                    "words"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our analysis focuses on two model architectures trained on the MuST-C dataset <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cattoni2021must</span></cite>. While these models are not state-of-the-art in terms of overall speech translation performance, we selected them for specific methodological reasons. The Transformer model <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">wang2020fairseq</span></cite> demonstrates notably higher accuracy on gender assignment compared to more recent systems like SeamlessM4T <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">seamless2025joint</span></cite>, making it better positioned to reveal how models successfully leverage acoustic cues for gender disambiguation. Additionally, both models are trained exclusively on MuST-C, which enables the training data analysis in &#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S6\" title=\"6. Training Data Analysis &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>. In contrast, modern speech translation systems and speech-enhanced large language models are typically trained on multiple large-scale datasets without transparent documentation, making it difficult to establish connections between training data patterns and model behavior. The models we analyze provide architectural diversity (Transformer versus Conformer encoders) and scope differences (multilingual versus monolingual), allowing us to examine how gender assignment strategies vary across different system configurations. However, they are trained with the same objective (supervised training with cross entropy) and we do not cover different training regimes such as non-autoregressive or self-supervised trainings. Additionally, our analysis does not extend to speech-enhanced large language models (SpeechLLMs) <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">rubenstein2023audiopalm</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">wu2023decoder</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">tang2024salmonn</span></cite>, which represent an emerging paradigm for speech translation with potentially different mechanisms for processing acoustic information and assigning gender. Future work should investigate whether the patterns we identified&#8212;particularly the use of first-person pronouns for coreference resolution, the distribution of salient features across the frequency spectrum rather than concentration in pitch, and the relationship between internal language model biases and full model predictions&#8212;generalize to recent models trained on large-scale data, to models trained with different objectives, and to SpeechLLMs.</p>\n\n",
                "matched_terms": [
                    "wang2020fairseq",
                    "model",
                    "transformer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our analysis uses the MuST-SHE benchmark <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">bentivogli-etal-2020-gender</span></cite>, which covers the translation from English into three Romance languages (Spanish, French, and Italian). Since gender cues may manifest differently in other languages, this may influence how models learn gender assignment patterns. For this reason, future work should extend our analysis to typologically diverse language pairs, including languages with different gender marking strategies or non-gendered source languages. This would help determine whether the mechanisms we identify represent general model strategies or language-specific patterns.</p>\n\n",
                "matched_terms": [
                    "model",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The benchmark also constrains our dataset size. After filtering as described in &#167;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.21517v1#S5\" title=\"5. Experimental Setup &#8227; Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, we obtain 440 gender terms for Spanish, 355 for French, and 357 for Italian for the Transformer model, and 453 gender terms for Spanish, 379 for French, and 309 for Italian for the Conformer models. While this represents a relatively small dataset, MuST-SHE is currently the only available resource for speech translation that provides the fine-grained annotations required for our interpretability methods: gender terms referring to the speaker that are gender-neutral in English but gendered in the target language, gold-standard gender labels reflecting speakers&#8217; self-identified gender, and contrastive gender alternatives for each term. These annotations are essential for the contrastive feature attribution method <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">conti2025unheard</span></cite> we employ. The consistency of findings across three language pairs strengthens confidence in our results despite the dataset size.</p>\n\n",
                "matched_terms": [
                    "model",
                    "results",
                    "transformer"
                ]
            }
        ]
    }
}