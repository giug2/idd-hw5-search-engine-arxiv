{
    "S4.T1": {
        "caption": "Table 1: Performance of LogSTOP on query matching and ranked retrieval drops as components (aggregation method, smoothing, threshold) are ablated. Results are shown on QMTP-video (with YOLOv8) and TP2VR-objects (with GroundingDINO). STL robustness is described in Appendix B.",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">\n<span class=\"ltx_ERROR undefined\">\\rowcolor</span>gray!20\n<span class=\"ltx_text ltx_font_bold\">Ablation</span>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">QMTP-video</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\"><span class=\"ltx_text ltx_font_bold\">TP2VR-objects</span></th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"/>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_italic\">Balanced Accuracy</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_italic\">mAP</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_italic\">R@r</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_italic\">MnR</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_italic\">LogSTOP</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">0.79 <math alttext=\"(\\downarrow 0\\%)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m1\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">(</mo><mrow><mi/><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">&#8595;</mo><mrow><mn mathcolor=\"#808080\" style=\"--ltx-fg-color:#808080;\">0</mn><mo mathcolor=\"#808080\" style=\"--ltx-fg-color:#808080;\">%</mo></mrow></mrow><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 0\\%)</annotation></semantics></math>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\">0.64 <math alttext=\"(\\downarrow 0\\%)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m2\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">(</mo><mrow><mi/><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">&#8595;</mo><mrow><mn mathcolor=\"#808080\" style=\"--ltx-fg-color:#808080;\">0</mn><mo mathcolor=\"#808080\" style=\"--ltx-fg-color:#808080;\">%</mo></mrow></mrow><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 0\\%)</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\">0.59 <math alttext=\"(\\downarrow 0\\%)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m3\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">(</mo><mrow><mi/><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">&#8595;</mo><mrow><mn mathcolor=\"#808080\" style=\"--ltx-fg-color:#808080;\">0</mn><mo mathcolor=\"#808080\" style=\"--ltx-fg-color:#808080;\">%</mo></mrow></mrow><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 0\\%)</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\">2.0 <math alttext=\"(\\downarrow 0)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m4\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">(</mo><mrow><mi/><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">&#8595;</mo><mn mathcolor=\"#808080\" style=\"--ltx-fg-color:#808080;\">0</mn></mrow><mo mathcolor=\"#808080\" stretchy=\"false\" style=\"--ltx-fg-color:#808080;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 0)</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\"><span class=\"ltx_text ltx_font_italic\">Replace LogSTOP with STL Robustness</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">0.77 <math alttext=\"(\\downarrow 2\\%)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m5\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">(</mo><mrow><mi/><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">&#8595;</mo><mrow><mn mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">2</mn><mo mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">%</mo></mrow></mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 2\\%)</annotation></semantics></math>\n</th>\n<td class=\"ltx_td ltx_align_left\">0.52 <math alttext=\"(\\downarrow 12\\%)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m6\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">(</mo><mrow><mi/><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">&#8595;</mo><mrow><mn mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">12</mn><mo mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">%</mo></mrow></mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 12\\%)</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_left\">0.45 <math alttext=\"(\\downarrow 14\\%)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m7\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">(</mo><mrow><mi/><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">&#8595;</mo><mrow><mn mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">14</mn><mo mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">%</mo></mrow></mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 14\\%)</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_left\">3.8 <math alttext=\"(\\uparrow 1.8)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m8\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">(</mo><mrow><mi/><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">&#8593;</mo><mn mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">1.8</mn></mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\uparrow 1.8)</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\"><span class=\"ltx_text ltx_font_italic\">LogSTOP without local smoothing</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">0.77 <math alttext=\"(\\downarrow 2\\%)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m9\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">(</mo><mrow><mi/><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">&#8595;</mo><mrow><mn mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">2</mn><mo mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">%</mo></mrow></mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 2\\%)</annotation></semantics></math>\n</th>\n<td class=\"ltx_td ltx_align_left\">0.59 <math alttext=\"(\\downarrow 5\\%)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m10\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">(</mo><mrow><mi/><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">&#8595;</mo><mrow><mn mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">5</mn><mo mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">%</mo></mrow></mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 5\\%)</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_left\">0.55 <math alttext=\"(\\downarrow 4\\%)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m11\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">(</mo><mrow><mi/><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">&#8595;</mo><mrow><mn mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">4</mn><mo mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">%</mo></mrow></mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 4\\%)</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_left\">1.8 <math alttext=\"(\\downarrow 0.2)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m12\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#008000\" stretchy=\"false\" style=\"--ltx-fg-color:#008000;\">(</mo><mrow><mi/><mo mathcolor=\"#008000\" stretchy=\"false\" style=\"--ltx-fg-color:#008000;\">&#8595;</mo><mn mathcolor=\"#008000\" style=\"--ltx-fg-color:#008000;\">0.2</mn></mrow><mo mathcolor=\"#008000\" stretchy=\"false\" style=\"--ltx-fg-color:#008000;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 0.2)</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\"><span class=\"ltx_text ltx_font_italic\">LogSTOP with (<math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m13\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math>) threshold</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">0.76 <math alttext=\"(\\downarrow 3\\%)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m14\" intent=\":literal\"><semantics><mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">(</mo><mrow><mi/><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">&#8595;</mo><mrow><mn mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">3</mn><mo mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">%</mo></mrow></mrow><mo mathcolor=\"#FF0000\" stretchy=\"false\" style=\"--ltx-fg-color:#FF0000;\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\downarrow 3\\%)</annotation></semantics></math>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">-</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">-</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">-</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "drops",
            "balanced",
            "matching",
            "query",
            "ablated",
            "mnr",
            "smoothing",
            "↓14downarrow",
            "groundingdino",
            "↓2downarrow",
            "↓5downarrow",
            "stl",
            "qmtpvideo",
            "appendix",
            "↓02downarrow",
            "ablation",
            "described",
            "accuracy",
            "retrieval",
            "replace",
            "performance",
            "↓4downarrow",
            "↓3downarrow",
            "without",
            "↓0downarrow",
            "logstop",
            "results",
            "map",
            "yolov8",
            "components",
            "robustness",
            "aggregation",
            "local",
            "↓12downarrow",
            "↑18uparrow",
            "ranked",
            "method",
            "tp2vrobjects",
            "log⁡05log",
            "rowcolorgray20",
            "threshold"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Finally, we evaluate how the various design choices for LogSTOP affect the performance (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.T1\" title=\"Table 1 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>). We find that the accuracy drops by <math alttext=\"2\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m1\" intent=\":literal\"><semantics><mrow><mn>2</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">2\\%</annotation></semantics></math> when the standard STL robustness is used for aggregating scores instead of LogSTOP, or when local smoothing from Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l8\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>) is not performed.\nA <math alttext=\"3\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m2\" intent=\":literal\"><semantics><mrow><mn>3</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">3\\%</annotation></semantics></math> drop is also observed when the adaptive threshold is replaced with <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m3\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math>; Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F3\" title=\"Figure 3 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> demonstrates how the adaptive threshold\nis\nbetter at distinguishing between matching and non-matching sequences.</p>\n\n",
            "<p class=\"ltx_p\">Ablating various components of LogSTOP also degrades retrieval performance (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.T1\" title=\"Table 1 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>). The standard STL robustness reduces mAP and R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m1\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> by more than <math alttext=\"12\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m2\" intent=\":literal\"><semantics><mrow><mn>12</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">12\\%</annotation></semantics></math>. While removing the smoothing step from LogSTOP leads to a slight increase of 0.2 in MnR, it reduces mAP and R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m3\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> by at least <math alttext=\"4\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m4\" intent=\":literal\"><semantics><mrow><mn>4</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">4\\%</annotation></semantics></math>.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Neural models such as YOLO and HuBERT can be used to detect local properties such as objects (\"car\") and emotions (\"angry\") in individual frames of videos and audio clips respectively. The likelihood of these detections is indicated by scores in [0, 1]. Lifting these scores to temporal properties over sequences can be useful for several downstream applications such as query matching (e.g., \"does the speaker eventually sound happy in this audio clip?\"), and ranked retrieval (e.g., \"retrieve top 5 videos with a 10 second scene where a car is detected until a pedestrian is detected\").\nIn this work, we formalize this problem of assigning Scores for TempOral Properties (STOPs) over sequences, given potentially noisy score predictors for local properties.\nWe then propose a scoring function called LogSTOP that can efficiently compute these scores for temporal properties represented in Linear Temporal Logic.\nEmpirically, LogSTOP, with YOLO and HuBERT, outperforms Large Vision / Audio Language Models and other Temporal Logic-based baselines by at least 16% on query matching with temporal properties over objects-in-videos and emotions-in-speech respectively. Similarly, on ranked retrieval with temporal properties over objects and actions in videos, LogSTOP with Grounding DINO and SlowR50 reports at least a 19% and 16% increase in mean average precision and recall over zero-shot text-to-video retrieval baselines respectively.</p>\n\n",
                "matched_terms": [
                    "local",
                    "matching",
                    "query",
                    "logstop",
                    "ranked",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The sequences and local properties could correspond to arbitrary modalities and classes of interest, including objects or actions in videos, and speakers or emotions in audio clips. These STOPs are useful for several downstream applications such as\n<span class=\"ltx_text ltx_font_bold\">query matching</span>\n, i.e., checking if the scores\nare over a threshold to decide if the sequence expresses a temporal property,\nand\n<span class=\"ltx_text ltx_font_bold\">ranked retrieval</span>, i.e.,\nranking sequences\nagainst a temporal query by these scores to provide the top-k most relevant results.</p>\n\n",
                "matched_terms": [
                    "local",
                    "matching",
                    "query",
                    "ranked",
                    "results",
                    "threshold",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We argue that Linear Temporal Logic, with temporal operators such as \"Always\" (<math alttext=\"\\square\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m1\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#9633;</mi><annotation encoding=\"application/x-tex\">\\square</annotation></semantics></math>) and \"Until\" (<math alttext=\"\\mathbin{\\mathcal{U}}\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m2\" intent=\":literal\"><semantics><mo class=\"ltx_font_mathcaligraphic\">&#119984;</mo><annotation encoding=\"application/x-tex\">\\mathbin{\\mathcal{U}}</annotation></semantics></math>), provides a suitable language\nfor expressing diverse\ntemporal properties of interest.\nFor example,\nthe property \"A and B sound happy until A sounds sad\" can be written in LTL\nas <math alttext=\"(\\mathsf{{happy}_{A}}\\land\\mathsf{{happy}_{B}})\\mathbin{\\mathcal{U}}\\mathsf{{sad}_{A}}\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m3\" intent=\":literal\"><semantics><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>&#120257;&#120250;&#120265;&#120265;&#120274;</mi><mi>&#120224;</mi></msub><mo>&#8743;</mo><msub><mi>&#120257;&#120250;&#120265;&#120265;&#120274;</mi><mi>&#120225;</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#120268;&#120250;&#120253;</mi><mi>&#120224;</mi></msub></mrow><annotation encoding=\"application/x-tex\">(\\mathsf{{happy}_{A}}\\land\\mathsf{{happy}_{B}})\\mathbin{\\mathcal{U}}\\mathsf{{sad}_{A}}</annotation></semantics></math>.\nFor temporal properties in LTL, the framework proposed by <cite class=\"ltx_cite ltx_citemacro_citet\">Yang et&#160;al. [<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>]</cite> can be used as a solution to the STOP problem with two major caveats.\nFirstly, this approach requires <math alttext=\"\\mathcal{O}(T\\cdot 2^{|C|})\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><msup><mn>2</mn><mrow><mo stretchy=\"false\">|</mo><mi>C</mi><mo stretchy=\"false\">|</mo></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot 2^{|C|})</annotation></semantics></math> space and time for a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m5\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> and <math alttext=\"|C|\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m6\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>C</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|C|</annotation></semantics></math> local properties.\nThis exponential space and time complexity renders this approach inefficient for applications such as retrieval where sequences from a large database (with potentially many local properties) need to be checked.\nSecondly, this approach has no provision to handle incorrectly low or high, i.e., <span class=\"ltx_text ltx_font_italic\">potentially noisy</span>, scores for local properties.</p>\n\n",
                "matched_terms": [
                    "retrieval",
                    "local"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose a novel scoring function called LogSTOP, inspired by quantitative semantics for LTL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib14\" title=\"\">14</a>]</cite>,\nthat\nassigns a score for a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m1\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> satisfying temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\nin <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m3\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> time and space.\nLogSTOP employs a simple downsampling and smoothing strategy for handling locally incorrect\npredictions by the local property predictors.\nThis makes it robust to cases where, for example, an object detector detects a car with very low scores in some frames because it is occluded.\nMoreover, the linear time computational complexity makes it an efficient solution for applications such as query matching and ranked retrieval (see example in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).\nFor query matching, we propose a length and query-adaptive threshold which is guaranteed to accept at least as many sequences as a fixed threshold.\nWe also demonstrate how LogSTOP can be used to rank sequences based on subsequence relevance to temporal queries in <math alttext=\"\\mathcal{O}(T^{2}\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>T</mi><mn>2</mn></msup><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T^{2}\\cdot|\\varphi|)</annotation></semantics></math> time.</p>\n\n",
                "matched_terms": [
                    "local",
                    "matching",
                    "query",
                    "smoothing",
                    "logstop",
                    "ranked",
                    "threshold",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate LogSTOP on query matching and ranked retrieval,\nwith sequence modalities including videos and speech, and local properties such as objects, actions, and emotions.\nWe focus on 15 diverse temporal property templates of varying complexity.\nSince no existing benchmarks support this breadth of temporal properties\nand sequence types, we propose two new benchmarks:\nthe QMTP (Query Matching for Temporal Properties) benchmark\nfor objects-in-videos from the RealTLV dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>,\nand emotions-in-speech from the IEMOCAP dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite>;\nand the TP2VR (Temporal Property to Video Retrieval) benchmark\nfor objects-in-videos from the RealTLV dataset,\nand actions-in-videos from the AVA dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite>.</p>\n\n",
                "matched_terms": [
                    "local",
                    "matching",
                    "query",
                    "logstop",
                    "ranked",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We find that LogSTOP with simple detection models,\nsuch as YOLO and HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib21\" title=\"\">21</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite>,\noutperforms baselines including Large Vision / Audio Language Models (LVLMs / LALMs), and\nNSVS-TL\n, on query matching by more than <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m1\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of balanced accuracy.\nSimilarly,\nLogSTOP with Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite>\nand SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> outperforms\nzero-shot text-to-video retrieval methods, such as mPLUG&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite>\nand text-text similarity with video captions,\nby more than <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m2\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> and <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m3\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of mean average precision and recall respectively.</p>\n\n",
                "matched_terms": [
                    "balanced",
                    "matching",
                    "query",
                    "logstop",
                    "accuracy",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Given the true labeling functions for local properties <math alttext=\"y(X,c,\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m1\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(X,c,\\cdot)</annotation></semantics></math>,\nthis semantics can perfectly determine if a sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m2\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> expresses a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m3\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\n(if and only if <math alttext=\"y(X,\\varphi,1)=1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m4\" intent=\":literal\"><semantics><mrow><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>&#966;</mi><mo>,</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">y(X,\\varphi,1)=1</annotation></semantics></math>).\nIn practice, however, we do not have access to these true labeling functions.\nWe assume that noisy predictors can be used instead to provide\n<span class=\"ltx_text ltx_font_italic\">scores</span> <math alttext=\"\\hat{y}:\\mathcal{X}\\times C\\times\\mathcal{T}\\mapsto[a,b]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m5\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119987;</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><mi>C</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi></mrow><mo stretchy=\"false\">&#8614;</mo><mrow><mo stretchy=\"false\">[</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}:\\mathcal{X}\\times C\\times\\mathcal{T}\\mapsto[a,b]</annotation></semantics></math> for the label being 1,\nwhere <math alttext=\"a\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m6\" intent=\":literal\"><semantics><mi>a</mi><annotation encoding=\"application/x-tex\">a</annotation></semantics></math> and <math alttext=\"b\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m7\" intent=\":literal\"><semantics><mi>b</mi><annotation encoding=\"application/x-tex\">b</annotation></semantics></math> are the lower and upper bounds of the score range respectively.\nThe estimate for true label <math alttext=\"y(X,c,t)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m8\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(X,c,t)</annotation></semantics></math> can then be computed as <math alttext=\"\\tilde{y}(X,c,t)=\\hat{y}(X,c,t)&gt;\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m9\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>~</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mi>&#964;</mi></mrow><annotation encoding=\"application/x-tex\">\\tilde{y}(X,c,t)=\\hat{y}(X,c,t)&gt;\\tau</annotation></semantics></math>\nfor some threshold <math alttext=\"\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m10\" intent=\":literal\"><semantics><mi>&#964;</mi><annotation encoding=\"application/x-tex\">\\tau</annotation></semantics></math>.\nMost neural models, including object detection models such as YOLO,\nprovide scores in <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m11\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math> and an object <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m12\" intent=\":literal\"><semantics><mi>c</mi><annotation encoding=\"application/x-tex\">c</annotation></semantics></math> is said to be detected at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m13\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>\nif <math alttext=\"\\hat{y}(X,c,t)&gt;\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m14\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mi>&#964;</mi></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(X,c,t)&gt;\\tau</annotation></semantics></math>, where <math alttext=\"\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m15\" intent=\":literal\"><semantics><mi>&#964;</mi><annotation encoding=\"application/x-tex\">\\tau</annotation></semantics></math> usually is <math alttext=\"0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m16\" intent=\":literal\"><semantics><mn>0.5</mn><annotation encoding=\"application/x-tex\">0.5</annotation></semantics></math>.\nThe accuracy of these predictors then just measures how well <math alttext=\"\\tilde{y}(X,c,\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m17\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>~</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\tilde{y}(X,c,\\cdot)</annotation></semantics></math> estimates <math alttext=\"y(X,c,\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m18\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(X,c,\\cdot)</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "accuracy",
                    "threshold",
                    "local"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Quantitative semantics for variants of LTL, such as Metric or Signal Temporal Logic (MTL/STL), have been proposed to quantify how well a sequence satisfies a temporal property, in <math alttext=\"\\mathcal{O}(poly(T\\cdot|\\varphi|))\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p1.m1\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(poly(T\\cdot|\\varphi|))</annotation></semantics></math> time.\nThese semantics have been widely used for monitoring, falsification, and control synthesis\nand differ in how the degree of satisfaction is interpreted&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib33\" title=\"\">33</a>]</cite>.\nFor instance, the standard quantitative semantics for STL, <span class=\"ltx_text ltx_font_italic\">spatial robustness</span>, uses the <math alttext=\"\\min\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p1.m2\" intent=\":literal\"><semantics><mi>min</mi><annotation encoding=\"application/x-tex\">\\min</annotation></semantics></math> and <math alttext=\"\\max\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p1.m3\" intent=\":literal\"><semantics><mi>max</mi><annotation encoding=\"application/x-tex\">\\max</annotation></semantics></math> operators to\ncompute deviations from satisfaction&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib14\" title=\"\">14</a>]</cite>; robustness of \"Always p\" is the minimum score for <math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p1.m4\" intent=\":literal\"><semantics><mi>p</mi><annotation encoding=\"application/x-tex\">p</annotation></semantics></math> over the sequence. We provide more details on this standard semantics in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A2\" title=\"Appendix B More Details on Quantitative Semantics for Temporal Logic &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">B</span></a>.\n<cite class=\"ltx_cite ltx_citemacro_citet\">Donz&#233; &amp; Maler [<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib13\" title=\"\">13</a>]</cite> propose extending this to <span class=\"ltx_text ltx_font_italic\">space-time robustness</span> which is higher if the property is satisfied earlier.</p>\n\n",
                "matched_terms": [
                    "appendix",
                    "robustness",
                    "stl"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Inspired by this literature on quantitative semantics, we propose a scoring function <span class=\"ltx_text ltx_font_italic\">LogSTOP</span>,\nthat recursively computes a score\nfor a sequence <math alttext=\"X[t_{s}:t_{e}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.p2.m1\" intent=\":literal\"><semantics><mrow><mi>X</mi><mrow><mo stretchy=\"false\">[</mo><msub><mi>t</mi><mi>s</mi></msub><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><msub><mi>t</mi><mi>e</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X[t_{s}:t_{e}]</annotation></semantics></math> satisfying temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\n, given start and end timesteps <math alttext=\"t_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m3\" intent=\":literal\"><semantics><msub><mi>t</mi><mi>s</mi></msub><annotation encoding=\"application/x-tex\">t_{s}</annotation></semantics></math> and <math alttext=\"t_{e}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m4\" intent=\":literal\"><semantics><msub><mi>t</mi><mi>e</mi></msub><annotation encoding=\"application/x-tex\">t_{e}</annotation></semantics></math>, and a smoothing window <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m5\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> that we discuss later (Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).\nLogSTOP provides a solution to the STOP problem with <math alttext=\"t_{s}=t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m6\" intent=\":literal\"><semantics><mrow><msub><mi>t</mi><mi>s</mi></msub><mo>=</mo><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t_{s}=t</annotation></semantics></math> and <math alttext=\"t_{e}=T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m7\" intent=\":literal\"><semantics><mrow><msub><mi>t</mi><mi>e</mi></msub><mo>=</mo><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">t_{e}=T</annotation></semantics></math>.\nThere are three key design choices that distinguish LogSTOP from other quantitative semantics and prior work:</p>\n\n",
                "matched_terms": [
                    "smoothing",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, the LogSTOP for a sequence with respect to a temporal property represents the log probability of the sequence\nsatisfying the temporal property if certain assumptions are met.\nConcretely, this is true when (1) the local properties represent independent events over time,\n(2) the scores for local properties reflect true log probabilities,\nand (3) temporal properties consist of compositions of independent local properties.\nWe acknowledge that these assumptions are rarely true for real-world sequences and properties.\nFor instance, the presence of \"car\" at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m1\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and <math alttext=\"t+1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m2\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t+1</annotation></semantics></math> are not independent events.\nHowever, these assumptions allow us to use ideas from probability theory for independent events to compute the score.\nMoreover, our experiments in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>\nshow that LogSTOPs are useful for applications such as query matching and ranked retrieval\neven when these assumptions are not met.</p>\n\n",
                "matched_terms": [
                    "local",
                    "matching",
                    "query",
                    "logstop",
                    "ranked",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, LogSTOP deals with potentially noisy local predictions\nby downsampling and smoothing predictions over windows of length <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m1\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math>\n(Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l8\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>).\nThis\nessentially captures the property that local property scores cannot change drastically in a short local window\n(objects cannot momentarily disappear and reappear, actions cannot change in fractions of seconds, etc.).\nNote that <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m2\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> is a hyperparameter; a higher value of <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m3\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> can be used to control for higher variance in local predictions.</p>\n\n",
                "matched_terms": [
                    "smoothing",
                    "logstop",
                    "local"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Third, LogSTOP operates in the <math alttext=\"\\log\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p5.m1\" intent=\":literal\"><semantics><mi>log</mi><annotation encoding=\"application/x-tex\">\\log</annotation></semantics></math> space to prevent underflow with fixed precision and hence assumes that\nthe scores for local properties are given in range <math alttext=\"[-\\infty,0]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p5.m2\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mrow><mo>&#8722;</mo><mi mathvariant=\"normal\">&#8734;</mi></mrow><mo>,</mo><mn>0</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[-\\infty,0]</annotation></semantics></math>, i.e., <math alttext=\"\\hat{y}(c,\\cdot)\\in[-\\infty,0]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p5.m3\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mo>&#8722;</mo><mi mathvariant=\"normal\">&#8734;</mi></mrow><mo>,</mo><mn>0</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(c,\\cdot)\\in[-\\infty,0]</annotation></semantics></math>.\nWhenever needed, we normalize the\n<math alttext=\"\\hat{y}(c,\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p5.m4\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(c,\\cdot)</annotation></semantics></math> to be in the <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p5.m5\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math> range using <math alttext=\"e^{\\hat{y}(c,\\cdot)}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p5.m6\" intent=\":literal\"><semantics><msup><mi>e</mi><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow></msup><annotation encoding=\"application/x-tex\">e^{\\hat{y}(c,\\cdot)}</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "local"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We briefly discuss how different operators\nare handled in Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>\nand defer a detailed discussion with examples to Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A1\" title=\"Appendix A More details on Algorithm 1 &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">A</span></a>.\nThe scores for logical operators, negation <math alttext=\"\\neg\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\neg\\varphi</annotation></semantics></math>, conjunction <math alttext=\"\\varphi_{1}\\land\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m2\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8743;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\land\\varphi_{2}</annotation></semantics></math>, and disjunction <math alttext=\"\\varphi_{1}\\lor\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m3\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8744;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\lor\\varphi_{2}</annotation></semantics></math>\nare computed using simple rules from probability theory.\nConcretely, LogSTOP for <math alttext=\"\\varphi_{1}\\land\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m4\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8743;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\land\\varphi_{2}</annotation></semantics></math> is the sum of the LogSTOPs for <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m5\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> and <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m6\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l12\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">12</span></a>), and\nthe LogSTOP for <math alttext=\"\\varphi_{1}\\lor\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m7\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8744;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\lor\\varphi_{2}</annotation></semantics></math> is computed using DeMorgan&#8217;s law\n(line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l14\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">14</span></a>).\nThe score for the \"next\" operator <math alttext=\"\\bigcirc\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m8\" intent=\":literal\"><semantics><mrow><mi/><mo lspace=\"0.222em\" rspace=\"0.222em\">&#9675;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\bigcirc\\varphi</annotation></semantics></math> is computed by shifting the timestep by one window (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l16\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">16</span></a>).\nScores for the \"always\" (<math alttext=\"\\square\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m9\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\varphi</annotation></semantics></math>) and \"until\" (<math alttext=\"\\varphi_{1}\\mathcal{U}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m10\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi class=\"ltx_font_mathcaligraphic\">&#119984;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathcal{U}\\varphi_{2}</annotation></semantics></math>)\noperators\nare computed recursively using the scores for these properties at the next window (lines&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l18\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">18</span></a>-<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l20\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">20</span></a>).\nInformally, the LogSTOP for Always <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m11\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m12\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> can be computed with a <span class=\"ltx_text ltx_font_italic\">\"temporal and\"</span> over <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m13\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m14\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and Always <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m15\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at the next window, <math alttext=\"t+w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m16\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">t+w</annotation></semantics></math>.\nSimilarly, the LogSTOP for <math alttext=\"\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m17\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}</annotation></semantics></math> can be computed with a <span class=\"ltx_text ltx_font_italic\">\"temporal or\"</span> over (1) <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m18\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m19\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, and (2) <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m20\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m21\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> with <math alttext=\"\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m22\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}</annotation></semantics></math> at the next window.</p>\n\n",
                "matched_terms": [
                    "appendix",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Complexity analysis for LogSTOP.</span>\nThe computational complexity of Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>,\nfor a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m1\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> with length <math alttext=\"|\\varphi|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m2\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|\\varphi|</annotation></semantics></math> and a sequence of <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m3\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> predictions\nis <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math>.\nThis uses dynamic programming to cache scores for all sub-properties over the sequence&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib15\" title=\"\">15</a>]</cite>.\nThe key observation here is that at any timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m5\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, the LogSTOP for <span class=\"ltx_text ltx_font_italic\">any</span> property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m6\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> can be computed in <math alttext=\"\\mathcal{O}(|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m7\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(|\\varphi|)</annotation></semantics></math> given the LogSTOPs for its sub-properties at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m8\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and itself at <math alttext=\"t+w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m9\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">t+w</annotation></semantics></math>.\nThis is because the LogSTOPs for temporal properties are defined recursively and there are at most <math alttext=\"|\\varphi|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m10\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|\\varphi|</annotation></semantics></math> sub-properties.\nFor <math alttext=\"T/w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m11\" intent=\":literal\"><semantics><mrow><mi>T</mi><mo>/</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">T/w</annotation></semantics></math> timesteps, this results in <math alttext=\"\\mathcal{O}((T/w)\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m12\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>/</mo><mi>w</mi></mrow><mo rspace=\"0.055em\" stretchy=\"false\">)</mo></mrow><mo rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}((T/w)\\cdot|\\varphi|)</annotation></semantics></math> time.\nSince the smoothing operation takes <math alttext=\"\\mathcal{O}(w)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m13\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(w)</annotation></semantics></math> time per window,\ncomputing LogSTOP for <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m14\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> over a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m15\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> requires <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m16\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> time.</p>\n\n",
                "matched_terms": [
                    "smoothing",
                    "logstop",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We define query matching with temporal properties as the task of predicting whether a given temporal property / query matches, or is expressed by, a sequence.\nLogSTOPs can be used for matching sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m1\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> with query <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> by comparing <math alttext=\"\\hat{y}(X,\\varphi,1,T)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m3\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>&#966;</mi><mo>,</mo><mn>1</mn><mo>,</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(X,\\varphi,1,T)</annotation></semantics></math> with an appropriate threshold.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "threshold",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">A natural first choice for such a threshold for LogSTOP is the constant <math alttext=\"\\tau=\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><mi>&#964;</mi><mo>=</mo><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\tau=\\log 0.5</annotation></semantics></math>. This threshold, is employed by existing works to determine if a video satisfies a temporal property&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>. This, however, does not scale with the length of the sequence. For instance, given a 6-frame video with constant <math alttext=\"\\log 0.9\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m2\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.9</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.9</annotation></semantics></math> scores for \"car\",\nthe LogSTOP for temporal property \"Always car\", with <math alttext=\"w=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">w=1</annotation></semantics></math>, is <math alttext=\"\\log(0.9^{6})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><msup><mn>0.9</mn><mn>6</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9^{6})</annotation></semantics></math>. This is greater than <math alttext=\"\\log(0.5)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m5\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.5</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.5)</annotation></semantics></math> and hence the video matches the query.\nHowever, when another frame with the same high score <math alttext=\"\\log(0.9)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m6\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9)</annotation></semantics></math> is added,\nthe score drops to <math alttext=\"\\log(0.9^{7})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m7\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><msup><mn>0.9</mn><mn>7</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9^{7})</annotation></semantics></math>, which is less than <math alttext=\"\\log(0.5)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m8\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.5</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.5)</annotation></semantics></math> and hence the video no longer matches the query.\nWe would ideally also like the latter to match the query since the property \"car\" is detected with high scores.</p>\n\n",
                "matched_terms": [
                    "drops",
                    "logstop",
                    "threshold",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose an adaptive threshold <math alttext=\"\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p3.m1\" intent=\":literal\"><semantics><mi>&#964;</mi><annotation encoding=\"application/x-tex\">\\tau</annotation></semantics></math> for query <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p3.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> and sequence length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p3.m3\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> as follows:</p>\n\n",
                "matched_terms": [
                    "threshold",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Informally, a sequence expresses a temporal property if the LogSTOP is higher than both random chance <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m1\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math>\nand LogSTOP using random chance predictors for local properties <math alttext=\"\\hat{y}_{0.5}(\\cdot,\\varphi,T,w)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m2\" intent=\":literal\"><semantics><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>0.5</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo>,</mo><mi>&#966;</mi><mo>,</mo><mi>T</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{0.5}(\\cdot,\\varphi,T,w)</annotation></semantics></math>.\nThis threshold can be computed in <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m3\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> and is guaranteed to match at least as many sequences as the constant <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m4\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math> threshold.\nFor properties where the score decreases with sequence length (e.g., <math alttext=\"\\square\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m5\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\varphi</annotation></semantics></math>), the adaptive threshold\nallows more sequences to match\nthe query\nthan the constant threshold.</p>\n\n",
                "matched_terms": [
                    "local",
                    "query",
                    "logstop",
                    "log⁡05log",
                    "threshold"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LogSTOP\ncan also be used for the task of ranking and\nretrieving sequences relevant to temporal properties of interest.\nFormally, given a database of <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> sequences <math alttext=\"\\mathcal{D}=\\{X_{1},\\ldots,X_{N}\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m2\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119967;</mi><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><msub><mi>X</mi><mi>N</mi></msub><mo stretchy=\"false\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{D}=\\{X_{1},\\ldots,X_{N}\\}</annotation></semantics></math>\na temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m3\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>,\nand a range of event lengths <math alttext=\"(T_{lo},T_{hi})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(T_{lo},T_{hi})</annotation></semantics></math>,\nthe goal is to rank each <math alttext=\"X_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m5\" intent=\":literal\"><semantics><msub><mi>X</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">X_{i}</annotation></semantics></math> based on whether\nit contains a subsequence <math alttext=\"X_{i}[t:t^{\\prime}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.SS2.p1.m6\" intent=\":literal\"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">[</mo><mi>t</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><msup><mi>t</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X_{i}[t:t^{\\prime}]</annotation></semantics></math> of length <math alttext=\"t^{\\prime}-t\\in[T_{lo},T_{hi}]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m7\" intent=\":literal\"><semantics><mrow><mrow><msup><mi>t</mi><mo>&#8242;</mo></msup><mo>&#8722;</mo><mi>t</mi></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">t^{\\prime}-t\\in[T_{lo},T_{hi}]</annotation></semantics></math> that expresses <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m8\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>.\nExamples of such queries include \"videos with a 10 to 20 second scene where a person is sitting down until they stand up\".\nThis task is different from the query matching task in two key ways:\nfirstly, the relative ranking of sequences is more important than absolute scores.\nSecondly and more importantly,\nthe relevance of a sequence may only be with respect to a part of the sequence (a <span class=\"ltx_text ltx_font_italic\">moment</span> in the video, for example).</p>\n\n",
                "matched_terms": [
                    "matching",
                    "logstop",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg2\" title=\"Algorithm 2 &#8227; 3.1 LogSTOP for Query Matching &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> outlines how LogSTOP can be used for ranked retrieval.\nInformally, given a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m1\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>, sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m2\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math>, and event duration <math alttext=\"(T_{lo},T_{hi})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m3\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(T_{lo},T_{hi})</annotation></semantics></math>,\nthe relevance of <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m4\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> to <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m5\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\nis defined as the maximum LogSTOP of any subsequence of <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m6\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> of length in <math alttext=\"[T_{lo},T_{hi}]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m7\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[T_{lo},T_{hi}]</annotation></semantics></math>.\nThe relevance score for any sequence can be computed in <math alttext=\"\\mathcal{O}(T^{2}\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m8\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>T</mi><mn>2</mn></msup><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T^{2}\\cdot|\\varphi|)</annotation></semantics></math> time\nsince LogSTOPs for suffix subsequences are cached with dynamic programming.\nNote\nthat this represents one way of computing scores for ranking videos, where subsequences of certain lengths are relevant to queries; there could be other variants which LogSTOP could be used for but are not considered (for example, computing the score with respect to the entire video, or only considering videos where the subsequence score is over a threshold).</p>\n\n",
                "matched_terms": [
                    "threshold",
                    "logstop",
                    "ranked",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">There are no existing benchmarks that evaluate query matching and ranked retrieval on\nvideo and speech sequences with the breadth of temporal properties discussed above.\nWe hence introduce two new benchmarks for evaluation\nusing\nthree existing datasets with frame/segment-level annotations for local properties:\nRealTLV&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>\nfor objects in videos (6 classes),\nIEMOCAP&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite>\nfor emotions in speech (4 classes), and\nAVA&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite>\nfor actions in videos (80 classes).\nWe briefly describe the two benchmarks below, with more details in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A3\" title=\"Appendix C More Details on Datasets &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">C</span></a>.</p>\n\n",
                "matched_terms": [
                    "local",
                    "matching",
                    "appendix",
                    "query",
                    "ranked",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The QMTP benchmark.</span>\nThe QMTP benchmark evaluates query matching with temporal properties over objects in video and emotions in speech sequences.\n<span class=\"ltx_text ltx_font_bold\">QMTP-video</span> consists of <math alttext=\"7468\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\"><semantics><mn>7468</mn><annotation encoding=\"application/x-tex\">7468</annotation></semantics></math> samples\n(<math alttext=\"3750\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m2\" intent=\":literal\"><semantics><mn>3750</mn><annotation encoding=\"application/x-tex\">3750</annotation></semantics></math> matching and <math alttext=\"3718\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m3\" intent=\":literal\"><semantics><mn>3718</mn><annotation encoding=\"application/x-tex\">3718</annotation></semantics></math> non-matching)\nwith <math alttext=\"10-50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mn>10</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">10-50</annotation></semantics></math> frames per sample.\n<span class=\"ltx_text ltx_font_bold\">QMTP-speech</span> contains <math alttext=\"3300\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m5\" intent=\":literal\"><semantics><mn>3300</mn><annotation encoding=\"application/x-tex\">3300</annotation></semantics></math> samples (balanced),\nincluding speech sequences with <math alttext=\"5-30\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m6\" intent=\":literal\"><semantics><mrow><mn>5</mn><mo>&#8722;</mo><mn>30</mn></mrow><annotation encoding=\"application/x-tex\">5-30</annotation></semantics></math> segments per sample.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "qmtpvideo",
                    "balanced",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The TP2VR benchmark.</span>\nThe TP2VR benchmark evaluates ranked retrieval of video sequences given temporal property queries over objects and actions.\nThe <span class=\"ltx_text ltx_font_bold\">TP2VR-objects dataset</span> consists of <math alttext=\"746\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m1\" intent=\":literal\"><semantics><mn>746</mn><annotation encoding=\"application/x-tex\">746</annotation></semantics></math> videos with <math alttext=\"39-199\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m2\" intent=\":literal\"><semantics><mrow><mn>39</mn><mo>&#8722;</mo><mn>199</mn></mrow><annotation encoding=\"application/x-tex\">39-199</annotation></semantics></math> frames, collected from the RealTLV dataset, and <math alttext=\"42\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m3\" intent=\":literal\"><semantics><mn>42</mn><annotation encoding=\"application/x-tex\">42</annotation></semantics></math> queries over objects. Each query corresponds to <math alttext=\"25-50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m4\" intent=\":literal\"><semantics><mrow><mn>25</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">25-50</annotation></semantics></math> frame temporal events and is relevant to no more than <math alttext=\"250\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m5\" intent=\":literal\"><semantics><mn>250</mn><annotation encoding=\"application/x-tex\">250</annotation></semantics></math> videos in the dataset.\nSimilarly, the <span class=\"ltx_text ltx_font_bold\">TP2VR-actions dataset</span> consists of <math alttext=\"952\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m6\" intent=\":literal\"><semantics><mn>952</mn><annotation encoding=\"application/x-tex\">952</annotation></semantics></math> videos with <math alttext=\"300\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m7\" intent=\":literal\"><semantics><mn>300</mn><annotation encoding=\"application/x-tex\">300</annotation></semantics></math> frames each, collected from 1-min segments of videos in the AVA dataset,\nwith <math alttext=\"70\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m8\" intent=\":literal\"><semantics><mn>70</mn><annotation encoding=\"application/x-tex\">70</annotation></semantics></math> queries over actions.\nEach query corresponds to <math alttext=\"10\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m9\" intent=\":literal\"><semantics><mn>10</mn><annotation encoding=\"application/x-tex\">10</annotation></semantics></math>-second temporal events and is relevant to no more than <math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m10\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> videos in the dataset.</p>\n\n",
                "matched_terms": [
                    "ranked",
                    "retrieval",
                    "tp2vrobjects",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methods.</span> We evaluate LogSTOP for temporal query matching\nusing simple neural predictors for object and emotion detection.\nWe use YOLOv8&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib23\" title=\"\">23</a>]</cite>, OWLv2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib34\" title=\"\">34</a>]</cite>, and Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite> to obtain\nframe-level object detection scores.\nWe use HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite> for segment-level emotion recognition.\nThese scores are matched using the adaptive threshold discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S3.SS1\" title=\"3.1 LogSTOP for Query Matching &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">3.1</span></a>.\nFor QMTP-video, we compare against two Large Vision Language Models (LVLMs),\nnamely <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib27\" title=\"\">27</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib45\" title=\"\">45</a>]</cite>,\nand the PCTL-based method, NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>.\nFor QMTP-speech, we compare against two Large Audio Language Models (LALMs),\nnamely <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib10\" title=\"\">10</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">Qwen2-Audio-7B-Instruct</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib11\" title=\"\">11</a>]</cite>.\nWe provide more details on the prompts and parameters used for all methods in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A4\" title=\"Appendix D More details on Query Matching Methods &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">D</span></a>.</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "matching",
                    "appendix",
                    "query",
                    "logstop",
                    "method",
                    "threshold",
                    "qmtpvideo"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Results.</span>\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F2\" title=\"Figure 2 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> shows the balanced accuracies of different methods on the QMTP-video and QMTP-speech datasets.\nLogSTOP outperforms other methods by at least <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> on QMTP-video and QMTP-speech using object detection scores from YOLOv8 and emotion detection scores from HuBERT respectively. LogSTOP with Grounding DINO also performs better than the baselines.\nThe accuracies of detecting objects with scores <math alttext=\"&gt;0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">&gt;0.5</annotation></semantics></math> for YOLO, Grounding DINO and OWLv2 are <math alttext=\"46\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m3\" intent=\":literal\"><semantics><mrow><mn>46</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">46\\%</annotation></semantics></math>, <math alttext=\"38\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m4\" intent=\":literal\"><semantics><mrow><mn>38</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">38\\%</annotation></semantics></math> and <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m5\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> resp. which reflect the order of their performances on query matching.</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "balanced",
                    "matching",
                    "query",
                    "logstop",
                    "results",
                    "qmtpvideo"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LogSTOP consistently reports accuracies over <math alttext=\"75\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p3.m1\" intent=\":literal\"><semantics><mrow><mn>75</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">75\\%</annotation></semantics></math> on all query categories.\n<span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span> and <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>\nperform better on simple temporal queries than queries with boolean/temporal compositions.\nNSVS-TL also performs poorly on\ncategories with compositions over boolean expressions.\nThese results\nsuggest that the understanding of temporal queries is still an open problem for LVLMs and LALMs. Moreover, the higher accuracy of LogSTOP with much smaller neural models suggests that using well-defined logics for reasoning is beneficial.</p>\n\n",
                "matched_terms": [
                    "accuracy",
                    "logstop",
                    "results",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methods.</span> We evaluate LogSTOP for ranked retrieval using Grounding DINO for object detection and Detectron2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib42\" title=\"\">42</a>]</cite> with SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> for action detection.\nSince there are no methods specifically designed for temporal property to sequence retrieval, we adapt existing text-to-video retrieval methods for this task. Since LogSTOP does not require explicit training for retrieval, we specifically only include zero-shot text-to-video retrieval methods for comparison.\nWe include <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite>, a large multimodal model that jointly embeds videos and text queries. Inspired by ELIOT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib29\" title=\"\">29</a>]</cite>, we also include embedding similarity between video captions and text queries.\nWe refer to this as <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> and use\n<span class=\"ltx_text ltx_font_typewriter\">LLaVA-NeXT-Video-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib46\" title=\"\">46</a>]</cite> for generating video captions and <span class=\"ltx_text ltx_font_typewriter\">SentenceBERT</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib37\" title=\"\">37</a>]</cite> for embedding captions and queries. More details are provided in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A5\" title=\"Appendix E More details on the Ranked Retrieval methods &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">E</span></a>.</p>\n\n",
                "matched_terms": [
                    "appendix",
                    "logstop",
                    "ranked",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Metrics.</span>\nFollowing existing work, we include standard retrieval metrics such as Recall at <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m1\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> (R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m2\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math>, where <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m3\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> is the number of relevant results) for evaluating coverage, and mean / median ranks of first retrieval (MnR / MdR).\nSince multiple videos could be relevant to a query, we also evaluate if relevant results are ranked higher using Precision (P@<math alttext=\"\\{1,r\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mi>r</mi><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{1,r\\}</annotation></semantics></math>), and mean average precision (mAP).</p>\n\n",
                "matched_terms": [
                    "query",
                    "mnr",
                    "ranked",
                    "results",
                    "map",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Results.</span>\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F4\" title=\"Figure 4 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>\npresents the results for ranked retrieval on the TP2VR benchmark.\nThe performance of all methods on TP2VR-actions is lower than that on TP2VR-objects due to the significantly higher number of classes (<math alttext=\"80\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m1\" intent=\":literal\"><semantics><mn>80</mn><annotation encoding=\"application/x-tex\">80</annotation></semantics></math> actions vs. <math alttext=\"6\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m2\" intent=\":literal\"><semantics><mn>6</mn><annotation encoding=\"application/x-tex\">6</annotation></semantics></math> objects) and lower number of relevant results (on average, <math alttext=\"21\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m3\" intent=\":literal\"><semantics><mn>21</mn><annotation encoding=\"application/x-tex\">21</annotation></semantics></math> vs. <math alttext=\"163\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m4\" intent=\":literal\"><semantics><mn>163</mn><annotation encoding=\"application/x-tex\">163</annotation></semantics></math> relevant videos).\nLogSTOP with GroundingDINO outperforms <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> and <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> on TP2VR-objects by\nat least <math alttext=\"28\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m5\" intent=\":literal\"><semantics><mrow><mn>28</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">28\\%</annotation></semantics></math> in mAP and <math alttext=\"24\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m6\" intent=\":literal\"><semantics><mrow><mn>24</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">24\\%</annotation></semantics></math> in R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m7\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math>, indicating that relevant results are retrieved at earlier ranks and the retrieved results include more relevant items than other methods.\nSimilarly, LogSTOP with SlowR50 outperforms baselines by more than <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m8\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> and <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m9\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of mAP and R@r respectively.\nThe first relevant result is also retrieved earlier by LogSTOP as is indicated by at least a <math alttext=\"24\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m10\" intent=\":literal\"><semantics><mrow><mn>24</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">24\\%</annotation></semantics></math> higher P@1 and better mean ranks;\non TP2VR-actions, LogSTOP retrieves the first relevant result at rank <math alttext=\"7.9\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m11\" intent=\":literal\"><semantics><mn>7.9</mn><annotation encoding=\"application/x-tex\">7.9</annotation></semantics></math> while <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> and <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> retrieve it at ranks <math alttext=\"&gt;20\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m12\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>20</mn></mrow><annotation encoding=\"application/x-tex\">&gt;20</annotation></semantics></math>.\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F5\" title=\"Figure 5 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents examples of ranking using the three methods.\nWe discuss these in detail in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A8\" title=\"Appendix H Examples &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">H</span></a>.</p>\n\n",
                "matched_terms": [
                    "map",
                    "appendix",
                    "logstop",
                    "ranked",
                    "results",
                    "groundingdino",
                    "tp2vrobjects",
                    "retrieval",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Popular text-video retrieval methods include CLIP4Clip&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib32\" title=\"\">32</a>]</cite>, TS2-Net&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib31\" title=\"\">31</a>]</cite>,&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib4\" title=\"\">4</a>]</cite>, which employ training to improve embeddings for retrieval, and zero-shot methods such as mPLUG&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite> and ELIOT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib29\" title=\"\">29</a>]</cite>. Since we use off-the-shelf models with LogSTOP for retrieval, we only include the latter for comparison.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this work, we\npresent the\nproblem of assigning scores for temporal properties (STOPs) given potentially noisy score predictors for local properties. We represent these properties using LTL and propose a scoring function LogSTOP for assigning STOPs. We then introduce the QMTP and TP2VR benchmarks for evaluating query matching and ranked retrieval\nwith temporal properties\nover objects / actions in videos and emotions in speech. LogSTOP with simple neural predictors outperforms LVLMs / LALMs, Temporal Logic-based baselines, and text-to-retrieval methods on the benchmarks.\n</p>\n\n",
                "matched_terms": [
                    "local",
                    "matching",
                    "query",
                    "logstop",
                    "ranked",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Limitations. </span>\nThere are properties such as \"there are always 2 cars\" that cannot directly be expressed in LTL.\nFuture work should hence explore more expressive logics&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib22\" title=\"\">22</a>]</cite> or construct local predictors for complex properties.\nWhile we only focus on sequences with single modalities, it will be interesting to see LogSTOP being for multi-modal applications where the local properties are over different modalities with scores from different local predictors.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "local"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> describes how LogSTOP is computed for a sequence <math alttext=\"X[t_{s}:t_{e}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A1.p1.m1\" intent=\":literal\"><semantics><mrow><mi>X</mi><mrow><mo stretchy=\"false\">[</mo><msub><mi>t</mi><mi>s</mi></msub><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><msub><mi>t</mi><mi>e</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X[t_{s}:t_{e}]</annotation></semantics></math> with respect to temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p1.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>, given start and end timesteps <math alttext=\"t_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p1.m3\" intent=\":literal\"><semantics><msub><mi>t</mi><mi>s</mi></msub><annotation encoding=\"application/x-tex\">t_{s}</annotation></semantics></math> and <math alttext=\"t_{e}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p1.m4\" intent=\":literal\"><semantics><msub><mi>t</mi><mi>e</mi></msub><annotation encoding=\"application/x-tex\">t_{e}</annotation></semantics></math>, and smoothing window <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p1.m5\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math>. Here we discuss the intuition behind the operators, along with some examples:</p>\n\n",
                "matched_terms": [
                    "smoothing",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Downsampling and average smoothing of confidence scores of local properties.</span> Firstly, LogSTOP downsamples the sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m1\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> to contiguous blocks of length <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m2\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math>. The confidence scores for any local property in each block starting at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m3\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, <math alttext=\"\\hat{y}(c,t^{\\prime}\\in[t,t+w])\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m4\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>c</mi><mo>,</mo><msup><mi>t</mi><mo>&#8242;</mo></msup></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mi>t</mi><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><mo stretchy=\"false\">]</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(c,t^{\\prime}\\in[t,t+w])</annotation></semantics></math> are first averaged after being normalized to the <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m5\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math> range. The confidence score for each block is then the <math alttext=\"\\log\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m6\" intent=\":literal\"><semantics><mi>log</mi><annotation encoding=\"application/x-tex\">\\log</annotation></semantics></math> of this averaged <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m7\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math>-normalized score. This series of downsampling, normalizing and smoothing operations starting at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m8\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> for a window <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m9\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> can be seen on line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l8\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>. For example, given a sequence of log scores for object \"car\",</p>\n\n",
                "matched_terms": [
                    "smoothing",
                    "logstop",
                    "local"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this example, note that the score <math alttext=\"\\log(0.1)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m11\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.1)</annotation></semantics></math> is likely incorrect since the car cannot momentarily disappear. Downsampling and then smoothing reduce the impact of this incorrect local prediction hence essentially capturing the property that confidence scores cannot drastically change in a local window.\nNote that this is done online for each successive block and the shifting for temporal operators is handled by the Next operator (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l16\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">16</span></a>).</p>\n\n",
                "matched_terms": [
                    "smoothing",
                    "local"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The LogSTOP for <math alttext=\"\\varphi_{1}\\land\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m1\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8743;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\land\\varphi_{2}</annotation></semantics></math> at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m2\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> is high only when the scores for both <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m3\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> and <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m4\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> are high (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l12\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">12</span></a>). For example, given high scores <math alttext=\"\\hat{y}({car},t,w)=\\log(0.9)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m5\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({car},t,w)=\\log(0.9)</annotation></semantics></math> and <math alttext=\"\\hat{y}({pedestrian},t,w)=0.9\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m6\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0.9</mn></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({pedestrian},t,w)=0.9</annotation></semantics></math>, the score for \"car and pedestrian\" <math alttext=\"\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.9)=\\log(0.81)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m7\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.81</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.9)=\\log(0.81)</annotation></semantics></math>. However, if either of the scores are low, e.g., if <math alttext=\"\\hat{y}({pedestrian},t,w)=0.1\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m8\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({pedestrian},t,w)=0.1</annotation></semantics></math>, the score drops significantly to <math alttext=\"\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.1)=\\log(0.09)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m9\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.09</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.1)=\\log(0.09)</annotation></semantics></math>. Inspired by DeMorgan&#8217;s law, the LogSTOP for <math alttext=\"\\varphi_{1}\\lor\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m10\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8744;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\lor\\varphi_{2}</annotation></semantics></math> is simply the score for equivalent property <math alttext=\"\\neg(\\neg\\varphi_{1}\\land\\neg\\varphi_{2})\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m11\" intent=\":literal\"><semantics><mrow><mo>&#172;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo rspace=\"0.167em\">&#172;</mo><msub><mi>&#966;</mi><mn>1</mn></msub></mrow><mo>&#8743;</mo><mrow><mo rspace=\"0.167em\">&#172;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg(\\neg\\varphi_{1}\\land\\neg\\varphi_{2})</annotation></semantics></math> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l14\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">14</span></a>). This is intuitively only low when both the scores are low.</p>\n\n",
                "matched_terms": [
                    "drops",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The STL quantitative semantics, also called <span class=\"ltx_text ltx_font_italic\">robustness</span> <math alttext=\"\\rho\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p6.m1\" intent=\":literal\"><semantics><mi>&#961;</mi><annotation encoding=\"application/x-tex\">\\rho</annotation></semantics></math>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib14\" title=\"\">14</a>]</cite>, is defined as follows to indicate how much a signal satisfies or violates the formula:</p>\n\n",
                "matched_terms": [
                    "robustness",
                    "stl"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We argue that LogSTOP offers advantages over such semantics in the context of the STOP problem.\nThis is primarily because the traditional robustness measure is defined using <math alttext=\"\\max\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m1\" intent=\":literal\"><semantics><mi>max</mi><annotation encoding=\"application/x-tex\">\\max</annotation></semantics></math> and <math alttext=\"\\min\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m2\" intent=\":literal\"><semantics><mi>min</mi><annotation encoding=\"application/x-tex\">\\min</annotation></semantics></math> functions over temporal and logical formulae.\nThe measure, hence, only reflects the most violating or most satisfying timestep in the sequence. For example, consider assigning confidence scores to the property \"Always car\" in two different scenarios:</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "robustness"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Ideally, the confidence score for \"Always car\" should follow the order:\n<math alttext=\"\\hat{y}_{1}(\\square{car},\\cdot)&gt;\\hat{y}_{2}(\\square{car},\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m3\" intent=\":literal\"><semantics><mrow><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>1</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>2</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{1}(\\square{car},\\cdot)&gt;\\hat{y}_{2}(\\square{car},\\cdot)</annotation></semantics></math>.\nThe standard STL semantics, however, would assign the same robustness to both sequences for any <math alttext=\"\\tau&gt;0.1\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m4\" intent=\":literal\"><semantics><mrow><mi>&#964;</mi><mo>&gt;</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\tau&gt;0.1</annotation></semantics></math> since the most violating score is <math alttext=\"\\log(0.1)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m5\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.1)</annotation></semantics></math> in either case. This makes the robustness measure unsuitable for downstream applications that require such ordering: for example, ranking / search.</p>\n\n",
                "matched_terms": [
                    "robustness",
                    "stl"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Ideally, the confidence scores for \"car and pedestrian\" should follow the order:\n<math alttext=\"\\hat{y}_{1}({car}\\land{pedestrian},t=0)&gt;\\hat{y}_{2}({car}\\land{pedestrian},t=0)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m2\" intent=\":literal\"><semantics><mrow><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>1</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></mrow><mo>,</mo><mi>t</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>2</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></mrow><mo>,</mo><mi>t</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{1}({car}\\land{pedestrian},t=0)&gt;\\hat{y}_{2}({car}\\land{pedestrian},t=0)</annotation></semantics></math> since <math alttext=\"\\hat{y}_{1}({car},t=0)&gt;\\hat{y}_{2}({car},t=0)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m3\" intent=\":literal\"><semantics><mrow><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>1</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>,</mo><mi>t</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>2</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>,</mo><mi>t</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{1}({car},t=0)&gt;\\hat{y}_{2}({car},t=0)</annotation></semantics></math>. The robustness for both the cases is the same, i.e., <math alttext=\"\\log(0.6)-\\log(0.5)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m4\" intent=\":literal\"><semantics><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.6</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8722;</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.5</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.6)-\\log(0.5)</annotation></semantics></math>, because of the <math alttext=\"\\min\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m5\" intent=\":literal\"><semantics><mi>min</mi><annotation encoding=\"application/x-tex\">\\min</annotation></semantics></math> semantics for the Boolean <span class=\"ltx_text ltx_font_italic\">and</span> operator. The LogSTOP for the two cases are <math alttext=\"\\log(0.9)+\\log(0.6)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m6\" intent=\":literal\"><semantics><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.6</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9)+\\log(0.6)</annotation></semantics></math> and <math alttext=\"\\log(0.6)+\\log(0.6)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m7\" intent=\":literal\"><semantics><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.6</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.6</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.6)+\\log(0.6)</annotation></semantics></math> respectively, which reflect the expected order.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "robustness"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Note that the only difference between the two scenarios is the score for \"pedestrian\" at <math alttext=\"t=2\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m1\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">t=2</annotation></semantics></math> (a high score of <math alttext=\"0.9\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m2\" intent=\":literal\"><semantics><mn>0.9</mn><annotation encoding=\"application/x-tex\">0.9</annotation></semantics></math> for the first scenario and a lower score of <math alttext=\"0.6\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m3\" intent=\":literal\"><semantics><mn>0.6</mn><annotation encoding=\"application/x-tex\">0.6</annotation></semantics></math> for the second scenario) . The robustness for the two cases is the same because of the <math alttext=\"\\min\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m4\" intent=\":literal\"><semantics><mi>min</mi><annotation encoding=\"application/x-tex\">\\min</annotation></semantics></math> semantics within the <span class=\"ltx_text ltx_font_italic\">Until</span> operator. LogSTOP assigns a higher score for the first scenario because of the difference at <math alttext=\"t=2\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m5\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">t=2</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "robustness"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The QMTP dataset.</span>\nFor any temporal property template (for example, \"p1 Until p2\") and samples from these datasets, we identify matching and non-matching sequences of desired length as follows: for every sample, we first identify candidates for local properties in the template (p1, p2, etc.) as the set of all ground-truth objects / emotions in the sequence. We then use the standard LTL semantics over the frame/segment-level ground-truth labels to collect matching and non-matching subsequences of the desired length. This creates a TP-query matching dataset for an arbitrary set of temporal properties as long as these properties are sufficiently expressed by sequences from the underlying dataset. Moreover, this pipeline is agnostic to the choice of the dataset since it only requires sequences of ground-truth labels for local properties. We use this pipeline to create\nthe <span class=\"ltx_text ltx_font_bold\">QMTP-video dataset</span> with <math alttext=\"7468\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m1\" intent=\":literal\"><semantics><mn>7468</mn><annotation encoding=\"application/x-tex\">7468</annotation></semantics></math> samples (<math alttext=\"3750\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m2\" intent=\":literal\"><semantics><mn>3750</mn><annotation encoding=\"application/x-tex\">3750</annotation></semantics></math> matching and <math alttext=\"3718\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m3\" intent=\":literal\"><semantics><mn>3718</mn><annotation encoding=\"application/x-tex\">3718</annotation></semantics></math> non-matching) with video sequences of lengths <math alttext=\"\\{10,20,30,40,50\\}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mn>10</mn><mo>,</mo><mn>20</mn><mo>,</mo><mn>30</mn><mo>,</mo><mn>40</mn><mo>,</mo><mn>50</mn><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{10,20,30,40,50\\}</annotation></semantics></math>. For each target length, this dataset contains approximately <math alttext=\"100\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m5\" intent=\":literal\"><semantics><mn>100</mn><annotation encoding=\"application/x-tex\">100</annotation></semantics></math> samples corresponding to each of the <math alttext=\"15\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m6\" intent=\":literal\"><semantics><mn>15</mn><annotation encoding=\"application/x-tex\">15</annotation></semantics></math> property templates. Similarly, we create the <span class=\"ltx_text ltx_font_bold\">QMTP-speech dataset</span> with <math alttext=\"3300\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m7\" intent=\":literal\"><semantics><mn>3300</mn><annotation encoding=\"application/x-tex\">3300</annotation></semantics></math> samples, including speech sequences of lengths in ranges <math alttext=\"\\{5-10,10-20,20-30\\}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m8\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mrow><mn>5</mn><mo>&#8722;</mo><mn>10</mn></mrow><mo>,</mo><mrow><mn>10</mn><mo>&#8722;</mo><mn>20</mn></mrow><mo>,</mo><mrow><mn>20</mn><mo>&#8722;</mo><mn>30</mn></mrow><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{5-10,10-20,20-30\\}</annotation></semantics></math>. The QMTP-speech dataset only contains samples from <math alttext=\"11/15\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m9\" intent=\":literal\"><semantics><mrow><mn>11</mn><mo>/</mo><mn>15</mn></mrow><annotation encoding=\"application/x-tex\">11/15</annotation></semantics></math> property templates. This is because there are no sequences matching <math alttext=\"4\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m10\" intent=\":literal\"><semantics><mn>4</mn><annotation encoding=\"application/x-tex\">4</annotation></semantics></math> properties \"Always p1 and Eventually p2\", \"Always (p1 and p2)\", \"(p1 and p2) Until p3\", and \"(p1 and p2) Until Eventually p3\" since two emotions cannot be expressed at the same time.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "local",
                    "qmtpvideo"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">LogSTOP with simple trained neural predictors:</span> We use YOLOv8&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib23\" title=\"\">23</a>]</cite>, Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite>, and OWLv2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib34\" title=\"\">34</a>]</cite>, to get confidence scores for object detection in video frames, and HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite> for speech emotion recognition in audio segments. Since the scores are in the <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math> range, we normalize them in the <math alttext=\"[-\\infty,0]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m2\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mrow><mo>&#8722;</mo><mi mathvariant=\"normal\">&#8734;</mi></mrow><mo>,</mo><mn>0</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[-\\infty,0]</annotation></semantics></math> range using the <math alttext=\"\\log\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m3\" intent=\":literal\"><semantics><mi>log</mi><annotation encoding=\"application/x-tex\">\\log</annotation></semantics></math> operation, as required by LogSTOP.\nA video matches query <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m4\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> if LogSTOP <math alttext=\"\\hat{y}(\\varphi,0,w)&gt;\\tau(\\varphi,0)\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m5\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><mi>&#964;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(\\varphi,0,w)&gt;\\tau(\\varphi,0)</annotation></semantics></math> (and vice versa for non-matching examples). The estimates are evaluated against ground-truth labels <math alttext=\"y(\\varphi,0)\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m6\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(\\varphi,0)</annotation></semantics></math>. The window <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m7\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> is selected as follows: <math alttext=\"w=2\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m8\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">w=2</annotation></semantics></math> for <math alttext=\"T&lt;20\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m9\" intent=\":literal\"><semantics><mrow><mi>T</mi><mo>&lt;</mo><mn>20</mn></mrow><annotation encoding=\"application/x-tex\">T&lt;20</annotation></semantics></math> and <math alttext=\"w=5\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m10\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">w=5</annotation></semantics></math> otherwise.</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "logstop",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Large Vision Language Models (LVLMs)</span>. We evaluate two popular LVLMs on query matching for videos: <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib27\" title=\"\">27</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib45\" title=\"\">45</a>]</cite>.\nFor the \"always car\" example, we provide the models with the video sequence and a text prompt \"Is a car detected in all frames of this video?\". The response is considered correct if the model responds with \"Yes\" or \"No\" for matching and non-matching samples respectively. <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span> supports a context window of <math alttext=\"4096\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m1\" intent=\":literal\"><semantics><mn>4096</mn><annotation encoding=\"application/x-tex\">4096</annotation></semantics></math> tokens while <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span> can handle up to 2000 frames. We set the maximum tokens to generate to <math alttext=\"60\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m2\" intent=\":literal\"><semantics><mn>60</mn><annotation encoding=\"application/x-tex\">60</annotation></semantics></math> and <math alttext=\"1024\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m3\" intent=\":literal\"><semantics><mn>1024</mn><annotation encoding=\"application/x-tex\">1024</annotation></semantics></math> respectively and use a temperature of 0.1 and standard values for the other parameters.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Large Audio Language Models (LALMs)</span>. Similarly, we evaluate two popular LALMs on query matching for speech: <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib10\" title=\"\">10</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">Qwen2-Audio-7B-Instruct</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib11\" title=\"\">11</a>]</cite>.\nFor the \"eventually happy\" example, we provide the models with the audio sequence and a text prompt \"Does the speaker sound happy at some time in this audio clip?\". We set the sampling rate to <math alttext=\"16000\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p3.m1\" intent=\":literal\"><semantics><mn>16000</mn><annotation encoding=\"application/x-tex\">16000</annotation></semantics></math> and generate a maximum of <math alttext=\"256\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p3.m2\" intent=\":literal\"><semantics><mn>256</mn><annotation encoding=\"application/x-tex\">256</annotation></semantics></math> new tokens, with standard values for other parameters.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>.</span> Proposed for event detection in videos, NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite> uses the PCTL-based model checker STORM&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib20\" title=\"\">20</a>]</cite> to identify video frame subsequences where a certain event is detected. NSVS-TL reports state-of-the-art performance on detecting temporal events in videos, surpassing large language models such as GPT-4.\nFor our task, we specify the target query in PCTL (\"always car\" is <math alttext=\"P&gt;0.5[G\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A4.p4.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo stretchy=\"false\">[</mo><mi>G</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5[G</annotation></semantics></math> \"<math alttext=\"{car}\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p4.m2\" intent=\":literal\"><semantics><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><annotation encoding=\"application/x-tex\">{car}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p4.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math>) and the response is considered correct if NSVS-TL returns / does not return the entire video sequence as output for a matching / non-matching query respectively.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "performance",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">LogSTOP.</span>\nWe use LogSTOP with Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite> for TP2VR-objects and with SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> for TP2VR-actions respectively.\nWe repurpose the script from <span class=\"ltx_text ltx_font_typewriter\">tutorials/video_detection_example</span> at <span class=\"ltx_text ltx_font_typewriter\">https://github.com/facebookresearch/pytorchvideo/</span>\nto run SlowR50 on videos from the TP2VR-actions dataset.\nWe use a smoothing window <math alttext=\"w=5\" class=\"ltx_Math\" display=\"inline\" id=\"A5.p1.m1\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">w=5</annotation></semantics></math> for all retrieval experiments.</p>\n\n",
                "matched_terms": [
                    "smoothing",
                    "logstop",
                    "retrieval",
                    "tp2vrobjects"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">CaptionSim.</span>\nInspired by ELIOT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib29\" title=\"\">29</a>]</cite>, we also include embedding similarity between video captions and text queries as a baseline.\nWe refer to this as <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> in the discussion, and use\n<span class=\"ltx_text ltx_font_typewriter\">LLaVA-NeXT-Video-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib46\" title=\"\">46</a>]</cite> for generating video captions and <span class=\"ltx_text ltx_font_typewriter\">SentenceBERT/all-MiniLM-L6-v2</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib37\" title=\"\">37</a>]</cite> for embedding captions and queries.\nDue to the limited context window of <span class=\"ltx_text ltx_font_typewriter\">LLaVA-NeXT-Video-7B</span>, we divide videos in sections of 50 frames and generate captions for each before concatenating them together. We use the following prompt to generate the captions for the first 50 frames: \"Describe this video in detail, listing objects in each frame. Keep the descriptions concise.\" for TP2VR-objects.\nFor any next sections, we use the prompt \"Continue describing the video, listing objects in each frame. You are now at frame i, you have already described the previous i frames.\"\nFor TP2VR-actions, we use the prompt \"Describe this video in detail, listing actions and objects in each frame. Keep the descriptions concise.\" We set the <span class=\"ltx_text ltx_font_typewriter\">max_new_tokens</span> to 1024.</p>\n\n",
                "matched_terms": [
                    "described",
                    "tp2vrobjects"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> because the implementation of ELIOT is not publicly available. Our local implementation of ELIOT did not report good results (the video captions generated by &#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib40\" title=\"\">40</a>]</cite> did not include mentions of objects or actions).</p>\n\n",
                "matched_terms": [
                    "results",
                    "local"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The prompts for LVLMs for query matching on QMTP-video are as follows:</p>\n\n",
                "matched_terms": [
                    "matching",
                    "qmtpvideo",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The prompts for LALMs for query matching on QMTP-speech are as follows:</p>\n\n",
                "matched_terms": [
                    "matching",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The queries for <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> and <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> for retrieval on TP2VR-objects are as follows (<math alttext=\"t_{lo}=25\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p11.m1\" intent=\":literal\"><semantics><mrow><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>=</mo><mn>25</mn></mrow><annotation encoding=\"application/x-tex\">t_{lo}=25</annotation></semantics></math> and <math alttext=\"t_{hi}=50\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p11.m2\" intent=\":literal\"><semantics><mrow><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo>=</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">t_{hi}=50</annotation></semantics></math> here):</p>\n\n",
                "matched_terms": [
                    "retrieval",
                    "tp2vrobjects"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F5\" title=\"Figure 5 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents examples of ranking using the three methods.\nIn the first example, the video captions used by <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> do not include smaller objects that might be relevant to the query (\"car\" in this example). In the second example, the two actions are mentioned in the caption &#8211; the video is ranked lower than other videos with more mentions of the actions (\"stand\" and \"hand clap\" in this case).\nThis demonstrates that while caption-based methods outperform joint model embeddings (<span class=\"ltx_text ltx_font_typewriter\">mPLUG</span>), they rely on semantic similarity between captions and text to determine relevance, which might not be sufficient for effective retrieval with temporal queries.</p>\n\n",
                "matched_terms": [
                    "ranked",
                    "retrieval",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A9.F6\" title=\"Figure 6 &#8227; Appendix I Adaptive threshold vs. constant threshold &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> presents a comparison of the adaptive threshold and the constant <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"A9.p1.m1\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math> threshold for all temporal property templates, using LogSTOPs for matching and non-matching sequences from the QMTP-video (detections using YOLOv8).</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "matching",
                    "log⁡05log",
                    "threshold",
                    "qmtpvideo"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we present the results for ranked retrieval with different methods. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.SS1\" title=\"J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">J.1</span></a> reports these results (with additional metrics, including Precision@5 and Precision@10).</p>\n\n",
                "matched_terms": [
                    "ranked",
                    "retrieval",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we present the query matching results for the QMTP datasets.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.SS2\" title=\"J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">J.2</span></a> presents the results (balanced accuracies) aggregated by category.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.T4\" title=\"Table 4 &#8227; J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.T5\" title=\"Table 5 &#8227; J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> report the results for the 15 temporal property templates for QMTP-video and QMTP-speech respectively.</p>\n\n",
                "matched_terms": [
                    "balanced",
                    "matching",
                    "query",
                    "results",
                    "qmtpvideo"
                ]
            }
        ]
    },
    "A10.SS1.tab1": {
        "caption": "Table 2: Retrieval results on the TP2VR datasets.",
        "body": "<table class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_border_tt\"/>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_tt\">\n<span class=\"ltx_text ltx_font_bold\">P@1</span> <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"A10.SS1.m1\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">\n<span class=\"ltx_text ltx_font_bold\">P@5</span> <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"A10.SS1.m2\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">\n<span class=\"ltx_text ltx_font_bold\">P@10</span> <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"A10.SS1.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">\n<span class=\"ltx_text ltx_font_bold\">P@r</span> <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"A10.SS1.m4\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">\n<span class=\"ltx_text ltx_font_bold\">mAP</span> <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"A10.SS1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">\n<span class=\"ltx_text ltx_font_bold\">R@r</span> <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"A10.SS1.m6\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">\n<span class=\"ltx_text ltx_font_bold\">MnR</span> <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"A10.SS1.m7\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">\n<span class=\"ltx_text ltx_font_bold\">MdR</span> <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"A10.SS1.m8\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"10\">\n<span class=\"ltx_ERROR undefined\">\\rowcolor</span>gray!20 &#8194;&#8202;&#8194;&#8202; <span class=\"ltx_text ltx_font_italic\">TP2VR-objects (mean <math alttext=\"r=163\" class=\"ltx_Math\" display=\"inline\" id=\"A10.SS1.m9\" intent=\":literal\"><semantics><mrow><mi>r</mi><mo>=</mo><mn>163</mn></mrow><annotation encoding=\"application/x-tex\">r=163</annotation></semantics></math>)</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text ltx_font_italic\">mPLUG</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_border_t\"/>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\">0.10</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.22</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.33</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.35</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.34</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.35</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">8.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">7.0</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_italic\">CaptionSim</span></td>\n<td class=\"ltx_td ltx_nopad_r\"/>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center\">0.50</td>\n<td class=\"ltx_td ltx_align_center\">0.64</td>\n<td class=\"ltx_td ltx_align_center\">0.57</td>\n<td class=\"ltx_td ltx_align_center\">0.35</td>\n<td class=\"ltx_td ltx_align_center\">0.36</td>\n<td class=\"ltx_td ltx_align_center\">0.35</td>\n<td class=\"ltx_td ltx_align_center\">3.1</td>\n<td class=\"ltx_td ltx_align_center\">2.0</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_italic\">LogSTOP (GroundingDINO)</span></td>\n<td class=\"ltx_td ltx_nopad_r\"/>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center\">0.79</td>\n<td class=\"ltx_td ltx_align_center\">0.77</td>\n<td class=\"ltx_td ltx_align_center\">0.79</td>\n<td class=\"ltx_td ltx_align_center\">0.59</td>\n<td class=\"ltx_td ltx_align_center\">0.64</td>\n<td class=\"ltx_td ltx_align_center\">0.59</td>\n<td class=\"ltx_td ltx_align_center\">2.0</td>\n<td class=\"ltx_td ltx_align_center\">1.0</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"10\">\n<span class=\"ltx_ERROR undefined\">\\rowcolor</span>gray!20 &#8194;&#8202;&#8194;&#8202; <span class=\"ltx_text ltx_font_italic\">TP2VR-actions (mean <math alttext=\"r=21\" class=\"ltx_Math\" display=\"inline\" id=\"A10.SS1.m10\" intent=\":literal\"><semantics><mrow><mi>r</mi><mo>=</mo><mn>21</mn></mrow><annotation encoding=\"application/x-tex\">r=21</annotation></semantics></math>)</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text ltx_font_italic\">mPLUG</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_border_t\"/>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\">0.07</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.05</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.06</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.05</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.06</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.05</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">60.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">28.5</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_italic\">CaptionSim</span></td>\n<td class=\"ltx_td ltx_nopad_r\"/>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center\">0.23</td>\n<td class=\"ltx_td ltx_align_center\">0.15</td>\n<td class=\"ltx_td ltx_align_center\">0.17</td>\n<td class=\"ltx_td ltx_align_center\">0.11</td>\n<td class=\"ltx_td ltx_align_center\">0.09</td>\n<td class=\"ltx_td ltx_align_center\">0.11</td>\n<td class=\"ltx_td ltx_align_center\">20.4</td>\n<td class=\"ltx_td ltx_align_center\">5.0</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text ltx_font_italic\">LogSTOP (SlowR50)</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_border_bb\"/>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_bb\">0.47</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.38</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.37</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.27</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.28</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.27</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">7.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">2.0</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "mdr",
            "r21r21",
            "tp2vr",
            "mnr",
            "groundingdino",
            "↓downarrow",
            "r163r163",
            "captionsim",
            "retrieval",
            "mean",
            "mplug",
            "logstop",
            "results",
            "map",
            "datasets",
            "↑uparrow",
            "tp2vractions",
            "method",
            "tp2vrobjects",
            "slowr50",
            "rowcolorgray20",
            "p10"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Neural models such as YOLO and HuBERT can be used to detect local properties such as objects (\"car\") and emotions (\"angry\") in individual frames of videos and audio clips respectively. The likelihood of these detections is indicated by scores in [0, 1]. Lifting these scores to temporal properties over sequences can be useful for several downstream applications such as query matching (e.g., \"does the speaker eventually sound happy in this audio clip?\"), and ranked retrieval (e.g., \"retrieve top 5 videos with a 10 second scene where a car is detected until a pedestrian is detected\").\nIn this work, we formalize this problem of assigning Scores for TempOral Properties (STOPs) over sequences, given potentially noisy score predictors for local properties.\nWe then propose a scoring function called LogSTOP that can efficiently compute these scores for temporal properties represented in Linear Temporal Logic.\nEmpirically, LogSTOP, with YOLO and HuBERT, outperforms Large Vision / Audio Language Models and other Temporal Logic-based baselines by at least 16% on query matching with temporal properties over objects-in-videos and emotions-in-speech respectively. Similarly, on ranked retrieval with temporal properties over objects and actions in videos, LogSTOP with Grounding DINO and SlowR50 reports at least a 19% and 16% increase in mean average precision and recall over zero-shot text-to-video retrieval baselines respectively.</p>\n\n",
                "matched_terms": [
                    "mean",
                    "logstop",
                    "retrieval",
                    "slowr50"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The sequences and local properties could correspond to arbitrary modalities and classes of interest, including objects or actions in videos, and speakers or emotions in audio clips. These STOPs are useful for several downstream applications such as\n<span class=\"ltx_text ltx_font_bold\">query matching</span>\n, i.e., checking if the scores\nare over a threshold to decide if the sequence expresses a temporal property,\nand\n<span class=\"ltx_text ltx_font_bold\">ranked retrieval</span>, i.e.,\nranking sequences\nagainst a temporal query by these scores to provide the top-k most relevant results.</p>\n\n",
                "matched_terms": [
                    "retrieval",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose a novel scoring function called LogSTOP, inspired by quantitative semantics for LTL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib14\" title=\"\">14</a>]</cite>,\nthat\nassigns a score for a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m1\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> satisfying temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\nin <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m3\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> time and space.\nLogSTOP employs a simple downsampling and smoothing strategy for handling locally incorrect\npredictions by the local property predictors.\nThis makes it robust to cases where, for example, an object detector detects a car with very low scores in some frames because it is occluded.\nMoreover, the linear time computational complexity makes it an efficient solution for applications such as query matching and ranked retrieval (see example in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).\nFor query matching, we propose a length and query-adaptive threshold which is guaranteed to accept at least as many sequences as a fixed threshold.\nWe also demonstrate how LogSTOP can be used to rank sequences based on subsequence relevance to temporal queries in <math alttext=\"\\mathcal{O}(T^{2}\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>T</mi><mn>2</mn></msup><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T^{2}\\cdot|\\varphi|)</annotation></semantics></math> time.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate LogSTOP on query matching and ranked retrieval,\nwith sequence modalities including videos and speech, and local properties such as objects, actions, and emotions.\nWe focus on 15 diverse temporal property templates of varying complexity.\nSince no existing benchmarks support this breadth of temporal properties\nand sequence types, we propose two new benchmarks:\nthe QMTP (Query Matching for Temporal Properties) benchmark\nfor objects-in-videos from the RealTLV dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>,\nand emotions-in-speech from the IEMOCAP dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite>;\nand the TP2VR (Temporal Property to Video Retrieval) benchmark\nfor objects-in-videos from the RealTLV dataset,\nand actions-in-videos from the AVA dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite>.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "retrieval",
                    "tp2vr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We find that LogSTOP with simple detection models,\nsuch as YOLO and HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib21\" title=\"\">21</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite>,\noutperforms baselines including Large Vision / Audio Language Models (LVLMs / LALMs), and\nNSVS-TL\n, on query matching by more than <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m1\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of balanced accuracy.\nSimilarly,\nLogSTOP with Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite>\nand SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> outperforms\nzero-shot text-to-video retrieval methods, such as mPLUG&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite>\nand text-text similarity with video captions,\nby more than <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m2\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> and <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m3\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of mean average precision and recall respectively.</p>\n\n",
                "matched_terms": [
                    "mean",
                    "logstop",
                    "mplug",
                    "slowr50",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, the LogSTOP for a sequence with respect to a temporal property represents the log probability of the sequence\nsatisfying the temporal property if certain assumptions are met.\nConcretely, this is true when (1) the local properties represent independent events over time,\n(2) the scores for local properties reflect true log probabilities,\nand (3) temporal properties consist of compositions of independent local properties.\nWe acknowledge that these assumptions are rarely true for real-world sequences and properties.\nFor instance, the presence of \"car\" at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m1\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and <math alttext=\"t+1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m2\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t+1</annotation></semantics></math> are not independent events.\nHowever, these assumptions allow us to use ideas from probability theory for independent events to compute the score.\nMoreover, our experiments in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>\nshow that LogSTOPs are useful for applications such as query matching and ranked retrieval\neven when these assumptions are not met.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Complexity analysis for LogSTOP.</span>\nThe computational complexity of Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>,\nfor a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m1\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> with length <math alttext=\"|\\varphi|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m2\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|\\varphi|</annotation></semantics></math> and a sequence of <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m3\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> predictions\nis <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math>.\nThis uses dynamic programming to cache scores for all sub-properties over the sequence&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib15\" title=\"\">15</a>]</cite>.\nThe key observation here is that at any timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m5\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, the LogSTOP for <span class=\"ltx_text ltx_font_italic\">any</span> property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m6\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> can be computed in <math alttext=\"\\mathcal{O}(|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m7\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(|\\varphi|)</annotation></semantics></math> given the LogSTOPs for its sub-properties at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m8\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and itself at <math alttext=\"t+w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m9\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">t+w</annotation></semantics></math>.\nThis is because the LogSTOPs for temporal properties are defined recursively and there are at most <math alttext=\"|\\varphi|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m10\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|\\varphi|</annotation></semantics></math> sub-properties.\nFor <math alttext=\"T/w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m11\" intent=\":literal\"><semantics><mrow><mi>T</mi><mo>/</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">T/w</annotation></semantics></math> timesteps, this results in <math alttext=\"\\mathcal{O}((T/w)\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m12\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>/</mo><mi>w</mi></mrow><mo rspace=\"0.055em\" stretchy=\"false\">)</mo></mrow><mo rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}((T/w)\\cdot|\\varphi|)</annotation></semantics></math> time.\nSince the smoothing operation takes <math alttext=\"\\mathcal{O}(w)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m13\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(w)</annotation></semantics></math> time per window,\ncomputing LogSTOP for <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m14\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> over a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m15\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> requires <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m16\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> time.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg2\" title=\"Algorithm 2 &#8227; 3.1 LogSTOP for Query Matching &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> outlines how LogSTOP can be used for ranked retrieval.\nInformally, given a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m1\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>, sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m2\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math>, and event duration <math alttext=\"(T_{lo},T_{hi})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m3\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(T_{lo},T_{hi})</annotation></semantics></math>,\nthe relevance of <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m4\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> to <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m5\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\nis defined as the maximum LogSTOP of any subsequence of <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m6\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> of length in <math alttext=\"[T_{lo},T_{hi}]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m7\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[T_{lo},T_{hi}]</annotation></semantics></math>.\nThe relevance score for any sequence can be computed in <math alttext=\"\\mathcal{O}(T^{2}\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m8\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>T</mi><mn>2</mn></msup><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T^{2}\\cdot|\\varphi|)</annotation></semantics></math> time\nsince LogSTOPs for suffix subsequences are cached with dynamic programming.\nNote\nthat this represents one way of computing scores for ranking videos, where subsequences of certain lengths are relevant to queries; there could be other variants which LogSTOP could be used for but are not considered (for example, computing the score with respect to the entire video, or only considering videos where the subsequence score is over a threshold).</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">There are no existing benchmarks that evaluate query matching and ranked retrieval on\nvideo and speech sequences with the breadth of temporal properties discussed above.\nWe hence introduce two new benchmarks for evaluation\nusing\nthree existing datasets with frame/segment-level annotations for local properties:\nRealTLV&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>\nfor objects in videos (6 classes),\nIEMOCAP&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite>\nfor emotions in speech (4 classes), and\nAVA&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite>\nfor actions in videos (80 classes).\nWe briefly describe the two benchmarks below, with more details in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A3\" title=\"Appendix C More Details on Datasets &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">C</span></a>.</p>\n\n",
                "matched_terms": [
                    "datasets",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The TP2VR benchmark.</span>\nThe TP2VR benchmark evaluates ranked retrieval of video sequences given temporal property queries over objects and actions.\nThe <span class=\"ltx_text ltx_font_bold\">TP2VR-objects dataset</span> consists of <math alttext=\"746\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m1\" intent=\":literal\"><semantics><mn>746</mn><annotation encoding=\"application/x-tex\">746</annotation></semantics></math> videos with <math alttext=\"39-199\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m2\" intent=\":literal\"><semantics><mrow><mn>39</mn><mo>&#8722;</mo><mn>199</mn></mrow><annotation encoding=\"application/x-tex\">39-199</annotation></semantics></math> frames, collected from the RealTLV dataset, and <math alttext=\"42\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m3\" intent=\":literal\"><semantics><mn>42</mn><annotation encoding=\"application/x-tex\">42</annotation></semantics></math> queries over objects. Each query corresponds to <math alttext=\"25-50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m4\" intent=\":literal\"><semantics><mrow><mn>25</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">25-50</annotation></semantics></math> frame temporal events and is relevant to no more than <math alttext=\"250\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m5\" intent=\":literal\"><semantics><mn>250</mn><annotation encoding=\"application/x-tex\">250</annotation></semantics></math> videos in the dataset.\nSimilarly, the <span class=\"ltx_text ltx_font_bold\">TP2VR-actions dataset</span> consists of <math alttext=\"952\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m6\" intent=\":literal\"><semantics><mn>952</mn><annotation encoding=\"application/x-tex\">952</annotation></semantics></math> videos with <math alttext=\"300\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m7\" intent=\":literal\"><semantics><mn>300</mn><annotation encoding=\"application/x-tex\">300</annotation></semantics></math> frames each, collected from 1-min segments of videos in the AVA dataset,\nwith <math alttext=\"70\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m8\" intent=\":literal\"><semantics><mn>70</mn><annotation encoding=\"application/x-tex\">70</annotation></semantics></math> queries over actions.\nEach query corresponds to <math alttext=\"10\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m9\" intent=\":literal\"><semantics><mn>10</mn><annotation encoding=\"application/x-tex\">10</annotation></semantics></math>-second temporal events and is relevant to no more than <math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m10\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> videos in the dataset.</p>\n\n",
                "matched_terms": [
                    "tp2vractions",
                    "retrieval",
                    "tp2vrobjects",
                    "tp2vr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methods.</span> We evaluate LogSTOP for temporal query matching\nusing simple neural predictors for object and emotion detection.\nWe use YOLOv8&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib23\" title=\"\">23</a>]</cite>, OWLv2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib34\" title=\"\">34</a>]</cite>, and Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite> to obtain\nframe-level object detection scores.\nWe use HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite> for segment-level emotion recognition.\nThese scores are matched using the adaptive threshold discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S3.SS1\" title=\"3.1 LogSTOP for Query Matching &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">3.1</span></a>.\nFor QMTP-video, we compare against two Large Vision Language Models (LVLMs),\nnamely <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib27\" title=\"\">27</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib45\" title=\"\">45</a>]</cite>,\nand the PCTL-based method, NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>.\nFor QMTP-speech, we compare against two Large Audio Language Models (LALMs),\nnamely <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib10\" title=\"\">10</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">Qwen2-Audio-7B-Instruct</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib11\" title=\"\">11</a>]</cite>.\nWe provide more details on the prompts and parameters used for all methods in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A4\" title=\"Appendix D More details on Query Matching Methods &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">D</span></a>.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "method"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Results.</span>\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F2\" title=\"Figure 2 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> shows the balanced accuracies of different methods on the QMTP-video and QMTP-speech datasets.\nLogSTOP outperforms other methods by at least <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> on QMTP-video and QMTP-speech using object detection scores from YOLOv8 and emotion detection scores from HuBERT respectively. LogSTOP with Grounding DINO also performs better than the baselines.\nThe accuracies of detecting objects with scores <math alttext=\"&gt;0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">&gt;0.5</annotation></semantics></math> for YOLO, Grounding DINO and OWLv2 are <math alttext=\"46\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m3\" intent=\":literal\"><semantics><mrow><mn>46</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">46\\%</annotation></semantics></math>, <math alttext=\"38\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m4\" intent=\":literal\"><semantics><mrow><mn>38</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">38\\%</annotation></semantics></math> and <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m5\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> resp. which reflect the order of their performances on query matching.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "datasets",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LogSTOP consistently reports accuracies over <math alttext=\"75\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p3.m1\" intent=\":literal\"><semantics><mrow><mn>75</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">75\\%</annotation></semantics></math> on all query categories.\n<span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span> and <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>\nperform better on simple temporal queries than queries with boolean/temporal compositions.\nNSVS-TL also performs poorly on\ncategories with compositions over boolean expressions.\nThese results\nsuggest that the understanding of temporal queries is still an open problem for LVLMs and LALMs. Moreover, the higher accuracy of LogSTOP with much smaller neural models suggests that using well-defined logics for reasoning is beneficial.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methods.</span> We evaluate LogSTOP for ranked retrieval using Grounding DINO for object detection and Detectron2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib42\" title=\"\">42</a>]</cite> with SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> for action detection.\nSince there are no methods specifically designed for temporal property to sequence retrieval, we adapt existing text-to-video retrieval methods for this task. Since LogSTOP does not require explicit training for retrieval, we specifically only include zero-shot text-to-video retrieval methods for comparison.\nWe include <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite>, a large multimodal model that jointly embeds videos and text queries. Inspired by ELIOT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib29\" title=\"\">29</a>]</cite>, we also include embedding similarity between video captions and text queries.\nWe refer to this as <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> and use\n<span class=\"ltx_text ltx_font_typewriter\">LLaVA-NeXT-Video-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib46\" title=\"\">46</a>]</cite> for generating video captions and <span class=\"ltx_text ltx_font_typewriter\">SentenceBERT</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib37\" title=\"\">37</a>]</cite> for embedding captions and queries. More details are provided in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A5\" title=\"Appendix E More details on the Ranked Retrieval methods &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">E</span></a>.</p>\n\n",
                "matched_terms": [
                    "captionsim",
                    "logstop",
                    "mplug",
                    "slowr50",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Metrics.</span>\nFollowing existing work, we include standard retrieval metrics such as Recall at <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m1\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> (R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m2\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math>, where <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m3\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> is the number of relevant results) for evaluating coverage, and mean / median ranks of first retrieval (MnR / MdR).\nSince multiple videos could be relevant to a query, we also evaluate if relevant results are ranked higher using Precision (P@<math alttext=\"\\{1,r\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mi>r</mi><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{1,r\\}</annotation></semantics></math>), and mean average precision (mAP).</p>\n\n",
                "matched_terms": [
                    "mdr",
                    "mnr",
                    "mean",
                    "results",
                    "map",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Results.</span>\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F4\" title=\"Figure 4 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>\npresents the results for ranked retrieval on the TP2VR benchmark.\nThe performance of all methods on TP2VR-actions is lower than that on TP2VR-objects due to the significantly higher number of classes (<math alttext=\"80\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m1\" intent=\":literal\"><semantics><mn>80</mn><annotation encoding=\"application/x-tex\">80</annotation></semantics></math> actions vs. <math alttext=\"6\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m2\" intent=\":literal\"><semantics><mn>6</mn><annotation encoding=\"application/x-tex\">6</annotation></semantics></math> objects) and lower number of relevant results (on average, <math alttext=\"21\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m3\" intent=\":literal\"><semantics><mn>21</mn><annotation encoding=\"application/x-tex\">21</annotation></semantics></math> vs. <math alttext=\"163\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m4\" intent=\":literal\"><semantics><mn>163</mn><annotation encoding=\"application/x-tex\">163</annotation></semantics></math> relevant videos).\nLogSTOP with GroundingDINO outperforms <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> and <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> on TP2VR-objects by\nat least <math alttext=\"28\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m5\" intent=\":literal\"><semantics><mrow><mn>28</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">28\\%</annotation></semantics></math> in mAP and <math alttext=\"24\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m6\" intent=\":literal\"><semantics><mrow><mn>24</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">24\\%</annotation></semantics></math> in R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m7\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math>, indicating that relevant results are retrieved at earlier ranks and the retrieved results include more relevant items than other methods.\nSimilarly, LogSTOP with SlowR50 outperforms baselines by more than <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m8\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> and <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m9\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of mAP and R@r respectively.\nThe first relevant result is also retrieved earlier by LogSTOP as is indicated by at least a <math alttext=\"24\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m10\" intent=\":literal\"><semantics><mrow><mn>24</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">24\\%</annotation></semantics></math> higher P@1 and better mean ranks;\non TP2VR-actions, LogSTOP retrieves the first relevant result at rank <math alttext=\"7.9\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m11\" intent=\":literal\"><semantics><mn>7.9</mn><annotation encoding=\"application/x-tex\">7.9</annotation></semantics></math> while <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> and <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> retrieve it at ranks <math alttext=\"&gt;20\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m12\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>20</mn></mrow><annotation encoding=\"application/x-tex\">&gt;20</annotation></semantics></math>.\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F5\" title=\"Figure 5 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents examples of ranking using the three methods.\nWe discuss these in detail in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A8\" title=\"Appendix H Examples &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">H</span></a>.</p>\n\n",
                "matched_terms": [
                    "map",
                    "tp2vractions",
                    "captionsim",
                    "tp2vr",
                    "mean",
                    "mplug",
                    "logstop",
                    "results",
                    "groundingdino",
                    "tp2vrobjects",
                    "slowr50",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Ablating various components of LogSTOP also degrades retrieval performance (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.T1\" title=\"Table 1 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>). The standard STL robustness reduces mAP and R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m1\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> by more than <math alttext=\"12\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m2\" intent=\":literal\"><semantics><mrow><mn>12</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">12\\%</annotation></semantics></math>. While removing the smoothing step from LogSTOP leads to a slight increase of 0.2 in MnR, it reduces mAP and R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m3\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> by at least <math alttext=\"4\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m4\" intent=\":literal\"><semantics><mrow><mn>4</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">4\\%</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "map",
                    "logstop",
                    "retrieval",
                    "mnr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Video retrieval with temporal queries. </span>\nPopular text-to-video retrieval datasets such as\nActivity Net Captions&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib24\" title=\"\">24</a>]</cite> and DiDeMo&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib3\" title=\"\">3</a>]</cite> focus on temporal segments within minute-long videos.\nOur TP2VR benchmark focuses on fine-grained temporal queries over short events in videos, with many-to-many mapping between queries and videos.</p>\n\n",
                "matched_terms": [
                    "datasets",
                    "retrieval",
                    "tp2vr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Popular text-video retrieval methods include CLIP4Clip&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib32\" title=\"\">32</a>]</cite>, TS2-Net&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib31\" title=\"\">31</a>]</cite>,&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib4\" title=\"\">4</a>]</cite>, which employ training to improve embeddings for retrieval, and zero-shot methods such as mPLUG&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite> and ELIOT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib29\" title=\"\">29</a>]</cite>. Since we use off-the-shelf models with LogSTOP for retrieval, we only include the latter for comparison.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "mplug",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this work, we\npresent the\nproblem of assigning scores for temporal properties (STOPs) given potentially noisy score predictors for local properties. We represent these properties using LTL and propose a scoring function LogSTOP for assigning STOPs. We then introduce the QMTP and TP2VR benchmarks for evaluating query matching and ranked retrieval\nwith temporal properties\nover objects / actions in videos and emotions in speech. LogSTOP with simple neural predictors outperforms LVLMs / LALMs, Temporal Logic-based baselines, and text-to-retrieval methods on the benchmarks.\n</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "retrieval",
                    "tp2vr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we briefly discuss the QMTP and TP2VR benchmarks for evaluation.\nFor\nconstructing these benchmarks\n, we use\nthree existing datasets with frame/segment-level annotations for local properties:\nThe RealTLV dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>\nconsists of videos from NuScenes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib6\" title=\"\">6</a>]</cite> and Waymo&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib39\" title=\"\">39</a>]</cite> driving datasets with frame-level annotations for 6 object classes.\n(for example, \"car\", \"truck\", etc).\nThe IEMOCAP dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite> provides speech segments from conversations\nbetween two speakers\nand each segment is labeled with one of the 4 major emotions expressed by the speaker.\n(for example, \"happy\", \"sad\", etc.).\nThe AVA dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite> consists of frame-level action annotations for 80 actions in 15-min clips from YouTube. We only consider the validation subset of this dataset and sample 5 frames per second.\nThese datasets can be used for evaluating\ntemporal properties over objects in videos\n(\"car until pedestrian\", for example)\n, emotions in speech\n(\"always happy\")\n, and actions in videos\n(\"a person sits until they stand up\")\nrespectively.</p>\n\n",
                "matched_terms": [
                    "datasets",
                    "tp2vr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The TP2VR dataset.</span>\nWe restrict queries to a maximum of 5 per temporal property template. For TP2VR objects, we aim to find <math alttext=\"25-50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m1\" intent=\":literal\"><semantics><mrow><mn>25</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">25-50</annotation></semantics></math> frame-long subsequences satisfying a temporal property; we only include a temporal property if less than <math alttext=\"250\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m2\" intent=\":literal\"><semantics><mn>250</mn><annotation encoding=\"application/x-tex\">250</annotation></semantics></math> videos are retrieved using the standard LTL semantics with the ground truth labels.\nWith all possible combinations of objects, this gives us a total of <math alttext=\"42\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m3\" intent=\":literal\"><semantics><mn>42</mn><annotation encoding=\"application/x-tex\">42</annotation></semantics></math> queries, with an average of <math alttext=\"163\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m4\" intent=\":literal\"><semantics><mn>163</mn><annotation encoding=\"application/x-tex\">163</annotation></semantics></math> videos relevant to a query.\nSimilarly, for TP2VR-actions, we aim to find 10-second long subsequences (<math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m5\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> frames) satisfying a temporal property; we only include a temporal property if less than <math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m6\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> videos are retrieved using the standard LTL semantics with the ground truth labels. With all possible combinations of actions, this gives us a total of <math alttext=\"70\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m7\" intent=\":literal\"><semantics><mn>70</mn><annotation encoding=\"application/x-tex\">70</annotation></semantics></math> queries, with an average of <math alttext=\"21\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m8\" intent=\":literal\"><semantics><mn>21</mn><annotation encoding=\"application/x-tex\">21</annotation></semantics></math> videos relevant to a query.</p>\n\n",
                "matched_terms": [
                    "tp2vractions",
                    "tp2vr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">LogSTOP.</span>\nWe use LogSTOP with Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite> for TP2VR-objects and with SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> for TP2VR-actions respectively.\nWe repurpose the script from <span class=\"ltx_text ltx_font_typewriter\">tutorials/video_detection_example</span> at <span class=\"ltx_text ltx_font_typewriter\">https://github.com/facebookresearch/pytorchvideo/</span>\nto run SlowR50 on videos from the TP2VR-actions dataset.\nWe use a smoothing window <math alttext=\"w=5\" class=\"ltx_Math\" display=\"inline\" id=\"A5.p1.m1\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">w=5</annotation></semantics></math> for all retrieval experiments.</p>\n\n",
                "matched_terms": [
                    "tp2vractions",
                    "logstop",
                    "tp2vrobjects",
                    "slowr50",
                    "retrieval"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">mPLUG.</span>\nWe use the implementation from <span class=\"ltx_text ltx_font_typewriter\">https://github.com/alibaba/AliceMind</span>. We repurpose the <span class=\"ltx_text ltx_font_typewriter\">mPLUG/retrieval_vid_mplug.py</span> script to run <span class=\"ltx_text ltx_font_typewriter\">mPLUG_large_v2</span> on videos and queries from the TP2VR datasets.</p>\n\n",
                "matched_terms": [
                    "mplug",
                    "datasets",
                    "tp2vr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">CaptionSim.</span>\nInspired by ELIOT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib29\" title=\"\">29</a>]</cite>, we also include embedding similarity between video captions and text queries as a baseline.\nWe refer to this as <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> in the discussion, and use\n<span class=\"ltx_text ltx_font_typewriter\">LLaVA-NeXT-Video-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib46\" title=\"\">46</a>]</cite> for generating video captions and <span class=\"ltx_text ltx_font_typewriter\">SentenceBERT/all-MiniLM-L6-v2</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib37\" title=\"\">37</a>]</cite> for embedding captions and queries.\nDue to the limited context window of <span class=\"ltx_text ltx_font_typewriter\">LLaVA-NeXT-Video-7B</span>, we divide videos in sections of 50 frames and generate captions for each before concatenating them together. We use the following prompt to generate the captions for the first 50 frames: \"Describe this video in detail, listing objects in each frame. Keep the descriptions concise.\" for TP2VR-objects.\nFor any next sections, we use the prompt \"Continue describing the video, listing objects in each frame. You are now at frame i, you have already described the previous i frames.\"\nFor TP2VR-actions, we use the prompt \"Describe this video in detail, listing actions and objects in each frame. Keep the descriptions concise.\" We set the <span class=\"ltx_text ltx_font_typewriter\">max_new_tokens</span> to 1024.</p>\n\n",
                "matched_terms": [
                    "tp2vrobjects",
                    "tp2vractions",
                    "captionsim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> because the implementation of ELIOT is not publicly available. Our local implementation of ELIOT did not report good results (the video captions generated by &#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib40\" title=\"\">40</a>]</cite> did not include mentions of objects or actions).</p>\n\n",
                "matched_terms": [
                    "results",
                    "captionsim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The queries for <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> and <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> for retrieval on TP2VR-objects are as follows (<math alttext=\"t_{lo}=25\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p11.m1\" intent=\":literal\"><semantics><mrow><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>=</mo><mn>25</mn></mrow><annotation encoding=\"application/x-tex\">t_{lo}=25</annotation></semantics></math> and <math alttext=\"t_{hi}=50\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p11.m2\" intent=\":literal\"><semantics><mrow><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo>=</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">t_{hi}=50</annotation></semantics></math> here):</p>\n\n",
                "matched_terms": [
                    "tp2vrobjects",
                    "mplug",
                    "retrieval",
                    "captionsim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The queries for <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> and <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> for retrieval on TP2VR-actions are as follows (note that <math alttext=\"t_{lo}=t_{hi}=50\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p13.m1\" intent=\":literal\"><semantics><mrow><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>=</mo><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo>=</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">t_{lo}=t_{hi}=50</annotation></semantics></math> here):</p>\n\n",
                "matched_terms": [
                    "retrieval",
                    "mplug",
                    "tp2vractions",
                    "captionsim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F5\" title=\"Figure 5 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents examples of ranking using the three methods.\nIn the first example, the video captions used by <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> do not include smaller objects that might be relevant to the query (\"car\" in this example). In the second example, the two actions are mentioned in the caption &#8211; the video is ranked lower than other videos with more mentions of the actions (\"stand\" and \"hand clap\" in this case).\nThis demonstrates that while caption-based methods outperform joint model embeddings (<span class=\"ltx_text ltx_font_typewriter\">mPLUG</span>), they rely on semantic similarity between captions and text to determine relevance, which might not be sufficient for effective retrieval with temporal queries.</p>\n\n",
                "matched_terms": [
                    "mplug",
                    "retrieval",
                    "captionsim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we present the results for ranked retrieval with different methods. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.SS1\" title=\"J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">J.1</span></a> reports these results (with additional metrics, including Precision@5 and Precision@10).</p>\n\n",
                "matched_terms": [
                    "retrieval",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we present the query matching results for the QMTP datasets.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.SS2\" title=\"J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">J.2</span></a> presents the results (balanced accuracies) aggregated by category.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.T4\" title=\"Table 4 &#8227; J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.T5\" title=\"Table 5 &#8227; J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> report the results for the 15 temporal property templates for QMTP-video and QMTP-speech respectively.</p>\n\n",
                "matched_terms": [
                    "datasets",
                    "results"
                ]
            }
        ]
    },
    "A10.SS2.tab1": {
        "caption": "Table 3: Average balanced accuracy for each temporal property category (columns) and method (rows) on the QMTP-video and QMTP-speech datasets.\nDetailed results per category and sequence length are in Appendix J.",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Method</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Simple</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Bool. over Temp.</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Temp. over Bool.</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Temp. over Temp.</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Mixed</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Overall</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" colspan=\"7\">\n<span class=\"ltx_ERROR undefined\">\\rowcolor</span>gray!20 &#8194;&#8202;&#8194;&#8202; <span class=\"ltx_text ltx_font_italic\">QMTP-video</span>\n</th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span class=\"ltx_text ltx_font_italic\">NSVS-TL</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.67</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.63</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.51</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.64</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.50</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.58</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text ltx_font_italic\">Video-LLaVA-7B</span></th>\n<td class=\"ltx_td ltx_align_center\">0.50</td>\n<td class=\"ltx_td ltx_align_center\">0.50</td>\n<td class=\"ltx_td ltx_align_center\">0.50</td>\n<td class=\"ltx_td ltx_align_center\">0.50</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.50</td>\n<td class=\"ltx_td ltx_align_center\">0.50</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text ltx_font_italic\">LongVA-7B</span></th>\n<td class=\"ltx_td ltx_align_center\">0.68</td>\n<td class=\"ltx_td ltx_align_center\">0.63</td>\n<td class=\"ltx_td ltx_align_center\">0.62</td>\n<td class=\"ltx_td ltx_align_center\">0.63</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.61</td>\n<td class=\"ltx_td ltx_align_center\">0.63</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text ltx_font_italic\">LogSTOP (OWLv2)</span></th>\n<td class=\"ltx_td ltx_align_center\">0.61</td>\n<td class=\"ltx_td ltx_align_center\">0.60</td>\n<td class=\"ltx_td ltx_align_center\">0.58</td>\n<td class=\"ltx_td ltx_align_center\">0.58</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.63</td>\n<td class=\"ltx_td ltx_align_center\">0.60</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text ltx_font_italic\">LogSTOP (GroundingDINO)</span></th>\n<td class=\"ltx_td ltx_align_center\">0.70</td>\n<td class=\"ltx_td ltx_align_center\">0.63</td>\n<td class=\"ltx_td ltx_align_center\">0.69</td>\n<td class=\"ltx_td ltx_align_center\">0.70</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.64</td>\n<td class=\"ltx_td ltx_align_center\">0.68</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text ltx_font_italic\">LogSTOP (YOLOv8)</span></th>\n<td class=\"ltx_td ltx_align_center\">0.82</td>\n<td class=\"ltx_td ltx_align_center\">0.75</td>\n<td class=\"ltx_td ltx_align_center\">0.78</td>\n<td class=\"ltx_td ltx_align_center\">0.77</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.81</td>\n<td class=\"ltx_td ltx_align_center\">0.79</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" colspan=\"7\">\n<span class=\"ltx_ERROR undefined\">\\rowcolor</span>gray!20 &#8194;&#8202;&#8194;&#8202; <span class=\"ltx_text ltx_font_italic\">QMTP-speech</span>\n</th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span class=\"ltx_text ltx_font_italic\">Qwen-Audio-Chat</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.70</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.58</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.71</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.66</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.64</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.68</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text ltx_font_italic\">Qwen2-Audio-7B-Instruct</span></th>\n<td class=\"ltx_td ltx_align_center\">0.64</td>\n<td class=\"ltx_td ltx_align_center\">0.64</td>\n<td class=\"ltx_td ltx_align_center\">0.65</td>\n<td class=\"ltx_td ltx_align_center\">0.58</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.56</td>\n<td class=\"ltx_td ltx_align_center\">0.63</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span class=\"ltx_text ltx_font_italic\">LogSTOP (HuBERT)</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.90</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.77</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.80</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.83</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">0.79</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.84</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "balanced",
            "qwenaudiochat",
            "hubert",
            "columns",
            "bool",
            "length",
            "overall",
            "each",
            "groundingdino",
            "longva7b",
            "qmtpvideo",
            "qmtpspeech",
            "nsvstl",
            "property",
            "videollava7b",
            "appendix",
            "average",
            "qwen2audio7binstruct",
            "category",
            "accuracy",
            "over",
            "simple",
            "logstop",
            "rows",
            "results",
            "mixed",
            "datasets",
            "yolov8",
            "sequence",
            "temp",
            "owlv2",
            "method",
            "rowcolorgray20",
            "detailed",
            "temporal"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Neural models such as YOLO and HuBERT can be used to detect local properties such as objects (\"car\") and emotions (\"angry\") in individual frames of videos and audio clips respectively. The likelihood of these detections is indicated by scores in [0, 1]. Lifting these scores to temporal properties over sequences can be useful for several downstream applications such as query matching (e.g., \"does the speaker eventually sound happy in this audio clip?\"), and ranked retrieval (e.g., \"retrieve top 5 videos with a 10 second scene where a car is detected until a pedestrian is detected\").\nIn this work, we formalize this problem of assigning Scores for TempOral Properties (STOPs) over sequences, given potentially noisy score predictors for local properties.\nWe then propose a scoring function called LogSTOP that can efficiently compute these scores for temporal properties represented in Linear Temporal Logic.\nEmpirically, LogSTOP, with YOLO and HuBERT, outperforms Large Vision / Audio Language Models and other Temporal Logic-based baselines by at least 16% on query matching with temporal properties over objects-in-videos and emotions-in-speech respectively. Similarly, on ranked retrieval with temporal properties over objects and actions in videos, LogSTOP with Grounding DINO and SlowR50 reports at least a 19% and 16% increase in mean average precision and recall over zero-shot text-to-video retrieval baselines respectively.</p>\n\n",
                "matched_terms": [
                    "over",
                    "hubert",
                    "average",
                    "logstop",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent work on temporal event detection in videos&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>\nhas focused on using neural detection models such as YOLO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib36\" title=\"\">36</a>]</cite>\nto detect objects (for example, \"car\") in individual video frames,\nand employing off-the-shelf model checkers such as STORM&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib20\" title=\"\">20</a>]</cite>\nto verify if the sequence of detection scores satisfies\na temporal property.\nInspired by these works, we introduce the problem\nof lifting scores for local properties to <span class=\"ltx_text ltx_font_italic\">Scores for TempOral Properties</span> (STOPs)\nover sequences. Concretely,</p>\n\n",
                "matched_terms": [
                    "over",
                    "temporal",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p ltx_align_center\">\n  <span class=\"ltx_text ltx_font_italic\">Given a temporal property and (potentially noisy) predictors for local properties, how can we assign a score for a sequence expressing the temporal property?</span>\n</p>\n\n",
                "matched_terms": [
                    "temporal",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The sequences and local properties could correspond to arbitrary modalities and classes of interest, including objects or actions in videos, and speakers or emotions in audio clips. These STOPs are useful for several downstream applications such as\n<span class=\"ltx_text ltx_font_bold\">query matching</span>\n, i.e., checking if the scores\nare over a threshold to decide if the sequence expresses a temporal property,\nand\n<span class=\"ltx_text ltx_font_bold\">ranked retrieval</span>, i.e.,\nranking sequences\nagainst a temporal query by these scores to provide the top-k most relevant results.</p>\n\n",
                "matched_terms": [
                    "over",
                    "property",
                    "sequence",
                    "results",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We argue that Linear Temporal Logic, with temporal operators such as \"Always\" (<math alttext=\"\\square\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m1\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#9633;</mi><annotation encoding=\"application/x-tex\">\\square</annotation></semantics></math>) and \"Until\" (<math alttext=\"\\mathbin{\\mathcal{U}}\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m2\" intent=\":literal\"><semantics><mo class=\"ltx_font_mathcaligraphic\">&#119984;</mo><annotation encoding=\"application/x-tex\">\\mathbin{\\mathcal{U}}</annotation></semantics></math>), provides a suitable language\nfor expressing diverse\ntemporal properties of interest.\nFor example,\nthe property \"A and B sound happy until A sounds sad\" can be written in LTL\nas <math alttext=\"(\\mathsf{{happy}_{A}}\\land\\mathsf{{happy}_{B}})\\mathbin{\\mathcal{U}}\\mathsf{{sad}_{A}}\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m3\" intent=\":literal\"><semantics><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>&#120257;&#120250;&#120265;&#120265;&#120274;</mi><mi>&#120224;</mi></msub><mo>&#8743;</mo><msub><mi>&#120257;&#120250;&#120265;&#120265;&#120274;</mi><mi>&#120225;</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#120268;&#120250;&#120253;</mi><mi>&#120224;</mi></msub></mrow><annotation encoding=\"application/x-tex\">(\\mathsf{{happy}_{A}}\\land\\mathsf{{happy}_{B}})\\mathbin{\\mathcal{U}}\\mathsf{{sad}_{A}}</annotation></semantics></math>.\nFor temporal properties in LTL, the framework proposed by <cite class=\"ltx_cite ltx_citemacro_citet\">Yang et&#160;al. [<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>]</cite> can be used as a solution to the STOP problem with two major caveats.\nFirstly, this approach requires <math alttext=\"\\mathcal{O}(T\\cdot 2^{|C|})\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><msup><mn>2</mn><mrow><mo stretchy=\"false\">|</mo><mi>C</mi><mo stretchy=\"false\">|</mo></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot 2^{|C|})</annotation></semantics></math> space and time for a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m5\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> and <math alttext=\"|C|\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m6\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>C</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|C|</annotation></semantics></math> local properties.\nThis exponential space and time complexity renders this approach inefficient for applications such as retrieval where sequences from a large database (with potentially many local properties) need to be checked.\nSecondly, this approach has no provision to handle incorrectly low or high, i.e., <span class=\"ltx_text ltx_font_italic\">potentially noisy</span>, scores for local properties.</p>\n\n",
                "matched_terms": [
                    "length",
                    "temporal",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose a novel scoring function called LogSTOP, inspired by quantitative semantics for LTL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib14\" title=\"\">14</a>]</cite>,\nthat\nassigns a score for a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m1\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> satisfying temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\nin <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m3\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> time and space.\nLogSTOP employs a simple downsampling and smoothing strategy for handling locally incorrect\npredictions by the local property predictors.\nThis makes it robust to cases where, for example, an object detector detects a car with very low scores in some frames because it is occluded.\nMoreover, the linear time computational complexity makes it an efficient solution for applications such as query matching and ranked retrieval (see example in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).\nFor query matching, we propose a length and query-adaptive threshold which is guaranteed to accept at least as many sequences as a fixed threshold.\nWe also demonstrate how LogSTOP can be used to rank sequences based on subsequence relevance to temporal queries in <math alttext=\"\\mathcal{O}(T^{2}\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>T</mi><mn>2</mn></msup><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T^{2}\\cdot|\\varphi|)</annotation></semantics></math> time.</p>\n\n",
                "matched_terms": [
                    "property",
                    "sequence",
                    "length",
                    "simple",
                    "logstop",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate LogSTOP on query matching and ranked retrieval,\nwith sequence modalities including videos and speech, and local properties such as objects, actions, and emotions.\nWe focus on 15 diverse temporal property templates of varying complexity.\nSince no existing benchmarks support this breadth of temporal properties\nand sequence types, we propose two new benchmarks:\nthe QMTP (Query Matching for Temporal Properties) benchmark\nfor objects-in-videos from the RealTLV dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>,\nand emotions-in-speech from the IEMOCAP dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite>;\nand the TP2VR (Temporal Property to Video Retrieval) benchmark\nfor objects-in-videos from the RealTLV dataset,\nand actions-in-videos from the AVA dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite>.</p>\n\n",
                "matched_terms": [
                    "temporal",
                    "logstop",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We find that LogSTOP with simple detection models,\nsuch as YOLO and HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib21\" title=\"\">21</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite>,\noutperforms baselines including Large Vision / Audio Language Models (LVLMs / LALMs), and\nNSVS-TL\n, on query matching by more than <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m1\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of balanced accuracy.\nSimilarly,\nLogSTOP with Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite>\nand SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> outperforms\nzero-shot text-to-video retrieval methods, such as mPLUG&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite>\nand text-text similarity with video captions,\nby more than <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m2\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> and <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m3\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of mean average precision and recall respectively.</p>\n\n",
                "matched_terms": [
                    "nsvstl",
                    "balanced",
                    "hubert",
                    "average",
                    "simple",
                    "logstop",
                    "accuracy"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Let <math alttext=\"X=[x_{1},\\ldots,x_{T}]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m1\" intent=\":literal\"><semantics><mrow><mi>X</mi><mo>=</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><msub><mi>x</mi><mi>T</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X=[x_{1},\\ldots,x_{T}]</annotation></semantics></math>\ndenote a sequence of data items of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m2\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math>, where <math alttext=\"x_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m3\" intent=\":literal\"><semantics><msub><mi>x</mi><mi>t</mi></msub><annotation encoding=\"application/x-tex\">x_{t}</annotation></semantics></math> denotes the data item at timestep <math alttext=\"1\\leq t\\leq T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m4\" intent=\":literal\"><semantics><mrow><mn>1</mn><mo>&#8804;</mo><mi>t</mi><mo>&#8804;</mo><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">1\\leq t\\leq T</annotation></semantics></math>.\nLet <math alttext=\"\\mathcal{X}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m5\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119987;</mi><annotation encoding=\"application/x-tex\">\\mathcal{X}</annotation></semantics></math> denote the set of all such sequences, and <math alttext=\"\\mathcal{T}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m6\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><annotation encoding=\"application/x-tex\">\\mathcal{T}</annotation></semantics></math> denote the set of all timesteps <math alttext=\"\\{1,\\ldots,T\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m7\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><mi>T</mi><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{1,\\ldots,T\\}</annotation></semantics></math>.\nFurther, let <math alttext=\"C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m8\" intent=\":literal\"><semantics><mi>C</mi><annotation encoding=\"application/x-tex\">C</annotation></semantics></math> denote a finite set of local properties of interest.\nIn general, <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m9\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> and <math alttext=\"C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m10\" intent=\":literal\"><semantics><mi>C</mi><annotation encoding=\"application/x-tex\">C</annotation></semantics></math> could correspond to sequences of arbitrary modalities and properties respectively,\nincluding but not limited to objects or actions in videos, and speakers or emotions in audio clips.\nWhile these sequences could be over continuous time, we assume that they are discretized into <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m11\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> timesteps for simplicity.</p>\n\n",
                "matched_terms": [
                    "length",
                    "over",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We find that Linear Temporal Logic (LTL),\nwidely used for formal specification and verification of reactive systems &#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib35\" title=\"\">35</a>]</cite>,\nprovides a suitable <span class=\"ltx_text ltx_font_italic\">language</span> for expressing such temporal properties.\nFormally, a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m1\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> over local properties <math alttext=\"C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m2\" intent=\":literal\"><semantics><mi>C</mi><annotation encoding=\"application/x-tex\">C</annotation></semantics></math> can be expressed in LTL as follows:</p>\n\n",
                "matched_terms": [
                    "over",
                    "property",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where, <math alttext=\"c\\in C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m3\" intent=\":literal\"><semantics><mrow><mi>c</mi><mo>&#8712;</mo><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">c\\in C</annotation></semantics></math> is a local property and <math alttext=\"\\varphi_{1},\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m4\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>,</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1},\\varphi_{2}</annotation></semantics></math> are temporal properties. <math alttext=\"\\neg,\\land,\\lor\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m5\" intent=\":literal\"><semantics><mrow><mo>&#172;</mo><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8743;</mo><mo rspace=\"0em\">,</mo><mo lspace=\"0em\">&#8744;</mo></mrow><annotation encoding=\"application/x-tex\">\\neg,\\land,\\lor</annotation></semantics></math> are the logical <span class=\"ltx_text ltx_font_italic\">not</span>, <span class=\"ltx_text ltx_font_italic\">and</span>, and <span class=\"ltx_text ltx_font_italic\">or</span> operators respectively. <math alttext=\"\\bigcirc\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m6\" intent=\":literal\"><semantics><mo>&#9675;</mo><annotation encoding=\"application/x-tex\">\\bigcirc</annotation></semantics></math>, <math alttext=\"\\square\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m7\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#9633;</mi><annotation encoding=\"application/x-tex\">\\square</annotation></semantics></math> and <math alttext=\"\\mathbin{\\mathcal{U}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m8\" intent=\":literal\"><semantics><mo class=\"ltx_font_mathcaligraphic\">&#119984;</mo><annotation encoding=\"application/x-tex\">\\mathbin{\\mathcal{U}}</annotation></semantics></math> are temporal operators <span class=\"ltx_text ltx_font_italic\">Next</span>, <span class=\"ltx_text ltx_font_italic\">Always</span>, and <span class=\"ltx_text ltx_font_italic\">Until</span> respectively. Other temporal operators such as \"Eventually <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m9\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\" (<math alttext=\"\\Diamond\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m10\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\Diamond\\varphi</annotation></semantics></math>) can then be derived as <math alttext=\"\\neg\\square\\neg\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m11\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.167em\" rspace=\"0em\">&#8203;</mo><mrow><mo rspace=\"0.167em\">&#172;</mo><mi>&#966;</mi></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg\\square\\neg\\varphi</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "property",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This language can now be used to represent properties from the previous examples. For instance, the temporal properties for a car being present in all frames and any frame in a video can be represented as <math alttext=\"\\varphi=\\square\\,\\mathsf{car}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p5.m1\" intent=\":literal\"><semantics><mrow><mi>&#966;</mi><mo>=</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#120252;&#120250;&#120267;</mi></mrow></mrow><annotation encoding=\"application/x-tex\">\\varphi=\\square\\,\\mathsf{car}</annotation></semantics></math> and <math alttext=\"\\varphi=\\Diamond\\,\\mathsf{car}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p5.m2\" intent=\":literal\"><semantics><mrow><mi>&#966;</mi><mo>=</mo><mrow><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#120252;&#120250;&#120267;</mi></mrow></mrow><annotation encoding=\"application/x-tex\">\\varphi=\\Diamond\\,\\mathsf{car}</annotation></semantics></math> respectively. Furthermore, the property that a car is present in all frames until a pedestrian is present can be represented as <math alttext=\"\\varphi=\\mathsf{car}\\mathbin{\\mathcal{U}}\\mathsf{pedestrian}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p5.m3\" intent=\":literal\"><semantics><mrow><mi>&#966;</mi><mo>=</mo><mrow><mi>&#120252;&#120250;&#120267;</mi><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi>&#120265;&#120254;&#120253;&#120254;&#120268;&#120269;&#120267;&#120258;&#120250;&#120263;</mi></mrow></mrow><annotation encoding=\"application/x-tex\">\\varphi=\\mathsf{car}\\mathbin{\\mathcal{U}}\\mathsf{pedestrian}</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "property",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The ground truth labeling function <math alttext=\"y(X,c,t)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p6.m1\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(X,c,t)</annotation></semantics></math> for local properties can be lifted to <math alttext=\"y(X,\\varphi,t)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p6.m2\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>&#966;</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(X,\\varphi,t)</annotation></semantics></math>, meaning that the sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p6.m3\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> expresses temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p6.m4\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> starting at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p6.m5\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, using the standard semantics for LTL over finite sequences&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib12\" title=\"\">12</a>]</cite> as follows: for <math alttext=\"1\\leq t\\leq T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p6.m6\" intent=\":literal\"><semantics><mrow><mn>1</mn><mo>&#8804;</mo><mi>t</mi><mo>&#8804;</mo><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">1\\leq t\\leq T</annotation></semantics></math>,</p>\n\n",
                "matched_terms": [
                    "over",
                    "temporal",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Given the true labeling functions for local properties <math alttext=\"y(X,c,\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m1\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(X,c,\\cdot)</annotation></semantics></math>,\nthis semantics can perfectly determine if a sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m2\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> expresses a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m3\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\n(if and only if <math alttext=\"y(X,\\varphi,1)=1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m4\" intent=\":literal\"><semantics><mrow><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>&#966;</mi><mo>,</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">y(X,\\varphi,1)=1</annotation></semantics></math>).\nIn practice, however, we do not have access to these true labeling functions.\nWe assume that noisy predictors can be used instead to provide\n<span class=\"ltx_text ltx_font_italic\">scores</span> <math alttext=\"\\hat{y}:\\mathcal{X}\\times C\\times\\mathcal{T}\\mapsto[a,b]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m5\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119987;</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><mi>C</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi></mrow><mo stretchy=\"false\">&#8614;</mo><mrow><mo stretchy=\"false\">[</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}:\\mathcal{X}\\times C\\times\\mathcal{T}\\mapsto[a,b]</annotation></semantics></math> for the label being 1,\nwhere <math alttext=\"a\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m6\" intent=\":literal\"><semantics><mi>a</mi><annotation encoding=\"application/x-tex\">a</annotation></semantics></math> and <math alttext=\"b\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m7\" intent=\":literal\"><semantics><mi>b</mi><annotation encoding=\"application/x-tex\">b</annotation></semantics></math> are the lower and upper bounds of the score range respectively.\nThe estimate for true label <math alttext=\"y(X,c,t)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m8\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(X,c,t)</annotation></semantics></math> can then be computed as <math alttext=\"\\tilde{y}(X,c,t)=\\hat{y}(X,c,t)&gt;\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m9\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>~</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mi>&#964;</mi></mrow><annotation encoding=\"application/x-tex\">\\tilde{y}(X,c,t)=\\hat{y}(X,c,t)&gt;\\tau</annotation></semantics></math>\nfor some threshold <math alttext=\"\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m10\" intent=\":literal\"><semantics><mi>&#964;</mi><annotation encoding=\"application/x-tex\">\\tau</annotation></semantics></math>.\nMost neural models, including object detection models such as YOLO,\nprovide scores in <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m11\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math> and an object <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m12\" intent=\":literal\"><semantics><mi>c</mi><annotation encoding=\"application/x-tex\">c</annotation></semantics></math> is said to be detected at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m13\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>\nif <math alttext=\"\\hat{y}(X,c,t)&gt;\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m14\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mi>&#964;</mi></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(X,c,t)&gt;\\tau</annotation></semantics></math>, where <math alttext=\"\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m15\" intent=\":literal\"><semantics><mi>&#964;</mi><annotation encoding=\"application/x-tex\">\\tau</annotation></semantics></math> usually is <math alttext=\"0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m16\" intent=\":literal\"><semantics><mn>0.5</mn><annotation encoding=\"application/x-tex\">0.5</annotation></semantics></math>.\nThe accuracy of these predictors then just measures how well <math alttext=\"\\tilde{y}(X,c,\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m17\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>~</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\tilde{y}(X,c,\\cdot)</annotation></semantics></math> estimates <math alttext=\"y(X,c,\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m18\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(X,c,\\cdot)</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "accuracy",
                    "temporal",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We formally introduce the problem of assigning Scores for TempOral Properties (STOPs) as follows:\n<span class=\"ltx_text ltx_font_italic\">\nGiven predictors for local properties <math alttext=\"\\hat{y}:\\mathcal{X}\\times C\\times\\mathcal{T}\\mapsto[a,b]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p9.m1\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119987;</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><mi>C</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi></mrow><mo stretchy=\"false\">&#8614;</mo><mrow><mo stretchy=\"false\">[</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}:\\mathcal{X}\\times C\\times\\mathcal{T}\\mapsto[a,b]</annotation></semantics></math>\nand a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p9.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> defined over local properties in <math alttext=\"C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p9.m3\" intent=\":literal\"><semantics><mi>C</mi><annotation encoding=\"application/x-tex\">C</annotation></semantics></math>,\nhow can a score for <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p9.m4\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> and sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p9.m5\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> at time step <math alttext=\"1\\leq t\\leq T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p9.m6\" intent=\":literal\"><semantics><mrow><mn>1</mn><mo>&#8804;</mo><mi>t</mi><mo>&#8804;</mo><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">1\\leq t\\leq T</annotation></semantics></math>, <math alttext=\"\\hat{y}(X,\\varphi,t)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p9.m7\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>&#966;</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(X,\\varphi,t)</annotation></semantics></math>, be assigned?\n</span></p>\n\n",
                "matched_terms": [
                    "over",
                    "temporal",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Quantitative semantics for variants of LTL, such as Metric or Signal Temporal Logic (MTL/STL), have been proposed to quantify how well a sequence satisfies a temporal property, in <math alttext=\"\\mathcal{O}(poly(T\\cdot|\\varphi|))\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p1.m1\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(poly(T\\cdot|\\varphi|))</annotation></semantics></math> time.\nThese semantics have been widely used for monitoring, falsification, and control synthesis\nand differ in how the degree of satisfaction is interpreted&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib33\" title=\"\">33</a>]</cite>.\nFor instance, the standard quantitative semantics for STL, <span class=\"ltx_text ltx_font_italic\">spatial robustness</span>, uses the <math alttext=\"\\min\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p1.m2\" intent=\":literal\"><semantics><mi>min</mi><annotation encoding=\"application/x-tex\">\\min</annotation></semantics></math> and <math alttext=\"\\max\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p1.m3\" intent=\":literal\"><semantics><mi>max</mi><annotation encoding=\"application/x-tex\">\\max</annotation></semantics></math> operators to\ncompute deviations from satisfaction&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib14\" title=\"\">14</a>]</cite>; robustness of \"Always p\" is the minimum score for <math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p1.m4\" intent=\":literal\"><semantics><mi>p</mi><annotation encoding=\"application/x-tex\">p</annotation></semantics></math> over the sequence. We provide more details on this standard semantics in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A2\" title=\"Appendix B More Details on Quantitative Semantics for Temporal Logic &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">B</span></a>.\n<cite class=\"ltx_cite ltx_citemacro_citet\">Donz&#233; &amp; Maler [<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib13\" title=\"\">13</a>]</cite> propose extending this to <span class=\"ltx_text ltx_font_italic\">space-time robustness</span> which is higher if the property is satisfied earlier.</p>\n\n",
                "matched_terms": [
                    "over",
                    "property",
                    "sequence",
                    "appendix",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Inspired by this literature on quantitative semantics, we propose a scoring function <span class=\"ltx_text ltx_font_italic\">LogSTOP</span>,\nthat recursively computes a score\nfor a sequence <math alttext=\"X[t_{s}:t_{e}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.p2.m1\" intent=\":literal\"><semantics><mrow><mi>X</mi><mrow><mo stretchy=\"false\">[</mo><msub><mi>t</mi><mi>s</mi></msub><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><msub><mi>t</mi><mi>e</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X[t_{s}:t_{e}]</annotation></semantics></math> satisfying temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\n, given start and end timesteps <math alttext=\"t_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m3\" intent=\":literal\"><semantics><msub><mi>t</mi><mi>s</mi></msub><annotation encoding=\"application/x-tex\">t_{s}</annotation></semantics></math> and <math alttext=\"t_{e}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m4\" intent=\":literal\"><semantics><msub><mi>t</mi><mi>e</mi></msub><annotation encoding=\"application/x-tex\">t_{e}</annotation></semantics></math>, and a smoothing window <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m5\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> that we discuss later (Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).\nLogSTOP provides a solution to the STOP problem with <math alttext=\"t_{s}=t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m6\" intent=\":literal\"><semantics><mrow><msub><mi>t</mi><mi>s</mi></msub><mo>=</mo><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t_{s}=t</annotation></semantics></math> and <math alttext=\"t_{e}=T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p2.m7\" intent=\":literal\"><semantics><mrow><msub><mi>t</mi><mi>e</mi></msub><mo>=</mo><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">t_{e}=T</annotation></semantics></math>.\nThere are three key design choices that distinguish LogSTOP from other quantitative semantics and prior work:</p>\n\n",
                "matched_terms": [
                    "temporal",
                    "logstop",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, the LogSTOP for a sequence with respect to a temporal property represents the log probability of the sequence\nsatisfying the temporal property if certain assumptions are met.\nConcretely, this is true when (1) the local properties represent independent events over time,\n(2) the scores for local properties reflect true log probabilities,\nand (3) temporal properties consist of compositions of independent local properties.\nWe acknowledge that these assumptions are rarely true for real-world sequences and properties.\nFor instance, the presence of \"car\" at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m1\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and <math alttext=\"t+1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m2\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t+1</annotation></semantics></math> are not independent events.\nHowever, these assumptions allow us to use ideas from probability theory for independent events to compute the score.\nMoreover, our experiments in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>\nshow that LogSTOPs are useful for applications such as query matching and ranked retrieval\neven when these assumptions are not met.</p>\n\n",
                "matched_terms": [
                    "over",
                    "property",
                    "sequence",
                    "logstop",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, LogSTOP deals with potentially noisy local predictions\nby downsampling and smoothing predictions over windows of length <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m1\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math>\n(Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l8\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>).\nThis\nessentially captures the property that local property scores cannot change drastically in a short local window\n(objects cannot momentarily disappear and reappear, actions cannot change in fractions of seconds, etc.).\nNote that <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m2\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> is a hyperparameter; a higher value of <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m3\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> can be used to control for higher variance in local predictions.</p>\n\n",
                "matched_terms": [
                    "length",
                    "over",
                    "logstop",
                    "property"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We briefly discuss how different operators\nare handled in Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>\nand defer a detailed discussion with examples to Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A1\" title=\"Appendix A More details on Algorithm 1 &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">A</span></a>.\nThe scores for logical operators, negation <math alttext=\"\\neg\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\neg\\varphi</annotation></semantics></math>, conjunction <math alttext=\"\\varphi_{1}\\land\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m2\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8743;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\land\\varphi_{2}</annotation></semantics></math>, and disjunction <math alttext=\"\\varphi_{1}\\lor\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m3\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8744;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\lor\\varphi_{2}</annotation></semantics></math>\nare computed using simple rules from probability theory.\nConcretely, LogSTOP for <math alttext=\"\\varphi_{1}\\land\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m4\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8743;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\land\\varphi_{2}</annotation></semantics></math> is the sum of the LogSTOPs for <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m5\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> and <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m6\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l12\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">12</span></a>), and\nthe LogSTOP for <math alttext=\"\\varphi_{1}\\lor\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m7\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8744;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\lor\\varphi_{2}</annotation></semantics></math> is computed using DeMorgan&#8217;s law\n(line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l14\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">14</span></a>).\nThe score for the \"next\" operator <math alttext=\"\\bigcirc\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m8\" intent=\":literal\"><semantics><mrow><mi/><mo lspace=\"0.222em\" rspace=\"0.222em\">&#9675;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\bigcirc\\varphi</annotation></semantics></math> is computed by shifting the timestep by one window (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l16\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">16</span></a>).\nScores for the \"always\" (<math alttext=\"\\square\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m9\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\varphi</annotation></semantics></math>) and \"until\" (<math alttext=\"\\varphi_{1}\\mathcal{U}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m10\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi class=\"ltx_font_mathcaligraphic\">&#119984;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathcal{U}\\varphi_{2}</annotation></semantics></math>)\noperators\nare computed recursively using the scores for these properties at the next window (lines&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l18\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">18</span></a>-<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l20\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">20</span></a>).\nInformally, the LogSTOP for Always <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m11\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m12\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> can be computed with a <span class=\"ltx_text ltx_font_italic\">\"temporal and\"</span> over <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m13\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m14\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and Always <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m15\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at the next window, <math alttext=\"t+w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m16\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">t+w</annotation></semantics></math>.\nSimilarly, the LogSTOP for <math alttext=\"\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m17\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}</annotation></semantics></math> can be computed with a <span class=\"ltx_text ltx_font_italic\">\"temporal or\"</span> over (1) <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m18\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m19\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, and (2) <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m20\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m21\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> with <math alttext=\"\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m22\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}</annotation></semantics></math> at the next window.</p>\n\n",
                "matched_terms": [
                    "over",
                    "appendix",
                    "simple",
                    "logstop",
                    "detailed",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Complexity analysis for LogSTOP.</span>\nThe computational complexity of Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>,\nfor a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m1\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> with length <math alttext=\"|\\varphi|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m2\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|\\varphi|</annotation></semantics></math> and a sequence of <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m3\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> predictions\nis <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math>.\nThis uses dynamic programming to cache scores for all sub-properties over the sequence&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib15\" title=\"\">15</a>]</cite>.\nThe key observation here is that at any timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m5\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, the LogSTOP for <span class=\"ltx_text ltx_font_italic\">any</span> property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m6\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> can be computed in <math alttext=\"\\mathcal{O}(|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m7\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(|\\varphi|)</annotation></semantics></math> given the LogSTOPs for its sub-properties at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m8\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and itself at <math alttext=\"t+w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m9\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">t+w</annotation></semantics></math>.\nThis is because the LogSTOPs for temporal properties are defined recursively and there are at most <math alttext=\"|\\varphi|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m10\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|\\varphi|</annotation></semantics></math> sub-properties.\nFor <math alttext=\"T/w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m11\" intent=\":literal\"><semantics><mrow><mi>T</mi><mo>/</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">T/w</annotation></semantics></math> timesteps, this results in <math alttext=\"\\mathcal{O}((T/w)\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m12\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>/</mo><mi>w</mi></mrow><mo rspace=\"0.055em\" stretchy=\"false\">)</mo></mrow><mo rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}((T/w)\\cdot|\\varphi|)</annotation></semantics></math> time.\nSince the smoothing operation takes <math alttext=\"\\mathcal{O}(w)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m13\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(w)</annotation></semantics></math> time per window,\ncomputing LogSTOP for <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m14\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> over a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m15\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> requires <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m16\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> time.</p>\n\n",
                "matched_terms": [
                    "over",
                    "property",
                    "sequence",
                    "length",
                    "logstop",
                    "results",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We define query matching with temporal properties as the task of predicting whether a given temporal property / query matches, or is expressed by, a sequence.\nLogSTOPs can be used for matching sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m1\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> with query <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> by comparing <math alttext=\"\\hat{y}(X,\\varphi,1,T)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m3\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>&#966;</mi><mo>,</mo><mn>1</mn><mo>,</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(X,\\varphi,1,T)</annotation></semantics></math> with an appropriate threshold.</p>\n\n",
                "matched_terms": [
                    "temporal",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">A natural first choice for such a threshold for LogSTOP is the constant <math alttext=\"\\tau=\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><mi>&#964;</mi><mo>=</mo><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\tau=\\log 0.5</annotation></semantics></math>. This threshold, is employed by existing works to determine if a video satisfies a temporal property&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>. This, however, does not scale with the length of the sequence. For instance, given a 6-frame video with constant <math alttext=\"\\log 0.9\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m2\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.9</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.9</annotation></semantics></math> scores for \"car\",\nthe LogSTOP for temporal property \"Always car\", with <math alttext=\"w=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">w=1</annotation></semantics></math>, is <math alttext=\"\\log(0.9^{6})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><msup><mn>0.9</mn><mn>6</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9^{6})</annotation></semantics></math>. This is greater than <math alttext=\"\\log(0.5)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m5\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.5</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.5)</annotation></semantics></math> and hence the video matches the query.\nHowever, when another frame with the same high score <math alttext=\"\\log(0.9)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m6\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9)</annotation></semantics></math> is added,\nthe score drops to <math alttext=\"\\log(0.9^{7})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m7\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><msup><mn>0.9</mn><mn>7</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9^{7})</annotation></semantics></math>, which is less than <math alttext=\"\\log(0.5)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m8\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.5</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.5)</annotation></semantics></math> and hence the video no longer matches the query.\nWe would ideally also like the latter to match the query since the property \"car\" is detected with high scores.</p>\n\n",
                "matched_terms": [
                    "property",
                    "sequence",
                    "length",
                    "logstop",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose an adaptive threshold <math alttext=\"\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p3.m1\" intent=\":literal\"><semantics><mi>&#964;</mi><annotation encoding=\"application/x-tex\">\\tau</annotation></semantics></math> for query <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p3.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> and sequence length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p3.m3\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> as follows:</p>\n\n",
                "matched_terms": [
                    "length",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Informally, a sequence expresses a temporal property if the LogSTOP is higher than both random chance <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m1\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math>\nand LogSTOP using random chance predictors for local properties <math alttext=\"\\hat{y}_{0.5}(\\cdot,\\varphi,T,w)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m2\" intent=\":literal\"><semantics><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>0.5</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo>,</mo><mi>&#966;</mi><mo>,</mo><mi>T</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{0.5}(\\cdot,\\varphi,T,w)</annotation></semantics></math>.\nThis threshold can be computed in <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m3\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> and is guaranteed to match at least as many sequences as the constant <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m4\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math> threshold.\nFor properties where the score decreases with sequence length (e.g., <math alttext=\"\\square\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m5\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\varphi</annotation></semantics></math>), the adaptive threshold\nallows more sequences to match\nthe query\nthan the constant threshold.</p>\n\n",
                "matched_terms": [
                    "property",
                    "sequence",
                    "length",
                    "logstop",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LogSTOP\ncan also be used for the task of ranking and\nretrieving sequences relevant to temporal properties of interest.\nFormally, given a database of <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> sequences <math alttext=\"\\mathcal{D}=\\{X_{1},\\ldots,X_{N}\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m2\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119967;</mi><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><msub><mi>X</mi><mi>N</mi></msub><mo stretchy=\"false\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{D}=\\{X_{1},\\ldots,X_{N}\\}</annotation></semantics></math>\na temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m3\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>,\nand a range of event lengths <math alttext=\"(T_{lo},T_{hi})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(T_{lo},T_{hi})</annotation></semantics></math>,\nthe goal is to rank each <math alttext=\"X_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m5\" intent=\":literal\"><semantics><msub><mi>X</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">X_{i}</annotation></semantics></math> based on whether\nit contains a subsequence <math alttext=\"X_{i}[t:t^{\\prime}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.SS2.p1.m6\" intent=\":literal\"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">[</mo><mi>t</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><msup><mi>t</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X_{i}[t:t^{\\prime}]</annotation></semantics></math> of length <math alttext=\"t^{\\prime}-t\\in[T_{lo},T_{hi}]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m7\" intent=\":literal\"><semantics><mrow><mrow><msup><mi>t</mi><mo>&#8242;</mo></msup><mo>&#8722;</mo><mi>t</mi></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">t^{\\prime}-t\\in[T_{lo},T_{hi}]</annotation></semantics></math> that expresses <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m8\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>.\nExamples of such queries include \"videos with a 10 to 20 second scene where a person is sitting down until they stand up\".\nThis task is different from the query matching task in two key ways:\nfirstly, the relative ranking of sequences is more important than absolute scores.\nSecondly and more importantly,\nthe relevance of a sequence may only be with respect to a part of the sequence (a <span class=\"ltx_text ltx_font_italic\">moment</span> in the video, for example).</p>\n\n",
                "matched_terms": [
                    "property",
                    "sequence",
                    "length",
                    "logstop",
                    "each",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg2\" title=\"Algorithm 2 &#8227; 3.1 LogSTOP for Query Matching &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> outlines how LogSTOP can be used for ranked retrieval.\nInformally, given a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m1\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>, sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m2\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math>, and event duration <math alttext=\"(T_{lo},T_{hi})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m3\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(T_{lo},T_{hi})</annotation></semantics></math>,\nthe relevance of <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m4\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> to <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m5\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\nis defined as the maximum LogSTOP of any subsequence of <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m6\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> of length in <math alttext=\"[T_{lo},T_{hi}]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m7\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[T_{lo},T_{hi}]</annotation></semantics></math>.\nThe relevance score for any sequence can be computed in <math alttext=\"\\mathcal{O}(T^{2}\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m8\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>T</mi><mn>2</mn></msup><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T^{2}\\cdot|\\varphi|)</annotation></semantics></math> time\nsince LogSTOPs for suffix subsequences are cached with dynamic programming.\nNote\nthat this represents one way of computing scores for ranking videos, where subsequences of certain lengths are relevant to queries; there could be other variants which LogSTOP could be used for but are not considered (for example, computing the score with respect to the entire video, or only considering videos where the subsequence score is over a threshold).</p>\n\n",
                "matched_terms": [
                    "over",
                    "property",
                    "sequence",
                    "length",
                    "logstop",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We select 15 temporal property templates\nfrom 5 broad categories for evaluation, in the order of increasing difficulty of operator selection and nesting (p1, p2, p3 are placeholders for local properties):</p>\n\n",
                "matched_terms": [
                    "property",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Simple temporal operators:</span> Eventually p1, Always p1, p1 Until p2.</p>\n\n",
                "matched_terms": [
                    "simple",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Boolean over temporal operators:</span> Always p1 and Eventually p2, Always p1 or Eventually p2.</p>\n\n",
                "matched_terms": [
                    "over",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Temporal over boolean operators:</span> (Not p1) Until p2, p1 Until (Not p2), Always (p1 and p2), (p1 and p2) Until p3.</p>\n\n",
                "matched_terms": [
                    "over",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Temporal over temporal operators:</span> p1 Until Always p2, Eventually Always p1, Always Eventually p1.</p>\n\n",
                "matched_terms": [
                    "over",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Temporal operators over boolean and temporal operators:</span> (Not p1) Until Eventually p2, (Not p1) Until Always p2, (p1 and p2) Until Eventually p3.</p>\n\n",
                "matched_terms": [
                    "over",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">There are no existing benchmarks that evaluate query matching and ranked retrieval on\nvideo and speech sequences with the breadth of temporal properties discussed above.\nWe hence introduce two new benchmarks for evaluation\nusing\nthree existing datasets with frame/segment-level annotations for local properties:\nRealTLV&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>\nfor objects in videos (6 classes),\nIEMOCAP&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite>\nfor emotions in speech (4 classes), and\nAVA&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite>\nfor actions in videos (80 classes).\nWe briefly describe the two benchmarks below, with more details in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A3\" title=\"Appendix C More Details on Datasets &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">C</span></a>.</p>\n\n",
                "matched_terms": [
                    "appendix",
                    "datasets",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The QMTP benchmark.</span>\nThe QMTP benchmark evaluates query matching with temporal properties over objects in video and emotions in speech sequences.\n<span class=\"ltx_text ltx_font_bold\">QMTP-video</span> consists of <math alttext=\"7468\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\"><semantics><mn>7468</mn><annotation encoding=\"application/x-tex\">7468</annotation></semantics></math> samples\n(<math alttext=\"3750\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m2\" intent=\":literal\"><semantics><mn>3750</mn><annotation encoding=\"application/x-tex\">3750</annotation></semantics></math> matching and <math alttext=\"3718\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m3\" intent=\":literal\"><semantics><mn>3718</mn><annotation encoding=\"application/x-tex\">3718</annotation></semantics></math> non-matching)\nwith <math alttext=\"10-50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mn>10</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">10-50</annotation></semantics></math> frames per sample.\n<span class=\"ltx_text ltx_font_bold\">QMTP-speech</span> contains <math alttext=\"3300\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m5\" intent=\":literal\"><semantics><mn>3300</mn><annotation encoding=\"application/x-tex\">3300</annotation></semantics></math> samples (balanced),\nincluding speech sequences with <math alttext=\"5-30\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m6\" intent=\":literal\"><semantics><mrow><mn>5</mn><mo>&#8722;</mo><mn>30</mn></mrow><annotation encoding=\"application/x-tex\">5-30</annotation></semantics></math> segments per sample.</p>\n\n",
                "matched_terms": [
                    "over",
                    "balanced",
                    "qmtpvideo",
                    "temporal",
                    "qmtpspeech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The TP2VR benchmark.</span>\nThe TP2VR benchmark evaluates ranked retrieval of video sequences given temporal property queries over objects and actions.\nThe <span class=\"ltx_text ltx_font_bold\">TP2VR-objects dataset</span> consists of <math alttext=\"746\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m1\" intent=\":literal\"><semantics><mn>746</mn><annotation encoding=\"application/x-tex\">746</annotation></semantics></math> videos with <math alttext=\"39-199\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m2\" intent=\":literal\"><semantics><mrow><mn>39</mn><mo>&#8722;</mo><mn>199</mn></mrow><annotation encoding=\"application/x-tex\">39-199</annotation></semantics></math> frames, collected from the RealTLV dataset, and <math alttext=\"42\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m3\" intent=\":literal\"><semantics><mn>42</mn><annotation encoding=\"application/x-tex\">42</annotation></semantics></math> queries over objects. Each query corresponds to <math alttext=\"25-50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m4\" intent=\":literal\"><semantics><mrow><mn>25</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">25-50</annotation></semantics></math> frame temporal events and is relevant to no more than <math alttext=\"250\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m5\" intent=\":literal\"><semantics><mn>250</mn><annotation encoding=\"application/x-tex\">250</annotation></semantics></math> videos in the dataset.\nSimilarly, the <span class=\"ltx_text ltx_font_bold\">TP2VR-actions dataset</span> consists of <math alttext=\"952\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m6\" intent=\":literal\"><semantics><mn>952</mn><annotation encoding=\"application/x-tex\">952</annotation></semantics></math> videos with <math alttext=\"300\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m7\" intent=\":literal\"><semantics><mn>300</mn><annotation encoding=\"application/x-tex\">300</annotation></semantics></math> frames each, collected from 1-min segments of videos in the AVA dataset,\nwith <math alttext=\"70\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m8\" intent=\":literal\"><semantics><mn>70</mn><annotation encoding=\"application/x-tex\">70</annotation></semantics></math> queries over actions.\nEach query corresponds to <math alttext=\"10\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m9\" intent=\":literal\"><semantics><mn>10</mn><annotation encoding=\"application/x-tex\">10</annotation></semantics></math>-second temporal events and is relevant to no more than <math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m10\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> videos in the dataset.</p>\n\n",
                "matched_terms": [
                    "over",
                    "property",
                    "each",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methods.</span> We evaluate LogSTOP for temporal query matching\nusing simple neural predictors for object and emotion detection.\nWe use YOLOv8&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib23\" title=\"\">23</a>]</cite>, OWLv2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib34\" title=\"\">34</a>]</cite>, and Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite> to obtain\nframe-level object detection scores.\nWe use HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite> for segment-level emotion recognition.\nThese scores are matched using the adaptive threshold discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S3.SS1\" title=\"3.1 LogSTOP for Query Matching &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">3.1</span></a>.\nFor QMTP-video, we compare against two Large Vision Language Models (LVLMs),\nnamely <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib27\" title=\"\">27</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib45\" title=\"\">45</a>]</cite>,\nand the PCTL-based method, NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>.\nFor QMTP-speech, we compare against two Large Audio Language Models (LALMs),\nnamely <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib10\" title=\"\">10</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">Qwen2-Audio-7B-Instruct</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib11\" title=\"\">11</a>]</cite>.\nWe provide more details on the prompts and parameters used for all methods in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A4\" title=\"Appendix D More details on Query Matching Methods &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">D</span></a>.</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "nsvstl",
                    "qmtpvideo",
                    "qwenaudiochat",
                    "hubert",
                    "videollava7b",
                    "temporal",
                    "appendix",
                    "qwen2audio7binstruct",
                    "simple",
                    "owlv2",
                    "logstop",
                    "method",
                    "longva7b",
                    "qmtpspeech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Results.</span>\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F2\" title=\"Figure 2 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> shows the balanced accuracies of different methods on the QMTP-video and QMTP-speech datasets.\nLogSTOP outperforms other methods by at least <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> on QMTP-video and QMTP-speech using object detection scores from YOLOv8 and emotion detection scores from HuBERT respectively. LogSTOP with Grounding DINO also performs better than the baselines.\nThe accuracies of detecting objects with scores <math alttext=\"&gt;0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">&gt;0.5</annotation></semantics></math> for YOLO, Grounding DINO and OWLv2 are <math alttext=\"46\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m3\" intent=\":literal\"><semantics><mrow><mn>46</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">46\\%</annotation></semantics></math>, <math alttext=\"38\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m4\" intent=\":literal\"><semantics><mrow><mn>38</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">38\\%</annotation></semantics></math> and <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m5\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> resp. which reflect the order of their performances on query matching.</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "balanced",
                    "qmtpvideo",
                    "hubert",
                    "owlv2",
                    "logstop",
                    "results",
                    "datasets",
                    "qmtpspeech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LogSTOP consistently reports accuracies over <math alttext=\"75\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p3.m1\" intent=\":literal\"><semantics><mrow><mn>75</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">75\\%</annotation></semantics></math> on all query categories.\n<span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span> and <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>\nperform better on simple temporal queries than queries with boolean/temporal compositions.\nNSVS-TL also performs poorly on\ncategories with compositions over boolean expressions.\nThese results\nsuggest that the understanding of temporal queries is still an open problem for LVLMs and LALMs. Moreover, the higher accuracy of LogSTOP with much smaller neural models suggests that using well-defined logics for reasoning is beneficial.</p>\n\n",
                "matched_terms": [
                    "over",
                    "nsvstl",
                    "qwenaudiochat",
                    "simple",
                    "logstop",
                    "results",
                    "accuracy",
                    "longva7b",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Finally, we evaluate how the various design choices for LogSTOP affect the performance (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.T1\" title=\"Table 1 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>). We find that the accuracy drops by <math alttext=\"2\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m1\" intent=\":literal\"><semantics><mrow><mn>2</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">2\\%</annotation></semantics></math> when the standard STL robustness is used for aggregating scores instead of LogSTOP, or when local smoothing from Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l8\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>) is not performed.\nA <math alttext=\"3\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m2\" intent=\":literal\"><semantics><mrow><mn>3</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">3\\%</annotation></semantics></math> drop is also observed when the adaptive threshold is replaced with <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m3\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math>; Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F3\" title=\"Figure 3 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> demonstrates how the adaptive threshold\nis\nbetter at distinguishing between matching and non-matching sequences.</p>\n\n",
                "matched_terms": [
                    "accuracy",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methods.</span> We evaluate LogSTOP for ranked retrieval using Grounding DINO for object detection and Detectron2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib42\" title=\"\">42</a>]</cite> with SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> for action detection.\nSince there are no methods specifically designed for temporal property to sequence retrieval, we adapt existing text-to-video retrieval methods for this task. Since LogSTOP does not require explicit training for retrieval, we specifically only include zero-shot text-to-video retrieval methods for comparison.\nWe include <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite>, a large multimodal model that jointly embeds videos and text queries. Inspired by ELIOT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib29\" title=\"\">29</a>]</cite>, we also include embedding similarity between video captions and text queries.\nWe refer to this as <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> and use\n<span class=\"ltx_text ltx_font_typewriter\">LLaVA-NeXT-Video-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib46\" title=\"\">46</a>]</cite> for generating video captions and <span class=\"ltx_text ltx_font_typewriter\">SentenceBERT</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib37\" title=\"\">37</a>]</cite> for embedding captions and queries. More details are provided in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A5\" title=\"Appendix E More details on the Ranked Retrieval methods &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">E</span></a>.</p>\n\n",
                "matched_terms": [
                    "property",
                    "sequence",
                    "appendix",
                    "logstop",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Metrics.</span>\nFollowing existing work, we include standard retrieval metrics such as Recall at <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m1\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> (R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m2\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math>, where <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m3\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> is the number of relevant results) for evaluating coverage, and mean / median ranks of first retrieval (MnR / MdR).\nSince multiple videos could be relevant to a query, we also evaluate if relevant results are ranked higher using Precision (P@<math alttext=\"\\{1,r\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p2.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mi>r</mi><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{1,r\\}</annotation></semantics></math>), and mean average precision (mAP).</p>\n\n",
                "matched_terms": [
                    "average",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Results.</span>\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F4\" title=\"Figure 4 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>\npresents the results for ranked retrieval on the TP2VR benchmark.\nThe performance of all methods on TP2VR-actions is lower than that on TP2VR-objects due to the significantly higher number of classes (<math alttext=\"80\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m1\" intent=\":literal\"><semantics><mn>80</mn><annotation encoding=\"application/x-tex\">80</annotation></semantics></math> actions vs. <math alttext=\"6\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m2\" intent=\":literal\"><semantics><mn>6</mn><annotation encoding=\"application/x-tex\">6</annotation></semantics></math> objects) and lower number of relevant results (on average, <math alttext=\"21\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m3\" intent=\":literal\"><semantics><mn>21</mn><annotation encoding=\"application/x-tex\">21</annotation></semantics></math> vs. <math alttext=\"163\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m4\" intent=\":literal\"><semantics><mn>163</mn><annotation encoding=\"application/x-tex\">163</annotation></semantics></math> relevant videos).\nLogSTOP with GroundingDINO outperforms <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> and <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> on TP2VR-objects by\nat least <math alttext=\"28\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m5\" intent=\":literal\"><semantics><mrow><mn>28</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">28\\%</annotation></semantics></math> in mAP and <math alttext=\"24\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m6\" intent=\":literal\"><semantics><mrow><mn>24</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">24\\%</annotation></semantics></math> in R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m7\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math>, indicating that relevant results are retrieved at earlier ranks and the retrieved results include more relevant items than other methods.\nSimilarly, LogSTOP with SlowR50 outperforms baselines by more than <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m8\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> and <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m9\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of mAP and R@r respectively.\nThe first relevant result is also retrieved earlier by LogSTOP as is indicated by at least a <math alttext=\"24\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m10\" intent=\":literal\"><semantics><mrow><mn>24</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">24\\%</annotation></semantics></math> higher P@1 and better mean ranks;\non TP2VR-actions, LogSTOP retrieves the first relevant result at rank <math alttext=\"7.9\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m11\" intent=\":literal\"><semantics><mn>7.9</mn><annotation encoding=\"application/x-tex\">7.9</annotation></semantics></math> while <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> and <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> retrieve it at ranks <math alttext=\"&gt;20\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m12\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>20</mn></mrow><annotation encoding=\"application/x-tex\">&gt;20</annotation></semantics></math>.\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F5\" title=\"Figure 5 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents examples of ranking using the three methods.\nWe discuss these in detail in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A8\" title=\"Appendix H Examples &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">H</span></a>.</p>\n\n",
                "matched_terms": [
                    "appendix",
                    "average",
                    "logstop",
                    "results",
                    "groundingdino"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Temporal Logic for video and audio understanding. </span>\n<cite class=\"ltx_cite ltx_citemacro_citet\">Yang et&#160;al. [<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>]</cite> and <cite class=\"ltx_cite ltx_citemacro_citet\">Choi et&#160;al. [<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite> (NSVS-TL) use the probabilistic model checker STORM to verify temporal properties over object detections in videos, using LTL and PCTL to represent properties respectively.</p>\n\n",
                "matched_terms": [
                    "over",
                    "nsvstl",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Benchmarks for video and audio understanding. </span>\nBenchmarks for video understanding such as Video-MME&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib17\" title=\"\">17</a>]</cite>, RexTIME&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib8\" title=\"\">8</a>]</cite>, Next-qa&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib43\" title=\"\">43</a>]</cite>, QVHighlights&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib25\" title=\"\">25</a>]</cite>, TemporalBench&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib7\" title=\"\">7</a>]</cite> and TempCompass&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib30\" title=\"\">30</a>]</cite> include tasks that require temporal understanding of events in videos. Similarly, audio understanding datasets such as MMAU&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib38\" title=\"\">38</a>]</cite> and CompA&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib18\" title=\"\">18</a>]</cite> evaluate temporal tasks such as detecting the order of two events.\nThese tasks are fundamentally different from the QMTP benchmark which focuses on more fine-grained temporal properties.</p>\n\n",
                "matched_terms": [
                    "datasets",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Video retrieval with temporal queries. </span>\nPopular text-to-video retrieval datasets such as\nActivity Net Captions&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib24\" title=\"\">24</a>]</cite> and DiDeMo&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib3\" title=\"\">3</a>]</cite> focus on temporal segments within minute-long videos.\nOur TP2VR benchmark focuses on fine-grained temporal queries over short events in videos, with many-to-many mapping between queries and videos.</p>\n\n",
                "matched_terms": [
                    "over",
                    "datasets",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this work, we\npresent the\nproblem of assigning scores for temporal properties (STOPs) given potentially noisy score predictors for local properties. We represent these properties using LTL and propose a scoring function LogSTOP for assigning STOPs. We then introduce the QMTP and TP2VR benchmarks for evaluating query matching and ranked retrieval\nwith temporal properties\nover objects / actions in videos and emotions in speech. LogSTOP with simple neural predictors outperforms LVLMs / LALMs, Temporal Logic-based baselines, and text-to-retrieval methods on the benchmarks.\n</p>\n\n",
                "matched_terms": [
                    "simple",
                    "over",
                    "logstop",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Limitations. </span>\nThere are properties such as \"there are always 2 cars\" that cannot directly be expressed in LTL.\nFuture work should hence explore more expressive logics&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib22\" title=\"\">22</a>]</cite> or construct local predictors for complex properties.\nWhile we only focus on sequences with single modalities, it will be interesting to see LogSTOP being for multi-modal applications where the local properties are over different modalities with scores from different local predictors.</p>\n\n",
                "matched_terms": [
                    "over",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> describes how LogSTOP is computed for a sequence <math alttext=\"X[t_{s}:t_{e}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A1.p1.m1\" intent=\":literal\"><semantics><mrow><mi>X</mi><mrow><mo stretchy=\"false\">[</mo><msub><mi>t</mi><mi>s</mi></msub><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><msub><mi>t</mi><mi>e</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X[t_{s}:t_{e}]</annotation></semantics></math> with respect to temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p1.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>, given start and end timesteps <math alttext=\"t_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p1.m3\" intent=\":literal\"><semantics><msub><mi>t</mi><mi>s</mi></msub><annotation encoding=\"application/x-tex\">t_{s}</annotation></semantics></math> and <math alttext=\"t_{e}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p1.m4\" intent=\":literal\"><semantics><msub><mi>t</mi><mi>e</mi></msub><annotation encoding=\"application/x-tex\">t_{e}</annotation></semantics></math>, and smoothing window <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p1.m5\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math>. Here we discuss the intuition behind the operators, along with some examples:</p>\n\n",
                "matched_terms": [
                    "temporal",
                    "logstop",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Downsampling and average smoothing of confidence scores of local properties.</span> Firstly, LogSTOP downsamples the sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m1\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> to contiguous blocks of length <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m2\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math>. The confidence scores for any local property in each block starting at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m3\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, <math alttext=\"\\hat{y}(c,t^{\\prime}\\in[t,t+w])\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m4\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>c</mi><mo>,</mo><msup><mi>t</mi><mo>&#8242;</mo></msup></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mi>t</mi><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><mo stretchy=\"false\">]</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(c,t^{\\prime}\\in[t,t+w])</annotation></semantics></math> are first averaged after being normalized to the <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m5\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math> range. The confidence score for each block is then the <math alttext=\"\\log\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m6\" intent=\":literal\"><semantics><mi>log</mi><annotation encoding=\"application/x-tex\">\\log</annotation></semantics></math> of this averaged <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m7\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math>-normalized score. This series of downsampling, normalizing and smoothing operations starting at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m8\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> for a window <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m9\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> can be seen on line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l8\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>. For example, given a sequence of log scores for object \"car\",</p>\n\n",
                "matched_terms": [
                    "property",
                    "sequence",
                    "average",
                    "length",
                    "logstop",
                    "each"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this example, note that the score <math alttext=\"\\log(0.1)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m11\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.1)</annotation></semantics></math> is likely incorrect since the car cannot momentarily disappear. Downsampling and then smoothing reduce the impact of this incorrect local prediction hence essentially capturing the property that confidence scores cannot drastically change in a local window.\nNote that this is done online for each successive block and the shifting for temporal operators is handled by the Next operator (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l16\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">16</span></a>).</p>\n\n",
                "matched_terms": [
                    "property",
                    "each",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The LogSTOP for <math alttext=\"\\varphi_{1}\\land\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m1\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8743;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\land\\varphi_{2}</annotation></semantics></math> at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m2\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> is high only when the scores for both <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m3\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> and <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m4\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> are high (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l12\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">12</span></a>). For example, given high scores <math alttext=\"\\hat{y}({car},t,w)=\\log(0.9)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m5\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({car},t,w)=\\log(0.9)</annotation></semantics></math> and <math alttext=\"\\hat{y}({pedestrian},t,w)=0.9\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m6\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0.9</mn></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({pedestrian},t,w)=0.9</annotation></semantics></math>, the score for \"car and pedestrian\" <math alttext=\"\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.9)=\\log(0.81)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m7\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.81</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.9)=\\log(0.81)</annotation></semantics></math>. However, if either of the scores are low, e.g., if <math alttext=\"\\hat{y}({pedestrian},t,w)=0.1\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m8\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({pedestrian},t,w)=0.1</annotation></semantics></math>, the score drops significantly to <math alttext=\"\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.1)=\\log(0.09)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m9\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.09</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.1)=\\log(0.09)</annotation></semantics></math>. Inspired by DeMorgan&#8217;s law, the LogSTOP for <math alttext=\"\\varphi_{1}\\lor\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m10\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8744;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\lor\\varphi_{2}</annotation></semantics></math> is simply the score for equivalent property <math alttext=\"\\neg(\\neg\\varphi_{1}\\land\\neg\\varphi_{2})\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m11\" intent=\":literal\"><semantics><mrow><mo>&#172;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo rspace=\"0.167em\">&#172;</mo><msub><mi>&#966;</mi><mn>1</mn></msub></mrow><mo>&#8743;</mo><mrow><mo rspace=\"0.167em\">&#172;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg(\\neg\\varphi_{1}\\land\\neg\\varphi_{2})</annotation></semantics></math> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l14\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">14</span></a>). This is intuitively only low when both the scores are low.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "property"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Note that these operators are defined not only over local properties <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m1\" intent=\":literal\"><semantics><mi>c</mi><annotation encoding=\"application/x-tex\">c</annotation></semantics></math> as in the examples above, but over any temporal property <math alttext=\"\\varphi,\\varphi_{1},\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m2\" intent=\":literal\"><semantics><mrow><mi>&#966;</mi><mo>,</mo><msub><mi>&#966;</mi><mn>1</mn></msub><mo>,</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi,\\varphi_{1},\\varphi_{2}</annotation></semantics></math>. Hence, for temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m3\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> = \"(car or truck) and (not pedestrian)\", the score is high only if it is high for both <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m4\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> = \"(car or truck)\" and <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m5\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> = \"(not pedestrian)\". The scores for <math alttext=\"\\varphi_{1},\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m6\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>,</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1},\\varphi_{2}</annotation></semantics></math> can be recursively computed.</p>\n\n",
                "matched_terms": [
                    "over",
                    "property",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Handling of temporal operators (<math alttext=\"\\bigcirc,\\square,\\mathbin{\\mathcal{U}}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0em\">&#9675;</mo><mo>,</mo><mi mathvariant=\"normal\">&#9633;</mi><mo rspace=\"0em\">,</mo><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0em\">&#119984;</mo></mrow><annotation encoding=\"application/x-tex\">\\bigcirc,\\square,\\mathbin{\\mathcal{U}}</annotation></semantics></math>).</span> \nAs discussed above, the property Next <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> (<math alttext=\"\\bigcirc\\,\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m3\" intent=\":literal\"><semantics><mrow><mi/><mo lspace=\"0.222em\" rspace=\"0.392em\">&#9675;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\bigcirc\\,\\varphi</annotation></semantics></math>) evaluates whether <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m4\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> is expressed starting at the next block <math alttext=\"t+w\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m5\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">t+w</annotation></semantics></math> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l16\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">16</span></a>). When <math alttext=\"w=1\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m6\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">w=1</annotation></semantics></math>, this represents the standard Next operator.\nThe property Always <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m7\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> (<math alttext=\"\\square\\,\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m8\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\,\\varphi</annotation></semantics></math>) is interpreted here as a \"temporal and\" operator over the sequence (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l18\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">18</span></a>). Hence, <math alttext=\"\\square\\,\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m9\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\,\\varphi</annotation></semantics></math> can be equivalently written as <math alttext=\"\\varphi\\land\\bigcirc\\,\\square\\,\\varphi\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A1.p6.m10\" intent=\":literal\"><semantics><mrow><mi>&#966;</mi><mo rspace=\"0em\">&#8743;</mo><mo lspace=\"0em\" rspace=\"0.392em\">&#9675;</mo><mi mathvariant=\"normal\">&#9633;</mi><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\varphi\\land\\bigcirc\\,\\square\\,\\varphi</annotation></semantics></math>: the property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m11\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> is expressed by <math alttext=\"x_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m12\" intent=\":literal\"><semantics><msub><mi>x</mi><mi>t</mi></msub><annotation encoding=\"application/x-tex\">x_{t}</annotation></semantics></math> and always after by <math alttext=\"[x_{t+w},\\ldots]\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m13\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow></msub><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[x_{t+w},\\ldots]</annotation></semantics></math> (<math alttext=\"\\bigcirc\\,{\\square\\,\\varphi}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m14\" intent=\":literal\"><semantics><mrow><mi/><mo lspace=\"0.222em\" rspace=\"0.392em\">&#9675;</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow></mrow><annotation encoding=\"application/x-tex\">\\bigcirc\\,{\\square\\,\\varphi}</annotation></semantics></math>). Similar to the logical <math alttext=\"\\land\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m15\" intent=\":literal\"><semantics><mo>&#8743;</mo><annotation encoding=\"application/x-tex\">\\land</annotation></semantics></math> operator, the score is high only if it is high for all timesteps of the sequence. The computation in <math alttext=\"\\log\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m16\" intent=\":literal\"><semantics><mi>log</mi><annotation encoding=\"application/x-tex\">\\log</annotation></semantics></math> space is beneficial to prevent any underflow here with fixed precision.</p>\n\n",
                "matched_terms": [
                    "over",
                    "temporal",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We argue that LogSTOP offers advantages over such semantics in the context of the STOP problem.\nThis is primarily because the traditional robustness measure is defined using <math alttext=\"\\max\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m1\" intent=\":literal\"><semantics><mi>max</mi><annotation encoding=\"application/x-tex\">\\max</annotation></semantics></math> and <math alttext=\"\\min\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m2\" intent=\":literal\"><semantics><mi>min</mi><annotation encoding=\"application/x-tex\">\\min</annotation></semantics></math> functions over temporal and logical formulae.\nThe measure, hence, only reflects the most violating or most satisfying timestep in the sequence. For example, consider assigning confidence scores to the property \"Always car\" in two different scenarios:</p>\n\n",
                "matched_terms": [
                    "over",
                    "property",
                    "sequence",
                    "logstop",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we briefly discuss the QMTP and TP2VR benchmarks for evaluation.\nFor\nconstructing these benchmarks\n, we use\nthree existing datasets with frame/segment-level annotations for local properties:\nThe RealTLV dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>\nconsists of videos from NuScenes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib6\" title=\"\">6</a>]</cite> and Waymo&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib39\" title=\"\">39</a>]</cite> driving datasets with frame-level annotations for 6 object classes.\n(for example, \"car\", \"truck\", etc).\nThe IEMOCAP dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite> provides speech segments from conversations\nbetween two speakers\nand each segment is labeled with one of the 4 major emotions expressed by the speaker.\n(for example, \"happy\", \"sad\", etc.).\nThe AVA dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite> consists of frame-level action annotations for 80 actions in 15-min clips from YouTube. We only consider the validation subset of this dataset and sample 5 frames per second.\nThese datasets can be used for evaluating\ntemporal properties over objects in videos\n(\"car until pedestrian\", for example)\n, emotions in speech\n(\"always happy\")\n, and actions in videos\n(\"a person sits until they stand up\")\nrespectively.</p>\n\n",
                "matched_terms": [
                    "over",
                    "each",
                    "datasets",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The QMTP dataset.</span>\nFor any temporal property template (for example, \"p1 Until p2\") and samples from these datasets, we identify matching and non-matching sequences of desired length as follows: for every sample, we first identify candidates for local properties in the template (p1, p2, etc.) as the set of all ground-truth objects / emotions in the sequence. We then use the standard LTL semantics over the frame/segment-level ground-truth labels to collect matching and non-matching subsequences of the desired length. This creates a TP-query matching dataset for an arbitrary set of temporal properties as long as these properties are sufficiently expressed by sequences from the underlying dataset. Moreover, this pipeline is agnostic to the choice of the dataset since it only requires sequences of ground-truth labels for local properties. We use this pipeline to create\nthe <span class=\"ltx_text ltx_font_bold\">QMTP-video dataset</span> with <math alttext=\"7468\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m1\" intent=\":literal\"><semantics><mn>7468</mn><annotation encoding=\"application/x-tex\">7468</annotation></semantics></math> samples (<math alttext=\"3750\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m2\" intent=\":literal\"><semantics><mn>3750</mn><annotation encoding=\"application/x-tex\">3750</annotation></semantics></math> matching and <math alttext=\"3718\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m3\" intent=\":literal\"><semantics><mn>3718</mn><annotation encoding=\"application/x-tex\">3718</annotation></semantics></math> non-matching) with video sequences of lengths <math alttext=\"\\{10,20,30,40,50\\}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mn>10</mn><mo>,</mo><mn>20</mn><mo>,</mo><mn>30</mn><mo>,</mo><mn>40</mn><mo>,</mo><mn>50</mn><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{10,20,30,40,50\\}</annotation></semantics></math>. For each target length, this dataset contains approximately <math alttext=\"100\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m5\" intent=\":literal\"><semantics><mn>100</mn><annotation encoding=\"application/x-tex\">100</annotation></semantics></math> samples corresponding to each of the <math alttext=\"15\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m6\" intent=\":literal\"><semantics><mn>15</mn><annotation encoding=\"application/x-tex\">15</annotation></semantics></math> property templates. Similarly, we create the <span class=\"ltx_text ltx_font_bold\">QMTP-speech dataset</span> with <math alttext=\"3300\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m7\" intent=\":literal\"><semantics><mn>3300</mn><annotation encoding=\"application/x-tex\">3300</annotation></semantics></math> samples, including speech sequences of lengths in ranges <math alttext=\"\\{5-10,10-20,20-30\\}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m8\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mrow><mn>5</mn><mo>&#8722;</mo><mn>10</mn></mrow><mo>,</mo><mrow><mn>10</mn><mo>&#8722;</mo><mn>20</mn></mrow><mo>,</mo><mrow><mn>20</mn><mo>&#8722;</mo><mn>30</mn></mrow><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{5-10,10-20,20-30\\}</annotation></semantics></math>. The QMTP-speech dataset only contains samples from <math alttext=\"11/15\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m9\" intent=\":literal\"><semantics><mrow><mn>11</mn><mo>/</mo><mn>15</mn></mrow><annotation encoding=\"application/x-tex\">11/15</annotation></semantics></math> property templates. This is because there are no sequences matching <math alttext=\"4\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m10\" intent=\":literal\"><semantics><mn>4</mn><annotation encoding=\"application/x-tex\">4</annotation></semantics></math> properties \"Always p1 and Eventually p2\", \"Always (p1 and p2)\", \"(p1 and p2) Until p3\", and \"(p1 and p2) Until Eventually p3\" since two emotions cannot be expressed at the same time.</p>\n\n",
                "matched_terms": [
                    "over",
                    "property",
                    "qmtpvideo",
                    "sequence",
                    "temporal",
                    "length",
                    "each",
                    "datasets",
                    "qmtpspeech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The TP2VR dataset.</span>\nWe restrict queries to a maximum of 5 per temporal property template. For TP2VR objects, we aim to find <math alttext=\"25-50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m1\" intent=\":literal\"><semantics><mrow><mn>25</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">25-50</annotation></semantics></math> frame-long subsequences satisfying a temporal property; we only include a temporal property if less than <math alttext=\"250\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m2\" intent=\":literal\"><semantics><mn>250</mn><annotation encoding=\"application/x-tex\">250</annotation></semantics></math> videos are retrieved using the standard LTL semantics with the ground truth labels.\nWith all possible combinations of objects, this gives us a total of <math alttext=\"42\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m3\" intent=\":literal\"><semantics><mn>42</mn><annotation encoding=\"application/x-tex\">42</annotation></semantics></math> queries, with an average of <math alttext=\"163\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m4\" intent=\":literal\"><semantics><mn>163</mn><annotation encoding=\"application/x-tex\">163</annotation></semantics></math> videos relevant to a query.\nSimilarly, for TP2VR-actions, we aim to find 10-second long subsequences (<math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m5\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> frames) satisfying a temporal property; we only include a temporal property if less than <math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m6\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> videos are retrieved using the standard LTL semantics with the ground truth labels. With all possible combinations of actions, this gives us a total of <math alttext=\"70\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m7\" intent=\":literal\"><semantics><mn>70</mn><annotation encoding=\"application/x-tex\">70</annotation></semantics></math> queries, with an average of <math alttext=\"21\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m8\" intent=\":literal\"><semantics><mn>21</mn><annotation encoding=\"application/x-tex\">21</annotation></semantics></math> videos relevant to a query.</p>\n\n",
                "matched_terms": [
                    "average",
                    "property",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">LogSTOP with simple trained neural predictors:</span> We use YOLOv8&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib23\" title=\"\">23</a>]</cite>, Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite>, and OWLv2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib34\" title=\"\">34</a>]</cite>, to get confidence scores for object detection in video frames, and HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite> for speech emotion recognition in audio segments. Since the scores are in the <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math> range, we normalize them in the <math alttext=\"[-\\infty,0]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m2\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mrow><mo>&#8722;</mo><mi mathvariant=\"normal\">&#8734;</mi></mrow><mo>,</mo><mn>0</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[-\\infty,0]</annotation></semantics></math> range using the <math alttext=\"\\log\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m3\" intent=\":literal\"><semantics><mi>log</mi><annotation encoding=\"application/x-tex\">\\log</annotation></semantics></math> operation, as required by LogSTOP.\nA video matches query <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m4\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> if LogSTOP <math alttext=\"\\hat{y}(\\varphi,0,w)&gt;\\tau(\\varphi,0)\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m5\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><mi>&#964;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(\\varphi,0,w)&gt;\\tau(\\varphi,0)</annotation></semantics></math> (and vice versa for non-matching examples). The estimates are evaluated against ground-truth labels <math alttext=\"y(\\varphi,0)\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m6\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(\\varphi,0)</annotation></semantics></math>. The window <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m7\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> is selected as follows: <math alttext=\"w=2\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m8\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">w=2</annotation></semantics></math> for <math alttext=\"T&lt;20\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m9\" intent=\":literal\"><semantics><mrow><mi>T</mi><mo>&lt;</mo><mn>20</mn></mrow><annotation encoding=\"application/x-tex\">T&lt;20</annotation></semantics></math> and <math alttext=\"w=5\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m10\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">w=5</annotation></semantics></math> otherwise.</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "hubert",
                    "simple",
                    "owlv2",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Large Vision Language Models (LVLMs)</span>. We evaluate two popular LVLMs on query matching for videos: <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib27\" title=\"\">27</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib45\" title=\"\">45</a>]</cite>.\nFor the \"always car\" example, we provide the models with the video sequence and a text prompt \"Is a car detected in all frames of this video?\". The response is considered correct if the model responds with \"Yes\" or \"No\" for matching and non-matching samples respectively. <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span> supports a context window of <math alttext=\"4096\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m1\" intent=\":literal\"><semantics><mn>4096</mn><annotation encoding=\"application/x-tex\">4096</annotation></semantics></math> tokens while <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span> can handle up to 2000 frames. We set the maximum tokens to generate to <math alttext=\"60\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m2\" intent=\":literal\"><semantics><mn>60</mn><annotation encoding=\"application/x-tex\">60</annotation></semantics></math> and <math alttext=\"1024\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m3\" intent=\":literal\"><semantics><mn>1024</mn><annotation encoding=\"application/x-tex\">1024</annotation></semantics></math> respectively and use a temperature of 0.1 and standard values for the other parameters.</p>\n\n",
                "matched_terms": [
                    "videollava7b",
                    "longva7b",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Large Audio Language Models (LALMs)</span>. Similarly, we evaluate two popular LALMs on query matching for speech: <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib10\" title=\"\">10</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">Qwen2-Audio-7B-Instruct</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib11\" title=\"\">11</a>]</cite>.\nFor the \"eventually happy\" example, we provide the models with the audio sequence and a text prompt \"Does the speaker sound happy at some time in this audio clip?\". We set the sampling rate to <math alttext=\"16000\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p3.m1\" intent=\":literal\"><semantics><mn>16000</mn><annotation encoding=\"application/x-tex\">16000</annotation></semantics></math> and generate a maximum of <math alttext=\"256\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p3.m2\" intent=\":literal\"><semantics><mn>256</mn><annotation encoding=\"application/x-tex\">256</annotation></semantics></math> new tokens, with standard values for other parameters.</p>\n\n",
                "matched_terms": [
                    "qwen2audio7binstruct",
                    "qwenaudiochat",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>.</span> Proposed for event detection in videos, NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite> uses the PCTL-based model checker STORM&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib20\" title=\"\">20</a>]</cite> to identify video frame subsequences where a certain event is detected. NSVS-TL reports state-of-the-art performance on detecting temporal events in videos, surpassing large language models such as GPT-4.\nFor our task, we specify the target query in PCTL (\"always car\" is <math alttext=\"P&gt;0.5[G\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A4.p4.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo stretchy=\"false\">[</mo><mi>G</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5[G</annotation></semantics></math> \"<math alttext=\"{car}\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p4.m2\" intent=\":literal\"><semantics><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><annotation encoding=\"application/x-tex\">{car}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p4.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math>) and the response is considered correct if NSVS-TL returns / does not return the entire video sequence as output for a matching / non-matching query respectively.</p>\n\n",
                "matched_terms": [
                    "temporal",
                    "nsvstl",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We choose <math alttext=\"15\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p1.m1\" intent=\":literal\"><semantics><mn>15</mn><annotation encoding=\"application/x-tex\">15</annotation></semantics></math> temporal property templates for the experiments in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>.</p>\n\n",
                "matched_terms": [
                    "property",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite> uses the model checker STORM&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib20\" title=\"\">20</a>]</cite> to verify if a given sequence satisfies a temporal property, where the temporal properties are represented in Probabilistic Computation Tree Logic (PCTL). In PCTL, the <math alttext=\"F\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m1\" intent=\":literal\"><semantics><mi>F</mi><annotation encoding=\"application/x-tex\">F</annotation></semantics></math>, <math alttext=\"G\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m2\" intent=\":literal\"><semantics><mi>G</mi><annotation encoding=\"application/x-tex\">G</annotation></semantics></math> and <math alttext=\"U\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m3\" intent=\":literal\"><semantics><mi>U</mi><annotation encoding=\"application/x-tex\">U</annotation></semantics></math> operators represent the <span class=\"ltx_text ltx_font_italic\">Eventually</span>, <span class=\"ltx_text ltx_font_italic\">Always</span> and <span class=\"ltx_text ltx_font_italic\">Until</span> operators respectively. The <math alttext=\"\\sim\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m4\" intent=\":literal\"><semantics><mo>&#8764;</mo><annotation encoding=\"application/x-tex\">\\sim</annotation></semantics></math>, <math alttext=\"\\&amp;\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m5\" intent=\":literal\"><semantics><mo>&amp;</mo><annotation encoding=\"application/x-tex\">\\&amp;</annotation></semantics></math> and <math alttext=\"\\mid\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m6\" intent=\":literal\"><semantics><mo>&#8739;</mo><annotation encoding=\"application/x-tex\">\\mid</annotation></semantics></math> operators represent the Boolean <span class=\"ltx_text ltx_font_italic\">negation</span>, <span class=\"ltx_text ltx_font_italic\">and</span>, and <span class=\"ltx_text ltx_font_italic\">or</span> operators respectively. The operator <math alttext=\"P\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m7\" intent=\":literal\"><semantics><mi>P</mi><annotation encoding=\"application/x-tex\">P</annotation></semantics></math> is used to indicate the ranges of probability of a given property being satisfied: for example, <math alttext=\"P&gt;0.5[F\\,\\varphi]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m8\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mrow><mn>0.5</mn><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>F</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5[F\\,\\varphi]</annotation></semantics></math> translates to \"the probability of <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m9\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> eventually being satisfied is more than <math alttext=\"0.5\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m10\" intent=\":literal\"><semantics><mn>0.5</mn><annotation encoding=\"application/x-tex\">0.5</annotation></semantics></math>\".</p>\n\n",
                "matched_terms": [
                    "temporal",
                    "nsvstl",
                    "property",
                    "sequence"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The PCTL queries for the 15 temporal property templates are as follows:</p>\n\n",
                "matched_terms": [
                    "property",
                    "temporal"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A9.F6\" title=\"Figure 6 &#8227; Appendix I Adaptive threshold vs. constant threshold &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> presents a comparison of the adaptive threshold and the constant <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"A9.p1.m1\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math> threshold for all temporal property templates, using LogSTOPs for matching and non-matching sequences from the QMTP-video (detections using YOLOv8).</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "temporal",
                    "property",
                    "qmtpvideo"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we present the query matching results for the QMTP datasets.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.SS2\" title=\"J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">J.2</span></a> presents the results (balanced accuracies) aggregated by category.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.T4\" title=\"Table 4 &#8227; J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.T5\" title=\"Table 5 &#8227; J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> report the results for the 15 temporal property templates for QMTP-video and QMTP-speech respectively.</p>\n\n",
                "matched_terms": [
                    "property",
                    "balanced",
                    "qmtpvideo",
                    "temporal",
                    "category",
                    "results",
                    "datasets",
                    "qmtpspeech"
                ]
            }
        ]
    },
    "A10.T4": {
        "caption": "Table 4: LogSTOP reports the best overall balanced accuracy on the QMTP-video dataset, outperforming LVLMs and NSVS-TL. Moreover, it reports the best performance on all queries. The dataset contains 3750 matching and 3718 non-matching sequences of lengths {10,20,30,40,50}\\{10,20,30,40,50\\}. The best performing method is highlighted in bold and the second best is underlined.",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">Query</th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">NSVS-TL</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">Video-LLaVA-7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">LongVA-7B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\">LogSTOP</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_row\"/>\n<td class=\"ltx_td\"/>\n<td class=\"ltx_td\"/>\n<td class=\"ltx_td\"/>\n<td class=\"ltx_td ltx_align_center\">OWLv2</td>\n<td class=\"ltx_td ltx_align_center\">GroundingDINO</td>\n<td class=\"ltx_td ltx_align_center\">YOLOv8</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Eventually p1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.62</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.71</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.65</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.62</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.84</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Always p1</th>\n<td class=\"ltx_td ltx_align_center\">0.68</td>\n<td class=\"ltx_td ltx_align_center\">0.51</td>\n<td class=\"ltx_td ltx_align_center\">0.72</td>\n<td class=\"ltx_td ltx_align_center\">0.54</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.76</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.81</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">p1 Until p2</th>\n<td class=\"ltx_td ltx_align_center\">0.7</td>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.61</td>\n<td class=\"ltx_td ltx_align_center\">0.63</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.73</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.8</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Always p1 and Eventually p2</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.55</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.65</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.51</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.65</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.72</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Always p1 or Eventually p2</th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.71</span></td>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.61</td>\n<td class=\"ltx_td ltx_align_center\">0.68</td>\n<td class=\"ltx_td ltx_align_center\">0.61</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.78</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Not p1 Until p2</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.68</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.71</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.77</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.85</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">p1 Until Not p2</th>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.64</td>\n<td class=\"ltx_td ltx_align_center\">0.53</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.66</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.78</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Always (p1 and p2)</th>\n<td class=\"ltx_td ltx_align_center\">0.55</td>\n<td class=\"ltx_td ltx_align_center\">0.51</td>\n<td class=\"ltx_td ltx_align_center\">0.62</td>\n<td class=\"ltx_td ltx_align_center\">0.51</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.65</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.73</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">p1 and p2 Until p3</th>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.55</td>\n<td class=\"ltx_td ltx_align_center\">0.56</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.71</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.78</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">p1 Until Always p2</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.64</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.57</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.51</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.62</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.75</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Eventually Always p1</th>\n<td class=\"ltx_td ltx_align_center\">0.64</td>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.62</td>\n<td class=\"ltx_td ltx_align_center\">0.7</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.76</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.79</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Always Eventually p1</th>\n<td class=\"ltx_td ltx_align_center\">0.64</td>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.69</td>\n<td class=\"ltx_td ltx_align_center\">0.55</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.72</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.76</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">(Not p1) Until Eventually p2</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.61</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.59</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.59</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.81</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">(Not p1) Until Always p2</th>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.68</td>\n<td class=\"ltx_td ltx_align_center\">0.66</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.71</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.78</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">(p1 and p2) Until Eventually p3</th>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\">0.55</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.65</span></td>\n<td class=\"ltx_td ltx_align_center\">0.62</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.84</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\">Overall</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.58</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.63</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.6</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.68</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.79</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "queries",
            "nonmatching",
            "balanced",
            "second",
            "matching",
            "query",
            "overall",
            "groundingdino",
            "lengths",
            "eventually",
            "not",
            "longva7b",
            "qmtpvideo",
            "nsvstl",
            "videollava7b",
            "lvlms",
            "until",
            "accuracy",
            "moreover",
            "performance",
            "performing",
            "bold",
            "highlighted",
            "logstop",
            "sequences",
            "underlined",
            "reports",
            "yolov8",
            "outperforming",
            "best",
            "all",
            "owlv2",
            "method",
            "dataset",
            "contains",
            "always"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">In Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we present the query matching results for the QMTP datasets.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.SS2\" title=\"J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">J.2</span></a> presents the results (balanced accuracies) aggregated by category.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.T4\" title=\"Table 4 &#8227; J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.T5\" title=\"Table 5 &#8227; J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> report the results for the 15 temporal property templates for QMTP-video and QMTP-speech respectively.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Neural models such as YOLO and HuBERT can be used to detect local properties such as objects (\"car\") and emotions (\"angry\") in individual frames of videos and audio clips respectively. The likelihood of these detections is indicated by scores in [0, 1]. Lifting these scores to temporal properties over sequences can be useful for several downstream applications such as query matching (e.g., \"does the speaker eventually sound happy in this audio clip?\"), and ranked retrieval (e.g., \"retrieve top 5 videos with a 10 second scene where a car is detected until a pedestrian is detected\").\nIn this work, we formalize this problem of assigning Scores for TempOral Properties (STOPs) over sequences, given potentially noisy score predictors for local properties.\nWe then propose a scoring function called LogSTOP that can efficiently compute these scores for temporal properties represented in Linear Temporal Logic.\nEmpirically, LogSTOP, with YOLO and HuBERT, outperforms Large Vision / Audio Language Models and other Temporal Logic-based baselines by at least 16% on query matching with temporal properties over objects-in-videos and emotions-in-speech respectively. Similarly, on ranked retrieval with temporal properties over objects and actions in videos, LogSTOP with Grounding DINO and SlowR50 reports at least a 19% and 16% increase in mean average precision and recall over zero-shot text-to-video retrieval baselines respectively.</p>\n\n",
                "matched_terms": [
                    "reports",
                    "second",
                    "matching",
                    "query",
                    "until",
                    "logstop",
                    "sequences",
                    "eventually"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Detecting complex temporal events in unstructured data sequences such as videos and audio clips is important in several domains.\nFor instance, traffic surveillance systems\nneed to\n<span class=\"ltx_text ltx_font_italic\">match</span> scenes perceived by autonomous vehicles\nagainst critical <span class=\"ltx_text ltx_font_italic\">temporal</span> properties such as\n\"the vehicle <span class=\"ltx_text ltx_font_italic\">always</span> remains in a given lane\".\nSimilarly, search engines\nmight need to\n<span class=\"ltx_text ltx_font_italic\">rank</span> videos or audio clips by relevance to temporal scenes (\"a 10 second scene where a person <span class=\"ltx_text ltx_font_italic\">eventually</span> starts running\" or \"a 20-30 second segment where speaker A sounds sad and B sounds frustrated <span class=\"ltx_text ltx_font_italic\">until</span> both sound neutral\").</p>\n\n",
                "matched_terms": [
                    "second",
                    "until",
                    "sequences",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The sequences and local properties could correspond to arbitrary modalities and classes of interest, including objects or actions in videos, and speakers or emotions in audio clips. These STOPs are useful for several downstream applications such as\n<span class=\"ltx_text ltx_font_bold\">query matching</span>\n, i.e., checking if the scores\nare over a threshold to decide if the sequence expresses a temporal property,\nand\n<span class=\"ltx_text ltx_font_bold\">ranked retrieval</span>, i.e.,\nranking sequences\nagainst a temporal query by these scores to provide the top-k most relevant results.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "sequences",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We argue that Linear Temporal Logic, with temporal operators such as \"Always\" (<math alttext=\"\\square\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m1\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#9633;</mi><annotation encoding=\"application/x-tex\">\\square</annotation></semantics></math>) and \"Until\" (<math alttext=\"\\mathbin{\\mathcal{U}}\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m2\" intent=\":literal\"><semantics><mo class=\"ltx_font_mathcaligraphic\">&#119984;</mo><annotation encoding=\"application/x-tex\">\\mathbin{\\mathcal{U}}</annotation></semantics></math>), provides a suitable language\nfor expressing diverse\ntemporal properties of interest.\nFor example,\nthe property \"A and B sound happy until A sounds sad\" can be written in LTL\nas <math alttext=\"(\\mathsf{{happy}_{A}}\\land\\mathsf{{happy}_{B}})\\mathbin{\\mathcal{U}}\\mathsf{{sad}_{A}}\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m3\" intent=\":literal\"><semantics><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>&#120257;&#120250;&#120265;&#120265;&#120274;</mi><mi>&#120224;</mi></msub><mo>&#8743;</mo><msub><mi>&#120257;&#120250;&#120265;&#120265;&#120274;</mi><mi>&#120225;</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#120268;&#120250;&#120253;</mi><mi>&#120224;</mi></msub></mrow><annotation encoding=\"application/x-tex\">(\\mathsf{{happy}_{A}}\\land\\mathsf{{happy}_{B}})\\mathbin{\\mathcal{U}}\\mathsf{{sad}_{A}}</annotation></semantics></math>.\nFor temporal properties in LTL, the framework proposed by <cite class=\"ltx_cite ltx_citemacro_citet\">Yang et&#160;al. [<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>]</cite> can be used as a solution to the STOP problem with two major caveats.\nFirstly, this approach requires <math alttext=\"\\mathcal{O}(T\\cdot 2^{|C|})\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><msup><mn>2</mn><mrow><mo stretchy=\"false\">|</mo><mi>C</mi><mo stretchy=\"false\">|</mo></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot 2^{|C|})</annotation></semantics></math> space and time for a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m5\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> and <math alttext=\"|C|\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m6\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>C</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|C|</annotation></semantics></math> local properties.\nThis exponential space and time complexity renders this approach inefficient for applications such as retrieval where sequences from a large database (with potentially many local properties) need to be checked.\nSecondly, this approach has no provision to handle incorrectly low or high, i.e., <span class=\"ltx_text ltx_font_italic\">potentially noisy</span>, scores for local properties.</p>\n\n",
                "matched_terms": [
                    "until",
                    "sequences",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose a novel scoring function called LogSTOP, inspired by quantitative semantics for LTL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib14\" title=\"\">14</a>]</cite>,\nthat\nassigns a score for a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m1\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> satisfying temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\nin <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m3\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> time and space.\nLogSTOP employs a simple downsampling and smoothing strategy for handling locally incorrect\npredictions by the local property predictors.\nThis makes it robust to cases where, for example, an object detector detects a car with very low scores in some frames because it is occluded.\nMoreover, the linear time computational complexity makes it an efficient solution for applications such as query matching and ranked retrieval (see example in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).\nFor query matching, we propose a length and query-adaptive threshold which is guaranteed to accept at least as many sequences as a fixed threshold.\nWe also demonstrate how LogSTOP can be used to rank sequences based on subsequence relevance to temporal queries in <math alttext=\"\\mathcal{O}(T^{2}\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>T</mi><mn>2</mn></msup><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T^{2}\\cdot|\\varphi|)</annotation></semantics></math> time.</p>\n\n",
                "matched_terms": [
                    "queries",
                    "matching",
                    "query",
                    "logstop",
                    "sequences",
                    "moreover"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate LogSTOP on query matching and ranked retrieval,\nwith sequence modalities including videos and speech, and local properties such as objects, actions, and emotions.\nWe focus on 15 diverse temporal property templates of varying complexity.\nSince no existing benchmarks support this breadth of temporal properties\nand sequence types, we propose two new benchmarks:\nthe QMTP (Query Matching for Temporal Properties) benchmark\nfor objects-in-videos from the RealTLV dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>,\nand emotions-in-speech from the IEMOCAP dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite>;\nand the TP2VR (Temporal Property to Video Retrieval) benchmark\nfor objects-in-videos from the RealTLV dataset,\nand actions-in-videos from the AVA dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite>.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "dataset",
                    "logstop",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We find that LogSTOP with simple detection models,\nsuch as YOLO and HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib21\" title=\"\">21</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite>,\noutperforms baselines including Large Vision / Audio Language Models (LVLMs / LALMs), and\nNSVS-TL\n, on query matching by more than <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m1\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of balanced accuracy.\nSimilarly,\nLogSTOP with Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite>\nand SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> outperforms\nzero-shot text-to-video retrieval methods, such as mPLUG&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite>\nand text-text similarity with video captions,\nby more than <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m2\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> and <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m3\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of mean average precision and recall respectively.</p>\n\n",
                "matched_terms": [
                    "nsvstl",
                    "balanced",
                    "matching",
                    "lvlms",
                    "query",
                    "logstop",
                    "accuracy"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Let <math alttext=\"X=[x_{1},\\ldots,x_{T}]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m1\" intent=\":literal\"><semantics><mrow><mi>X</mi><mo>=</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><msub><mi>x</mi><mi>T</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X=[x_{1},\\ldots,x_{T}]</annotation></semantics></math>\ndenote a sequence of data items of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m2\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math>, where <math alttext=\"x_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m3\" intent=\":literal\"><semantics><msub><mi>x</mi><mi>t</mi></msub><annotation encoding=\"application/x-tex\">x_{t}</annotation></semantics></math> denotes the data item at timestep <math alttext=\"1\\leq t\\leq T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m4\" intent=\":literal\"><semantics><mrow><mn>1</mn><mo>&#8804;</mo><mi>t</mi><mo>&#8804;</mo><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">1\\leq t\\leq T</annotation></semantics></math>.\nLet <math alttext=\"\\mathcal{X}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m5\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119987;</mi><annotation encoding=\"application/x-tex\">\\mathcal{X}</annotation></semantics></math> denote the set of all such sequences, and <math alttext=\"\\mathcal{T}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m6\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><annotation encoding=\"application/x-tex\">\\mathcal{T}</annotation></semantics></math> denote the set of all timesteps <math alttext=\"\\{1,\\ldots,T\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m7\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><mi>T</mi><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{1,\\ldots,T\\}</annotation></semantics></math>.\nFurther, let <math alttext=\"C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m8\" intent=\":literal\"><semantics><mi>C</mi><annotation encoding=\"application/x-tex\">C</annotation></semantics></math> denote a finite set of local properties of interest.\nIn general, <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m9\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> and <math alttext=\"C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m10\" intent=\":literal\"><semantics><mi>C</mi><annotation encoding=\"application/x-tex\">C</annotation></semantics></math> could correspond to sequences of arbitrary modalities and properties respectively,\nincluding but not limited to objects or actions in videos, and speakers or emotions in audio clips.\nWhile these sequences could be over continuous time, we assume that they are discretized into <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m11\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> timesteps for simplicity.</p>\n\n",
                "matched_terms": [
                    "all",
                    "not",
                    "sequences"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this work, we are interested in temporal compositions of these local properties.\nFor example, given the true labels for the object \"car\" in individual frames,\nhow can we define the label for a car being present in all frames or alternatively any frame?\nOr, given the true labels for \"car\" and \"pedestrian\",\nhow can we define the label for a car being present in all frames until a pedestrian is detected?</p>\n\n",
                "matched_terms": [
                    "until",
                    "all"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where, <math alttext=\"c\\in C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m3\" intent=\":literal\"><semantics><mrow><mi>c</mi><mo>&#8712;</mo><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">c\\in C</annotation></semantics></math> is a local property and <math alttext=\"\\varphi_{1},\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m4\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>,</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1},\\varphi_{2}</annotation></semantics></math> are temporal properties. <math alttext=\"\\neg,\\land,\\lor\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m5\" intent=\":literal\"><semantics><mrow><mo>&#172;</mo><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8743;</mo><mo rspace=\"0em\">,</mo><mo lspace=\"0em\">&#8744;</mo></mrow><annotation encoding=\"application/x-tex\">\\neg,\\land,\\lor</annotation></semantics></math> are the logical <span class=\"ltx_text ltx_font_italic\">not</span>, <span class=\"ltx_text ltx_font_italic\">and</span>, and <span class=\"ltx_text ltx_font_italic\">or</span> operators respectively. <math alttext=\"\\bigcirc\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m6\" intent=\":literal\"><semantics><mo>&#9675;</mo><annotation encoding=\"application/x-tex\">\\bigcirc</annotation></semantics></math>, <math alttext=\"\\square\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m7\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#9633;</mi><annotation encoding=\"application/x-tex\">\\square</annotation></semantics></math> and <math alttext=\"\\mathbin{\\mathcal{U}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m8\" intent=\":literal\"><semantics><mo class=\"ltx_font_mathcaligraphic\">&#119984;</mo><annotation encoding=\"application/x-tex\">\\mathbin{\\mathcal{U}}</annotation></semantics></math> are temporal operators <span class=\"ltx_text ltx_font_italic\">Next</span>, <span class=\"ltx_text ltx_font_italic\">Always</span>, and <span class=\"ltx_text ltx_font_italic\">Until</span> respectively. Other temporal operators such as \"Eventually <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m9\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\" (<math alttext=\"\\Diamond\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m10\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\Diamond\\varphi</annotation></semantics></math>) can then be derived as <math alttext=\"\\neg\\square\\neg\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m11\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.167em\" rspace=\"0em\">&#8203;</mo><mrow><mo rspace=\"0.167em\">&#172;</mo><mi>&#966;</mi></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg\\square\\neg\\varphi</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This language can now be used to represent properties from the previous examples. For instance, the temporal properties for a car being present in all frames and any frame in a video can be represented as <math alttext=\"\\varphi=\\square\\,\\mathsf{car}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p5.m1\" intent=\":literal\"><semantics><mrow><mi>&#966;</mi><mo>=</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#120252;&#120250;&#120267;</mi></mrow></mrow><annotation encoding=\"application/x-tex\">\\varphi=\\square\\,\\mathsf{car}</annotation></semantics></math> and <math alttext=\"\\varphi=\\Diamond\\,\\mathsf{car}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p5.m2\" intent=\":literal\"><semantics><mrow><mi>&#966;</mi><mo>=</mo><mrow><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#120252;&#120250;&#120267;</mi></mrow></mrow><annotation encoding=\"application/x-tex\">\\varphi=\\Diamond\\,\\mathsf{car}</annotation></semantics></math> respectively. Furthermore, the property that a car is present in all frames until a pedestrian is present can be represented as <math alttext=\"\\varphi=\\mathsf{car}\\mathbin{\\mathcal{U}}\\mathsf{pedestrian}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p5.m3\" intent=\":literal\"><semantics><mrow><mi>&#966;</mi><mo>=</mo><mrow><mi>&#120252;&#120250;&#120267;</mi><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi>&#120265;&#120254;&#120253;&#120254;&#120268;&#120269;&#120267;&#120258;&#120250;&#120263;</mi></mrow></mrow><annotation encoding=\"application/x-tex\">\\varphi=\\mathsf{car}\\mathbin{\\mathcal{U}}\\mathsf{pedestrian}</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "until",
                    "all"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Given the true labeling functions for local properties <math alttext=\"y(X,c,\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m1\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(X,c,\\cdot)</annotation></semantics></math>,\nthis semantics can perfectly determine if a sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m2\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> expresses a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m3\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\n(if and only if <math alttext=\"y(X,\\varphi,1)=1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m4\" intent=\":literal\"><semantics><mrow><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>&#966;</mi><mo>,</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">y(X,\\varphi,1)=1</annotation></semantics></math>).\nIn practice, however, we do not have access to these true labeling functions.\nWe assume that noisy predictors can be used instead to provide\n<span class=\"ltx_text ltx_font_italic\">scores</span> <math alttext=\"\\hat{y}:\\mathcal{X}\\times C\\times\\mathcal{T}\\mapsto[a,b]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m5\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119987;</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><mi>C</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi></mrow><mo stretchy=\"false\">&#8614;</mo><mrow><mo stretchy=\"false\">[</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}:\\mathcal{X}\\times C\\times\\mathcal{T}\\mapsto[a,b]</annotation></semantics></math> for the label being 1,\nwhere <math alttext=\"a\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m6\" intent=\":literal\"><semantics><mi>a</mi><annotation encoding=\"application/x-tex\">a</annotation></semantics></math> and <math alttext=\"b\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m7\" intent=\":literal\"><semantics><mi>b</mi><annotation encoding=\"application/x-tex\">b</annotation></semantics></math> are the lower and upper bounds of the score range respectively.\nThe estimate for true label <math alttext=\"y(X,c,t)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m8\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(X,c,t)</annotation></semantics></math> can then be computed as <math alttext=\"\\tilde{y}(X,c,t)=\\hat{y}(X,c,t)&gt;\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m9\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>~</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mi>&#964;</mi></mrow><annotation encoding=\"application/x-tex\">\\tilde{y}(X,c,t)=\\hat{y}(X,c,t)&gt;\\tau</annotation></semantics></math>\nfor some threshold <math alttext=\"\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m10\" intent=\":literal\"><semantics><mi>&#964;</mi><annotation encoding=\"application/x-tex\">\\tau</annotation></semantics></math>.\nMost neural models, including object detection models such as YOLO,\nprovide scores in <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m11\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math> and an object <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m12\" intent=\":literal\"><semantics><mi>c</mi><annotation encoding=\"application/x-tex\">c</annotation></semantics></math> is said to be detected at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m13\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>\nif <math alttext=\"\\hat{y}(X,c,t)&gt;\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m14\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mi>&#964;</mi></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(X,c,t)&gt;\\tau</annotation></semantics></math>, where <math alttext=\"\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m15\" intent=\":literal\"><semantics><mi>&#964;</mi><annotation encoding=\"application/x-tex\">\\tau</annotation></semantics></math> usually is <math alttext=\"0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m16\" intent=\":literal\"><semantics><mn>0.5</mn><annotation encoding=\"application/x-tex\">0.5</annotation></semantics></math>.\nThe accuracy of these predictors then just measures how well <math alttext=\"\\tilde{y}(X,c,\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m17\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>~</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\tilde{y}(X,c,\\cdot)</annotation></semantics></math> estimates <math alttext=\"y(X,c,\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p8.m18\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(X,c,\\cdot)</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "accuracy",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, the LogSTOP for a sequence with respect to a temporal property represents the log probability of the sequence\nsatisfying the temporal property if certain assumptions are met.\nConcretely, this is true when (1) the local properties represent independent events over time,\n(2) the scores for local properties reflect true log probabilities,\nand (3) temporal properties consist of compositions of independent local properties.\nWe acknowledge that these assumptions are rarely true for real-world sequences and properties.\nFor instance, the presence of \"car\" at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m1\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and <math alttext=\"t+1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m2\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t+1</annotation></semantics></math> are not independent events.\nHowever, these assumptions allow us to use ideas from probability theory for independent events to compute the score.\nMoreover, our experiments in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>\nshow that LogSTOPs are useful for applications such as query matching and ranked retrieval\neven when these assumptions are not met.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "query",
                    "logstop",
                    "sequences",
                    "not",
                    "moreover"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, LogSTOP deals with potentially noisy local predictions\nby downsampling and smoothing predictions over windows of length <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m1\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math>\n(Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l8\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>).\nThis\nessentially captures the property that local property scores cannot change drastically in a short local window\n(objects cannot momentarily disappear and reappear, actions cannot change in fractions of seconds, etc.).\nNote that <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m2\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> is a hyperparameter; a higher value of <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m3\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> can be used to control for higher variance in local predictions.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "second"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We briefly discuss how different operators\nare handled in Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>\nand defer a detailed discussion with examples to Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A1\" title=\"Appendix A More details on Algorithm 1 &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">A</span></a>.\nThe scores for logical operators, negation <math alttext=\"\\neg\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\neg\\varphi</annotation></semantics></math>, conjunction <math alttext=\"\\varphi_{1}\\land\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m2\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8743;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\land\\varphi_{2}</annotation></semantics></math>, and disjunction <math alttext=\"\\varphi_{1}\\lor\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m3\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8744;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\lor\\varphi_{2}</annotation></semantics></math>\nare computed using simple rules from probability theory.\nConcretely, LogSTOP for <math alttext=\"\\varphi_{1}\\land\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m4\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8743;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\land\\varphi_{2}</annotation></semantics></math> is the sum of the LogSTOPs for <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m5\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> and <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m6\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l12\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">12</span></a>), and\nthe LogSTOP for <math alttext=\"\\varphi_{1}\\lor\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m7\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8744;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\lor\\varphi_{2}</annotation></semantics></math> is computed using DeMorgan&#8217;s law\n(line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l14\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">14</span></a>).\nThe score for the \"next\" operator <math alttext=\"\\bigcirc\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m8\" intent=\":literal\"><semantics><mrow><mi/><mo lspace=\"0.222em\" rspace=\"0.222em\">&#9675;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\bigcirc\\varphi</annotation></semantics></math> is computed by shifting the timestep by one window (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l16\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">16</span></a>).\nScores for the \"always\" (<math alttext=\"\\square\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m9\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\varphi</annotation></semantics></math>) and \"until\" (<math alttext=\"\\varphi_{1}\\mathcal{U}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m10\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi class=\"ltx_font_mathcaligraphic\">&#119984;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathcal{U}\\varphi_{2}</annotation></semantics></math>)\noperators\nare computed recursively using the scores for these properties at the next window (lines&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l18\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">18</span></a>-<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l20\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">20</span></a>).\nInformally, the LogSTOP for Always <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m11\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m12\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> can be computed with a <span class=\"ltx_text ltx_font_italic\">\"temporal and\"</span> over <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m13\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m14\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and Always <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m15\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at the next window, <math alttext=\"t+w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m16\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">t+w</annotation></semantics></math>.\nSimilarly, the LogSTOP for <math alttext=\"\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m17\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}</annotation></semantics></math> can be computed with a <span class=\"ltx_text ltx_font_italic\">\"temporal or\"</span> over (1) <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m18\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m19\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, and (2) <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m20\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m21\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> with <math alttext=\"\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m22\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}</annotation></semantics></math> at the next window.</p>\n\n",
                "matched_terms": [
                    "until",
                    "logstop",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Complexity analysis for LogSTOP.</span>\nThe computational complexity of Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>,\nfor a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m1\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> with length <math alttext=\"|\\varphi|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m2\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|\\varphi|</annotation></semantics></math> and a sequence of <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m3\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> predictions\nis <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math>.\nThis uses dynamic programming to cache scores for all sub-properties over the sequence&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib15\" title=\"\">15</a>]</cite>.\nThe key observation here is that at any timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m5\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, the LogSTOP for <span class=\"ltx_text ltx_font_italic\">any</span> property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m6\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> can be computed in <math alttext=\"\\mathcal{O}(|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m7\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(|\\varphi|)</annotation></semantics></math> given the LogSTOPs for its sub-properties at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m8\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and itself at <math alttext=\"t+w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m9\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">t+w</annotation></semantics></math>.\nThis is because the LogSTOPs for temporal properties are defined recursively and there are at most <math alttext=\"|\\varphi|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m10\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|\\varphi|</annotation></semantics></math> sub-properties.\nFor <math alttext=\"T/w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m11\" intent=\":literal\"><semantics><mrow><mi>T</mi><mo>/</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">T/w</annotation></semantics></math> timesteps, this results in <math alttext=\"\\mathcal{O}((T/w)\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m12\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>/</mo><mi>w</mi></mrow><mo rspace=\"0.055em\" stretchy=\"false\">)</mo></mrow><mo rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}((T/w)\\cdot|\\varphi|)</annotation></semantics></math> time.\nSince the smoothing operation takes <math alttext=\"\\mathcal{O}(w)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m13\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(w)</annotation></semantics></math> time per window,\ncomputing LogSTOP for <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m14\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> over a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m15\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> requires <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p7.m16\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> time.</p>\n\n",
                "matched_terms": [
                    "all",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We define query matching with temporal properties as the task of predicting whether a given temporal property / query matches, or is expressed by, a sequence.\nLogSTOPs can be used for matching sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m1\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> with query <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> by comparing <math alttext=\"\\hat{y}(X,\\varphi,1,T)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m3\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>&#966;</mi><mo>,</mo><mn>1</mn><mo>,</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(X,\\varphi,1,T)</annotation></semantics></math> with an appropriate threshold.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">A natural first choice for such a threshold for LogSTOP is the constant <math alttext=\"\\tau=\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><mi>&#964;</mi><mo>=</mo><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\tau=\\log 0.5</annotation></semantics></math>. This threshold, is employed by existing works to determine if a video satisfies a temporal property&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>. This, however, does not scale with the length of the sequence. For instance, given a 6-frame video with constant <math alttext=\"\\log 0.9\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m2\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.9</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.9</annotation></semantics></math> scores for \"car\",\nthe LogSTOP for temporal property \"Always car\", with <math alttext=\"w=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">w=1</annotation></semantics></math>, is <math alttext=\"\\log(0.9^{6})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><msup><mn>0.9</mn><mn>6</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9^{6})</annotation></semantics></math>. This is greater than <math alttext=\"\\log(0.5)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m5\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.5</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.5)</annotation></semantics></math> and hence the video matches the query.\nHowever, when another frame with the same high score <math alttext=\"\\log(0.9)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m6\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9)</annotation></semantics></math> is added,\nthe score drops to <math alttext=\"\\log(0.9^{7})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m7\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><msup><mn>0.9</mn><mn>7</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9^{7})</annotation></semantics></math>, which is less than <math alttext=\"\\log(0.5)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m8\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.5</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.5)</annotation></semantics></math> and hence the video no longer matches the query.\nWe would ideally also like the latter to match the query since the property \"car\" is detected with high scores.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "not",
                    "always",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Informally, a sequence expresses a temporal property if the LogSTOP is higher than both random chance <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m1\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math>\nand LogSTOP using random chance predictors for local properties <math alttext=\"\\hat{y}_{0.5}(\\cdot,\\varphi,T,w)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m2\" intent=\":literal\"><semantics><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>0.5</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo>,</mo><mi>&#966;</mi><mo>,</mo><mi>T</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{0.5}(\\cdot,\\varphi,T,w)</annotation></semantics></math>.\nThis threshold can be computed in <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m3\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> and is guaranteed to match at least as many sequences as the constant <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m4\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math> threshold.\nFor properties where the score decreases with sequence length (e.g., <math alttext=\"\\square\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m5\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\varphi</annotation></semantics></math>), the adaptive threshold\nallows more sequences to match\nthe query\nthan the constant threshold.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "sequences",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LogSTOP\ncan also be used for the task of ranking and\nretrieving sequences relevant to temporal properties of interest.\nFormally, given a database of <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> sequences <math alttext=\"\\mathcal{D}=\\{X_{1},\\ldots,X_{N}\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m2\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119967;</mi><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><msub><mi>X</mi><mi>N</mi></msub><mo stretchy=\"false\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{D}=\\{X_{1},\\ldots,X_{N}\\}</annotation></semantics></math>\na temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m3\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>,\nand a range of event lengths <math alttext=\"(T_{lo},T_{hi})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(T_{lo},T_{hi})</annotation></semantics></math>,\nthe goal is to rank each <math alttext=\"X_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m5\" intent=\":literal\"><semantics><msub><mi>X</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">X_{i}</annotation></semantics></math> based on whether\nit contains a subsequence <math alttext=\"X_{i}[t:t^{\\prime}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.SS2.p1.m6\" intent=\":literal\"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">[</mo><mi>t</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><msup><mi>t</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X_{i}[t:t^{\\prime}]</annotation></semantics></math> of length <math alttext=\"t^{\\prime}-t\\in[T_{lo},T_{hi}]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m7\" intent=\":literal\"><semantics><mrow><mrow><msup><mi>t</mi><mo>&#8242;</mo></msup><mo>&#8722;</mo><mi>t</mi></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">t^{\\prime}-t\\in[T_{lo},T_{hi}]</annotation></semantics></math> that expresses <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m8\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>.\nExamples of such queries include \"videos with a 10 to 20 second scene where a person is sitting down until they stand up\".\nThis task is different from the query matching task in two key ways:\nfirstly, the relative ranking of sequences is more important than absolute scores.\nSecondly and more importantly,\nthe relevance of a sequence may only be with respect to a part of the sequence (a <span class=\"ltx_text ltx_font_italic\">moment</span> in the video, for example).</p>\n\n",
                "matched_terms": [
                    "queries",
                    "second",
                    "matching",
                    "query",
                    "until",
                    "logstop",
                    "sequences",
                    "lengths",
                    "contains"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg2\" title=\"Algorithm 2 &#8227; 3.1 LogSTOP for Query Matching &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> outlines how LogSTOP can be used for ranked retrieval.\nInformally, given a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m1\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>, sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m2\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math>, and event duration <math alttext=\"(T_{lo},T_{hi})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m3\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(T_{lo},T_{hi})</annotation></semantics></math>,\nthe relevance of <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m4\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> to <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m5\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\nis defined as the maximum LogSTOP of any subsequence of <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m6\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> of length in <math alttext=\"[T_{lo},T_{hi}]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m7\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[T_{lo},T_{hi}]</annotation></semantics></math>.\nThe relevance score for any sequence can be computed in <math alttext=\"\\mathcal{O}(T^{2}\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m8\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>T</mi><mn>2</mn></msup><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T^{2}\\cdot|\\varphi|)</annotation></semantics></math> time\nsince LogSTOPs for suffix subsequences are cached with dynamic programming.\nNote\nthat this represents one way of computing scores for ranking videos, where subsequences of certain lengths are relevant to queries; there could be other variants which LogSTOP could be used for but are not considered (for example, computing the score with respect to the entire video, or only considering videos where the subsequence score is over a threshold).</p>\n\n",
                "matched_terms": [
                    "queries",
                    "lengths",
                    "not",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Simple temporal operators:</span> Eventually p1, Always p1, p1 Until p2.</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Boolean over temporal operators:</span> Always p1 and Eventually p2, Always p1 or Eventually p2.</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Temporal over boolean operators:</span> (Not p1) Until p2, p1 Until (Not p2), Always (p1 and p2), (p1 and p2) Until p3.</p>\n\n",
                "matched_terms": [
                    "until",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Temporal over temporal operators:</span> p1 Until Always p2, Eventually Always p1, Always Eventually p1.</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Temporal operators over boolean and temporal operators:</span> (Not p1) Until Eventually p2, (Not p1) Until Always p2, (p1 and p2) Until Eventually p3.</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">There are no existing benchmarks that evaluate query matching and ranked retrieval on\nvideo and speech sequences with the breadth of temporal properties discussed above.\nWe hence introduce two new benchmarks for evaluation\nusing\nthree existing datasets with frame/segment-level annotations for local properties:\nRealTLV&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>\nfor objects in videos (6 classes),\nIEMOCAP&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite>\nfor emotions in speech (4 classes), and\nAVA&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite>\nfor actions in videos (80 classes).\nWe briefly describe the two benchmarks below, with more details in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A3\" title=\"Appendix C More Details on Datasets &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">C</span></a>.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "sequences",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The QMTP benchmark.</span>\nThe QMTP benchmark evaluates query matching with temporal properties over objects in video and emotions in speech sequences.\n<span class=\"ltx_text ltx_font_bold\">QMTP-video</span> consists of <math alttext=\"7468\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\"><semantics><mn>7468</mn><annotation encoding=\"application/x-tex\">7468</annotation></semantics></math> samples\n(<math alttext=\"3750\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m2\" intent=\":literal\"><semantics><mn>3750</mn><annotation encoding=\"application/x-tex\">3750</annotation></semantics></math> matching and <math alttext=\"3718\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m3\" intent=\":literal\"><semantics><mn>3718</mn><annotation encoding=\"application/x-tex\">3718</annotation></semantics></math> non-matching)\nwith <math alttext=\"10-50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mn>10</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">10-50</annotation></semantics></math> frames per sample.\n<span class=\"ltx_text ltx_font_bold\">QMTP-speech</span> contains <math alttext=\"3300\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m5\" intent=\":literal\"><semantics><mn>3300</mn><annotation encoding=\"application/x-tex\">3300</annotation></semantics></math> samples (balanced),\nincluding speech sequences with <math alttext=\"5-30\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m6\" intent=\":literal\"><semantics><mrow><mn>5</mn><mo>&#8722;</mo><mn>30</mn></mrow><annotation encoding=\"application/x-tex\">5-30</annotation></semantics></math> segments per sample.</p>\n\n",
                "matched_terms": [
                    "nonmatching",
                    "balanced",
                    "matching",
                    "query",
                    "sequences",
                    "contains",
                    "qmtpvideo"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The TP2VR benchmark.</span>\nThe TP2VR benchmark evaluates ranked retrieval of video sequences given temporal property queries over objects and actions.\nThe <span class=\"ltx_text ltx_font_bold\">TP2VR-objects dataset</span> consists of <math alttext=\"746\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m1\" intent=\":literal\"><semantics><mn>746</mn><annotation encoding=\"application/x-tex\">746</annotation></semantics></math> videos with <math alttext=\"39-199\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m2\" intent=\":literal\"><semantics><mrow><mn>39</mn><mo>&#8722;</mo><mn>199</mn></mrow><annotation encoding=\"application/x-tex\">39-199</annotation></semantics></math> frames, collected from the RealTLV dataset, and <math alttext=\"42\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m3\" intent=\":literal\"><semantics><mn>42</mn><annotation encoding=\"application/x-tex\">42</annotation></semantics></math> queries over objects. Each query corresponds to <math alttext=\"25-50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m4\" intent=\":literal\"><semantics><mrow><mn>25</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">25-50</annotation></semantics></math> frame temporal events and is relevant to no more than <math alttext=\"250\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m5\" intent=\":literal\"><semantics><mn>250</mn><annotation encoding=\"application/x-tex\">250</annotation></semantics></math> videos in the dataset.\nSimilarly, the <span class=\"ltx_text ltx_font_bold\">TP2VR-actions dataset</span> consists of <math alttext=\"952\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m6\" intent=\":literal\"><semantics><mn>952</mn><annotation encoding=\"application/x-tex\">952</annotation></semantics></math> videos with <math alttext=\"300\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m7\" intent=\":literal\"><semantics><mn>300</mn><annotation encoding=\"application/x-tex\">300</annotation></semantics></math> frames each, collected from 1-min segments of videos in the AVA dataset,\nwith <math alttext=\"70\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m8\" intent=\":literal\"><semantics><mn>70</mn><annotation encoding=\"application/x-tex\">70</annotation></semantics></math> queries over actions.\nEach query corresponds to <math alttext=\"10\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m9\" intent=\":literal\"><semantics><mn>10</mn><annotation encoding=\"application/x-tex\">10</annotation></semantics></math>-second temporal events and is relevant to no more than <math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m10\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> videos in the dataset.</p>\n\n",
                "matched_terms": [
                    "dataset",
                    "queries",
                    "sequences",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methods.</span> We evaluate LogSTOP for temporal query matching\nusing simple neural predictors for object and emotion detection.\nWe use YOLOv8&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib23\" title=\"\">23</a>]</cite>, OWLv2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib34\" title=\"\">34</a>]</cite>, and Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite> to obtain\nframe-level object detection scores.\nWe use HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite> for segment-level emotion recognition.\nThese scores are matched using the adaptive threshold discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S3.SS1\" title=\"3.1 LogSTOP for Query Matching &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">3.1</span></a>.\nFor QMTP-video, we compare against two Large Vision Language Models (LVLMs),\nnamely <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib27\" title=\"\">27</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib45\" title=\"\">45</a>]</cite>,\nand the PCTL-based method, NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>.\nFor QMTP-speech, we compare against two Large Audio Language Models (LALMs),\nnamely <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib10\" title=\"\">10</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">Qwen2-Audio-7B-Instruct</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib11\" title=\"\">11</a>]</cite>.\nWe provide more details on the prompts and parameters used for all methods in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A4\" title=\"Appendix D More details on Query Matching Methods &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">D</span></a>.</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "nsvstl",
                    "videollava7b",
                    "matching",
                    "query",
                    "lvlms",
                    "all",
                    "owlv2",
                    "logstop",
                    "method",
                    "longva7b",
                    "qmtpvideo"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Results.</span>\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F2\" title=\"Figure 2 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> shows the balanced accuracies of different methods on the QMTP-video and QMTP-speech datasets.\nLogSTOP outperforms other methods by at least <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> on QMTP-video and QMTP-speech using object detection scores from YOLOv8 and emotion detection scores from HuBERT respectively. LogSTOP with Grounding DINO also performs better than the baselines.\nThe accuracies of detecting objects with scores <math alttext=\"&gt;0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">&gt;0.5</annotation></semantics></math> for YOLO, Grounding DINO and OWLv2 are <math alttext=\"46\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m3\" intent=\":literal\"><semantics><mrow><mn>46</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">46\\%</annotation></semantics></math>, <math alttext=\"38\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m4\" intent=\":literal\"><semantics><mrow><mn>38</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">38\\%</annotation></semantics></math> and <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m5\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> resp. which reflect the order of their performances on query matching.</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "balanced",
                    "matching",
                    "query",
                    "owlv2",
                    "logstop",
                    "qmtpvideo"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LogSTOP consistently reports accuracies over <math alttext=\"75\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p3.m1\" intent=\":literal\"><semantics><mrow><mn>75</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">75\\%</annotation></semantics></math> on all query categories.\n<span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span> and <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>\nperform better on simple temporal queries than queries with boolean/temporal compositions.\nNSVS-TL also performs poorly on\ncategories with compositions over boolean expressions.\nThese results\nsuggest that the understanding of temporal queries is still an open problem for LVLMs and LALMs. Moreover, the higher accuracy of LogSTOP with much smaller neural models suggests that using well-defined logics for reasoning is beneficial.</p>\n\n",
                "matched_terms": [
                    "reports",
                    "queries",
                    "nsvstl",
                    "lvlms",
                    "query",
                    "all",
                    "logstop",
                    "accuracy",
                    "moreover",
                    "longva7b"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Finally, we evaluate how the various design choices for LogSTOP affect the performance (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.T1\" title=\"Table 1 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>). We find that the accuracy drops by <math alttext=\"2\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m1\" intent=\":literal\"><semantics><mrow><mn>2</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">2\\%</annotation></semantics></math> when the standard STL robustness is used for aggregating scores instead of LogSTOP, or when local smoothing from Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l8\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>) is not performed.\nA <math alttext=\"3\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m2\" intent=\":literal\"><semantics><mrow><mn>3</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">3\\%</annotation></semantics></math> drop is also observed when the adaptive threshold is replaced with <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m3\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math>; Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F3\" title=\"Figure 3 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> demonstrates how the adaptive threshold\nis\nbetter at distinguishing between matching and non-matching sequences.</p>\n\n",
                "matched_terms": [
                    "nonmatching",
                    "matching",
                    "logstop",
                    "sequences",
                    "accuracy",
                    "not",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methods.</span> We evaluate LogSTOP for ranked retrieval using Grounding DINO for object detection and Detectron2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib42\" title=\"\">42</a>]</cite> with SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> for action detection.\nSince there are no methods specifically designed for temporal property to sequence retrieval, we adapt existing text-to-video retrieval methods for this task. Since LogSTOP does not require explicit training for retrieval, we specifically only include zero-shot text-to-video retrieval methods for comparison.\nWe include <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite>, a large multimodal model that jointly embeds videos and text queries. Inspired by ELIOT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib29\" title=\"\">29</a>]</cite>, we also include embedding similarity between video captions and text queries.\nWe refer to this as <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> and use\n<span class=\"ltx_text ltx_font_typewriter\">LLaVA-NeXT-Video-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib46\" title=\"\">46</a>]</cite> for generating video captions and <span class=\"ltx_text ltx_font_typewriter\">SentenceBERT</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib37\" title=\"\">37</a>]</cite> for embedding captions and queries. More details are provided in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A5\" title=\"Appendix E More details on the Ranked Retrieval methods &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">E</span></a>.</p>\n\n",
                "matched_terms": [
                    "queries",
                    "logstop",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Results.</span>\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F4\" title=\"Figure 4 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>\npresents the results for ranked retrieval on the TP2VR benchmark.\nThe performance of all methods on TP2VR-actions is lower than that on TP2VR-objects due to the significantly higher number of classes (<math alttext=\"80\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m1\" intent=\":literal\"><semantics><mn>80</mn><annotation encoding=\"application/x-tex\">80</annotation></semantics></math> actions vs. <math alttext=\"6\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m2\" intent=\":literal\"><semantics><mn>6</mn><annotation encoding=\"application/x-tex\">6</annotation></semantics></math> objects) and lower number of relevant results (on average, <math alttext=\"21\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m3\" intent=\":literal\"><semantics><mn>21</mn><annotation encoding=\"application/x-tex\">21</annotation></semantics></math> vs. <math alttext=\"163\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m4\" intent=\":literal\"><semantics><mn>163</mn><annotation encoding=\"application/x-tex\">163</annotation></semantics></math> relevant videos).\nLogSTOP with GroundingDINO outperforms <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> and <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> on TP2VR-objects by\nat least <math alttext=\"28\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m5\" intent=\":literal\"><semantics><mrow><mn>28</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">28\\%</annotation></semantics></math> in mAP and <math alttext=\"24\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m6\" intent=\":literal\"><semantics><mrow><mn>24</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">24\\%</annotation></semantics></math> in R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m7\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math>, indicating that relevant results are retrieved at earlier ranks and the retrieved results include more relevant items than other methods.\nSimilarly, LogSTOP with SlowR50 outperforms baselines by more than <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m8\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> and <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m9\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of mAP and R@r respectively.\nThe first relevant result is also retrieved earlier by LogSTOP as is indicated by at least a <math alttext=\"24\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m10\" intent=\":literal\"><semantics><mrow><mn>24</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">24\\%</annotation></semantics></math> higher P@1 and better mean ranks;\non TP2VR-actions, LogSTOP retrieves the first relevant result at rank <math alttext=\"7.9\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m11\" intent=\":literal\"><semantics><mn>7.9</mn><annotation encoding=\"application/x-tex\">7.9</annotation></semantics></math> while <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> and <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> retrieve it at ranks <math alttext=\"&gt;20\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m12\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>20</mn></mrow><annotation encoding=\"application/x-tex\">&gt;20</annotation></semantics></math>.\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F5\" title=\"Figure 5 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents examples of ranking using the three methods.\nWe discuss these in detail in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A8\" title=\"Appendix H Examples &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">H</span></a>.</p>\n\n",
                "matched_terms": [
                    "all",
                    "logstop",
                    "performance",
                    "groundingdino"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Ablating various components of LogSTOP also degrades retrieval performance (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.T1\" title=\"Table 1 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>). The standard STL robustness reduces mAP and R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m1\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> by more than <math alttext=\"12\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m2\" intent=\":literal\"><semantics><mrow><mn>12</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">12\\%</annotation></semantics></math>. While removing the smoothing step from LogSTOP leads to a slight increase of 0.2 in MnR, it reduces mAP and R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m3\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math> by at least <math alttext=\"4\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p4.m4\" intent=\":literal\"><semantics><mrow><mn>4</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">4\\%</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this work, we\npresent the\nproblem of assigning scores for temporal properties (STOPs) given potentially noisy score predictors for local properties. We represent these properties using LTL and propose a scoring function LogSTOP for assigning STOPs. We then introduce the QMTP and TP2VR benchmarks for evaluating query matching and ranked retrieval\nwith temporal properties\nover objects / actions in videos and emotions in speech. LogSTOP with simple neural predictors outperforms LVLMs / LALMs, Temporal Logic-based baselines, and text-to-retrieval methods on the benchmarks.\n</p>\n\n",
                "matched_terms": [
                    "matching",
                    "lvlms",
                    "logstop",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Limitations. </span>\nThere are properties such as \"there are always 2 cars\" that cannot directly be expressed in LTL.\nFuture work should hence explore more expressive logics&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib22\" title=\"\">22</a>]</cite> or construct local predictors for complex properties.\nWhile we only focus on sequences with single modalities, it will be interesting to see LogSTOP being for multi-modal applications where the local properties are over different modalities with scores from different local predictors.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "sequences",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Handling of logical operators (<math alttext=\"\\neg,\\land,\\lor\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m1\" intent=\":literal\"><semantics><mrow><mo>&#172;</mo><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8743;</mo><mo rspace=\"0em\">,</mo><mo lspace=\"0em\">&#8744;</mo></mrow><annotation encoding=\"application/x-tex\">\\neg,\\land,\\lor</annotation></semantics></math>)</span>.\nThe LogSTOP for <math alttext=\"\\neg\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m2\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\neg\\varphi</annotation></semantics></math> at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m3\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> is intuitively high when the score for <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m4\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> is low (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l10\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">10</span></a>). For example, given a high score <math alttext=\"\\hat{y}({car},t,w)=\\log(0.9)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m5\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({car},t,w)=\\log(0.9)</annotation></semantics></math>, the score for \"not car\" <math alttext=\"\\hat{y}(\\neg{car},t,w)=\\log(1-0.9)=\\log(0.1)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m6\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>&#8722;</mo><mn>0.9</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(\\neg{car},t,w)=\\log(1-0.9)=\\log(0.1)</annotation></semantics></math> is low.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Handling of temporal operators (<math alttext=\"\\bigcirc,\\square,\\mathbin{\\mathcal{U}}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0em\">&#9675;</mo><mo>,</mo><mi mathvariant=\"normal\">&#9633;</mi><mo rspace=\"0em\">,</mo><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0em\">&#119984;</mo></mrow><annotation encoding=\"application/x-tex\">\\bigcirc,\\square,\\mathbin{\\mathcal{U}}</annotation></semantics></math>).</span> \nAs discussed above, the property Next <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> (<math alttext=\"\\bigcirc\\,\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m3\" intent=\":literal\"><semantics><mrow><mi/><mo lspace=\"0.222em\" rspace=\"0.392em\">&#9675;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\bigcirc\\,\\varphi</annotation></semantics></math>) evaluates whether <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m4\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> is expressed starting at the next block <math alttext=\"t+w\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m5\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">t+w</annotation></semantics></math> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l16\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">16</span></a>). When <math alttext=\"w=1\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m6\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">w=1</annotation></semantics></math>, this represents the standard Next operator.\nThe property Always <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m7\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> (<math alttext=\"\\square\\,\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m8\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\,\\varphi</annotation></semantics></math>) is interpreted here as a \"temporal and\" operator over the sequence (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l18\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">18</span></a>). Hence, <math alttext=\"\\square\\,\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m9\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\,\\varphi</annotation></semantics></math> can be equivalently written as <math alttext=\"\\varphi\\land\\bigcirc\\,\\square\\,\\varphi\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A1.p6.m10\" intent=\":literal\"><semantics><mrow><mi>&#966;</mi><mo rspace=\"0em\">&#8743;</mo><mo lspace=\"0em\" rspace=\"0.392em\">&#9675;</mo><mi mathvariant=\"normal\">&#9633;</mi><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\varphi\\land\\bigcirc\\,\\square\\,\\varphi</annotation></semantics></math>: the property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m11\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> is expressed by <math alttext=\"x_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m12\" intent=\":literal\"><semantics><msub><mi>x</mi><mi>t</mi></msub><annotation encoding=\"application/x-tex\">x_{t}</annotation></semantics></math> and always after by <math alttext=\"[x_{t+w},\\ldots]\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m13\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow></msub><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[x_{t+w},\\ldots]</annotation></semantics></math> (<math alttext=\"\\bigcirc\\,{\\square\\,\\varphi}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m14\" intent=\":literal\"><semantics><mrow><mi/><mo lspace=\"0.222em\" rspace=\"0.392em\">&#9675;</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow></mrow><annotation encoding=\"application/x-tex\">\\bigcirc\\,{\\square\\,\\varphi}</annotation></semantics></math>). Similar to the logical <math alttext=\"\\land\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m15\" intent=\":literal\"><semantics><mo>&#8743;</mo><annotation encoding=\"application/x-tex\">\\land</annotation></semantics></math> operator, the score is high only if it is high for all timesteps of the sequence. The computation in <math alttext=\"\\log\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p6.m16\" intent=\":literal\"><semantics><mi>log</mi><annotation encoding=\"application/x-tex\">\\log</annotation></semantics></math> space is beneficial to prevent any underflow here with fixed precision.</p>\n\n",
                "matched_terms": [
                    "all",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"\\mu=f(s(t))\\geq 0\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p3.m1\" intent=\":literal\"><semantics><mrow><mi>&#956;</mi><mo>=</mo><mrow><mi>f</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8805;</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\mu=f(s(t))\\geq 0</annotation></semantics></math> is a Lipschitz continuous function over the signal <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p3.m2\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math> and <math alttext=\"I=[t_{1},t_{2}]\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p3.m3\" intent=\":literal\"><semantics><mrow><mi>I</mi><mo>=</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>t</mi><mn>1</mn></msub><mo>,</mo><msub><mi>t</mi><mn>2</mn></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">I=[t_{1},t_{2}]</annotation></semantics></math> is a time interval, <math alttext=\"t_{2}\\geq t_{1}\\geq 0\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p3.m4\" intent=\":literal\"><semantics><mrow><msub><mi>t</mi><mn>2</mn></msub><mo>&#8805;</mo><msub><mi>t</mi><mn>1</mn></msub><mo>&#8805;</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">t_{2}\\geq t_{1}\\geq 0</annotation></semantics></math>. The operators <span class=\"ltx_text ltx_font_italic\">Eventually</span> and <span class=\"ltx_text ltx_font_italic\">Always</span> can be defined as follows:</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In the context of the STOP problem, <math alttext=\"s(t)=\\hat{y}(X,\\cdot,t)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m1\" intent=\":literal\"><semantics><mrow><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">s(t)=\\hat{y}(X,\\cdot,t)</annotation></semantics></math> and <math alttext=\"f_{c}(s(t))=\\hat{y}(X,c,t)-\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m2\" intent=\":literal\"><semantics><mrow><mrow><msub><mi>f</mi><mi>c</mi></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8722;</mo><mi>&#964;</mi></mrow></mrow><annotation encoding=\"application/x-tex\">f_{c}(s(t))=\\hat{y}(X,c,t)-\\tau</annotation></semantics></math>. The query \"car until pedestrian\" can be written as <math alttext=\"\\mu_{car}(s(t))\\mathbin{\\mathcal{U}_{I}}\\mu_{pedestrian}(s(t))\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m3\" intent=\":literal\"><semantics><mrow><mrow><mrow><msub><mi>&#956;</mi><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119984;</mi><mi>I</mi></msub><msub><mi>&#956;</mi><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></msub></mrow><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mu_{car}(s(t))\\mathbin{\\mathcal{U}_{I}}\\mu_{pedestrian}(s(t))</annotation></semantics></math> where <math alttext=\"I=[0,T]\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m4\" intent=\":literal\"><semantics><mrow><mi>I</mi><mo>=</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mi>T</mi><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">I=[0,T]</annotation></semantics></math> and <math alttext=\"\\mu_{car}(s(t))=\\hat{y}(X,{car},t)-\\tau\\geq 0\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m5\" intent=\":literal\"><semantics><mrow><mrow><msub><mi>&#956;</mi><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8722;</mo><mi>&#964;</mi></mrow><mo>&#8805;</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\mu_{car}(s(t))=\\hat{y}(X,{car},t)-\\tau\\geq 0</annotation></semantics></math> (<math alttext=\"\\mu_{pedestrian}\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m6\" intent=\":literal\"><semantics><msub><mi>&#956;</mi><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></msub><annotation encoding=\"application/x-tex\">\\mu_{pedestrian}</annotation></semantics></math> is defined similarly).</p>\n\n",
                "matched_terms": [
                    "until",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We argue that LogSTOP offers advantages over such semantics in the context of the STOP problem.\nThis is primarily because the traditional robustness measure is defined using <math alttext=\"\\max\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m1\" intent=\":literal\"><semantics><mi>max</mi><annotation encoding=\"application/x-tex\">\\max</annotation></semantics></math> and <math alttext=\"\\min\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m2\" intent=\":literal\"><semantics><mi>min</mi><annotation encoding=\"application/x-tex\">\\min</annotation></semantics></math> functions over temporal and logical formulae.\nThe measure, hence, only reflects the most violating or most satisfying timestep in the sequence. For example, consider assigning confidence scores to the property \"Always car\" in two different scenarios:</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Ideally, the confidence score for \"Always car\" should follow the order:\n<math alttext=\"\\hat{y}_{1}(\\square{car},\\cdot)&gt;\\hat{y}_{2}(\\square{car},\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m3\" intent=\":literal\"><semantics><mrow><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>1</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>2</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{1}(\\square{car},\\cdot)&gt;\\hat{y}_{2}(\\square{car},\\cdot)</annotation></semantics></math>.\nThe standard STL semantics, however, would assign the same robustness to both sequences for any <math alttext=\"\\tau&gt;0.1\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m4\" intent=\":literal\"><semantics><mrow><mi>&#964;</mi><mo>&gt;</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\tau&gt;0.1</annotation></semantics></math> since the most violating score is <math alttext=\"\\log(0.1)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m5\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.1)</annotation></semantics></math> in either case. This makes the robustness measure unsuitable for downstream applications that require such ordering: for example, ranking / search.</p>\n\n",
                "matched_terms": [
                    "sequences",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Note that the only difference between the two scenarios is the score for \"pedestrian\" at <math alttext=\"t=2\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m1\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">t=2</annotation></semantics></math> (a high score of <math alttext=\"0.9\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m2\" intent=\":literal\"><semantics><mn>0.9</mn><annotation encoding=\"application/x-tex\">0.9</annotation></semantics></math> for the first scenario and a lower score of <math alttext=\"0.6\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m3\" intent=\":literal\"><semantics><mn>0.6</mn><annotation encoding=\"application/x-tex\">0.6</annotation></semantics></math> for the second scenario) . The robustness for the two cases is the same because of the <math alttext=\"\\min\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m4\" intent=\":literal\"><semantics><mi>min</mi><annotation encoding=\"application/x-tex\">\\min</annotation></semantics></math> semantics within the <span class=\"ltx_text ltx_font_italic\">Until</span> operator. LogSTOP assigns a higher score for the first scenario because of the difference at <math alttext=\"t=2\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m5\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">t=2</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "until",
                    "logstop",
                    "second"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we briefly discuss the QMTP and TP2VR benchmarks for evaluation.\nFor\nconstructing these benchmarks\n, we use\nthree existing datasets with frame/segment-level annotations for local properties:\nThe RealTLV dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>\nconsists of videos from NuScenes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib6\" title=\"\">6</a>]</cite> and Waymo&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib39\" title=\"\">39</a>]</cite> driving datasets with frame-level annotations for 6 object classes.\n(for example, \"car\", \"truck\", etc).\nThe IEMOCAP dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite> provides speech segments from conversations\nbetween two speakers\nand each segment is labeled with one of the 4 major emotions expressed by the speaker.\n(for example, \"happy\", \"sad\", etc.).\nThe AVA dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite> consists of frame-level action annotations for 80 actions in 15-min clips from YouTube. We only consider the validation subset of this dataset and sample 5 frames per second.\nThese datasets can be used for evaluating\ntemporal properties over objects in videos\n(\"car until pedestrian\", for example)\n, emotions in speech\n(\"always happy\")\n, and actions in videos\n(\"a person sits until they stand up\")\nrespectively.</p>\n\n",
                "matched_terms": [
                    "until",
                    "dataset",
                    "second",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The QMTP dataset.</span>\nFor any temporal property template (for example, \"p1 Until p2\") and samples from these datasets, we identify matching and non-matching sequences of desired length as follows: for every sample, we first identify candidates for local properties in the template (p1, p2, etc.) as the set of all ground-truth objects / emotions in the sequence. We then use the standard LTL semantics over the frame/segment-level ground-truth labels to collect matching and non-matching subsequences of the desired length. This creates a TP-query matching dataset for an arbitrary set of temporal properties as long as these properties are sufficiently expressed by sequences from the underlying dataset. Moreover, this pipeline is agnostic to the choice of the dataset since it only requires sequences of ground-truth labels for local properties. We use this pipeline to create\nthe <span class=\"ltx_text ltx_font_bold\">QMTP-video dataset</span> with <math alttext=\"7468\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m1\" intent=\":literal\"><semantics><mn>7468</mn><annotation encoding=\"application/x-tex\">7468</annotation></semantics></math> samples (<math alttext=\"3750\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m2\" intent=\":literal\"><semantics><mn>3750</mn><annotation encoding=\"application/x-tex\">3750</annotation></semantics></math> matching and <math alttext=\"3718\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m3\" intent=\":literal\"><semantics><mn>3718</mn><annotation encoding=\"application/x-tex\">3718</annotation></semantics></math> non-matching) with video sequences of lengths <math alttext=\"\\{10,20,30,40,50\\}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mn>10</mn><mo>,</mo><mn>20</mn><mo>,</mo><mn>30</mn><mo>,</mo><mn>40</mn><mo>,</mo><mn>50</mn><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{10,20,30,40,50\\}</annotation></semantics></math>. For each target length, this dataset contains approximately <math alttext=\"100\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m5\" intent=\":literal\"><semantics><mn>100</mn><annotation encoding=\"application/x-tex\">100</annotation></semantics></math> samples corresponding to each of the <math alttext=\"15\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m6\" intent=\":literal\"><semantics><mn>15</mn><annotation encoding=\"application/x-tex\">15</annotation></semantics></math> property templates. Similarly, we create the <span class=\"ltx_text ltx_font_bold\">QMTP-speech dataset</span> with <math alttext=\"3300\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m7\" intent=\":literal\"><semantics><mn>3300</mn><annotation encoding=\"application/x-tex\">3300</annotation></semantics></math> samples, including speech sequences of lengths in ranges <math alttext=\"\\{5-10,10-20,20-30\\}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m8\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mrow><mn>5</mn><mo>&#8722;</mo><mn>10</mn></mrow><mo>,</mo><mrow><mn>10</mn><mo>&#8722;</mo><mn>20</mn></mrow><mo>,</mo><mrow><mn>20</mn><mo>&#8722;</mo><mn>30</mn></mrow><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{5-10,10-20,20-30\\}</annotation></semantics></math>. The QMTP-speech dataset only contains samples from <math alttext=\"11/15\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m9\" intent=\":literal\"><semantics><mrow><mn>11</mn><mo>/</mo><mn>15</mn></mrow><annotation encoding=\"application/x-tex\">11/15</annotation></semantics></math> property templates. This is because there are no sequences matching <math alttext=\"4\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m10\" intent=\":literal\"><semantics><mn>4</mn><annotation encoding=\"application/x-tex\">4</annotation></semantics></math> properties \"Always p1 and Eventually p2\", \"Always (p1 and p2)\", \"(p1 and p2) Until p3\", and \"(p1 and p2) Until Eventually p3\" since two emotions cannot be expressed at the same time.</p>\n\n",
                "matched_terms": [
                    "nonmatching",
                    "matching",
                    "always",
                    "until",
                    "all",
                    "sequences",
                    "dataset",
                    "lengths",
                    "eventually",
                    "contains",
                    "moreover",
                    "qmtpvideo"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The TP2VR dataset.</span>\nWe restrict queries to a maximum of 5 per temporal property template. For TP2VR objects, we aim to find <math alttext=\"25-50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m1\" intent=\":literal\"><semantics><mrow><mn>25</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">25-50</annotation></semantics></math> frame-long subsequences satisfying a temporal property; we only include a temporal property if less than <math alttext=\"250\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m2\" intent=\":literal\"><semantics><mn>250</mn><annotation encoding=\"application/x-tex\">250</annotation></semantics></math> videos are retrieved using the standard LTL semantics with the ground truth labels.\nWith all possible combinations of objects, this gives us a total of <math alttext=\"42\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m3\" intent=\":literal\"><semantics><mn>42</mn><annotation encoding=\"application/x-tex\">42</annotation></semantics></math> queries, with an average of <math alttext=\"163\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m4\" intent=\":literal\"><semantics><mn>163</mn><annotation encoding=\"application/x-tex\">163</annotation></semantics></math> videos relevant to a query.\nSimilarly, for TP2VR-actions, we aim to find 10-second long subsequences (<math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m5\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> frames) satisfying a temporal property; we only include a temporal property if less than <math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m6\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> videos are retrieved using the standard LTL semantics with the ground truth labels. With all possible combinations of actions, this gives us a total of <math alttext=\"70\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m7\" intent=\":literal\"><semantics><mn>70</mn><annotation encoding=\"application/x-tex\">70</annotation></semantics></math> queries, with an average of <math alttext=\"21\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m8\" intent=\":literal\"><semantics><mn>21</mn><annotation encoding=\"application/x-tex\">21</annotation></semantics></math> videos relevant to a query.</p>\n\n",
                "matched_terms": [
                    "all",
                    "queries",
                    "dataset",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">LogSTOP with simple trained neural predictors:</span> We use YOLOv8&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib23\" title=\"\">23</a>]</cite>, Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite>, and OWLv2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib34\" title=\"\">34</a>]</cite>, to get confidence scores for object detection in video frames, and HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite> for speech emotion recognition in audio segments. Since the scores are in the <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math> range, we normalize them in the <math alttext=\"[-\\infty,0]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m2\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mrow><mo>&#8722;</mo><mi mathvariant=\"normal\">&#8734;</mi></mrow><mo>,</mo><mn>0</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[-\\infty,0]</annotation></semantics></math> range using the <math alttext=\"\\log\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m3\" intent=\":literal\"><semantics><mi>log</mi><annotation encoding=\"application/x-tex\">\\log</annotation></semantics></math> operation, as required by LogSTOP.\nA video matches query <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m4\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> if LogSTOP <math alttext=\"\\hat{y}(\\varphi,0,w)&gt;\\tau(\\varphi,0)\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m5\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><mi>&#964;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(\\varphi,0,w)&gt;\\tau(\\varphi,0)</annotation></semantics></math> (and vice versa for non-matching examples). The estimates are evaluated against ground-truth labels <math alttext=\"y(\\varphi,0)\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m6\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(\\varphi,0)</annotation></semantics></math>. The window <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m7\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> is selected as follows: <math alttext=\"w=2\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m8\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">w=2</annotation></semantics></math> for <math alttext=\"T&lt;20\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m9\" intent=\":literal\"><semantics><mrow><mi>T</mi><mo>&lt;</mo><mn>20</mn></mrow><annotation encoding=\"application/x-tex\">T&lt;20</annotation></semantics></math> and <math alttext=\"w=5\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m10\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">w=5</annotation></semantics></math> otherwise.</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "nonmatching",
                    "query",
                    "owlv2",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Large Vision Language Models (LVLMs)</span>. We evaluate two popular LVLMs on query matching for videos: <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib27\" title=\"\">27</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib45\" title=\"\">45</a>]</cite>.\nFor the \"always car\" example, we provide the models with the video sequence and a text prompt \"Is a car detected in all frames of this video?\". The response is considered correct if the model responds with \"Yes\" or \"No\" for matching and non-matching samples respectively. <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span> supports a context window of <math alttext=\"4096\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m1\" intent=\":literal\"><semantics><mn>4096</mn><annotation encoding=\"application/x-tex\">4096</annotation></semantics></math> tokens while <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span> can handle up to 2000 frames. We set the maximum tokens to generate to <math alttext=\"60\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m2\" intent=\":literal\"><semantics><mn>60</mn><annotation encoding=\"application/x-tex\">60</annotation></semantics></math> and <math alttext=\"1024\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m3\" intent=\":literal\"><semantics><mn>1024</mn><annotation encoding=\"application/x-tex\">1024</annotation></semantics></math> respectively and use a temperature of 0.1 and standard values for the other parameters.</p>\n\n",
                "matched_terms": [
                    "nonmatching",
                    "videollava7b",
                    "matching",
                    "query",
                    "lvlms",
                    "all",
                    "longva7b",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Large Audio Language Models (LALMs)</span>. Similarly, we evaluate two popular LALMs on query matching for speech: <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib10\" title=\"\">10</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">Qwen2-Audio-7B-Instruct</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib11\" title=\"\">11</a>]</cite>.\nFor the \"eventually happy\" example, we provide the models with the audio sequence and a text prompt \"Does the speaker sound happy at some time in this audio clip?\". We set the sampling rate to <math alttext=\"16000\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p3.m1\" intent=\":literal\"><semantics><mn>16000</mn><annotation encoding=\"application/x-tex\">16000</annotation></semantics></math> and generate a maximum of <math alttext=\"256\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p3.m2\" intent=\":literal\"><semantics><mn>256</mn><annotation encoding=\"application/x-tex\">256</annotation></semantics></math> new tokens, with standard values for other parameters.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "eventually",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>.</span> Proposed for event detection in videos, NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite> uses the PCTL-based model checker STORM&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib20\" title=\"\">20</a>]</cite> to identify video frame subsequences where a certain event is detected. NSVS-TL reports state-of-the-art performance on detecting temporal events in videos, surpassing large language models such as GPT-4.\nFor our task, we specify the target query in PCTL (\"always car\" is <math alttext=\"P&gt;0.5[G\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A4.p4.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo stretchy=\"false\">[</mo><mi>G</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5[G</annotation></semantics></math> \"<math alttext=\"{car}\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p4.m2\" intent=\":literal\"><semantics><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><annotation encoding=\"application/x-tex\">{car}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p4.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math>) and the response is considered correct if NSVS-TL returns / does not return the entire video sequence as output for a matching / non-matching query respectively.</p>\n\n",
                "matched_terms": [
                    "reports",
                    "nonmatching",
                    "nsvstl",
                    "matching",
                    "always",
                    "query",
                    "not",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We do not evaluate the method from &#160;<cite class=\"ltx_cite ltx_citemacro_citet\">Yang et&#160;al. [<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>]</cite> since the implementation is not publicly available and LTL model checking with STORM is not well-documented.</p>\n\n",
                "matched_terms": [
                    "not",
                    "method"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">LogSTOP.</span>\nWe use LogSTOP with Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite> for TP2VR-objects and with SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> for TP2VR-actions respectively.\nWe repurpose the script from <span class=\"ltx_text ltx_font_typewriter\">tutorials/video_detection_example</span> at <span class=\"ltx_text ltx_font_typewriter\">https://github.com/facebookresearch/pytorchvideo/</span>\nto run SlowR50 on videos from the TP2VR-actions dataset.\nWe use a smoothing window <math alttext=\"w=5\" class=\"ltx_Math\" display=\"inline\" id=\"A5.p1.m1\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">w=5</annotation></semantics></math> for all retrieval experiments.</p>\n\n",
                "matched_terms": [
                    "all",
                    "logstop",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The LogSTOP queries for these templates are as follows:</p>\n\n",
                "matched_terms": [
                    "queries",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: <math alttext=\"\\square\\,p1\\land\\Diamond\\,p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i4.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo>&#8743;</mo><mrow><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\square\\,p1\\land\\Diamond\\,p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: <math alttext=\"\\square\\,p1\\lor\\Diamond\\,p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i5.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo>&#8744;</mo><mrow><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\square\\,p1\\lor\\Diamond\\,p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: <math alttext=\"\\neg p1\\mathbin{\\mathcal{U}}p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i6.p1.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi>p</mi></mrow><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg p1\\mathbin{\\mathcal{U}}p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): <math alttext=\"p1\\mathbin{\\mathcal{U}}\\neg p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i7.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">p1\\mathbin{\\mathcal{U}}\\neg p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: <math alttext=\"p1\\mathbin{\\mathcal{U}}\\square\\,p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i10.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi mathvariant=\"normal\">&#9633;</mi></mrow><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">p1\\mathbin{\\mathcal{U}}\\square\\,p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: <math alttext=\"\\Diamond\\,\\square\\,p1\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i11.p1.m1\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\Diamond\\,\\square\\,p1</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: <math alttext=\"\\square\\,\\Diamond\\,p1\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i12.p1.m1\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\square\\,\\Diamond\\,p1</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: <math alttext=\"\\neg p1\\mathbin{\\mathcal{U}}\\Diamond\\,p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i13.p1.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi mathvariant=\"normal\">&#9671;</mi></mrow><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg p1\\mathbin{\\mathcal{U}}\\Diamond\\,p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: <math alttext=\"\\neg p1\\mathbin{\\mathcal{U}}\\square\\,p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i14.p1.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi mathvariant=\"normal\">&#9633;</mi></mrow><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg p1\\mathbin{\\mathcal{U}}\\square\\,p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: <math alttext=\"(p1\\land p2)\\mathbin{\\mathcal{U}}\\Diamond\\,p3\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i15.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi mathvariant=\"normal\">&#9671;</mi></mrow><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">(p1\\land p2)\\mathbin{\\mathcal{U}}\\Diamond\\,p3</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite> uses the model checker STORM&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib20\" title=\"\">20</a>]</cite> to verify if a given sequence satisfies a temporal property, where the temporal properties are represented in Probabilistic Computation Tree Logic (PCTL). In PCTL, the <math alttext=\"F\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m1\" intent=\":literal\"><semantics><mi>F</mi><annotation encoding=\"application/x-tex\">F</annotation></semantics></math>, <math alttext=\"G\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m2\" intent=\":literal\"><semantics><mi>G</mi><annotation encoding=\"application/x-tex\">G</annotation></semantics></math> and <math alttext=\"U\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m3\" intent=\":literal\"><semantics><mi>U</mi><annotation encoding=\"application/x-tex\">U</annotation></semantics></math> operators represent the <span class=\"ltx_text ltx_font_italic\">Eventually</span>, <span class=\"ltx_text ltx_font_italic\">Always</span> and <span class=\"ltx_text ltx_font_italic\">Until</span> operators respectively. The <math alttext=\"\\sim\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m4\" intent=\":literal\"><semantics><mo>&#8764;</mo><annotation encoding=\"application/x-tex\">\\sim</annotation></semantics></math>, <math alttext=\"\\&amp;\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m5\" intent=\":literal\"><semantics><mo>&amp;</mo><annotation encoding=\"application/x-tex\">\\&amp;</annotation></semantics></math> and <math alttext=\"\\mid\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m6\" intent=\":literal\"><semantics><mo>&#8739;</mo><annotation encoding=\"application/x-tex\">\\mid</annotation></semantics></math> operators represent the Boolean <span class=\"ltx_text ltx_font_italic\">negation</span>, <span class=\"ltx_text ltx_font_italic\">and</span>, and <span class=\"ltx_text ltx_font_italic\">or</span> operators respectively. The operator <math alttext=\"P\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m7\" intent=\":literal\"><semantics><mi>P</mi><annotation encoding=\"application/x-tex\">P</annotation></semantics></math> is used to indicate the ranges of probability of a given property being satisfied: for example, <math alttext=\"P&gt;0.5[F\\,\\varphi]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m8\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mrow><mn>0.5</mn><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>F</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5[F\\,\\varphi]</annotation></semantics></math> translates to \"the probability of <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m9\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> eventually being satisfied is more than <math alttext=\"0.5\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m10\" intent=\":literal\"><semantics><mn>0.5</mn><annotation encoding=\"application/x-tex\">0.5</annotation></semantics></math>\".</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "nsvstl",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: <math alttext=\"P&gt;0.5\\,[\\,G\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i4.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" rspace=\"0.170em\" stretchy=\"false\">[</mo><mi>G</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[\\,G</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i4.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"\\&amp;\\,F\\,\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i4.p1.m3\" intent=\":literal\"><semantics><mrow><mo rspace=\"0em\">&amp;</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">\\&amp;\\,F\\,</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i4.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i4.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: <math alttext=\"P&gt;0.5\\,[\\,G\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i5.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" rspace=\"0.170em\" stretchy=\"false\">[</mo><mi>G</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[\\,G</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i5.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"\\mid\\,F\\,\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i5.p1.m3\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.337em\">&#8739;</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">\\mid\\,F\\,</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i5.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i5.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: <math alttext=\"P&gt;0.5\\,[\\sim\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i6.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" stretchy=\"false\">[</mo><mo lspace=\"0em\">&#8764;</mo></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[\\sim</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i6.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"U\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i6.p1.m3\" intent=\":literal\"><semantics><mi>U</mi><annotation encoding=\"application/x-tex\">U</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i6.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i6.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): <math alttext=\"P&gt;0.5\\,[\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i7.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mo lspace=\"0.170em\" stretchy=\"false\">[</mo></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i7.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"U\\sim\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i7.p1.m3\" intent=\":literal\"><semantics><mrow><mi>U</mi><mo>&#8764;</mo><mi/></mrow><annotation encoding=\"application/x-tex\">U\\sim</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i7.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i7.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: <math alttext=\"P&gt;0.5\\,[\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i10.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mo lspace=\"0.170em\" stretchy=\"false\">[</mo></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i10.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"U\\,G\\,\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i10.p1.m3\" intent=\":literal\"><semantics><mrow><mi>U</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>G</mi></mrow><annotation encoding=\"application/x-tex\">U\\,G\\,</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i10.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i10.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: <math alttext=\"P&gt;0.5\\,[F\\,G\\,\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i11.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" stretchy=\"false\">[</mo><mi>F</mi><mi>G</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[F\\,G\\,</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i11.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i11.p1.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: <math alttext=\"P&gt;0.5\\,[G\\,F\\,\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i12.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" stretchy=\"false\">[</mo><mi>G</mi><mi>F</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[G\\,F\\,</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i12.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i12.p1.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: <math alttext=\"P&gt;0.5\\,[\\sim\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i13.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" stretchy=\"false\">[</mo><mo lspace=\"0em\">&#8764;</mo></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[\\sim</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i13.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"U\\,F\\,\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i13.p1.m3\" intent=\":literal\"><semantics><mrow><mi>U</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">U\\,F\\,</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i13.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i13.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: <math alttext=\"P&gt;0.5\\,[\\sim\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i14.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" stretchy=\"false\">[</mo><mo lspace=\"0em\">&#8764;</mo></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[\\sim</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i14.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"U\\,G\\,\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i14.p1.m3\" intent=\":literal\"><semantics><mrow><mi>U</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>G</mi></mrow><annotation encoding=\"application/x-tex\">U\\,G\\,</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i14.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i14.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: <math alttext=\"P&gt;0.5\\,[\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i15.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mo lspace=\"0.170em\" stretchy=\"false\">[</mo></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"\\&amp;\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m3\" intent=\":literal\"><semantics><mo>&amp;</mo><annotation encoding=\"application/x-tex\">\\&amp;</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"U\\,F\\,\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m5\" intent=\":literal\"><semantics><mrow><mi>U</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">U\\,F\\,</annotation></semantics></math> \"<math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m6\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m7\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The prompts for LVLMs for query matching on QMTP-video are as follows:</p>\n\n",
                "matched_terms": [
                    "matching",
                    "lvlms",
                    "qmtpvideo",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1: \"Is a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i2.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all frames of this video?\"</p>\n\n",
                "matched_terms": [
                    "all",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until p2: \"Is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i3.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in any frame of this video and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i3.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: \"Is a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i4.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all frames of this video and is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i4.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in any frame of this video?\"</p>\n\n",
                "matched_terms": [
                    "all",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: \"Is a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i5.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all frames of this video or is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i5.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in any frame of this video?\"</p>\n\n",
                "matched_terms": [
                    "all",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: \"Is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i6.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in any frame of this video and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i6.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> absent in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): \"Is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i7.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> absent in any frame of this video and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i7.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always (p1 and p2): \"Are both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i8.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i8.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in all frames of this video?\"</p>\n\n",
                "matched_terms": [
                    "all",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until p3: \"Is a <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i9.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> present in any frame of this video and both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i9.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i9.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: \"Starting at some frame in this video, is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i10.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in all subsequent frames and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i10.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: \"Starting at some frame in this video, is a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i11.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all subsequent frames?\"</p>\n\n",
                "matched_terms": [
                    "all",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: \"Starting at any frame in this video, is a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i12.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in some subsequent frame?\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: \"Starting at some frame in this video, is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i13.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in some subsequent frame and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i13.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> absent in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: \"Starting at some frame in this video, is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i14.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in all subsequent frames and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i14.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> absent in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: \"Starting at some frame in this video, is a <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i15.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> present in some subsequent frame and both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i15.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i15.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "eventually"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The prompts for LALMs for query matching on QMTP-speech are as follows:</p>\n\n",
                "matched_terms": [
                    "matching",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1: \"Does the speaker&#8217;s emotion sound <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i2.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all times?\"</p>\n\n",
                "matched_terms": [
                    "all",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until p2: \"Does the speaker&#8217;s emotion sound <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i3.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at any time and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i3.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all times until then?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: \"Does the speaker&#8217;s emotion sound <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i4.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all times and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i4.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at any time?\"</p>\n\n",
                "matched_terms": [
                    "all",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: \"Does the speaker&#8217;s emotion sound <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i5.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all times or <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i5.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at any time?\"</p>\n\n",
                "matched_terms": [
                    "all",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: \"Does the speaker&#8217;s emotion sound <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i6.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at any time and not <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i6.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all times until then?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): \"Does the speaker&#8217;s emotion sound not <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i7.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at any time and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i7.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all times until then?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always (p1 and p2): \"Does the speaker&#8217;s emotion sound both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i8.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i8.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at all times?\"</p>\n\n",
                "matched_terms": [
                    "all",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until p3: \"Does the speaker&#8217;s emotion sound <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i9.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> at any time and both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i9.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i9.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at all times until then?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: \"Starting at some time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i10.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at all subsequent times and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i10.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all previous times?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: \"Starting at some time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i11.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all subsequent times?\"</p>\n\n",
                "matched_terms": [
                    "all",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: \"Starting at any time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i12.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at some subsequent time?\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: \"Starting at some time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i13.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at some subsequent time and not <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i13.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all previous times?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: \"Starting at some time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i14.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at all subsequent times and not <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i14.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all previous times?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: \"Starting at some time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i15.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> at some subsequent time and both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i15.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i15.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at all previous times?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "eventually"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i3.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i3.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i3.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> is present at some point and a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i3.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is present in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i4.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i4.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i4.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is always present and a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i4.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> appears at some point.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i5.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i5.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where either a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i5.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is always present or a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i5.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> appears at some point.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i6.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i6.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i6.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> is present at some point and a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i6.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is absent in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i7.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i7.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i7.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> is absent at some point and a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i7.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is present in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until p3: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i9.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i9.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where a <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i9.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> is present at some point and both a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i9.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i9.p1.m5\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> are present in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i10.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i10.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at some point, a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i10.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> is always present and a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i10.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is present in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i11.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i11.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at some point, a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i11.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> starts being always present.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i12.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i12.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at any point, a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i12.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> appears in some frames.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i13.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i13.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at some point, a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i13.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> appears in some frames and a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i13.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is absent in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i14.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i14.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at some point, a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i14.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> is always present and a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i14.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is absent in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i15.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i15.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at some point, a <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i15.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> appears at some point and both a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i15.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i15.p1.m5\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> are present in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "eventually"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i3.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i3.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; happens at some point and the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i3.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i4.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i4.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is always happening and the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i4.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; happens at some point.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i5.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where either the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i5.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is always happening or the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i5.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; happens at some point.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i6.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i6.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; happens at some point and the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i6.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is not happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i7.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i7.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; is not happening at some point and the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i7.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until p3: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i9.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where the action &#8217;<math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i9.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math>&#8217; happens at some point and both the actions &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i9.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; and &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i9.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; are happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i10.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at some point, the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i10.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; is always happening and the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i10.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i11.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at some point, the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i11.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is always happening.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i12.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at any point, the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i12.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; happens in some frames.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i13.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at some point, the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i13.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; happens in some frames and the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i13.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is not happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i14.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at some point, the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i14.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; is always happening and the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i14.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is not happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i15.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at some point, the action &#8217;<math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i15.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math>&#8217; happens at some point and both the actions &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i15.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; and &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i15.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; are happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "all",
                    "eventually"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F5\" title=\"Figure 5 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents examples of ranking using the three methods.\nIn the first example, the video captions used by <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> do not include smaller objects that might be relevant to the query (\"car\" in this example). In the second example, the two actions are mentioned in the caption &#8211; the video is ranked lower than other videos with more mentions of the actions (\"stand\" and \"hand clap\" in this case).\nThis demonstrates that while caption-based methods outperform joint model embeddings (<span class=\"ltx_text ltx_font_typewriter\">mPLUG</span>), they rely on semantic similarity between captions and text to determine relevance, which might not be sufficient for effective retrieval with temporal queries.</p>\n\n",
                "matched_terms": [
                    "queries",
                    "not",
                    "second",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A9.F6\" title=\"Figure 6 &#8227; Appendix I Adaptive threshold vs. constant threshold &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> presents a comparison of the adaptive threshold and the constant <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"A9.p1.m1\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math> threshold for all temporal property templates, using LogSTOPs for matching and non-matching sequences from the QMTP-video (detections using YOLOv8).</p>\n\n",
                "matched_terms": [
                    "yolov8",
                    "nonmatching",
                    "matching",
                    "all",
                    "sequences",
                    "qmtpvideo"
                ]
            }
        ]
    },
    "A10.T5": {
        "caption": "Table 5: LogSTOP with HuBERT outperforms LALMs on the QMTP-speech dataset, both overall and on each query. We report balanced accuracies on 1650 matching and 1650 non-matching sequences of lengths 5-30. The best performing method is highlighted in bold and the second best is underlined.",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Query</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Qwen-Audio-Chat</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Qwen2-Audio-7B-Instruct</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">LogSTOP</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Eventually p1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.75</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.72</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.94</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Always p1</th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.67</span></td>\n<td class=\"ltx_td ltx_align_center\">0.66</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.87</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">p1 Until p2</th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.69</span></td>\n<td class=\"ltx_td ltx_align_center\">0.53</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.9</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Always p1 or Eventually p2</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.58</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.64</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.77</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Not p1 Until p2</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.77</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.72</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.8</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">p1 Until Not p2</th>\n<td class=\"ltx_td ltx_align_center\">0.64</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.7</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.8</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">p1 Until Always p2</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.52</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.53</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.82</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Eventually Always p1</th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.75</span></td>\n<td class=\"ltx_td ltx_align_center\">0.74</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.92</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Always Eventually p1</th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.69</span></td>\n<td class=\"ltx_td ltx_align_center\">0.5</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.76</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">(Not p1) Until Eventually p2</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.68</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.55</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.76</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">(Not p1) Until Always p2</th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.59</span></td>\n<td class=\"ltx_td ltx_align_center\">0.49</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.79</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\">Overall</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.68</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.63</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.84</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "nonmatching",
            "balanced",
            "qwenaudiochat",
            "hubert",
            "second",
            "matching",
            "query",
            "overall",
            "each",
            "lengths",
            "outperforms",
            "eventually",
            "not",
            "qmtpspeech",
            "qwen2audio7binstruct",
            "until",
            "performing",
            "report",
            "bold",
            "accuracies",
            "highlighted",
            "logstop",
            "sequences",
            "both",
            "underlined",
            "lalms",
            "best",
            "method",
            "dataset",
            "always"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">In Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we present the query matching results for the QMTP datasets.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.SS2\" title=\"J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">J.2</span></a> presents the results (balanced accuracies) aggregated by category.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.T4\" title=\"Table 4 &#8227; J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A10.T5\" title=\"Table 5 &#8227; J.2 Query matching &#8227; J.1 Ranked retrieval &#8227; Appendix J Detailed Results &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> report the results for the 15 temporal property templates for QMTP-video and QMTP-speech respectively.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Neural models such as YOLO and HuBERT can be used to detect local properties such as objects (\"car\") and emotions (\"angry\") in individual frames of videos and audio clips respectively. The likelihood of these detections is indicated by scores in [0, 1]. Lifting these scores to temporal properties over sequences can be useful for several downstream applications such as query matching (e.g., \"does the speaker eventually sound happy in this audio clip?\"), and ranked retrieval (e.g., \"retrieve top 5 videos with a 10 second scene where a car is detected until a pedestrian is detected\").\nIn this work, we formalize this problem of assigning Scores for TempOral Properties (STOPs) over sequences, given potentially noisy score predictors for local properties.\nWe then propose a scoring function called LogSTOP that can efficiently compute these scores for temporal properties represented in Linear Temporal Logic.\nEmpirically, LogSTOP, with YOLO and HuBERT, outperforms Large Vision / Audio Language Models and other Temporal Logic-based baselines by at least 16% on query matching with temporal properties over objects-in-videos and emotions-in-speech respectively. Similarly, on ranked retrieval with temporal properties over objects and actions in videos, LogSTOP with Grounding DINO and SlowR50 reports at least a 19% and 16% increase in mean average precision and recall over zero-shot text-to-video retrieval baselines respectively.</p>\n\n",
                "matched_terms": [
                    "second",
                    "hubert",
                    "matching",
                    "query",
                    "until",
                    "logstop",
                    "sequences",
                    "eventually",
                    "outperforms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Detecting complex temporal events in unstructured data sequences such as videos and audio clips is important in several domains.\nFor instance, traffic surveillance systems\nneed to\n<span class=\"ltx_text ltx_font_italic\">match</span> scenes perceived by autonomous vehicles\nagainst critical <span class=\"ltx_text ltx_font_italic\">temporal</span> properties such as\n\"the vehicle <span class=\"ltx_text ltx_font_italic\">always</span> remains in a given lane\".\nSimilarly, search engines\nmight need to\n<span class=\"ltx_text ltx_font_italic\">rank</span> videos or audio clips by relevance to temporal scenes (\"a 10 second scene where a person <span class=\"ltx_text ltx_font_italic\">eventually</span> starts running\" or \"a 20-30 second segment where speaker A sounds sad and B sounds frustrated <span class=\"ltx_text ltx_font_italic\">until</span> both sound neutral\").</p>\n\n",
                "matched_terms": [
                    "second",
                    "until",
                    "sequences",
                    "both",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The sequences and local properties could correspond to arbitrary modalities and classes of interest, including objects or actions in videos, and speakers or emotions in audio clips. These STOPs are useful for several downstream applications such as\n<span class=\"ltx_text ltx_font_bold\">query matching</span>\n, i.e., checking if the scores\nare over a threshold to decide if the sequence expresses a temporal property,\nand\n<span class=\"ltx_text ltx_font_bold\">ranked retrieval</span>, i.e.,\nranking sequences\nagainst a temporal query by these scores to provide the top-k most relevant results.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "sequences",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We argue that Linear Temporal Logic, with temporal operators such as \"Always\" (<math alttext=\"\\square\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m1\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#9633;</mi><annotation encoding=\"application/x-tex\">\\square</annotation></semantics></math>) and \"Until\" (<math alttext=\"\\mathbin{\\mathcal{U}}\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m2\" intent=\":literal\"><semantics><mo class=\"ltx_font_mathcaligraphic\">&#119984;</mo><annotation encoding=\"application/x-tex\">\\mathbin{\\mathcal{U}}</annotation></semantics></math>), provides a suitable language\nfor expressing diverse\ntemporal properties of interest.\nFor example,\nthe property \"A and B sound happy until A sounds sad\" can be written in LTL\nas <math alttext=\"(\\mathsf{{happy}_{A}}\\land\\mathsf{{happy}_{B}})\\mathbin{\\mathcal{U}}\\mathsf{{sad}_{A}}\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m3\" intent=\":literal\"><semantics><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>&#120257;&#120250;&#120265;&#120265;&#120274;</mi><mi>&#120224;</mi></msub><mo>&#8743;</mo><msub><mi>&#120257;&#120250;&#120265;&#120265;&#120274;</mi><mi>&#120225;</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#120268;&#120250;&#120253;</mi><mi>&#120224;</mi></msub></mrow><annotation encoding=\"application/x-tex\">(\\mathsf{{happy}_{A}}\\land\\mathsf{{happy}_{B}})\\mathbin{\\mathcal{U}}\\mathsf{{sad}_{A}}</annotation></semantics></math>.\nFor temporal properties in LTL, the framework proposed by <cite class=\"ltx_cite ltx_citemacro_citet\">Yang et&#160;al. [<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>]</cite> can be used as a solution to the STOP problem with two major caveats.\nFirstly, this approach requires <math alttext=\"\\mathcal{O}(T\\cdot 2^{|C|})\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><msup><mn>2</mn><mrow><mo stretchy=\"false\">|</mo><mi>C</mi><mo stretchy=\"false\">|</mo></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot 2^{|C|})</annotation></semantics></math> space and time for a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m5\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> and <math alttext=\"|C|\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m6\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">|</mo><mi>C</mi><mo stretchy=\"false\">|</mo></mrow><annotation encoding=\"application/x-tex\">|C|</annotation></semantics></math> local properties.\nThis exponential space and time complexity renders this approach inefficient for applications such as retrieval where sequences from a large database (with potentially many local properties) need to be checked.\nSecondly, this approach has no provision to handle incorrectly low or high, i.e., <span class=\"ltx_text ltx_font_italic\">potentially noisy</span>, scores for local properties.</p>\n\n",
                "matched_terms": [
                    "until",
                    "sequences",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose a novel scoring function called LogSTOP, inspired by quantitative semantics for LTL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib14\" title=\"\">14</a>]</cite>,\nthat\nassigns a score for a sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m1\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> satisfying temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\nin <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m3\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> time and space.\nLogSTOP employs a simple downsampling and smoothing strategy for handling locally incorrect\npredictions by the local property predictors.\nThis makes it robust to cases where, for example, an object detector detects a car with very low scores in some frames because it is occluded.\nMoreover, the linear time computational complexity makes it an efficient solution for applications such as query matching and ranked retrieval (see example in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).\nFor query matching, we propose a length and query-adaptive threshold which is guaranteed to accept at least as many sequences as a fixed threshold.\nWe also demonstrate how LogSTOP can be used to rank sequences based on subsequence relevance to temporal queries in <math alttext=\"\\mathcal{O}(T^{2}\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p6.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>T</mi><mn>2</mn></msup><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T^{2}\\cdot|\\varphi|)</annotation></semantics></math> time.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "logstop",
                    "sequences",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate LogSTOP on query matching and ranked retrieval,\nwith sequence modalities including videos and speech, and local properties such as objects, actions, and emotions.\nWe focus on 15 diverse temporal property templates of varying complexity.\nSince no existing benchmarks support this breadth of temporal properties\nand sequence types, we propose two new benchmarks:\nthe QMTP (Query Matching for Temporal Properties) benchmark\nfor objects-in-videos from the RealTLV dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>,\nand emotions-in-speech from the IEMOCAP dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite>;\nand the TP2VR (Temporal Property to Video Retrieval) benchmark\nfor objects-in-videos from the RealTLV dataset,\nand actions-in-videos from the AVA dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite>.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "dataset",
                    "logstop",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We find that LogSTOP with simple detection models,\nsuch as YOLO and HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib21\" title=\"\">21</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite>,\noutperforms baselines including Large Vision / Audio Language Models (LVLMs / LALMs), and\nNSVS-TL\n, on query matching by more than <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m1\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of balanced accuracy.\nSimilarly,\nLogSTOP with Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite>\nand SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> outperforms\nzero-shot text-to-video retrieval methods, such as mPLUG&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite>\nand text-text similarity with video captions,\nby more than <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m2\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> and <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p8.m3\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of mean average precision and recall respectively.</p>\n\n",
                "matched_terms": [
                    "lalms",
                    "balanced",
                    "hubert",
                    "matching",
                    "query",
                    "logstop",
                    "outperforms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Let <math alttext=\"X=[x_{1},\\ldots,x_{T}]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m1\" intent=\":literal\"><semantics><mrow><mi>X</mi><mo>=</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><msub><mi>x</mi><mi>T</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X=[x_{1},\\ldots,x_{T}]</annotation></semantics></math>\ndenote a sequence of data items of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m2\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math>, where <math alttext=\"x_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m3\" intent=\":literal\"><semantics><msub><mi>x</mi><mi>t</mi></msub><annotation encoding=\"application/x-tex\">x_{t}</annotation></semantics></math> denotes the data item at timestep <math alttext=\"1\\leq t\\leq T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m4\" intent=\":literal\"><semantics><mrow><mn>1</mn><mo>&#8804;</mo><mi>t</mi><mo>&#8804;</mo><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">1\\leq t\\leq T</annotation></semantics></math>.\nLet <math alttext=\"\\mathcal{X}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m5\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119987;</mi><annotation encoding=\"application/x-tex\">\\mathcal{X}</annotation></semantics></math> denote the set of all such sequences, and <math alttext=\"\\mathcal{T}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m6\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><annotation encoding=\"application/x-tex\">\\mathcal{T}</annotation></semantics></math> denote the set of all timesteps <math alttext=\"\\{1,\\ldots,T\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m7\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><mi>T</mi><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{1,\\ldots,T\\}</annotation></semantics></math>.\nFurther, let <math alttext=\"C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m8\" intent=\":literal\"><semantics><mi>C</mi><annotation encoding=\"application/x-tex\">C</annotation></semantics></math> denote a finite set of local properties of interest.\nIn general, <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m9\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> and <math alttext=\"C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m10\" intent=\":literal\"><semantics><mi>C</mi><annotation encoding=\"application/x-tex\">C</annotation></semantics></math> could correspond to sequences of arbitrary modalities and properties respectively,\nincluding but not limited to objects or actions in videos, and speakers or emotions in audio clips.\nWhile these sequences could be over continuous time, we assume that they are discretized into <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m11\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> timesteps for simplicity.</p>\n\n",
                "matched_terms": [
                    "not",
                    "sequences"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where, <math alttext=\"c\\in C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m3\" intent=\":literal\"><semantics><mrow><mi>c</mi><mo>&#8712;</mo><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">c\\in C</annotation></semantics></math> is a local property and <math alttext=\"\\varphi_{1},\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m4\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>,</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1},\\varphi_{2}</annotation></semantics></math> are temporal properties. <math alttext=\"\\neg,\\land,\\lor\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m5\" intent=\":literal\"><semantics><mrow><mo>&#172;</mo><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8743;</mo><mo rspace=\"0em\">,</mo><mo lspace=\"0em\">&#8744;</mo></mrow><annotation encoding=\"application/x-tex\">\\neg,\\land,\\lor</annotation></semantics></math> are the logical <span class=\"ltx_text ltx_font_italic\">not</span>, <span class=\"ltx_text ltx_font_italic\">and</span>, and <span class=\"ltx_text ltx_font_italic\">or</span> operators respectively. <math alttext=\"\\bigcirc\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m6\" intent=\":literal\"><semantics><mo>&#9675;</mo><annotation encoding=\"application/x-tex\">\\bigcirc</annotation></semantics></math>, <math alttext=\"\\square\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m7\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#9633;</mi><annotation encoding=\"application/x-tex\">\\square</annotation></semantics></math> and <math alttext=\"\\mathbin{\\mathcal{U}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m8\" intent=\":literal\"><semantics><mo class=\"ltx_font_mathcaligraphic\">&#119984;</mo><annotation encoding=\"application/x-tex\">\\mathbin{\\mathcal{U}}</annotation></semantics></math> are temporal operators <span class=\"ltx_text ltx_font_italic\">Next</span>, <span class=\"ltx_text ltx_font_italic\">Always</span>, and <span class=\"ltx_text ltx_font_italic\">Until</span> respectively. Other temporal operators such as \"Eventually <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m9\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\" (<math alttext=\"\\Diamond\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m10\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\Diamond\\varphi</annotation></semantics></math>) can then be derived as <math alttext=\"\\neg\\square\\neg\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p4.m11\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.167em\" rspace=\"0em\">&#8203;</mo><mrow><mo rspace=\"0.167em\">&#172;</mo><mi>&#966;</mi></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg\\square\\neg\\varphi</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, the LogSTOP for a sequence with respect to a temporal property represents the log probability of the sequence\nsatisfying the temporal property if certain assumptions are met.\nConcretely, this is true when (1) the local properties represent independent events over time,\n(2) the scores for local properties reflect true log probabilities,\nand (3) temporal properties consist of compositions of independent local properties.\nWe acknowledge that these assumptions are rarely true for real-world sequences and properties.\nFor instance, the presence of \"car\" at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m1\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and <math alttext=\"t+1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m2\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">t+1</annotation></semantics></math> are not independent events.\nHowever, these assumptions allow us to use ideas from probability theory for independent events to compute the score.\nMoreover, our experiments in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>\nshow that LogSTOPs are useful for applications such as query matching and ranked retrieval\neven when these assumptions are not met.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "query",
                    "logstop",
                    "sequences",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, LogSTOP deals with potentially noisy local predictions\nby downsampling and smoothing predictions over windows of length <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m1\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math>\n(Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l8\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>).\nThis\nessentially captures the property that local property scores cannot change drastically in a short local window\n(objects cannot momentarily disappear and reappear, actions cannot change in fractions of seconds, etc.).\nNote that <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m2\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> is a hyperparameter; a higher value of <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m3\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> can be used to control for higher variance in local predictions.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "second"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We briefly discuss how different operators\nare handled in Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>\nand defer a detailed discussion with examples to Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A1\" title=\"Appendix A More details on Algorithm 1 &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">A</span></a>.\nThe scores for logical operators, negation <math alttext=\"\\neg\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\neg\\varphi</annotation></semantics></math>, conjunction <math alttext=\"\\varphi_{1}\\land\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m2\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8743;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\land\\varphi_{2}</annotation></semantics></math>, and disjunction <math alttext=\"\\varphi_{1}\\lor\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m3\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8744;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\lor\\varphi_{2}</annotation></semantics></math>\nare computed using simple rules from probability theory.\nConcretely, LogSTOP for <math alttext=\"\\varphi_{1}\\land\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m4\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8743;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\land\\varphi_{2}</annotation></semantics></math> is the sum of the LogSTOPs for <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m5\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> and <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m6\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l12\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">12</span></a>), and\nthe LogSTOP for <math alttext=\"\\varphi_{1}\\lor\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m7\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8744;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\lor\\varphi_{2}</annotation></semantics></math> is computed using DeMorgan&#8217;s law\n(line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l14\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">14</span></a>).\nThe score for the \"next\" operator <math alttext=\"\\bigcirc\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m8\" intent=\":literal\"><semantics><mrow><mi/><mo lspace=\"0.222em\" rspace=\"0.222em\">&#9675;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\bigcirc\\varphi</annotation></semantics></math> is computed by shifting the timestep by one window (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l16\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">16</span></a>).\nScores for the \"always\" (<math alttext=\"\\square\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m9\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\varphi</annotation></semantics></math>) and \"until\" (<math alttext=\"\\varphi_{1}\\mathcal{U}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m10\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi class=\"ltx_font_mathcaligraphic\">&#119984;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathcal{U}\\varphi_{2}</annotation></semantics></math>)\noperators\nare computed recursively using the scores for these properties at the next window (lines&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l18\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">18</span></a>-<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l20\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">20</span></a>).\nInformally, the LogSTOP for Always <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m11\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m12\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> can be computed with a <span class=\"ltx_text ltx_font_italic\">\"temporal and\"</span> over <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m13\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m14\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> and Always <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m15\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> at the next window, <math alttext=\"t+w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m16\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">t+w</annotation></semantics></math>.\nSimilarly, the LogSTOP for <math alttext=\"\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m17\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}</annotation></semantics></math> can be computed with a <span class=\"ltx_text ltx_font_italic\">\"temporal or\"</span> over (1) <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m18\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m19\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, and (2) <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m20\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m21\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> with <math alttext=\"\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p6.m22\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\mathbin{\\mathcal{U}}\\varphi_{2}</annotation></semantics></math> at the next window.</p>\n\n",
                "matched_terms": [
                    "until",
                    "logstop",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We define query matching with temporal properties as the task of predicting whether a given temporal property / query matches, or is expressed by, a sequence.\nLogSTOPs can be used for matching sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m1\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> with query <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m2\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> by comparing <math alttext=\"\\hat{y}(X,\\varphi,1,T)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m3\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>&#966;</mi><mo>,</mo><mn>1</mn><mo>,</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(X,\\varphi,1,T)</annotation></semantics></math> with an appropriate threshold.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">A natural first choice for such a threshold for LogSTOP is the constant <math alttext=\"\\tau=\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><mi>&#964;</mi><mo>=</mo><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\tau=\\log 0.5</annotation></semantics></math>. This threshold, is employed by existing works to determine if a video satisfies a temporal property&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>. This, however, does not scale with the length of the sequence. For instance, given a 6-frame video with constant <math alttext=\"\\log 0.9\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m2\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.9</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.9</annotation></semantics></math> scores for \"car\",\nthe LogSTOP for temporal property \"Always car\", with <math alttext=\"w=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">w=1</annotation></semantics></math>, is <math alttext=\"\\log(0.9^{6})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><msup><mn>0.9</mn><mn>6</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9^{6})</annotation></semantics></math>. This is greater than <math alttext=\"\\log(0.5)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m5\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.5</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.5)</annotation></semantics></math> and hence the video matches the query.\nHowever, when another frame with the same high score <math alttext=\"\\log(0.9)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m6\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9)</annotation></semantics></math> is added,\nthe score drops to <math alttext=\"\\log(0.9^{7})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m7\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><msup><mn>0.9</mn><mn>7</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9^{7})</annotation></semantics></math>, which is less than <math alttext=\"\\log(0.5)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m8\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.5</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.5)</annotation></semantics></math> and hence the video no longer matches the query.\nWe would ideally also like the latter to match the query since the property \"car\" is detected with high scores.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "not",
                    "always",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Informally, a sequence expresses a temporal property if the LogSTOP is higher than both random chance <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m1\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math>\nand LogSTOP using random chance predictors for local properties <math alttext=\"\\hat{y}_{0.5}(\\cdot,\\varphi,T,w)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m2\" intent=\":literal\"><semantics><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>0.5</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo>,</mo><mi>&#966;</mi><mo>,</mo><mi>T</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{0.5}(\\cdot,\\varphi,T,w)</annotation></semantics></math>.\nThis threshold can be computed in <math alttext=\"\\mathcal{O}(T\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m3\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T\\cdot|\\varphi|)</annotation></semantics></math> and is guaranteed to match at least as many sequences as the constant <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m4\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math> threshold.\nFor properties where the score decreases with sequence length (e.g., <math alttext=\"\\square\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p4.m5\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\square\\varphi</annotation></semantics></math>), the adaptive threshold\nallows more sequences to match\nthe query\nthan the constant threshold.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "sequences",
                    "both",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LogSTOP\ncan also be used for the task of ranking and\nretrieving sequences relevant to temporal properties of interest.\nFormally, given a database of <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> sequences <math alttext=\"\\mathcal{D}=\\{X_{1},\\ldots,X_{N}\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m2\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119967;</mi><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><msub><mi>X</mi><mi>N</mi></msub><mo stretchy=\"false\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{D}=\\{X_{1},\\ldots,X_{N}\\}</annotation></semantics></math>\na temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m3\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>,\nand a range of event lengths <math alttext=\"(T_{lo},T_{hi})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(T_{lo},T_{hi})</annotation></semantics></math>,\nthe goal is to rank each <math alttext=\"X_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m5\" intent=\":literal\"><semantics><msub><mi>X</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">X_{i}</annotation></semantics></math> based on whether\nit contains a subsequence <math alttext=\"X_{i}[t:t^{\\prime}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.SS2.p1.m6\" intent=\":literal\"><semantics><mrow><msub><mi>X</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">[</mo><mi>t</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><msup><mi>t</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">X_{i}[t:t^{\\prime}]</annotation></semantics></math> of length <math alttext=\"t^{\\prime}-t\\in[T_{lo},T_{hi}]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m7\" intent=\":literal\"><semantics><mrow><mrow><msup><mi>t</mi><mo>&#8242;</mo></msup><mo>&#8722;</mo><mi>t</mi></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">t^{\\prime}-t\\in[T_{lo},T_{hi}]</annotation></semantics></math> that expresses <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m8\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>.\nExamples of such queries include \"videos with a 10 to 20 second scene where a person is sitting down until they stand up\".\nThis task is different from the query matching task in two key ways:\nfirstly, the relative ranking of sequences is more important than absolute scores.\nSecondly and more importantly,\nthe relevance of a sequence may only be with respect to a part of the sequence (a <span class=\"ltx_text ltx_font_italic\">moment</span> in the video, for example).</p>\n\n",
                "matched_terms": [
                    "second",
                    "matching",
                    "query",
                    "until",
                    "logstop",
                    "each",
                    "sequences",
                    "lengths"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg2\" title=\"Algorithm 2 &#8227; 3.1 LogSTOP for Query Matching &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> outlines how LogSTOP can be used for ranked retrieval.\nInformally, given a temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m1\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>, sequence <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m2\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math>, and event duration <math alttext=\"(T_{lo},T_{hi})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m3\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(T_{lo},T_{hi})</annotation></semantics></math>,\nthe relevance of <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m4\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> to <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m5\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math>\nis defined as the maximum LogSTOP of any subsequence of <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m6\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math> of length in <math alttext=\"[T_{lo},T_{hi}]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m7\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>T</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[T_{lo},T_{hi}]</annotation></semantics></math>.\nThe relevance score for any sequence can be computed in <math alttext=\"\\mathcal{O}(T^{2}\\cdot|\\varphi|)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m8\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>T</mi><mn>2</mn></msup><mo lspace=\"0.222em\" rspace=\"0.222em\">&#8901;</mo><mrow><mo stretchy=\"false\">|</mo><mi>&#966;</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T^{2}\\cdot|\\varphi|)</annotation></semantics></math> time\nsince LogSTOPs for suffix subsequences are cached with dynamic programming.\nNote\nthat this represents one way of computing scores for ranking videos, where subsequences of certain lengths are relevant to queries; there could be other variants which LogSTOP could be used for but are not considered (for example, computing the score with respect to the entire video, or only considering videos where the subsequence score is over a threshold).</p>\n\n",
                "matched_terms": [
                    "lengths",
                    "logstop",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Simple temporal operators:</span> Eventually p1, Always p1, p1 Until p2.</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Boolean over temporal operators:</span> Always p1 and Eventually p2, Always p1 or Eventually p2.</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Temporal over boolean operators:</span> (Not p1) Until p2, p1 Until (Not p2), Always (p1 and p2), (p1 and p2) Until p3.</p>\n\n",
                "matched_terms": [
                    "until",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Temporal over temporal operators:</span> p1 Until Always p2, Eventually Always p1, Always Eventually p1.</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Temporal operators over boolean and temporal operators:</span> (Not p1) Until Eventually p2, (Not p1) Until Always p2, (p1 and p2) Until Eventually p3.</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">There are no existing benchmarks that evaluate query matching and ranked retrieval on\nvideo and speech sequences with the breadth of temporal properties discussed above.\nWe hence introduce two new benchmarks for evaluation\nusing\nthree existing datasets with frame/segment-level annotations for local properties:\nRealTLV&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>\nfor objects in videos (6 classes),\nIEMOCAP&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite>\nfor emotions in speech (4 classes), and\nAVA&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite>\nfor actions in videos (80 classes).\nWe briefly describe the two benchmarks below, with more details in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A3\" title=\"Appendix C More Details on Datasets &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">C</span></a>.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "sequences",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The QMTP benchmark.</span>\nThe QMTP benchmark evaluates query matching with temporal properties over objects in video and emotions in speech sequences.\n<span class=\"ltx_text ltx_font_bold\">QMTP-video</span> consists of <math alttext=\"7468\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\"><semantics><mn>7468</mn><annotation encoding=\"application/x-tex\">7468</annotation></semantics></math> samples\n(<math alttext=\"3750\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m2\" intent=\":literal\"><semantics><mn>3750</mn><annotation encoding=\"application/x-tex\">3750</annotation></semantics></math> matching and <math alttext=\"3718\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m3\" intent=\":literal\"><semantics><mn>3718</mn><annotation encoding=\"application/x-tex\">3718</annotation></semantics></math> non-matching)\nwith <math alttext=\"10-50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mn>10</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">10-50</annotation></semantics></math> frames per sample.\n<span class=\"ltx_text ltx_font_bold\">QMTP-speech</span> contains <math alttext=\"3300\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m5\" intent=\":literal\"><semantics><mn>3300</mn><annotation encoding=\"application/x-tex\">3300</annotation></semantics></math> samples (balanced),\nincluding speech sequences with <math alttext=\"5-30\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m6\" intent=\":literal\"><semantics><mrow><mn>5</mn><mo>&#8722;</mo><mn>30</mn></mrow><annotation encoding=\"application/x-tex\">5-30</annotation></semantics></math> segments per sample.</p>\n\n",
                "matched_terms": [
                    "nonmatching",
                    "balanced",
                    "matching",
                    "query",
                    "sequences",
                    "qmtpspeech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The TP2VR benchmark.</span>\nThe TP2VR benchmark evaluates ranked retrieval of video sequences given temporal property queries over objects and actions.\nThe <span class=\"ltx_text ltx_font_bold\">TP2VR-objects dataset</span> consists of <math alttext=\"746\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m1\" intent=\":literal\"><semantics><mn>746</mn><annotation encoding=\"application/x-tex\">746</annotation></semantics></math> videos with <math alttext=\"39-199\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m2\" intent=\":literal\"><semantics><mrow><mn>39</mn><mo>&#8722;</mo><mn>199</mn></mrow><annotation encoding=\"application/x-tex\">39-199</annotation></semantics></math> frames, collected from the RealTLV dataset, and <math alttext=\"42\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m3\" intent=\":literal\"><semantics><mn>42</mn><annotation encoding=\"application/x-tex\">42</annotation></semantics></math> queries over objects. Each query corresponds to <math alttext=\"25-50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m4\" intent=\":literal\"><semantics><mrow><mn>25</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">25-50</annotation></semantics></math> frame temporal events and is relevant to no more than <math alttext=\"250\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m5\" intent=\":literal\"><semantics><mn>250</mn><annotation encoding=\"application/x-tex\">250</annotation></semantics></math> videos in the dataset.\nSimilarly, the <span class=\"ltx_text ltx_font_bold\">TP2VR-actions dataset</span> consists of <math alttext=\"952\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m6\" intent=\":literal\"><semantics><mn>952</mn><annotation encoding=\"application/x-tex\">952</annotation></semantics></math> videos with <math alttext=\"300\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m7\" intent=\":literal\"><semantics><mn>300</mn><annotation encoding=\"application/x-tex\">300</annotation></semantics></math> frames each, collected from 1-min segments of videos in the AVA dataset,\nwith <math alttext=\"70\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m8\" intent=\":literal\"><semantics><mn>70</mn><annotation encoding=\"application/x-tex\">70</annotation></semantics></math> queries over actions.\nEach query corresponds to <math alttext=\"10\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m9\" intent=\":literal\"><semantics><mn>10</mn><annotation encoding=\"application/x-tex\">10</annotation></semantics></math>-second temporal events and is relevant to no more than <math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p3.m10\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> videos in the dataset.</p>\n\n",
                "matched_terms": [
                    "dataset",
                    "sequences",
                    "each",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methods.</span> We evaluate LogSTOP for temporal query matching\nusing simple neural predictors for object and emotion detection.\nWe use YOLOv8&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib23\" title=\"\">23</a>]</cite>, OWLv2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib34\" title=\"\">34</a>]</cite>, and Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite> to obtain\nframe-level object detection scores.\nWe use HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite> for segment-level emotion recognition.\nThese scores are matched using the adaptive threshold discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S3.SS1\" title=\"3.1 LogSTOP for Query Matching &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">3.1</span></a>.\nFor QMTP-video, we compare against two Large Vision Language Models (LVLMs),\nnamely <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib27\" title=\"\">27</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib45\" title=\"\">45</a>]</cite>,\nand the PCTL-based method, NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>.\nFor QMTP-speech, we compare against two Large Audio Language Models (LALMs),\nnamely <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib10\" title=\"\">10</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">Qwen2-Audio-7B-Instruct</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib11\" title=\"\">11</a>]</cite>.\nWe provide more details on the prompts and parameters used for all methods in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A4\" title=\"Appendix D More details on Query Matching Methods &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">D</span></a>.</p>\n\n",
                "matched_terms": [
                    "lalms",
                    "qwenaudiochat",
                    "hubert",
                    "matching",
                    "qwen2audio7binstruct",
                    "query",
                    "logstop",
                    "method",
                    "qmtpspeech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Results.</span>\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F2\" title=\"Figure 2 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> shows the balanced accuracies of different methods on the QMTP-video and QMTP-speech datasets.\nLogSTOP outperforms other methods by at least <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> on QMTP-video and QMTP-speech using object detection scores from YOLOv8 and emotion detection scores from HuBERT respectively. LogSTOP with Grounding DINO also performs better than the baselines.\nThe accuracies of detecting objects with scores <math alttext=\"&gt;0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">&gt;0.5</annotation></semantics></math> for YOLO, Grounding DINO and OWLv2 are <math alttext=\"46\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m3\" intent=\":literal\"><semantics><mrow><mn>46</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">46\\%</annotation></semantics></math>, <math alttext=\"38\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m4\" intent=\":literal\"><semantics><mrow><mn>38</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">38\\%</annotation></semantics></math> and <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m5\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> resp. which reflect the order of their performances on query matching.</p>\n\n",
                "matched_terms": [
                    "balanced",
                    "hubert",
                    "matching",
                    "query",
                    "accuracies",
                    "logstop",
                    "outperforms",
                    "qmtpspeech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LogSTOP consistently reports accuracies over <math alttext=\"75\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p3.m1\" intent=\":literal\"><semantics><mrow><mn>75</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">75\\%</annotation></semantics></math> on all query categories.\n<span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span> and <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>\nperform better on simple temporal queries than queries with boolean/temporal compositions.\nNSVS-TL also performs poorly on\ncategories with compositions over boolean expressions.\nThese results\nsuggest that the understanding of temporal queries is still an open problem for LVLMs and LALMs. Moreover, the higher accuracy of LogSTOP with much smaller neural models suggests that using well-defined logics for reasoning is beneficial.</p>\n\n",
                "matched_terms": [
                    "lalms",
                    "qwenaudiochat",
                    "query",
                    "accuracies",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Finally, we evaluate how the various design choices for LogSTOP affect the performance (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.T1\" title=\"Table 1 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>). We find that the accuracy drops by <math alttext=\"2\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m1\" intent=\":literal\"><semantics><mrow><mn>2</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">2\\%</annotation></semantics></math> when the standard STL robustness is used for aggregating scores instead of LogSTOP, or when local smoothing from Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1\" title=\"Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l8\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>) is not performed.\nA <math alttext=\"3\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m2\" intent=\":literal\"><semantics><mrow><mn>3</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">3\\%</annotation></semantics></math> drop is also observed when the adaptive threshold is replaced with <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p4.m3\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math>; Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F3\" title=\"Figure 3 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> demonstrates how the adaptive threshold\nis\nbetter at distinguishing between matching and non-matching sequences.</p>\n\n",
                "matched_terms": [
                    "nonmatching",
                    "matching",
                    "logstop",
                    "sequences",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methods.</span> We evaluate LogSTOP for ranked retrieval using Grounding DINO for object detection and Detectron2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib42\" title=\"\">42</a>]</cite> with SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> for action detection.\nSince there are no methods specifically designed for temporal property to sequence retrieval, we adapt existing text-to-video retrieval methods for this task. Since LogSTOP does not require explicit training for retrieval, we specifically only include zero-shot text-to-video retrieval methods for comparison.\nWe include <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib26\" title=\"\">26</a>]</cite>, a large multimodal model that jointly embeds videos and text queries. Inspired by ELIOT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib29\" title=\"\">29</a>]</cite>, we also include embedding similarity between video captions and text queries.\nWe refer to this as <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> and use\n<span class=\"ltx_text ltx_font_typewriter\">LLaVA-NeXT-Video-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib46\" title=\"\">46</a>]</cite> for generating video captions and <span class=\"ltx_text ltx_font_typewriter\">SentenceBERT</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib37\" title=\"\">37</a>]</cite> for embedding captions and queries. More details are provided in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A5\" title=\"Appendix E More details on the Ranked Retrieval methods &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">E</span></a>.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Results.</span>\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F4\" title=\"Figure 4 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>\npresents the results for ranked retrieval on the TP2VR benchmark.\nThe performance of all methods on TP2VR-actions is lower than that on TP2VR-objects due to the significantly higher number of classes (<math alttext=\"80\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m1\" intent=\":literal\"><semantics><mn>80</mn><annotation encoding=\"application/x-tex\">80</annotation></semantics></math> actions vs. <math alttext=\"6\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m2\" intent=\":literal\"><semantics><mn>6</mn><annotation encoding=\"application/x-tex\">6</annotation></semantics></math> objects) and lower number of relevant results (on average, <math alttext=\"21\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m3\" intent=\":literal\"><semantics><mn>21</mn><annotation encoding=\"application/x-tex\">21</annotation></semantics></math> vs. <math alttext=\"163\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m4\" intent=\":literal\"><semantics><mn>163</mn><annotation encoding=\"application/x-tex\">163</annotation></semantics></math> relevant videos).\nLogSTOP with GroundingDINO outperforms <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> and <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> on TP2VR-objects by\nat least <math alttext=\"28\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m5\" intent=\":literal\"><semantics><mrow><mn>28</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">28\\%</annotation></semantics></math> in mAP and <math alttext=\"24\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m6\" intent=\":literal\"><semantics><mrow><mn>24</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">24\\%</annotation></semantics></math> in R@<math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m7\" intent=\":literal\"><semantics><mi>r</mi><annotation encoding=\"application/x-tex\">r</annotation></semantics></math>, indicating that relevant results are retrieved at earlier ranks and the retrieved results include more relevant items than other methods.\nSimilarly, LogSTOP with SlowR50 outperforms baselines by more than <math alttext=\"19\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m8\" intent=\":literal\"><semantics><mrow><mn>19</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">19\\%</annotation></semantics></math> and <math alttext=\"16\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m9\" intent=\":literal\"><semantics><mrow><mn>16</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">16\\%</annotation></semantics></math> in terms of mAP and R@r respectively.\nThe first relevant result is also retrieved earlier by LogSTOP as is indicated by at least a <math alttext=\"24\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m10\" intent=\":literal\"><semantics><mrow><mn>24</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">24\\%</annotation></semantics></math> higher P@1 and better mean ranks;\non TP2VR-actions, LogSTOP retrieves the first relevant result at rank <math alttext=\"7.9\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m11\" intent=\":literal\"><semantics><mn>7.9</mn><annotation encoding=\"application/x-tex\">7.9</annotation></semantics></math> while <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> and <span class=\"ltx_text ltx_font_typewriter\">mPLUG</span> retrieve it at ranks <math alttext=\"&gt;20\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS3.p3.m12\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>20</mn></mrow><annotation encoding=\"application/x-tex\">&gt;20</annotation></semantics></math>.\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F5\" title=\"Figure 5 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents examples of ranking using the three methods.\nWe discuss these in detail in Appendix&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A8\" title=\"Appendix H Examples &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">H</span></a>.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "outperforms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this work, we\npresent the\nproblem of assigning scores for temporal properties (STOPs) given potentially noisy score predictors for local properties. We represent these properties using LTL and propose a scoring function LogSTOP for assigning STOPs. We then introduce the QMTP and TP2VR benchmarks for evaluating query matching and ranked retrieval\nwith temporal properties\nover objects / actions in videos and emotions in speech. LogSTOP with simple neural predictors outperforms LVLMs / LALMs, Temporal Logic-based baselines, and text-to-retrieval methods on the benchmarks.\n</p>\n\n",
                "matched_terms": [
                    "lalms",
                    "matching",
                    "query",
                    "logstop",
                    "outperforms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Limitations. </span>\nThere are properties such as \"there are always 2 cars\" that cannot directly be expressed in LTL.\nFuture work should hence explore more expressive logics&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib22\" title=\"\">22</a>]</cite> or construct local predictors for complex properties.\nWhile we only focus on sequences with single modalities, it will be interesting to see LogSTOP being for multi-modal applications where the local properties are over different modalities with scores from different local predictors.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "sequences",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Downsampling and average smoothing of confidence scores of local properties.</span> Firstly, LogSTOP downsamples the sequence of length <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m1\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> to contiguous blocks of length <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m2\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math>. The confidence scores for any local property in each block starting at <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m3\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>, <math alttext=\"\\hat{y}(c,t^{\\prime}\\in[t,t+w])\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m4\" intent=\":literal\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>c</mi><mo>,</mo><msup><mi>t</mi><mo>&#8242;</mo></msup></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mi>t</mi><mo>,</mo><mrow><mi>t</mi><mo>+</mo><mi>w</mi></mrow><mo stretchy=\"false\">]</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(c,t^{\\prime}\\in[t,t+w])</annotation></semantics></math> are first averaged after being normalized to the <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m5\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math> range. The confidence score for each block is then the <math alttext=\"\\log\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m6\" intent=\":literal\"><semantics><mi>log</mi><annotation encoding=\"application/x-tex\">\\log</annotation></semantics></math> of this averaged <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m7\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math>-normalized score. This series of downsampling, normalizing and smoothing operations starting at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m8\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> for a window <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p2.m9\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> can be seen on line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l8\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>. For example, given a sequence of log scores for object \"car\",</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "each"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Handling of logical operators (<math alttext=\"\\neg,\\land,\\lor\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m1\" intent=\":literal\"><semantics><mrow><mo>&#172;</mo><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8743;</mo><mo rspace=\"0em\">,</mo><mo lspace=\"0em\">&#8744;</mo></mrow><annotation encoding=\"application/x-tex\">\\neg,\\land,\\lor</annotation></semantics></math>)</span>.\nThe LogSTOP for <math alttext=\"\\neg\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m2\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mi>&#966;</mi></mrow><annotation encoding=\"application/x-tex\">\\neg\\varphi</annotation></semantics></math> at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m3\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> is intuitively high when the score for <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m4\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> is low (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l10\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">10</span></a>). For example, given a high score <math alttext=\"\\hat{y}({car},t,w)=\\log(0.9)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m5\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({car},t,w)=\\log(0.9)</annotation></semantics></math>, the score for \"not car\" <math alttext=\"\\hat{y}(\\neg{car},t,w)=\\log(1-0.9)=\\log(0.1)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p3.m6\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>&#8722;</mo><mn>0.9</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(\\neg{car},t,w)=\\log(1-0.9)=\\log(0.1)</annotation></semantics></math> is low.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The LogSTOP for <math alttext=\"\\varphi_{1}\\land\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m1\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8743;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\land\\varphi_{2}</annotation></semantics></math> at timestep <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m2\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math> is high only when the scores for both <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m3\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> and <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m4\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> are high (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l12\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">12</span></a>). For example, given high scores <math alttext=\"\\hat{y}({car},t,w)=\\log(0.9)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m5\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({car},t,w)=\\log(0.9)</annotation></semantics></math> and <math alttext=\"\\hat{y}({pedestrian},t,w)=0.9\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m6\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0.9</mn></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({pedestrian},t,w)=0.9</annotation></semantics></math>, the score for \"car and pedestrian\" <math alttext=\"\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.9)=\\log(0.81)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m7\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.81</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.9)=\\log(0.81)</annotation></semantics></math>. However, if either of the scores are low, e.g., if <math alttext=\"\\hat{y}({pedestrian},t,w)=0.1\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m8\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({pedestrian},t,w)=0.1</annotation></semantics></math>, the score drops significantly to <math alttext=\"\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.1)=\\log(0.09)\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m9\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></mrow><mo>,</mo><mi>t</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.09</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}({car}\\land{pedestrian},t,w)=\\log(0.9)+\\log(0.1)=\\log(0.09)</annotation></semantics></math>. Inspired by DeMorgan&#8217;s law, the LogSTOP for <math alttext=\"\\varphi_{1}\\lor\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m10\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>&#8744;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1}\\lor\\varphi_{2}</annotation></semantics></math> is simply the score for equivalent property <math alttext=\"\\neg(\\neg\\varphi_{1}\\land\\neg\\varphi_{2})\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p4.m11\" intent=\":literal\"><semantics><mrow><mo>&#172;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo rspace=\"0.167em\">&#172;</mo><msub><mi>&#966;</mi><mn>1</mn></msub></mrow><mo>&#8743;</mo><mrow><mo rspace=\"0.167em\">&#172;</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg(\\neg\\varphi_{1}\\land\\neg\\varphi_{2})</annotation></semantics></math> (line&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#alg1.l14\" title=\"In Algorithm 1 &#8227; 3 LogSTOP: An Algorithm for Computing STOPs &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">14</span></a>). This is intuitively only low when both the scores are low.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Note that these operators are defined not only over local properties <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m1\" intent=\":literal\"><semantics><mi>c</mi><annotation encoding=\"application/x-tex\">c</annotation></semantics></math> as in the examples above, but over any temporal property <math alttext=\"\\varphi,\\varphi_{1},\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m2\" intent=\":literal\"><semantics><mrow><mi>&#966;</mi><mo>,</mo><msub><mi>&#966;</mi><mn>1</mn></msub><mo>,</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi,\\varphi_{1},\\varphi_{2}</annotation></semantics></math>. Hence, for temporal property <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m3\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> = \"(car or truck) and (not pedestrian)\", the score is high only if it is high for both <math alttext=\"\\varphi_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m4\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{1}</annotation></semantics></math> = \"(car or truck)\" and <math alttext=\"\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m5\" intent=\":literal\"><semantics><msub><mi>&#966;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\varphi_{2}</annotation></semantics></math> = \"(not pedestrian)\". The scores for <math alttext=\"\\varphi_{1},\\varphi_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.p5.m6\" intent=\":literal\"><semantics><mrow><msub><mi>&#966;</mi><mn>1</mn></msub><mo>,</mo><msub><mi>&#966;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\varphi_{1},\\varphi_{2}</annotation></semantics></math> can be recursively computed.</p>\n\n",
                "matched_terms": [
                    "not",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"\\mu=f(s(t))\\geq 0\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p3.m1\" intent=\":literal\"><semantics><mrow><mi>&#956;</mi><mo>=</mo><mrow><mi>f</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8805;</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\mu=f(s(t))\\geq 0</annotation></semantics></math> is a Lipschitz continuous function over the signal <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p3.m2\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math> and <math alttext=\"I=[t_{1},t_{2}]\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p3.m3\" intent=\":literal\"><semantics><mrow><mi>I</mi><mo>=</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>t</mi><mn>1</mn></msub><mo>,</mo><msub><mi>t</mi><mn>2</mn></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">I=[t_{1},t_{2}]</annotation></semantics></math> is a time interval, <math alttext=\"t_{2}\\geq t_{1}\\geq 0\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p3.m4\" intent=\":literal\"><semantics><mrow><msub><mi>t</mi><mn>2</mn></msub><mo>&#8805;</mo><msub><mi>t</mi><mn>1</mn></msub><mo>&#8805;</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">t_{2}\\geq t_{1}\\geq 0</annotation></semantics></math>. The operators <span class=\"ltx_text ltx_font_italic\">Eventually</span> and <span class=\"ltx_text ltx_font_italic\">Always</span> can be defined as follows:</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In the context of the STOP problem, <math alttext=\"s(t)=\\hat{y}(X,\\cdot,t)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m1\" intent=\":literal\"><semantics><mrow><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">s(t)=\\hat{y}(X,\\cdot,t)</annotation></semantics></math> and <math alttext=\"f_{c}(s(t))=\\hat{y}(X,c,t)-\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m2\" intent=\":literal\"><semantics><mrow><mrow><msub><mi>f</mi><mi>c</mi></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8722;</mo><mi>&#964;</mi></mrow></mrow><annotation encoding=\"application/x-tex\">f_{c}(s(t))=\\hat{y}(X,c,t)-\\tau</annotation></semantics></math>. The query \"car until pedestrian\" can be written as <math alttext=\"\\mu_{car}(s(t))\\mathbin{\\mathcal{U}_{I}}\\mu_{pedestrian}(s(t))\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m3\" intent=\":literal\"><semantics><mrow><mrow><mrow><msub><mi>&#956;</mi><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119984;</mi><mi>I</mi></msub><msub><mi>&#956;</mi><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></msub></mrow><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mu_{car}(s(t))\\mathbin{\\mathcal{U}_{I}}\\mu_{pedestrian}(s(t))</annotation></semantics></math> where <math alttext=\"I=[0,T]\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m4\" intent=\":literal\"><semantics><mrow><mi>I</mi><mo>=</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mi>T</mi><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">I=[0,T]</annotation></semantics></math> and <math alttext=\"\\mu_{car}(s(t))=\\hat{y}(X,{car},t)-\\tau\\geq 0\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m5\" intent=\":literal\"><semantics><mrow><mrow><msub><mi>&#956;</mi><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8722;</mo><mi>&#964;</mi></mrow><mo>&#8805;</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\mu_{car}(s(t))=\\hat{y}(X,{car},t)-\\tau\\geq 0</annotation></semantics></math> (<math alttext=\"\\mu_{pedestrian}\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p5.m6\" intent=\":literal\"><semantics><msub><mi>&#956;</mi><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></msub><annotation encoding=\"application/x-tex\">\\mu_{pedestrian}</annotation></semantics></math> is defined similarly).</p>\n\n",
                "matched_terms": [
                    "until",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We argue that LogSTOP offers advantages over such semantics in the context of the STOP problem.\nThis is primarily because the traditional robustness measure is defined using <math alttext=\"\\max\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m1\" intent=\":literal\"><semantics><mi>max</mi><annotation encoding=\"application/x-tex\">\\max</annotation></semantics></math> and <math alttext=\"\\min\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m2\" intent=\":literal\"><semantics><mi>min</mi><annotation encoding=\"application/x-tex\">\\min</annotation></semantics></math> functions over temporal and logical formulae.\nThe measure, hence, only reflects the most violating or most satisfying timestep in the sequence. For example, consider assigning confidence scores to the property \"Always car\" in two different scenarios:</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Ideally, the confidence score for \"Always car\" should follow the order:\n<math alttext=\"\\hat{y}_{1}(\\square{car},\\cdot)&gt;\\hat{y}_{2}(\\square{car},\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m3\" intent=\":literal\"><semantics><mrow><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>1</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>2</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo rspace=\"0em\">,</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{1}(\\square{car},\\cdot)&gt;\\hat{y}_{2}(\\square{car},\\cdot)</annotation></semantics></math>.\nThe standard STL semantics, however, would assign the same robustness to both sequences for any <math alttext=\"\\tau&gt;0.1\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m4\" intent=\":literal\"><semantics><mrow><mi>&#964;</mi><mo>&gt;</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\tau&gt;0.1</annotation></semantics></math> since the most violating score is <math alttext=\"\\log(0.1)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p9.m5\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.1)</annotation></semantics></math> in either case. This makes the robustness measure unsuitable for downstream applications that require such ordering: for example, ranking / search.</p>\n\n",
                "matched_terms": [
                    "sequences",
                    "both",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Ideally, the confidence scores for \"car and pedestrian\" should follow the order:\n<math alttext=\"\\hat{y}_{1}({car}\\land{pedestrian},t=0)&gt;\\hat{y}_{2}({car}\\land{pedestrian},t=0)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m2\" intent=\":literal\"><semantics><mrow><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>1</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></mrow><mo>,</mo><mi>t</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>2</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>n</mi></mrow></mrow><mo>,</mo><mi>t</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{1}({car}\\land{pedestrian},t=0)&gt;\\hat{y}_{2}({car}\\land{pedestrian},t=0)</annotation></semantics></math> since <math alttext=\"\\hat{y}_{1}({car},t=0)&gt;\\hat{y}_{2}({car},t=0)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m3\" intent=\":literal\"><semantics><mrow><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>1</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>,</mo><mi>t</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mn>2</mn></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><mo>,</mo><mi>t</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_{1}({car},t=0)&gt;\\hat{y}_{2}({car},t=0)</annotation></semantics></math>. The robustness for both the cases is the same, i.e., <math alttext=\"\\log(0.6)-\\log(0.5)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m4\" intent=\":literal\"><semantics><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.6</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8722;</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.5</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.6)-\\log(0.5)</annotation></semantics></math>, because of the <math alttext=\"\\min\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m5\" intent=\":literal\"><semantics><mi>min</mi><annotation encoding=\"application/x-tex\">\\min</annotation></semantics></math> semantics for the Boolean <span class=\"ltx_text ltx_font_italic\">and</span> operator. The LogSTOP for the two cases are <math alttext=\"\\log(0.9)+\\log(0.6)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m6\" intent=\":literal\"><semantics><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.9</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.6</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.9)+\\log(0.6)</annotation></semantics></math> and <math alttext=\"\\log(0.6)+\\log(0.6)\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p10.m7\" intent=\":literal\"><semantics><mrow><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.6</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>&#8289;</mo><mrow><mo stretchy=\"false\">(</mo><mn>0.6</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\log(0.6)+\\log(0.6)</annotation></semantics></math> respectively, which reflect the expected order.</p>\n\n",
                "matched_terms": [
                    "logstop",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Note that the only difference between the two scenarios is the score for \"pedestrian\" at <math alttext=\"t=2\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m1\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">t=2</annotation></semantics></math> (a high score of <math alttext=\"0.9\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m2\" intent=\":literal\"><semantics><mn>0.9</mn><annotation encoding=\"application/x-tex\">0.9</annotation></semantics></math> for the first scenario and a lower score of <math alttext=\"0.6\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m3\" intent=\":literal\"><semantics><mn>0.6</mn><annotation encoding=\"application/x-tex\">0.6</annotation></semantics></math> for the second scenario) . The robustness for the two cases is the same because of the <math alttext=\"\\min\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m4\" intent=\":literal\"><semantics><mi>min</mi><annotation encoding=\"application/x-tex\">\\min</annotation></semantics></math> semantics within the <span class=\"ltx_text ltx_font_italic\">Until</span> operator. LogSTOP assigns a higher score for the first scenario because of the difference at <math alttext=\"t=2\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p12.m5\" intent=\":literal\"><semantics><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">t=2</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "until",
                    "logstop",
                    "second"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4\" title=\"4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we briefly discuss the QMTP and TP2VR benchmarks for evaluation.\nFor\nconstructing these benchmarks\n, we use\nthree existing datasets with frame/segment-level annotations for local properties:\nThe RealTLV dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>\nconsists of videos from NuScenes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib6\" title=\"\">6</a>]</cite> and Waymo&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib39\" title=\"\">39</a>]</cite> driving datasets with frame-level annotations for 6 object classes.\n(for example, \"car\", \"truck\", etc).\nThe IEMOCAP dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib5\" title=\"\">5</a>]</cite> provides speech segments from conversations\nbetween two speakers\nand each segment is labeled with one of the 4 major emotions expressed by the speaker.\n(for example, \"happy\", \"sad\", etc.).\nThe AVA dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib19\" title=\"\">19</a>]</cite> consists of frame-level action annotations for 80 actions in 15-min clips from YouTube. We only consider the validation subset of this dataset and sample 5 frames per second.\nThese datasets can be used for evaluating\ntemporal properties over objects in videos\n(\"car until pedestrian\", for example)\n, emotions in speech\n(\"always happy\")\n, and actions in videos\n(\"a person sits until they stand up\")\nrespectively.</p>\n\n",
                "matched_terms": [
                    "second",
                    "until",
                    "each",
                    "dataset",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The QMTP dataset.</span>\nFor any temporal property template (for example, \"p1 Until p2\") and samples from these datasets, we identify matching and non-matching sequences of desired length as follows: for every sample, we first identify candidates for local properties in the template (p1, p2, etc.) as the set of all ground-truth objects / emotions in the sequence. We then use the standard LTL semantics over the frame/segment-level ground-truth labels to collect matching and non-matching subsequences of the desired length. This creates a TP-query matching dataset for an arbitrary set of temporal properties as long as these properties are sufficiently expressed by sequences from the underlying dataset. Moreover, this pipeline is agnostic to the choice of the dataset since it only requires sequences of ground-truth labels for local properties. We use this pipeline to create\nthe <span class=\"ltx_text ltx_font_bold\">QMTP-video dataset</span> with <math alttext=\"7468\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m1\" intent=\":literal\"><semantics><mn>7468</mn><annotation encoding=\"application/x-tex\">7468</annotation></semantics></math> samples (<math alttext=\"3750\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m2\" intent=\":literal\"><semantics><mn>3750</mn><annotation encoding=\"application/x-tex\">3750</annotation></semantics></math> matching and <math alttext=\"3718\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m3\" intent=\":literal\"><semantics><mn>3718</mn><annotation encoding=\"application/x-tex\">3718</annotation></semantics></math> non-matching) with video sequences of lengths <math alttext=\"\\{10,20,30,40,50\\}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mn>10</mn><mo>,</mo><mn>20</mn><mo>,</mo><mn>30</mn><mo>,</mo><mn>40</mn><mo>,</mo><mn>50</mn><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{10,20,30,40,50\\}</annotation></semantics></math>. For each target length, this dataset contains approximately <math alttext=\"100\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m5\" intent=\":literal\"><semantics><mn>100</mn><annotation encoding=\"application/x-tex\">100</annotation></semantics></math> samples corresponding to each of the <math alttext=\"15\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m6\" intent=\":literal\"><semantics><mn>15</mn><annotation encoding=\"application/x-tex\">15</annotation></semantics></math> property templates. Similarly, we create the <span class=\"ltx_text ltx_font_bold\">QMTP-speech dataset</span> with <math alttext=\"3300\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m7\" intent=\":literal\"><semantics><mn>3300</mn><annotation encoding=\"application/x-tex\">3300</annotation></semantics></math> samples, including speech sequences of lengths in ranges <math alttext=\"\\{5-10,10-20,20-30\\}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m8\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">{</mo><mrow><mn>5</mn><mo>&#8722;</mo><mn>10</mn></mrow><mo>,</mo><mrow><mn>10</mn><mo>&#8722;</mo><mn>20</mn></mrow><mo>,</mo><mrow><mn>20</mn><mo>&#8722;</mo><mn>30</mn></mrow><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{5-10,10-20,20-30\\}</annotation></semantics></math>. The QMTP-speech dataset only contains samples from <math alttext=\"11/15\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m9\" intent=\":literal\"><semantics><mrow><mn>11</mn><mo>/</mo><mn>15</mn></mrow><annotation encoding=\"application/x-tex\">11/15</annotation></semantics></math> property templates. This is because there are no sequences matching <math alttext=\"4\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p2.m10\" intent=\":literal\"><semantics><mn>4</mn><annotation encoding=\"application/x-tex\">4</annotation></semantics></math> properties \"Always p1 and Eventually p2\", \"Always (p1 and p2)\", \"(p1 and p2) Until p3\", and \"(p1 and p2) Until Eventually p3\" since two emotions cannot be expressed at the same time.</p>\n\n",
                "matched_terms": [
                    "nonmatching",
                    "matching",
                    "always",
                    "until",
                    "each",
                    "sequences",
                    "dataset",
                    "lengths",
                    "eventually",
                    "qmtpspeech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">The TP2VR dataset.</span>\nWe restrict queries to a maximum of 5 per temporal property template. For TP2VR objects, we aim to find <math alttext=\"25-50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m1\" intent=\":literal\"><semantics><mrow><mn>25</mn><mo>&#8722;</mo><mn>50</mn></mrow><annotation encoding=\"application/x-tex\">25-50</annotation></semantics></math> frame-long subsequences satisfying a temporal property; we only include a temporal property if less than <math alttext=\"250\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m2\" intent=\":literal\"><semantics><mn>250</mn><annotation encoding=\"application/x-tex\">250</annotation></semantics></math> videos are retrieved using the standard LTL semantics with the ground truth labels.\nWith all possible combinations of objects, this gives us a total of <math alttext=\"42\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m3\" intent=\":literal\"><semantics><mn>42</mn><annotation encoding=\"application/x-tex\">42</annotation></semantics></math> queries, with an average of <math alttext=\"163\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m4\" intent=\":literal\"><semantics><mn>163</mn><annotation encoding=\"application/x-tex\">163</annotation></semantics></math> videos relevant to a query.\nSimilarly, for TP2VR-actions, we aim to find 10-second long subsequences (<math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m5\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> frames) satisfying a temporal property; we only include a temporal property if less than <math alttext=\"50\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m6\" intent=\":literal\"><semantics><mn>50</mn><annotation encoding=\"application/x-tex\">50</annotation></semantics></math> videos are retrieved using the standard LTL semantics with the ground truth labels. With all possible combinations of actions, this gives us a total of <math alttext=\"70\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m7\" intent=\":literal\"><semantics><mn>70</mn><annotation encoding=\"application/x-tex\">70</annotation></semantics></math> queries, with an average of <math alttext=\"21\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p3.m8\" intent=\":literal\"><semantics><mn>21</mn><annotation encoding=\"application/x-tex\">21</annotation></semantics></math> videos relevant to a query.</p>\n\n",
                "matched_terms": [
                    "dataset",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">LogSTOP with simple trained neural predictors:</span> We use YOLOv8&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib23\" title=\"\">23</a>]</cite>, Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite>, and OWLv2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib34\" title=\"\">34</a>]</cite>, to get confidence scores for object detection in video frames, and HuBERT&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib41\" title=\"\">41</a>]</cite> for speech emotion recognition in audio segments. Since the scores are in the <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math> range, we normalize them in the <math alttext=\"[-\\infty,0]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m2\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mrow><mo>&#8722;</mo><mi mathvariant=\"normal\">&#8734;</mi></mrow><mo>,</mo><mn>0</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[-\\infty,0]</annotation></semantics></math> range using the <math alttext=\"\\log\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m3\" intent=\":literal\"><semantics><mi>log</mi><annotation encoding=\"application/x-tex\">\\log</annotation></semantics></math> operation, as required by LogSTOP.\nA video matches query <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m4\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> if LogSTOP <math alttext=\"\\hat{y}(\\varphi,0,w)&gt;\\tau(\\varphi,0)\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m5\" intent=\":literal\"><semantics><mrow><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><mi>&#964;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\hat{y}(\\varphi,0,w)&gt;\\tau(\\varphi,0)</annotation></semantics></math> (and vice versa for non-matching examples). The estimates are evaluated against ground-truth labels <math alttext=\"y(\\varphi,0)\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m6\" intent=\":literal\"><semantics><mrow><mi>y</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>&#966;</mi><mo>,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">y(\\varphi,0)</annotation></semantics></math>. The window <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m7\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> is selected as follows: <math alttext=\"w=2\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m8\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">w=2</annotation></semantics></math> for <math alttext=\"T&lt;20\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m9\" intent=\":literal\"><semantics><mrow><mi>T</mi><mo>&lt;</mo><mn>20</mn></mrow><annotation encoding=\"application/x-tex\">T&lt;20</annotation></semantics></math> and <math alttext=\"w=5\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p1.m10\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">w=5</annotation></semantics></math> otherwise.</p>\n\n",
                "matched_terms": [
                    "nonmatching",
                    "logstop",
                    "hubert",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Large Vision Language Models (LVLMs)</span>. We evaluate two popular LVLMs on query matching for videos: <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib27\" title=\"\">27</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib45\" title=\"\">45</a>]</cite>.\nFor the \"always car\" example, we provide the models with the video sequence and a text prompt \"Is a car detected in all frames of this video?\". The response is considered correct if the model responds with \"Yes\" or \"No\" for matching and non-matching samples respectively. <span class=\"ltx_text ltx_font_typewriter\">Video-LLava-7B</span> supports a context window of <math alttext=\"4096\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m1\" intent=\":literal\"><semantics><mn>4096</mn><annotation encoding=\"application/x-tex\">4096</annotation></semantics></math> tokens while <span class=\"ltx_text ltx_font_typewriter\">LongVA-7B</span> can handle up to 2000 frames. We set the maximum tokens to generate to <math alttext=\"60\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m2\" intent=\":literal\"><semantics><mn>60</mn><annotation encoding=\"application/x-tex\">60</annotation></semantics></math> and <math alttext=\"1024\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p2.m3\" intent=\":literal\"><semantics><mn>1024</mn><annotation encoding=\"application/x-tex\">1024</annotation></semantics></math> respectively and use a temperature of 0.1 and standard values for the other parameters.</p>\n\n",
                "matched_terms": [
                    "matching",
                    "nonmatching",
                    "always",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Large Audio Language Models (LALMs)</span>. Similarly, we evaluate two popular LALMs on query matching for speech: <span class=\"ltx_text ltx_font_typewriter\">Qwen-Audio-Chat</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib10\" title=\"\">10</a>]</cite> and <span class=\"ltx_text ltx_font_typewriter\">Qwen2-Audio-7B-Instruct</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib11\" title=\"\">11</a>]</cite>.\nFor the \"eventually happy\" example, we provide the models with the audio sequence and a text prompt \"Does the speaker sound happy at some time in this audio clip?\". We set the sampling rate to <math alttext=\"16000\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p3.m1\" intent=\":literal\"><semantics><mn>16000</mn><annotation encoding=\"application/x-tex\">16000</annotation></semantics></math> and generate a maximum of <math alttext=\"256\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p3.m2\" intent=\":literal\"><semantics><mn>256</mn><annotation encoding=\"application/x-tex\">256</annotation></semantics></math> new tokens, with standard values for other parameters.</p>\n\n",
                "matched_terms": [
                    "lalms",
                    "qwenaudiochat",
                    "matching",
                    "qwen2audio7binstruct",
                    "query",
                    "eventually"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite>.</span> Proposed for event detection in videos, NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite> uses the PCTL-based model checker STORM&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib20\" title=\"\">20</a>]</cite> to identify video frame subsequences where a certain event is detected. NSVS-TL reports state-of-the-art performance on detecting temporal events in videos, surpassing large language models such as GPT-4.\nFor our task, we specify the target query in PCTL (\"always car\" is <math alttext=\"P&gt;0.5[G\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A4.p4.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo stretchy=\"false\">[</mo><mi>G</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5[G</annotation></semantics></math> \"<math alttext=\"{car}\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p4.m2\" intent=\":literal\"><semantics><mrow><mi>c</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>r</mi></mrow><annotation encoding=\"application/x-tex\">{car}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A4.p4.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math>) and the response is considered correct if NSVS-TL returns / does not return the entire video sequence as output for a matching / non-matching query respectively.</p>\n\n",
                "matched_terms": [
                    "nonmatching",
                    "matching",
                    "query",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We do not evaluate the method from &#160;<cite class=\"ltx_cite ltx_citemacro_citet\">Yang et&#160;al. [<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib44\" title=\"\">44</a>]</cite> since the implementation is not publicly available and LTL model checking with STORM is not well-documented.</p>\n\n",
                "matched_terms": [
                    "not",
                    "method"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">LogSTOP.</span>\nWe use LogSTOP with Grounding DINO&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib28\" title=\"\">28</a>]</cite> for TP2VR-objects and with SlowR50&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib16\" title=\"\">16</a>]</cite> for TP2VR-actions respectively.\nWe repurpose the script from <span class=\"ltx_text ltx_font_typewriter\">tutorials/video_detection_example</span> at <span class=\"ltx_text ltx_font_typewriter\">https://github.com/facebookresearch/pytorchvideo/</span>\nto run SlowR50 on videos from the TP2VR-actions dataset.\nWe use a smoothing window <math alttext=\"w=5\" class=\"ltx_Math\" display=\"inline\" id=\"A5.p1.m1\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">w=5</annotation></semantics></math> for all retrieval experiments.</p>\n\n",
                "matched_terms": [
                    "dataset",
                    "logstop"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> because the implementation of ELIOT is not publicly available. Our local implementation of ELIOT did not report good results (the video captions generated by &#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib40\" title=\"\">40</a>]</cite> did not include mentions of objects or actions).</p>\n\n",
                "matched_terms": [
                    "report",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: <math alttext=\"\\square\\,p1\\land\\Diamond\\,p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i4.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo>&#8743;</mo><mrow><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\square\\,p1\\land\\Diamond\\,p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: <math alttext=\"\\square\\,p1\\lor\\Diamond\\,p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i5.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo>&#8744;</mo><mrow><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\square\\,p1\\lor\\Diamond\\,p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: <math alttext=\"\\neg p1\\mathbin{\\mathcal{U}}p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i6.p1.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi>p</mi></mrow><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg p1\\mathbin{\\mathcal{U}}p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): <math alttext=\"p1\\mathbin{\\mathcal{U}}\\neg p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i7.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">p1\\mathbin{\\mathcal{U}}\\neg p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: <math alttext=\"p1\\mathbin{\\mathcal{U}}\\square\\,p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i10.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi mathvariant=\"normal\">&#9633;</mi></mrow><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">p1\\mathbin{\\mathcal{U}}\\square\\,p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: <math alttext=\"\\Diamond\\,\\square\\,p1\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i11.p1.m1\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\Diamond\\,\\square\\,p1</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: <math alttext=\"\\square\\,\\Diamond\\,p1\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i12.p1.m1\" intent=\":literal\"><semantics><mrow><mi mathvariant=\"normal\">&#9633;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi mathvariant=\"normal\">&#9671;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\square\\,\\Diamond\\,p1</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: <math alttext=\"\\neg p1\\mathbin{\\mathcal{U}}\\Diamond\\,p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i13.p1.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi mathvariant=\"normal\">&#9671;</mi></mrow><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg p1\\mathbin{\\mathcal{U}}\\Diamond\\,p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: <math alttext=\"\\neg p1\\mathbin{\\mathcal{U}}\\square\\,p2\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i14.p1.m1\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.167em\">&#172;</mo><mrow><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi mathvariant=\"normal\">&#9633;</mi></mrow><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\neg p1\\mathbin{\\mathcal{U}}\\square\\,p2</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: <math alttext=\"(p1\\land p2)\\mathbin{\\mathcal{U}}\\Diamond\\,p3\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I1.i15.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><mo>&#8743;</mo><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo class=\"ltx_font_mathcaligraphic\" lspace=\"0.222em\" rspace=\"0.222em\">&#119984;</mo><mi mathvariant=\"normal\">&#9671;</mi></mrow><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">(p1\\land p2)\\mathbin{\\mathcal{U}}\\Diamond\\,p3</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">NSVS-TL&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib9\" title=\"\">9</a>]</cite> uses the model checker STORM&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#bib.bib20\" title=\"\">20</a>]</cite> to verify if a given sequence satisfies a temporal property, where the temporal properties are represented in Probabilistic Computation Tree Logic (PCTL). In PCTL, the <math alttext=\"F\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m1\" intent=\":literal\"><semantics><mi>F</mi><annotation encoding=\"application/x-tex\">F</annotation></semantics></math>, <math alttext=\"G\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m2\" intent=\":literal\"><semantics><mi>G</mi><annotation encoding=\"application/x-tex\">G</annotation></semantics></math> and <math alttext=\"U\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m3\" intent=\":literal\"><semantics><mi>U</mi><annotation encoding=\"application/x-tex\">U</annotation></semantics></math> operators represent the <span class=\"ltx_text ltx_font_italic\">Eventually</span>, <span class=\"ltx_text ltx_font_italic\">Always</span> and <span class=\"ltx_text ltx_font_italic\">Until</span> operators respectively. The <math alttext=\"\\sim\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m4\" intent=\":literal\"><semantics><mo>&#8764;</mo><annotation encoding=\"application/x-tex\">\\sim</annotation></semantics></math>, <math alttext=\"\\&amp;\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m5\" intent=\":literal\"><semantics><mo>&amp;</mo><annotation encoding=\"application/x-tex\">\\&amp;</annotation></semantics></math> and <math alttext=\"\\mid\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m6\" intent=\":literal\"><semantics><mo>&#8739;</mo><annotation encoding=\"application/x-tex\">\\mid</annotation></semantics></math> operators represent the Boolean <span class=\"ltx_text ltx_font_italic\">negation</span>, <span class=\"ltx_text ltx_font_italic\">and</span>, and <span class=\"ltx_text ltx_font_italic\">or</span> operators respectively. The operator <math alttext=\"P\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m7\" intent=\":literal\"><semantics><mi>P</mi><annotation encoding=\"application/x-tex\">P</annotation></semantics></math> is used to indicate the ranges of probability of a given property being satisfied: for example, <math alttext=\"P&gt;0.5[F\\,\\varphi]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m8\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mrow><mn>0.5</mn><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>F</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>&#966;</mi></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5[F\\,\\varphi]</annotation></semantics></math> translates to \"the probability of <math alttext=\"\\varphi\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m9\" intent=\":literal\"><semantics><mi>&#966;</mi><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math> eventually being satisfied is more than <math alttext=\"0.5\" class=\"ltx_Math\" display=\"inline\" id=\"A6.p4.m10\" intent=\":literal\"><semantics><mn>0.5</mn><annotation encoding=\"application/x-tex\">0.5</annotation></semantics></math>\".</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: <math alttext=\"P&gt;0.5\\,[\\,G\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i4.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" rspace=\"0.170em\" stretchy=\"false\">[</mo><mi>G</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[\\,G</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i4.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"\\&amp;\\,F\\,\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i4.p1.m3\" intent=\":literal\"><semantics><mrow><mo rspace=\"0em\">&amp;</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">\\&amp;\\,F\\,</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i4.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i4.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: <math alttext=\"P&gt;0.5\\,[\\,G\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i5.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" rspace=\"0.170em\" stretchy=\"false\">[</mo><mi>G</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[\\,G</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i5.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"\\mid\\,F\\,\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i5.p1.m3\" intent=\":literal\"><semantics><mrow><mo rspace=\"0.337em\">&#8739;</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">\\mid\\,F\\,</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i5.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i5.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: <math alttext=\"P&gt;0.5\\,[\\sim\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i6.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" stretchy=\"false\">[</mo><mo lspace=\"0em\">&#8764;</mo></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[\\sim</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i6.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"U\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i6.p1.m3\" intent=\":literal\"><semantics><mi>U</mi><annotation encoding=\"application/x-tex\">U</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i6.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i6.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): <math alttext=\"P&gt;0.5\\,[\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i7.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mo lspace=\"0.170em\" stretchy=\"false\">[</mo></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i7.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"U\\sim\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i7.p1.m3\" intent=\":literal\"><semantics><mrow><mi>U</mi><mo>&#8764;</mo><mi/></mrow><annotation encoding=\"application/x-tex\">U\\sim</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i7.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i7.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: <math alttext=\"P&gt;0.5\\,[\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i10.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mo lspace=\"0.170em\" stretchy=\"false\">[</mo></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i10.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"U\\,G\\,\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i10.p1.m3\" intent=\":literal\"><semantics><mrow><mi>U</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>G</mi></mrow><annotation encoding=\"application/x-tex\">U\\,G\\,</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i10.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i10.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: <math alttext=\"P&gt;0.5\\,[F\\,G\\,\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i11.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" stretchy=\"false\">[</mo><mi>F</mi><mi>G</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[F\\,G\\,</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i11.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i11.p1.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: <math alttext=\"P&gt;0.5\\,[G\\,F\\,\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i12.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" stretchy=\"false\">[</mo><mi>G</mi><mi>F</mi></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[G\\,F\\,</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i12.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i12.p1.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: <math alttext=\"P&gt;0.5\\,[\\sim\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i13.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" stretchy=\"false\">[</mo><mo lspace=\"0em\">&#8764;</mo></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[\\sim</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i13.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"U\\,F\\,\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i13.p1.m3\" intent=\":literal\"><semantics><mrow><mi>U</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">U\\,F\\,</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i13.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i13.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: <math alttext=\"P&gt;0.5\\,[\\sim\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i14.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mrow><mo lspace=\"0.170em\" stretchy=\"false\">[</mo><mo lspace=\"0em\">&#8764;</mo></mrow></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[\\sim</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i14.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"U\\,G\\,\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i14.p1.m3\" intent=\":literal\"><semantics><mrow><mi>U</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>G</mi></mrow><annotation encoding=\"application/x-tex\">U\\,G\\,</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i14.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i14.p1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: <math alttext=\"P&gt;0.5\\,[\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"A6.I2.i15.p1.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mn>0.5</mn><mo lspace=\"0.170em\" stretchy=\"false\">[</mo></mrow><annotation encoding=\"application/x-tex\">P&gt;0.5\\,[</annotation></semantics></math> \"<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>\" <math alttext=\"\\&amp;\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m3\" intent=\":literal\"><semantics><mo>&amp;</mo><annotation encoding=\"application/x-tex\">\\&amp;</annotation></semantics></math> \"<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>\" <math alttext=\"U\\,F\\,\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m5\" intent=\":literal\"><semantics><mrow><mi>U</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">U\\,F\\,</annotation></semantics></math> \"<math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m6\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math>\" <math alttext=\"]\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I2.i15.p1.m7\" intent=\":literal\"><semantics><mo stretchy=\"false\">]</mo><annotation encoding=\"application/x-tex\">]</annotation></semantics></math></p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The prompts for LVLMs for query matching on QMTP-video are as follows:</p>\n\n",
                "matched_terms": [
                    "matching",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: \"Is a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i4.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all frames of this video and is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i4.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in any frame of this video?\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: \"Is a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i5.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all frames of this video or is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i5.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in any frame of this video?\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: \"Is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i6.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in any frame of this video and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i6.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> absent in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): \"Is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i7.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> absent in any frame of this video and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i7.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always (p1 and p2): \"Are both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i8.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i8.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in all frames of this video?\"</p>\n\n",
                "matched_terms": [
                    "both",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until p3: \"Is a <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i9.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> present in any frame of this video and both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i9.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i9.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: \"Starting at some frame in this video, is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i10.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in all subsequent frames and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i10.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: \"Starting at some frame in this video, is a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i11.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in all subsequent frames?\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: \"Starting at any frame in this video, is a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i12.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> present in some subsequent frame?\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: \"Starting at some frame in this video, is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i13.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in some subsequent frame and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i13.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> absent in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: \"Starting at some frame in this video, is a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i14.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in all subsequent frames and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i14.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> absent in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: \"Starting at some frame in this video, is a <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i15.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> present in some subsequent frame and both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i15.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I3.i15.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> present in all previous frames?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The prompts for LALMs for query matching on QMTP-speech are as follows:</p>\n\n",
                "matched_terms": [
                    "lalms",
                    "qmtpspeech",
                    "matching",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: \"Does the speaker&#8217;s emotion sound <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i4.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all times and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i4.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at any time?\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: \"Does the speaker&#8217;s emotion sound <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i5.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all times or <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i5.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at any time?\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: \"Does the speaker&#8217;s emotion sound <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i6.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at any time and not <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i6.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all times until then?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): \"Does the speaker&#8217;s emotion sound not <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i7.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at any time and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i7.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all times until then?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always (p1 and p2): \"Does the speaker&#8217;s emotion sound both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i8.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i8.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at all times?\"</p>\n\n",
                "matched_terms": [
                    "both",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until p3: \"Does the speaker&#8217;s emotion sound <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i9.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> at any time and both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i9.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i9.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at all times until then?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: \"Starting at some time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i10.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at all subsequent times and <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i10.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all previous times?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: \"Starting at some time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i11.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all subsequent times?\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: \"Starting at any time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i12.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at some subsequent time?\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: \"Starting at some time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i13.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at some subsequent time and not <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i13.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all previous times?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: \"Starting at some time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i14.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at all subsequent times and not <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i14.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> at all previous times?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: \"Starting at some time in this audio clip, does the speaker&#8217;s emotion sound <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i15.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> at some subsequent time and both <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i15.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I4.i15.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> at all previous times?\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i4.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i4.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i4.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is always present and a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i4.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> appears at some point.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i5.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i5.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where either a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i5.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is always present or a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i5.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> appears at some point.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i6.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i6.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i6.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> is present at some point and a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i6.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is absent in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i7.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i7.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i7.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> is absent at some point and a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i7.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is present in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until p3: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i9.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i9.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where a <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i9.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> is present at some point and both a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i9.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i9.p1.m5\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> are present in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i10.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i10.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at some point, a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i10.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> is always present and a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i10.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is present in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i11.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i11.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at some point, a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i11.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> starts being always present.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i12.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i12.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at any point, a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i12.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> appears in some frames.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i13.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i13.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at some point, a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i13.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> appears in some frames and a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i13.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is absent in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i14.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i14.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at some point, a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i14.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> is always present and a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i14.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> is absent in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i15.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> to <math alttext=\"t_{hi}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i15.p1.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>h</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>i</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{hi}</annotation></semantics></math> frames where starting at some point, a <math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i15.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math> appears at some point and both a <math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i15.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math> and a <math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I5.i15.p1.m5\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math> are present in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 and Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i4.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i4.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is always happening and the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i4.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; happens at some point.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always p1 or Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i5.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where either the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i5.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is always happening or the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i5.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; happens at some point.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i6.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i6.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; happens at some point and the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i6.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is not happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until (Not p2): \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i7.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i7.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; is not happening at some point and the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i7.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until p3: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i9.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where the action &#8217;<math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i9.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math>&#8217; happens at some point and both the actions &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i9.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; and &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i9.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; are happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">p1 Until Always p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i10.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at some point, the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i10.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; is always happening and the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i10.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Eventually Always p1: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i11.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at some point, the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i11.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is always happening.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Always Eventually p1: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i12.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at any point, the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i12.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; happens in some frames.\"</p>\n\n",
                "matched_terms": [
                    "eventually",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Eventually p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i13.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at some point, the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i13.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; happens in some frames and the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i13.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is not happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(Not p1) Until Always p2: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i14.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at some point, the action &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i14.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; is always happening and the action &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i14.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; is not happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "not",
                    "always"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">(p1 and p2) Until Eventually p3: \"A sequence of <math alttext=\"t_{lo}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i15.p1.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{lo}</annotation></semantics></math> frames where starting at some point, the action &#8217;<math alttext=\"{p3}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i15.p1.m2\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">{p3}</annotation></semantics></math>&#8217; happens at some point and both the actions &#8217;<math alttext=\"{p1}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i15.p1.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">{p1}</annotation></semantics></math>&#8217; and &#8217;<math alttext=\"{p2}\" class=\"ltx_Math\" display=\"inline\" id=\"A6.I6.i15.p1.m4\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">{p2}</annotation></semantics></math>&#8217; are happening in all frames before that.\"</p>\n\n",
                "matched_terms": [
                    "until",
                    "eventually",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#S4.F5\" title=\"Figure 5 &#8227; 4.2 Results on Query Matching &#8227; 4 Experiments &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents examples of ranking using the three methods.\nIn the first example, the video captions used by <span class=\"ltx_text ltx_font_typewriter\">CaptionSim</span> do not include smaller objects that might be relevant to the query (\"car\" in this example). In the second example, the two actions are mentioned in the caption &#8211; the video is ranked lower than other videos with more mentions of the actions (\"stand\" and \"hand clap\" in this case).\nThis demonstrates that while caption-based methods outperform joint model embeddings (<span class=\"ltx_text ltx_font_typewriter\">mPLUG</span>), they rely on semantic similarity between captions and text to determine relevance, which might not be sufficient for effective retrieval with temporal queries.</p>\n\n",
                "matched_terms": [
                    "not",
                    "second",
                    "query"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.06512v1#A9.F6\" title=\"Figure 6 &#8227; Appendix I Adaptive threshold vs. constant threshold &#8227; LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> presents a comparison of the adaptive threshold and the constant <math alttext=\"\\log 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"A9.p1.m1\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\log 0.5</annotation></semantics></math> threshold for all temporal property templates, using LogSTOPs for matching and non-matching sequences from the QMTP-video (detections using YOLOv8).</p>\n\n",
                "matched_terms": [
                    "matching",
                    "nonmatching",
                    "sequences"
                ]
            }
        ]
    }
}