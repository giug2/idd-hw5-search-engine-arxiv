{
    "S2.T1": {
        "caption": "Table 1: We split the TextrolSpeech-Train set to form the new Train and Eval subsets. We removed the emotion contempt in the Eval set because our emotion recognition model does not support it, resulting in eight emotions in Train and seven in Eval.",
        "body": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Subset</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\"># Seg</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\"># Emo</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">Dur (Hrs)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Train</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">234k</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">328</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Eval</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">700</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">1</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "dur",
            "does",
            "emotions",
            "subsets",
            "emo",
            "not",
            "our",
            "hrs",
            "seg",
            "new",
            "resulting",
            "seven",
            "eight",
            "contempt",
            "eval",
            "emotion",
            "set",
            "recognition",
            "removed",
            "form",
            "train",
            "model",
            "support",
            "234k",
            "because",
            "subset",
            "split",
            "textrolspeechtrain"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our experiments are conducted using the </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">TextrolSpeech</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> dataset. This is a large-scale open-source corpora, which includes 330 hours of real-recorded speech from over 1,000 speakers, with five different style labels: gender, pitch, speaking speed, volume, and emotion. These labels are constructed into 500 templates of style prompts that describe how the speaker deduces the speech.\nTable&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S2.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 2.2 Semantic Mismatch Guided CFG (SMG-CFG) &#8227; 2 Methods &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> summarizes the subsets we reorganized from the </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">TextrolSpeech</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThe TextrolSpeech covers eight emotions, such as neutral, sad, happy, surprised, angry, disgusted, contempt, and fearful, with over half falling under the neutral category. Our </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Train</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Eval</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> sets are split from the TextrolSpeech-Train set, where we ensure the number of samples for each emotion is balanced in </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Eval</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where we have 100 samples for each emotion, and the rest is in the </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Train</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. &#8221;Contempt&#8221; emotion is removed in the </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Eval</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We discard the TextrolSpeech-Test set since it only includes 5 out of 8 emotions, and most emotions are represented by fewer than 10 samples.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">While Text-to-Speech (TTS) systems can achieve fine-grained control over emotional expression via natural language prompts, a significant challenge emerges when the desired emotion (style prompt) conflicts with the semantic content of the text. This mismatch often results in unnatural-sounding speech, undermining the goal of achieving fine-grained emotional control. Classifier-Free Guidance (CFG) is a key technique for enhancing prompt alignment; however, its application to auto-regressive (AR) TTS models remains underexplored, which can lead to degraded audio quality. This paper directly addresses the challenge of style-content mismatch in AR TTS models by proposing an adaptive CFG scheme that adjusts to different levels of the detected mismatch, as measured using large language models or natural language inference models.\nThis solution is based on a comprehensive analysis of CFG&#8217;s impact on emotional expressiveness in state-of-the-art AR TTS models.\nOur results demonstrate that the proposed adaptive CFG scheme improves the emotional expressiveness of the AR TTS model while maintaining audio quality and intelligibility.</span>\n</p>\n\n",
                "matched_terms": [
                    "emotion",
                    "model",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Modern Text-to-Speech (TTS) systems are increasingly expected to produce not only intelligible, but also highly expressive and emotionally resonant speech, for applications such as virtual assistants, audiobook narration, and digital avatars&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib2\" title=\"\">2</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Achieving fine-grained emotional control is a key challenge in meeting this demand&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib4\" title=\"\">4</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nTraditional approaches often rely on predefined emotion categories from labeled datasets or extract style embeddings from reference audio snippets&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib5\" title=\"\">5</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. While effective, these methods can be restrictive, limiting users to a fixed set of styles and often failing to capture the subtle nuances of human expression&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib6\" title=\"\">6</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib7\" title=\"\">7</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "set",
                    "not",
                    "emotion"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The CFG inference stability can also be improved by a few-shot fine-tuning with a random dropout condition if the original AR TTS model was not trained in this style.</span>\n</p>\n\n",
                "matched_terms": [
                    "not",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The resulting framework enables fine-grained emotional control while maintaining high audio quality, even in the presence of severe semantic conflict under diverse emotion settings.\n</span>\n</p>\n\n",
                "matched_terms": [
                    "emotion",
                    "resulting"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In CFG inference, the usual practice is to use a fixed CFG scale </span>\n  <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">w</mi>\n      <annotation encoding=\"application/x-tex\">w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in Eq.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S2.E1\" style=\"font-size:90%;\" title=\"In 2.1.1 Standard CFG &#8227; 2.1 Classifier-Free Guidance (CFG) &#8227; 2 Methods &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where it does not explicitly address cases where the prescribed style is semantically inconsistent with the text to be spoken, for which cases, we believe </span>\n  <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">w</mi>\n      <annotation encoding=\"application/x-tex\">w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> should be adjusted accordingly. For instance, in the sample shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, saying </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">&#8220;I am going back home.&#8221;</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in an </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">amazed</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> emotion leads to a perceptually unnatural mismatch, leading to degraded quality if we guide the model to do so strongly.\nTo capture this, we propose measuring the semantic mismatch between the style prompt and the content, and using the resulting mismatch levels [</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">low, medium, high</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">] to adaptively adjust the CFG scale, as shown in the </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Mismatch Level Discriminator</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Specifically, we utilize two models (GPT-o3-Pro and a specifically tuned DeBERTa-V3-Large&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib20\" title=\"\">20</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> model for NLI&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib21\" title=\"\">21</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) to measure the mismatch considering two factors: overall style and emotion.\nUsing LLM, the mismatch levels are directly generated through reasoning. For the NLI model, we map the output distance value in the range of [0, 1] evenly to the three levels.</span>\n</p>\n\n",
                "matched_terms": [
                    "does",
                    "model",
                    "resulting",
                    "not",
                    "emotion"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We integrate our CFG methods using the </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">CosyVoice2</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> LLM-based TTS model, which supports fine-grained stylistic control via structured natural language prompts.\nAs illustrated in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, our implementation performs a parallel forward pass for both the conditional input and an unconditional or alternative random conditional input. The resulting conditional and unconditional logits are then fused using various CFG policies to produce the final guided logits. From these, the next acoustic token is sampled and subsequently fed back into the model, continuing the AR generation process.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "resulting",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We finetune the CosyVoice2 LLM using the </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Train</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> subset we describe in Sec&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S3.SS1\" style=\"font-size:90%;\" title=\"3.1 Dataset &#8227; 3 Experimental Setup &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">3.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> for one epoch, with a 15% random condition dropout strategy applied. The training is performed on one H20-HGX node equipped with 8 H20-96GB GPUs. The total effective batch size is 48, the learning rate is </span>\n  <math alttext=\"10^{-4}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.SSS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <msup>\n        <mn mathsize=\"0.900em\">10</mn>\n        <mrow>\n          <mo mathsize=\"0.900em\">&#8722;</mo>\n          <mn mathsize=\"0.900em\">4</mn>\n        </mrow>\n      </msup>\n      <annotation encoding=\"application/x-tex\">10^{-4}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and a linear learning rate scheduler is used. The AdamW optimizer is employed.</span>\n</p>\n\n",
                "matched_terms": [
                    "train",
                    "subset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We use a powerful pre-trained Speech Emotion Recognition (SER) model to quantitatively measure how accurately the synthesized speech conveys the target emotion. Specifically, we employ </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">emo2vec-plus-large</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which supports seven emotions: neutral, sad, happy, surprised, angry, disgusted, and fearful, to classify the emotions of the generated audio samples. We report the overall Emotion Recognition Accuracy (ER </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">ACC.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) to evaluate the general emotional expressiveness performance.</span>\n</p>\n\n",
                "matched_terms": [
                    "seven",
                    "recognition",
                    "emotions",
                    "model",
                    "emotion"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To measure the clarity and correctness of the synthesized speech, we calculate the Word Error Rate (</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">WER</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) using a state-of-the-art Automatic Speech Recognition model, </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Whisper-Large-V3-Turbo</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib25\" title=\"\">25</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, to transcribe the generated audio. A lower WER indicates higher intelligibility, demonstrating that the guidance does not introduce significant articulation artifacts or slurring.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "not",
                    "recognition",
                    "does"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3.3.3 Intelligibility &#8227; 3.3 Evaluation Methods &#8227; 3 Experimental Setup &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> compares the baseline model with several CFG strategies on the Zero-shot CosyVoice2 model. The baseline model without guidance achieves 73.6% ER ACC and a WER of 4.3%. Applying Standard CFG with a guidance scale of 2.0 yields the best improvement, raising ER ACC to 81.7%, but at the cost of intelligibility, with WER increasing to 5.9%. Larger scales further degrade intelligibility (up to 8.2% WER) without additional gains in ER ACC. An alternative Standard CFG variant that drops the target instead of the prompt performs consistently worse than the baseline in ER ACC while still increasing WER.\nThe CFG-Filter method provides a more balanced trade-off. At a scale of 2.0, it not only improves ER ACC over the baseline but also achieves a lower WER, showing greater robustness to scaling.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3.3.3 Intelligibility &#8227; 3.3 Evaluation Methods &#8227; 3 Experimental Setup &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, our proposed SMG-CFG achieves the most favorable results. Here, we adapt the guidance scale dynamically, adjusting it according to the mismatch level, and assign CFG scales of 3.0, 2.5, and 2.0 to the [</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">low, medium, high</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">] levels, respectively. When applied to Standard CFG, it slightly improves ER ACC (81.9% vs. 81.7%) with a moderate WER of 6.2%. More importantly, when combined with CFG-Filter, it delivers a 2% absolute gain in ER ACC over CFG-Filter alone, while maintaining the same low WER.\nThese results demonstrate that SMG-CFG substantially enhances emotional expressiveness without compromising intelligibility, producing synthesized audio with both diverse and natural emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "emotions",
                    "our"
                ]
            }
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Zero-shot CosyVoice2 with CFG-Filter inference. The filter Top-K is set to 50. ww is the CFG guidance scale. Uncondition stands for the dropout condition or random condition we proposed in Sec 2.1.3. wfw_{f} is the CFG guidance scale after the CFG-Filter, where wf=1.0w_{f}=1.0 means that no further guidance is applied.",
        "body": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.m7\" intent=\":literal\"><semantics><mi mathsize=\"0.900em\">w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><math alttext=\"w_{f}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.m8\" intent=\":literal\"><semantics><msub><mi mathsize=\"0.900em\">w</mi><mi mathsize=\"0.900em\">f</mi></msub><annotation encoding=\"application/x-tex\">w_{f}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Uncondition</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">ACC</span><span class=\"ltx_text\" style=\"font-size:90%;\"> </span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.m9\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">MOS</span><span class=\"ltx_text\" style=\"font-size:90%;\"> </span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.m10\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">WER</span><span class=\"ltx_text\" style=\"font-size:90%;\"> </span><math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.m11\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"6\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"3\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Drop Style</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">74.86%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.68</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.16%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.5</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">76.43%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.65</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.41%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.0</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">76.86%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.75</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.52%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"3\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Random Style</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">74.43%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.68</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.07%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.5</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">76.71%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.71</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.22%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.0</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.29%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.69</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.53%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"6\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"3\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Drop Style</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">75.86%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.60</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.18%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.5</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.43%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.62</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.94%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.0</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">76.00%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.61</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.15%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"3\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Random Style</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.71%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.66</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.28%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.5</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.57%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.63</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.00%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.0</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.00%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.66</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.64%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"4\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Drop Style</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.57%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.53</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.61%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.0</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.86%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.54</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.76%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Random Style</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">80.57%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.60</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.08%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.0</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">79.86%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.60</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.15%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt\" colspan=\"3\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">SMG CFG-Filter + Re-CFG</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">79.86%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.55</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.92%</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "wer",
            "cfgfilter",
            "style",
            "cfg",
            "drop",
            "inference",
            "uncondition",
            "↓downarrow",
            "wfwf",
            "applied",
            "mos",
            "smg",
            "zeroshot",
            "recfg",
            "after",
            "stands",
            "guidance",
            "filter",
            "condition",
            "scale",
            "cosyvoice2",
            "further",
            "topk",
            "where",
            "set",
            "random",
            "↑uparrow",
            "proposed",
            "means",
            "wf10wf10",
            "acc",
            "sec",
            "dropout"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 4.1 Zero-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> presents the results of the CFG-Filter. We first observe that simply re-applying the CFG (denoted as Re-CFG) after the CFG-Filter yields trends similar to the Standard CFG: ER ACC continues to improve as the Re-CFG scale increases, but at the cost of intelligibility and naturalness. For example, with a CFG-Filter scale of 2.5, increasing the Re-CFG scale from 1.0 to 2.0 raises ER ACC from 76.4% to 78.6%, but also increases WER from 4.4% to 5.6%, while UTMOS drops from 3.65 to 3.53.\nThen, replacing the dropped style prompt with a random style produces consistently better results. When using a large Re-CFG scale of 2.0, the random style setting achieves 80.6% ER ACC while maintaining a WER of 5.1% and UTMOS at 3.60. Across other scales, random style generally provides higher ER ACC with comparable or even lower WER and stable UTMOS.\nFinally, adding our SMG-CFG on top of CFG-Filter and Re-CFG also yields gains, where it improves ER ACC by 1.6% relatively; however, the WER increases 5.5% relatively.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">While Text-to-Speech (TTS) systems can achieve fine-grained control over emotional expression via natural language prompts, a significant challenge emerges when the desired emotion (style prompt) conflicts with the semantic content of the text. This mismatch often results in unnatural-sounding speech, undermining the goal of achieving fine-grained emotional control. Classifier-Free Guidance (CFG) is a key technique for enhancing prompt alignment; however, its application to auto-regressive (AR) TTS models remains underexplored, which can lead to degraded audio quality. This paper directly addresses the challenge of style-content mismatch in AR TTS models by proposing an adaptive CFG scheme that adjusts to different levels of the detected mismatch, as measured using large language models or natural language inference models.\nThis solution is based on a comprehensive analysis of CFG&#8217;s impact on emotional expressiveness in state-of-the-art AR TTS models.\nOur results demonstrate that the proposed adaptive CFG scheme improves the emotional expressiveness of the AR TTS model while maintaining audio quality and intelligibility.</span>\n</p>\n\n",
                "matched_terms": [
                    "proposed",
                    "style",
                    "cfg",
                    "inference",
                    "guidance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Modern Text-to-Speech (TTS) systems are increasingly expected to produce not only intelligible, but also highly expressive and emotionally resonant speech, for applications such as virtual assistants, audiobook narration, and digital avatars&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib2\" title=\"\">2</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Achieving fine-grained emotional control is a key challenge in meeting this demand&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib4\" title=\"\">4</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nTraditional approaches often rely on predefined emotion categories from labeled datasets or extract style embeddings from reference audio snippets&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib5\" title=\"\">5</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. While effective, these methods can be restrictive, limiting users to a fixed set of styles and often failing to capture the subtle nuances of human expression&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib6\" title=\"\">6</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib7\" title=\"\">7</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "set",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To better align generated speech with such detailed prompts, classifier-free guidance (CFG) has become a standard technique&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib15\" title=\"\">15</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and is widely adopted in generating audio in diffusion and flow-matching-based models&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib16\" title=\"\">16</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib17\" title=\"\">17</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. However, its behavior in auto-regressive (AR) TTS remains underexplored&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib18\" title=\"\">18</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">: naively applying CFG can degrade audio quality (e.g., unnatural pacing)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and a central challenge persists when emotional style prompts conflict with textual semantics (e.g., saying &#8220;I am so happy&#8221; in a </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">sad</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> tone).</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "guidance",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This work addresses these challenges with an adaptive CFG scheme for AR TTS that modulates guidance strength based on a detected semantic mismatch between the style requirement and the target content. Specifically, our contributions lie in the following:</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "guidance",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Grounded in a detailed analysis of CFG behavior in state-of-the-art AR TTS systems (e.g., CosyVoice2&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib11\" title=\"\">11</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">), we demonstrate that a random condition, rather than a dropout condition, improves CFG performance.</span>\n</p>\n\n",
                "matched_terms": [
                    "random",
                    "condition",
                    "cfg",
                    "cosyvoice2",
                    "dropout"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The CFG inference stability can also be improved by a few-shot fine-tuning with a random dropout condition if the original AR TTS model was not trained in this style.</span>\n</p>\n\n",
                "matched_terms": [
                    "random",
                    "condition",
                    "style",
                    "cfg",
                    "inference",
                    "dropout"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We demonstrate that the effectiveness of CFG is correlated with the semantic mismatch between the style and the synthesis content, which can be measured by LLMs or Natural Language Inference (NLI) models. We propose adjusting the CFG scale based on the extent of mismatch to improve the robustness and naturalness of the synthesized speech.</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "scale",
                    "inference",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Let </span>\n  <math alttext=\"L(c)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\">c</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(c)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> be the logits predicted by the model given a condition </span>\n  <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">c</mi>\n      <annotation encoding=\"application/x-tex\">c</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (e.g., target content with style prompt), and let </span>\n  <math alttext=\"L(\\emptyset)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#8709;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(\\emptyset)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> be the logits from an unconditional prediction (e.g., target content only). The CFG-guided logits, </span>\n  <math alttext=\"L_{Guide}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m4\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">G</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">u</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">d</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">e</mi>\n        </mrow>\n      </msub>\n      <annotation encoding=\"application/x-tex\">L_{Guide}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, are calculated as:</span>\n</p>\n\n",
                "matched_terms": [
                    "condition",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">where </span>\n  <math alttext=\"L_{Guide}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m5\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">G</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">u</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">d</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">e</mi>\n        </mrow>\n      </msub>\n      <annotation encoding=\"application/x-tex\">L_{Guide}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the final, guidance-adjusted logits used for sampling in each step of AR decoding.\n</span>\n  <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m6\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">w</mi>\n      <annotation encoding=\"application/x-tex\">w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the guidance scale, showing the strength to emphasize the condition while alienating the unconditional model output. A value of </span>\n  <math alttext=\"w=0\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m7\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">w</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">0</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=0</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> results in unconditional generation, </span>\n  <math alttext=\"w=1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m8\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">w</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">1</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=1</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> results in conditional generation, while </span>\n  <math alttext=\"w&gt;1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m9\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">w</mi>\n        <mo mathsize=\"0.900em\">&gt;</mo>\n        <mn mathsize=\"0.900em\">1</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w&gt;1</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> amplifies the effect of the condition.</span>\n</p>\n\n",
                "matched_terms": [
                    "scale",
                    "condition",
                    "where",
                    "guidance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The CFG-Filter method&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> uses the CFG-adjusted logits to select a candidate set of tokens, but applies this selection to the original conditional logits.\nThis avoids certain artifacts, such as unexpected speed wrap and quality degradation, while still benefiting from the guidance.\nThe process involves two steps:</span>\n</p>\n\n",
                "matched_terms": [
                    "set",
                    "cfgfilter",
                    "guidance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">After this filtering process, we can still apply a standard CFG on top of </span>\n  <math alttext=\"L_{Filter}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">F</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">l</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">e</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">r</mi>\n        </mrow>\n      </msub>\n      <annotation encoding=\"application/x-tex\">L_{Filter}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with a smaller scale </span>\n  <math alttext=\"w_{f}&lt;w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <msub>\n          <mi mathsize=\"0.900em\">w</mi>\n          <mi mathsize=\"0.900em\">f</mi>\n        </msub>\n        <mo mathsize=\"0.900em\">&lt;</mo>\n        <mi mathsize=\"0.900em\">w</mi>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w_{f}&lt;w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">:</span>\n</p>\n\n",
                "matched_terms": [
                    "scale",
                    "cfg",
                    "after"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We also propose that in CFG, the guidance can be made more targeted by replacing the unconditional logits </span>\n  <math alttext=\"L(\\emptyset)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#8709;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(\\emptyset)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with logits derived from a specific random condition. Instead of steering the generation away from a generic, prompt-free output, this method steers it away from an undesirable or irrelevant one. As the sample shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, given a style prompt: </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">She talks <span class=\"ltx_text ltx_font_bold\">briskly</span>, her <span class=\"ltx_text ltx_font_bold\">amazed</span> tone pitched <span class=\"ltx_text ltx_font_bold\">high</span>.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, instead of using an empty style prompt for the unconditional counterpart, we randomly replace the emotion tag, and the unconditional input becomes a random conditioned input: </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">She talks briskly, her <span class=\"ltx_text ltx_font_bold\">horrific</span> tone pitched high.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nLet </span>\n  <math alttext=\"L(c_{rand})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">c</mi>\n            <mrow>\n              <mi mathsize=\"0.900em\">r</mi>\n              <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n              <mi mathsize=\"0.900em\">a</mi>\n              <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n              <mi mathsize=\"0.900em\">n</mi>\n              <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n              <mi mathsize=\"0.900em\">d</mi>\n            </mrow>\n          </msub>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(c_{rand})</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> be the logits produced from a random condition that serves as the negative example. Eq.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S2.E1\" style=\"font-size:90%;\" title=\"In 2.1.1 Standard CFG &#8227; 2.1 Classifier-Free Guidance (CFG) &#8227; 2 Methods &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> becomes:</span>\n</p>\n\n",
                "matched_terms": [
                    "random",
                    "condition",
                    "style",
                    "cfg",
                    "guidance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In CFG inference, the usual practice is to use a fixed CFG scale </span>\n  <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">w</mi>\n      <annotation encoding=\"application/x-tex\">w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in Eq.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S2.E1\" style=\"font-size:90%;\" title=\"In 2.1.1 Standard CFG &#8227; 2.1 Classifier-Free Guidance (CFG) &#8227; 2 Methods &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where it does not explicitly address cases where the prescribed style is semantically inconsistent with the text to be spoken, for which cases, we believe </span>\n  <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">w</mi>\n      <annotation encoding=\"application/x-tex\">w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> should be adjusted accordingly. For instance, in the sample shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, saying </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">&#8220;I am going back home.&#8221;</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in an </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">amazed</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> emotion leads to a perceptually unnatural mismatch, leading to degraded quality if we guide the model to do so strongly.\nTo capture this, we propose measuring the semantic mismatch between the style prompt and the content, and using the resulting mismatch levels [</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">low, medium, high</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">] to adaptively adjust the CFG scale, as shown in the </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Mismatch Level Discriminator</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Specifically, we utilize two models (GPT-o3-Pro and a specifically tuned DeBERTa-V3-Large&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib20\" title=\"\">20</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> model for NLI&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib21\" title=\"\">21</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) to measure the mismatch considering two factors: overall style and emotion.\nUsing LLM, the mismatch levels are directly generated through reasoning. For the NLI model, we map the output distance value in the range of [0, 1] evenly to the three levels.</span>\n</p>\n\n",
                "matched_terms": [
                    "scale",
                    "style",
                    "cfg",
                    "inference",
                    "where"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our experiments are conducted using the </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">TextrolSpeech</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> dataset. This is a large-scale open-source corpora, which includes 330 hours of real-recorded speech from over 1,000 speakers, with five different style labels: gender, pitch, speaking speed, volume, and emotion. These labels are constructed into 500 templates of style prompts that describe how the speaker deduces the speech.\nTable&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S2.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 2.2 Semantic Mismatch Guided CFG (SMG-CFG) &#8227; 2 Methods &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> summarizes the subsets we reorganized from the </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">TextrolSpeech</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThe TextrolSpeech covers eight emotions, such as neutral, sad, happy, surprised, angry, disgusted, contempt, and fearful, with over half falling under the neutral category. Our </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Train</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Eval</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> sets are split from the TextrolSpeech-Train set, where we ensure the number of samples for each emotion is balanced in </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Eval</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where we have 100 samples for each emotion, and the rest is in the </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Train</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. &#8221;Contempt&#8221; emotion is removed in the </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Eval</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We discard the TextrolSpeech-Test set since it only includes 5 out of 8 emotions, and most emotions are represented by fewer than 10 samples.</span>\n</p>\n\n",
                "matched_terms": [
                    "set",
                    "where",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We integrate our CFG methods using the </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">CosyVoice2</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> LLM-based TTS model, which supports fine-grained stylistic control via structured natural language prompts.\nAs illustrated in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, our implementation performs a parallel forward pass for both the conditional input and an unconditional or alternative random conditional input. The resulting conditional and unconditional logits are then fused using various CFG policies to produce the final guided logits. From these, the next acoustic token is sampled and subsequently fed back into the model, continuing the AR generation process.</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "random",
                    "cosyvoice2"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We finetune the CosyVoice2 LLM using the </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Train</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> subset we describe in Sec&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S3.SS1\" style=\"font-size:90%;\" title=\"3.1 Dataset &#8227; 3 Experimental Setup &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">3.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> for one epoch, with a 15% random condition dropout strategy applied. The training is performed on one H20-HGX node equipped with 8 H20-96GB GPUs. The total effective batch size is 48, the learning rate is </span>\n  <math alttext=\"10^{-4}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.SSS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <msup>\n        <mn mathsize=\"0.900em\">10</mn>\n        <mrow>\n          <mo mathsize=\"0.900em\">&#8722;</mo>\n          <mn mathsize=\"0.900em\">4</mn>\n        </mrow>\n      </msup>\n      <annotation encoding=\"application/x-tex\">10^{-4}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and a linear learning rate scheduler is used. The AdamW optimizer is employed.</span>\n</p>\n\n",
                "matched_terms": [
                    "random",
                    "condition",
                    "cosyvoice2",
                    "sec",
                    "dropout",
                    "applied"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To measure the clarity and correctness of the synthesized speech, we calculate the Word Error Rate (</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">WER</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) using a state-of-the-art Automatic Speech Recognition model, </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Whisper-Large-V3-Turbo</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib25\" title=\"\">25</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, to transcribe the generated audio. A lower WER indicates higher intelligibility, demonstrating that the guidance does not introduce significant articulation artifacts or slurring.</span>\n</p>\n\n",
                "matched_terms": [
                    "guidance",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3.3.3 Intelligibility &#8227; 3.3 Evaluation Methods &#8227; 3 Experimental Setup &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> compares the baseline model with several CFG strategies on the Zero-shot CosyVoice2 model. The baseline model without guidance achieves 73.6% ER ACC and a WER of 4.3%. Applying Standard CFG with a guidance scale of 2.0 yields the best improvement, raising ER ACC to 81.7%, but at the cost of intelligibility, with WER increasing to 5.9%. Larger scales further degrade intelligibility (up to 8.2% WER) without additional gains in ER ACC. An alternative Standard CFG variant that drops the target instead of the prompt performs consistently worse than the baseline in ER ACC while still increasing WER.\nThe CFG-Filter method provides a more balanced trade-off. At a scale of 2.0, it not only improves ER ACC over the baseline but also achieves a lower WER, showing greater robustness to scaling.</span>\n</p>\n\n",
                "matched_terms": [
                    "zeroshot",
                    "wer",
                    "scale",
                    "cfgfilter",
                    "cfg",
                    "acc",
                    "cosyvoice2",
                    "guidance",
                    "further"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3.3.3 Intelligibility &#8227; 3.3 Evaluation Methods &#8227; 3 Experimental Setup &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, our proposed SMG-CFG achieves the most favorable results. Here, we adapt the guidance scale dynamically, adjusting it according to the mismatch level, and assign CFG scales of 3.0, 2.5, and 2.0 to the [</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">low, medium, high</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">] levels, respectively. When applied to Standard CFG, it slightly improves ER ACC (81.9% vs. 81.7%) with a moderate WER of 6.2%. More importantly, when combined with CFG-Filter, it delivers a 2% absolute gain in ER ACC over CFG-Filter alone, while maintaining the same low WER.\nThese results demonstrate that SMG-CFG substantially enhances emotional expressiveness without compromising intelligibility, producing synthesized audio with both diverse and natural emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "proposed",
                    "wer",
                    "scale",
                    "cfgfilter",
                    "cfg",
                    "acc",
                    "guidance",
                    "applied"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2 Few-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> summarizes the results after few-shot fine-tuning of the CosyVoice2 model. First, few-shot learning alone provides clear benefits: the model without CFG inference achieves a 2% absolute gain in ER ACC compared to the zero-shot counterpart, while maintaining similar UTMOS and WER (Z0 vs. F0).</span>\n</p>\n\n",
                "matched_terms": [
                    "zeroshot",
                    "wer",
                    "after",
                    "cfg",
                    "acc",
                    "cosyvoice2",
                    "inference"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Second, when comparing the same CFG strategies (Z1/2/3 vs. F1/2/3), the fine-tuned model consistently yields better ER ACC and WER than the zero-shot models. Notably, F3 achieves 82% ER ACC with a WER of only 5.5%, representing a 10.8% relative WER improvement over the best ER ACC (81.9%) obtained by the SMG-CFG system in zero-shot settings. This indicates that CFG applied to models trained with dropout leads to more stable generations.\nThen, applying SMG-CFG on F1 results in similar ER ACC and UTMOS to F1, but with an 8.2% relative WER improvement.\nFinally, the F3+SMG-CFG system delivers the most favorable overall performance, achieving 81% ER ACC, 3.54 UTMOS, and 4.61% WER. Compared to Z0, this corresponds to a 7.4% absolute gain in ER ACC with only a 0.33% absolute performance degradation in WER.</span>\n</p>\n\n",
                "matched_terms": [
                    "zeroshot",
                    "wer",
                    "cfg",
                    "acc",
                    "dropout",
                    "applied"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T4\" style=\"font-size:90%;\" title=\"Table 4 &#8227; 4.2 Few-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we present the four configurations used for the SMG-CFG method, along with the results of an ablation study on system M2 in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2 Few-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Here, the configuration of mismatch levels is as follows: low corresponds to </span>\n  <math alttext=\"w=3.0,w_{f}=2.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mrow>\n          <mi mathsize=\"0.900em\">w</mi>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">3.0</mn>\n        </mrow>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">w</mi>\n            <mi mathsize=\"0.900em\">f</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">2.5</mn>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=3.0,w_{f}=2.5</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while medium and high use </span>\n  <math alttext=\"w=2.5,w_{f}=2.0\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p3.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mrow>\n          <mi mathsize=\"0.900em\">w</mi>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">2.5</mn>\n        </mrow>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">w</mi>\n            <mi mathsize=\"0.900em\">f</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">2.0</mn>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=2.5,w_{f}=2.0</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, respectively. The results of ER ACC and WER demonstrate that different configurations for our proposed method achieve similar performance. Specifically, even though different settings yield diverse mismatch level ratios among the dataset, especially for the low mismatch, which have values ranging from 1% to 21%, all show a close ER ACC performance of around 81% with a WER of approximately 4.6%. This shows the robustness and the generalization of the proposed SMG-CFG method.</span>\n</p>\n\n",
                "matched_terms": [
                    "acc",
                    "proposed",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this work, we comprehensively studied classifier-free guidance (CFG) on Auto-regressive TTS models and examined its impact on emotional expressiveness, intelligibility, and naturalness. We proposed replacing the dropout condition with a random style, which yielded more stable improvements across settings. Additionally, we introduced a semantic mismatch discriminator-based CFG scale adjustment mechanism that dynamically decides the guidance strength based on the alignment between style prompts and content. These methods enhanced the performance of the zero-shot TTS system, and when combined with CFG-Filter and few-shot fine-tuning, these strategies further improved emotional expressiveness, preserving intelligibility and audio quality, offering practical advances for controllable expressive speech synthesis.</span>\n</p>\n\n",
                "matched_terms": [
                    "random",
                    "zeroshot",
                    "condition",
                    "proposed",
                    "scale",
                    "cfgfilter",
                    "style",
                    "cfg",
                    "guidance",
                    "further",
                    "dropout"
                ]
            }
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Overall best performance comparison among the diverse experimental settings. Drop Style refers to dropping the style prompt as the unconditional input. Filter stands for CFG-Filter. Re-CFG is re-applying the CFG after the CFG-Filter. SMG-CFG is the proposed CFG adjustment method.",
        "body": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">ID</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">ACC<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T3.m1\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">MOS<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T3.m2\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math></span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">WER<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T3.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math></span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Z0</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Zero-shot</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">73.57%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.69</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.28%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Z1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">+Drop Style</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.71%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.53</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.89%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Z2</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">&#8194;&#8202;&#160;&#160;&#160;&#160;+Filter</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">76.86%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.75</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.52%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Z3</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">&#8194;&#8202;&#160;&#160;&#160;&#160;&#160;&#160;&#160;+Re-CFG</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.29%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.48</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">6.77%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">F0</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Few-shot</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">75.71%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.62</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.31%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">+Drop Style</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">82.29%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.50</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.74%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">F2</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">&#8194;&#8202;&#160;&#160;&#160;&#160;+Filter</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.00%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.62</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.43%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">F3</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">&#8194;&#8202;&#160;&#160;&#160;&#160;&#160;&#160;&#160;+Re-CFG</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">82.00%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.51</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.53%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">M1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">F1 + SMG-CFG</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">82.00%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.52</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">5.27%</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">M2</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">F3 + SMG-CFG</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">81.00%</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.54</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">4.61%</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "wer↓downarrow",
            "reapplying",
            "cfgfilter",
            "style",
            "overall",
            "drop",
            "cfg",
            "settings",
            "fewshot",
            "comparison",
            "experimental",
            "zeroshot",
            "adjustment",
            "recfg",
            "after",
            "stands",
            "unconditional",
            "input",
            "dropping",
            "performance",
            "filter",
            "smgcfg",
            "among",
            "proposed",
            "acc↑uparrow",
            "prompt",
            "model",
            "best",
            "method",
            "mos↑uparrow",
            "refers",
            "diverse"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2 Few-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> summarizes the results after few-shot fine-tuning of the CosyVoice2 model. First, few-shot learning alone provides clear benefits: the model without CFG inference achieves a 2% absolute gain in ER ACC compared to the zero-shot counterpart, while maintaining similar UTMOS and WER (Z0 vs. F0).</span>\n</p>\n\n",
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T4\" style=\"font-size:90%;\" title=\"Table 4 &#8227; 4.2 Few-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we present the four configurations used for the SMG-CFG method, along with the results of an ablation study on system M2 in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2 Few-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Here, the configuration of mismatch levels is as follows: low corresponds to </span>\n  <math alttext=\"w=3.0,w_{f}=2.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mrow>\n          <mi mathsize=\"0.900em\">w</mi>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">3.0</mn>\n        </mrow>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">w</mi>\n            <mi mathsize=\"0.900em\">f</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">2.5</mn>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=3.0,w_{f}=2.5</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while medium and high use </span>\n  <math alttext=\"w=2.5,w_{f}=2.0\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p3.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mrow>\n          <mi mathsize=\"0.900em\">w</mi>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">2.5</mn>\n        </mrow>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">w</mi>\n            <mi mathsize=\"0.900em\">f</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">2.0</mn>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=2.5,w_{f}=2.0</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, respectively. The results of ER ACC and WER demonstrate that different configurations for our proposed method achieve similar performance. Specifically, even though different settings yield diverse mismatch level ratios among the dataset, especially for the low mismatch, which have values ranging from 1% to 21%, all show a close ER ACC performance of around 81% with a WER of approximately 4.6%. This shows the robustness and the generalization of the proposed SMG-CFG method.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">While Text-to-Speech (TTS) systems can achieve fine-grained control over emotional expression via natural language prompts, a significant challenge emerges when the desired emotion (style prompt) conflicts with the semantic content of the text. This mismatch often results in unnatural-sounding speech, undermining the goal of achieving fine-grained emotional control. Classifier-Free Guidance (CFG) is a key technique for enhancing prompt alignment; however, its application to auto-regressive (AR) TTS models remains underexplored, which can lead to degraded audio quality. This paper directly addresses the challenge of style-content mismatch in AR TTS models by proposing an adaptive CFG scheme that adjusts to different levels of the detected mismatch, as measured using large language models or natural language inference models.\nThis solution is based on a comprehensive analysis of CFG&#8217;s impact on emotional expressiveness in state-of-the-art AR TTS models.\nOur results demonstrate that the proposed adaptive CFG scheme improves the emotional expressiveness of the AR TTS model while maintaining audio quality and intelligibility.</span>\n</p>\n\n",
                "matched_terms": [
                    "proposed",
                    "model",
                    "prompt",
                    "style",
                    "cfg"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To better align generated speech with such detailed prompts, classifier-free guidance (CFG) has become a standard technique&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib15\" title=\"\">15</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and is widely adopted in generating audio in diffusion and flow-matching-based models&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib16\" title=\"\">16</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib17\" title=\"\">17</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. However, its behavior in auto-regressive (AR) TTS remains underexplored&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib18\" title=\"\">18</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">: naively applying CFG can degrade audio quality (e.g., unnatural pacing)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and a central challenge persists when emotional style prompts conflict with textual semantics (e.g., saying &#8220;I am so happy&#8221; in a </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">sad</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> tone).</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This work addresses these challenges with an adaptive CFG scheme for AR TTS that modulates guidance strength based on a detected semantic mismatch between the style requirement and the target content. Specifically, our contributions lie in the following:</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Grounded in a detailed analysis of CFG behavior in state-of-the-art AR TTS systems (e.g., CosyVoice2&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib11\" title=\"\">11</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">), we demonstrate that a random condition, rather than a dropout condition, improves CFG performance.</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The CFG inference stability can also be improved by a few-shot fine-tuning with a random dropout condition if the original AR TTS model was not trained in this style.</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "model",
                    "style",
                    "fewshot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We demonstrate that the effectiveness of CFG is correlated with the semantic mismatch between the style and the synthesis content, which can be measured by LLMs or Natural Language Inference (NLI) models. We propose adjusting the CFG scale based on the extent of mismatch to improve the robustness and naturalness of the synthesized speech.</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The resulting framework enables fine-grained emotional control while maintaining high audio quality, even in the presence of severe semantic conflict under diverse emotion settings.\n</span>\n</p>\n\n",
                "matched_terms": [
                    "settings",
                    "diverse"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In the context of an AR model that predicts logits for the next token, CFG modifies the output logits by extrapolating from an unconditional prediction towards a conditional one.</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "model",
                    "unconditional"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Let </span>\n  <math alttext=\"L(c)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\">c</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(c)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> be the logits predicted by the model given a condition </span>\n  <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">c</mi>\n      <annotation encoding=\"application/x-tex\">c</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (e.g., target content with style prompt), and let </span>\n  <math alttext=\"L(\\emptyset)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#8709;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(\\emptyset)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> be the logits from an unconditional prediction (e.g., target content only). The CFG-guided logits, </span>\n  <math alttext=\"L_{Guide}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m4\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">G</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">u</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">d</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">e</mi>\n        </mrow>\n      </msub>\n      <annotation encoding=\"application/x-tex\">L_{Guide}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, are calculated as:</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "prompt",
                    "unconditional",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">where </span>\n  <math alttext=\"L_{Guide}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m5\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">G</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">u</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">d</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">e</mi>\n        </mrow>\n      </msub>\n      <annotation encoding=\"application/x-tex\">L_{Guide}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the final, guidance-adjusted logits used for sampling in each step of AR decoding.\n</span>\n  <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m6\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">w</mi>\n      <annotation encoding=\"application/x-tex\">w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the guidance scale, showing the strength to emphasize the condition while alienating the unconditional model output. A value of </span>\n  <math alttext=\"w=0\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m7\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">w</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">0</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=0</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> results in unconditional generation, </span>\n  <math alttext=\"w=1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m8\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">w</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">1</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=1</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> results in conditional generation, while </span>\n  <math alttext=\"w&gt;1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m9\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">w</mi>\n        <mo mathsize=\"0.900em\">&gt;</mo>\n        <mn mathsize=\"0.900em\">1</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w&gt;1</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> amplifies the effect of the condition.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "unconditional"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The CFG-Filter method&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> uses the CFG-adjusted logits to select a candidate set of tokens, but applies this selection to the original conditional logits.\nThis avoids certain artifacts, such as unexpected speed wrap and quality degradation, while still benefiting from the guidance.\nThe process involves two steps:</span>\n</p>\n\n",
                "matched_terms": [
                    "cfgfilter",
                    "method"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">After this filtering process, we can still apply a standard CFG on top of </span>\n  <math alttext=\"L_{Filter}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">F</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">l</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">e</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">r</mi>\n        </mrow>\n      </msub>\n      <annotation encoding=\"application/x-tex\">L_{Filter}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with a smaller scale </span>\n  <math alttext=\"w_{f}&lt;w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <msub>\n          <mi mathsize=\"0.900em\">w</mi>\n          <mi mathsize=\"0.900em\">f</mi>\n        </msub>\n        <mo mathsize=\"0.900em\">&lt;</mo>\n        <mi mathsize=\"0.900em\">w</mi>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w_{f}&lt;w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">:</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "after"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We also propose that in CFG, the guidance can be made more targeted by replacing the unconditional logits </span>\n  <math alttext=\"L(\\emptyset)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#8709;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(\\emptyset)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with logits derived from a specific random condition. Instead of steering the generation away from a generic, prompt-free output, this method steers it away from an undesirable or irrelevant one. As the sample shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, given a style prompt: </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">She talks <span class=\"ltx_text ltx_font_bold\">briskly</span>, her <span class=\"ltx_text ltx_font_bold\">amazed</span> tone pitched <span class=\"ltx_text ltx_font_bold\">high</span>.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, instead of using an empty style prompt for the unconditional counterpart, we randomly replace the emotion tag, and the unconditional input becomes a random conditioned input: </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">She talks briskly, her <span class=\"ltx_text ltx_font_bold\">horrific</span> tone pitched high.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nLet </span>\n  <math alttext=\"L(c_{rand})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">c</mi>\n            <mrow>\n              <mi mathsize=\"0.900em\">r</mi>\n              <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n              <mi mathsize=\"0.900em\">a</mi>\n              <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n              <mi mathsize=\"0.900em\">n</mi>\n              <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n              <mi mathsize=\"0.900em\">d</mi>\n            </mrow>\n          </msub>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(c_{rand})</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> be the logits produced from a random condition that serves as the negative example. Eq.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S2.E1\" style=\"font-size:90%;\" title=\"In 2.1.1 Standard CFG &#8227; 2.1 Classifier-Free Guidance (CFG) &#8227; 2 Methods &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> becomes:</span>\n</p>\n\n",
                "matched_terms": [
                    "prompt",
                    "style",
                    "cfg",
                    "unconditional",
                    "method",
                    "input"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In CFG inference, the usual practice is to use a fixed CFG scale </span>\n  <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">w</mi>\n      <annotation encoding=\"application/x-tex\">w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in Eq.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S2.E1\" style=\"font-size:90%;\" title=\"In 2.1.1 Standard CFG &#8227; 2.1 Classifier-Free Guidance (CFG) &#8227; 2 Methods &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where it does not explicitly address cases where the prescribed style is semantically inconsistent with the text to be spoken, for which cases, we believe </span>\n  <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">w</mi>\n      <annotation encoding=\"application/x-tex\">w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> should be adjusted accordingly. For instance, in the sample shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, saying </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">&#8220;I am going back home.&#8221;</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in an </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">amazed</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> emotion leads to a perceptually unnatural mismatch, leading to degraded quality if we guide the model to do so strongly.\nTo capture this, we propose measuring the semantic mismatch between the style prompt and the content, and using the resulting mismatch levels [</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">low, medium, high</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">] to adaptively adjust the CFG scale, as shown in the </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Mismatch Level Discriminator</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Specifically, we utilize two models (GPT-o3-Pro and a specifically tuned DeBERTa-V3-Large&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib20\" title=\"\">20</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> model for NLI&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib21\" title=\"\">21</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) to measure the mismatch considering two factors: overall style and emotion.\nUsing LLM, the mismatch levels are directly generated through reasoning. For the NLI model, we map the output distance value in the range of [0, 1] evenly to the three levels.</span>\n</p>\n\n",
                "matched_terms": [
                    "prompt",
                    "model",
                    "style",
                    "overall",
                    "cfg"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We integrate our CFG methods using the </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">CosyVoice2</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> LLM-based TTS model, which supports fine-grained stylistic control via structured natural language prompts.\nAs illustrated in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, our implementation performs a parallel forward pass for both the conditional input and an unconditional or alternative random conditional input. The resulting conditional and unconditional logits are then fused using various CFG policies to produce the final guided logits. From these, the next acoustic token is sampled and subsequently fed back into the model, continuing the AR generation process.</span>\n</p>\n\n",
                "matched_terms": [
                    "cfg",
                    "input",
                    "model",
                    "unconditional"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To thoroughly assess the performance of our proposed methods, we evaluate the synthesized speech from three key perspectives: emotional expressiveness, overall audio quality, and intelligibility.</span>\n</p>\n\n",
                "matched_terms": [
                    "overall",
                    "proposed",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We use a powerful pre-trained Speech Emotion Recognition (SER) model to quantitatively measure how accurately the synthesized speech conveys the target emotion. Specifically, we employ </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">emo2vec-plus-large</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which supports seven emotions: neutral, sad, happy, surprised, angry, disgusted, and fearful, to classify the emotions of the generated audio samples. We report the overall Emotion Recognition Accuracy (ER </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">ACC.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) to evaluate the general emotional expressiveness performance.</span>\n</p>\n\n",
                "matched_terms": [
                    "overall",
                    "model",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3.3.3 Intelligibility &#8227; 3.3 Evaluation Methods &#8227; 3 Experimental Setup &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> compares the baseline model with several CFG strategies on the Zero-shot CosyVoice2 model. The baseline model without guidance achieves 73.6% ER ACC and a WER of 4.3%. Applying Standard CFG with a guidance scale of 2.0 yields the best improvement, raising ER ACC to 81.7%, but at the cost of intelligibility, with WER increasing to 5.9%. Larger scales further degrade intelligibility (up to 8.2% WER) without additional gains in ER ACC. An alternative Standard CFG variant that drops the target instead of the prompt performs consistently worse than the baseline in ER ACC while still increasing WER.\nThe CFG-Filter method provides a more balanced trade-off. At a scale of 2.0, it not only improves ER ACC over the baseline but also achieves a lower WER, showing greater robustness to scaling.</span>\n</p>\n\n",
                "matched_terms": [
                    "zeroshot",
                    "prompt",
                    "cfgfilter",
                    "model",
                    "cfg",
                    "best",
                    "method"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3.3.3 Intelligibility &#8227; 3.3 Evaluation Methods &#8227; 3 Experimental Setup &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, our proposed SMG-CFG achieves the most favorable results. Here, we adapt the guidance scale dynamically, adjusting it according to the mismatch level, and assign CFG scales of 3.0, 2.5, and 2.0 to the [</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">low, medium, high</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">] levels, respectively. When applied to Standard CFG, it slightly improves ER ACC (81.9% vs. 81.7%) with a moderate WER of 6.2%. More importantly, when combined with CFG-Filter, it delivers a 2% absolute gain in ER ACC over CFG-Filter alone, while maintaining the same low WER.\nThese results demonstrate that SMG-CFG substantially enhances emotional expressiveness without compromising intelligibility, producing synthesized audio with both diverse and natural emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "proposed",
                    "smgcfg",
                    "cfgfilter",
                    "cfg",
                    "diverse"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 4.1 Zero-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> presents the results of the CFG-Filter. We first observe that simply re-applying the CFG (denoted as Re-CFG) after the CFG-Filter yields trends similar to the Standard CFG: ER ACC continues to improve as the Re-CFG scale increases, but at the cost of intelligibility and naturalness. For example, with a CFG-Filter scale of 2.5, increasing the Re-CFG scale from 1.0 to 2.0 raises ER ACC from 76.4% to 78.6%, but also increases WER from 4.4% to 5.6%, while UTMOS drops from 3.65 to 3.53.\nThen, replacing the dropped style prompt with a random style produces consistently better results. When using a large Re-CFG scale of 2.0, the random style setting achieves 80.6% ER ACC while maintaining a WER of 5.1% and UTMOS at 3.60. Across other scales, random style generally provides higher ER ACC with comparable or even lower WER and stable UTMOS.\nFinally, adding our SMG-CFG on top of CFG-Filter and Re-CFG also yields gains, where it improves ER ACC by 1.6% relatively; however, the WER increases 5.5% relatively.</span>\n</p>\n\n",
                "matched_terms": [
                    "reapplying",
                    "smgcfg",
                    "recfg",
                    "cfgfilter",
                    "style",
                    "after",
                    "cfg",
                    "prompt"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Second, when comparing the same CFG strategies (Z1/2/3 vs. F1/2/3), the fine-tuned model consistently yields better ER ACC and WER than the zero-shot models. Notably, F3 achieves 82% ER ACC with a WER of only 5.5%, representing a 10.8% relative WER improvement over the best ER ACC (81.9%) obtained by the SMG-CFG system in zero-shot settings. This indicates that CFG applied to models trained with dropout leads to more stable generations.\nThen, applying SMG-CFG on F1 results in similar ER ACC and UTMOS to F1, but with an 8.2% relative WER improvement.\nFinally, the F3+SMG-CFG system delivers the most favorable overall performance, achieving 81% ER ACC, 3.54 UTMOS, and 4.61% WER. Compared to Z0, this corresponds to a 7.4% absolute gain in ER ACC with only a 0.33% absolute performance degradation in WER.</span>\n</p>\n\n",
                "matched_terms": [
                    "zeroshot",
                    "smgcfg",
                    "model",
                    "overall",
                    "cfg",
                    "best",
                    "settings",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this work, we comprehensively studied classifier-free guidance (CFG) on Auto-regressive TTS models and examined its impact on emotional expressiveness, intelligibility, and naturalness. We proposed replacing the dropout condition with a random style, which yielded more stable improvements across settings. Additionally, we introduced a semantic mismatch discriminator-based CFG scale adjustment mechanism that dynamically decides the guidance strength based on the alignment between style prompts and content. These methods enhanced the performance of the zero-shot TTS system, and when combined with CFG-Filter and few-shot fine-tuning, these strategies further improved emotional expressiveness, preserving intelligibility and audio quality, offering practical advances for controllable expressive speech synthesis.</span>\n</p>\n\n",
                "matched_terms": [
                    "zeroshot",
                    "proposed",
                    "adjustment",
                    "cfgfilter",
                    "style",
                    "cfg",
                    "settings",
                    "fewshot",
                    "performance"
                ]
            }
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Ablation study on different configurations for the proposed SMG-CFG method. M-Level Ratio shows the ratio of the number of samples for each Mismatch Level (Low, Medium, and High) measured using the specific model and factor.",
        "body": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Factor</span></td>\n<td class=\"ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt\" colspan=\"3\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">M-Level Ratio</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" rowspan=\"2\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:19.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">ACC</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\" rowspan=\"2\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:16.0pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_center\" style=\"font-size:90%;\">WER</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">&#160;&#160;</span><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">L</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">M</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">H</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">GPT-o3-Pro</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emo</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">21%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">34%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">45%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:19.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.0%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:16.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.6%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Style</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">9%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">48%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">43%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:19.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.0%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:16.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.5%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">DeBERTa-NLI</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emo</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">11%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">48%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">41%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:19.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">80.4%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:16.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.7%</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Style</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">1%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">68%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:12.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">31%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:19.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">80.9%</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b\" style=\"padding-top:-0.9pt;padding-bottom:-0.9pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:16.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.7%</span></span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "debertanli",
            "wer",
            "configurations",
            "style",
            "high",
            "level",
            "each",
            "emo",
            "study",
            "low",
            "ablation",
            "ratio",
            "medium",
            "smgcfg",
            "samples",
            "measured",
            "mlevel",
            "factor",
            "mismatch",
            "number",
            "proposed",
            "model",
            "acc",
            "shows",
            "specific",
            "method",
            "gpto3pro",
            "different"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T4\" style=\"font-size:90%;\" title=\"Table 4 &#8227; 4.2 Few-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we present the four configurations used for the SMG-CFG method, along with the results of an ablation study on system M2 in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2 Few-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Here, the configuration of mismatch levels is as follows: low corresponds to </span>\n  <math alttext=\"w=3.0,w_{f}=2.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mrow>\n          <mi mathsize=\"0.900em\">w</mi>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">3.0</mn>\n        </mrow>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">w</mi>\n            <mi mathsize=\"0.900em\">f</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">2.5</mn>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=3.0,w_{f}=2.5</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while medium and high use </span>\n  <math alttext=\"w=2.5,w_{f}=2.0\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p3.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mrow>\n          <mi mathsize=\"0.900em\">w</mi>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">2.5</mn>\n        </mrow>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">w</mi>\n            <mi mathsize=\"0.900em\">f</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mn mathsize=\"0.900em\">2.0</mn>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=2.5,w_{f}=2.0</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, respectively. The results of ER ACC and WER demonstrate that different configurations for our proposed method achieve similar performance. Specifically, even though different settings yield diverse mismatch level ratios among the dataset, especially for the low mismatch, which have values ranging from 1% to 21%, all show a close ER ACC performance of around 81% with a WER of approximately 4.6%. This shows the robustness and the generalization of the proposed SMG-CFG method.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">While Text-to-Speech (TTS) systems can achieve fine-grained control over emotional expression via natural language prompts, a significant challenge emerges when the desired emotion (style prompt) conflicts with the semantic content of the text. This mismatch often results in unnatural-sounding speech, undermining the goal of achieving fine-grained emotional control. Classifier-Free Guidance (CFG) is a key technique for enhancing prompt alignment; however, its application to auto-regressive (AR) TTS models remains underexplored, which can lead to degraded audio quality. This paper directly addresses the challenge of style-content mismatch in AR TTS models by proposing an adaptive CFG scheme that adjusts to different levels of the detected mismatch, as measured using large language models or natural language inference models.\nThis solution is based on a comprehensive analysis of CFG&#8217;s impact on emotional expressiveness in state-of-the-art AR TTS models.\nOur results demonstrate that the proposed adaptive CFG scheme improves the emotional expressiveness of the AR TTS model while maintaining audio quality and intelligibility.</span>\n</p>\n\n",
                "matched_terms": [
                    "proposed",
                    "model",
                    "style",
                    "measured",
                    "different",
                    "mismatch"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This work addresses these challenges with an adaptive CFG scheme for AR TTS that modulates guidance strength based on a detected semantic mismatch between the style requirement and the target content. Specifically, our contributions lie in the following:</span>\n</p>\n\n",
                "matched_terms": [
                    "mismatch",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The CFG inference stability can also be improved by a few-shot fine-tuning with a random dropout condition if the original AR TTS model was not trained in this style.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We demonstrate that the effectiveness of CFG is correlated with the semantic mismatch between the style and the synthesis content, which can be measured by LLMs or Natural Language Inference (NLI) models. We propose adjusting the CFG scale based on the extent of mismatch to improve the robustness and naturalness of the synthesized speech.</span>\n</p>\n\n",
                "matched_terms": [
                    "mismatch",
                    "style",
                    "measured"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Let </span>\n  <math alttext=\"L(c)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\">c</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(c)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> be the logits predicted by the model given a condition </span>\n  <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">c</mi>\n      <annotation encoding=\"application/x-tex\">c</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (e.g., target content with style prompt), and let </span>\n  <math alttext=\"L(\\emptyset)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#8709;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(\\emptyset)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> be the logits from an unconditional prediction (e.g., target content only). The CFG-guided logits, </span>\n  <math alttext=\"L_{Guide}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m4\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">G</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">u</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">d</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">e</mi>\n        </mrow>\n      </msub>\n      <annotation encoding=\"application/x-tex\">L_{Guide}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, are calculated as:</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">where </span>\n  <math alttext=\"L_{Guide}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m5\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">G</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">u</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">d</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">e</mi>\n        </mrow>\n      </msub>\n      <annotation encoding=\"application/x-tex\">L_{Guide}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the final, guidance-adjusted logits used for sampling in each step of AR decoding.\n</span>\n  <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m6\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">w</mi>\n      <annotation encoding=\"application/x-tex\">w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the guidance scale, showing the strength to emphasize the condition while alienating the unconditional model output. A value of </span>\n  <math alttext=\"w=0\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m7\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">w</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">0</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=0</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> results in unconditional generation, </span>\n  <math alttext=\"w=1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m8\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">w</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">1</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w=1</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> results in conditional generation, while </span>\n  <math alttext=\"w&gt;1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS1.p1.m9\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">w</mi>\n        <mo mathsize=\"0.900em\">&gt;</mo>\n        <mn mathsize=\"0.900em\">1</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">w&gt;1</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> amplifies the effect of the condition.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "each"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We also propose that in CFG, the guidance can be made more targeted by replacing the unconditional logits </span>\n  <math alttext=\"L(\\emptyset)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#8709;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(\\emptyset)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with logits derived from a specific random condition. Instead of steering the generation away from a generic, prompt-free output, this method steers it away from an undesirable or irrelevant one. As the sample shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, given a style prompt: </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">She talks <span class=\"ltx_text ltx_font_bold\">briskly</span>, her <span class=\"ltx_text ltx_font_bold\">amazed</span> tone pitched <span class=\"ltx_text ltx_font_bold\">high</span>.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, instead of using an empty style prompt for the unconditional counterpart, we randomly replace the emotion tag, and the unconditional input becomes a random conditioned input: </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">She talks briskly, her <span class=\"ltx_text ltx_font_bold\">horrific</span> tone pitched high.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nLet </span>\n  <math alttext=\"L(c_{rand})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.SSS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">c</mi>\n            <mrow>\n              <mi mathsize=\"0.900em\">r</mi>\n              <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n              <mi mathsize=\"0.900em\">a</mi>\n              <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n              <mi mathsize=\"0.900em\">n</mi>\n              <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n              <mi mathsize=\"0.900em\">d</mi>\n            </mrow>\n          </msub>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(c_{rand})</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> be the logits produced from a random condition that serves as the negative example. Eq.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S2.E1\" style=\"font-size:90%;\" title=\"In 2.1.1 Standard CFG &#8227; 2.1 Classifier-Free Guidance (CFG) &#8227; 2 Methods &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> becomes:</span>\n</p>\n\n",
                "matched_terms": [
                    "high",
                    "method",
                    "specific",
                    "style"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In CFG inference, the usual practice is to use a fixed CFG scale </span>\n  <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">w</mi>\n      <annotation encoding=\"application/x-tex\">w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in Eq.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S2.E1\" style=\"font-size:90%;\" title=\"In 2.1.1 Standard CFG &#8227; 2.1 Classifier-Free Guidance (CFG) &#8227; 2 Methods &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where it does not explicitly address cases where the prescribed style is semantically inconsistent with the text to be spoken, for which cases, we believe </span>\n  <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">w</mi>\n      <annotation encoding=\"application/x-tex\">w</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> should be adjusted accordingly. For instance, in the sample shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, saying </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">&#8220;I am going back home.&#8221;</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in an </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">amazed</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> emotion leads to a perceptually unnatural mismatch, leading to degraded quality if we guide the model to do so strongly.\nTo capture this, we propose measuring the semantic mismatch between the style prompt and the content, and using the resulting mismatch levels [</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">low, medium, high</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">] to adaptively adjust the CFG scale, as shown in the </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Mismatch Level Discriminator</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Specifically, we utilize two models (GPT-o3-Pro and a specifically tuned DeBERTa-V3-Large&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib20\" title=\"\">20</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> model for NLI&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib21\" title=\"\">21</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) to measure the mismatch considering two factors: overall style and emotion.\nUsing LLM, the mismatch levels are directly generated through reasoning. For the NLI model, we map the output distance value in the range of [0, 1] evenly to the three levels.</span>\n</p>\n\n",
                "matched_terms": [
                    "medium",
                    "low",
                    "model",
                    "style",
                    "high",
                    "level",
                    "gpto3pro",
                    "mismatch"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our experiments are conducted using the </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">TextrolSpeech</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> dataset. This is a large-scale open-source corpora, which includes 330 hours of real-recorded speech from over 1,000 speakers, with five different style labels: gender, pitch, speaking speed, volume, and emotion. These labels are constructed into 500 templates of style prompts that describe how the speaker deduces the speech.\nTable&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S2.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 2.2 Semantic Mismatch Guided CFG (SMG-CFG) &#8227; 2 Methods &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> summarizes the subsets we reorganized from the </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">TextrolSpeech</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThe TextrolSpeech covers eight emotions, such as neutral, sad, happy, surprised, angry, disgusted, contempt, and fearful, with over half falling under the neutral category. Our </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Train</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Eval</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> sets are split from the TextrolSpeech-Train set, where we ensure the number of samples for each emotion is balanced in </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Eval</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where we have 100 samples for each emotion, and the rest is in the </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Train</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. &#8221;Contempt&#8221; emotion is removed in the </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Eval</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We discard the TextrolSpeech-Test set since it only includes 5 out of 8 emotions, and most emotions are represented by fewer than 10 samples.</span>\n</p>\n\n",
                "matched_terms": [
                    "samples",
                    "style",
                    "each",
                    "different",
                    "number"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We use a powerful pre-trained Speech Emotion Recognition (SER) model to quantitatively measure how accurately the synthesized speech conveys the target emotion. Specifically, we employ </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">emo2vec-plus-large</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which supports seven emotions: neutral, sad, happy, surprised, angry, disgusted, and fearful, to classify the emotions of the generated audio samples. We report the overall Emotion Recognition Accuracy (ER </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">ACC.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) to evaluate the general emotional expressiveness performance.</span>\n</p>\n\n",
                "matched_terms": [
                    "acc",
                    "samples",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To measure the clarity and correctness of the synthesized speech, we calculate the Word Error Rate (</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">WER</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) using a state-of-the-art Automatic Speech Recognition model, </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Whisper-Large-V3-Turbo</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#bib.bib25\" title=\"\">25</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, to transcribe the generated audio. A lower WER indicates higher intelligibility, demonstrating that the guidance does not introduce significant articulation artifacts or slurring.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3.3.3 Intelligibility &#8227; 3.3 Evaluation Methods &#8227; 3 Experimental Setup &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> compares the baseline model with several CFG strategies on the Zero-shot CosyVoice2 model. The baseline model without guidance achieves 73.6% ER ACC and a WER of 4.3%. Applying Standard CFG with a guidance scale of 2.0 yields the best improvement, raising ER ACC to 81.7%, but at the cost of intelligibility, with WER increasing to 5.9%. Larger scales further degrade intelligibility (up to 8.2% WER) without additional gains in ER ACC. An alternative Standard CFG variant that drops the target instead of the prompt performs consistently worse than the baseline in ER ACC while still increasing WER.\nThe CFG-Filter method provides a more balanced trade-off. At a scale of 2.0, it not only improves ER ACC over the baseline but also achieves a lower WER, showing greater robustness to scaling.</span>\n</p>\n\n",
                "matched_terms": [
                    "acc",
                    "model",
                    "method",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3.3.3 Intelligibility &#8227; 3.3 Evaluation Methods &#8227; 3 Experimental Setup &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, our proposed SMG-CFG achieves the most favorable results. Here, we adapt the guidance scale dynamically, adjusting it according to the mismatch level, and assign CFG scales of 3.0, 2.5, and 2.0 to the [</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">low, medium, high</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">] levels, respectively. When applied to Standard CFG, it slightly improves ER ACC (81.9% vs. 81.7%) with a moderate WER of 6.2%. More importantly, when combined with CFG-Filter, it delivers a 2% absolute gain in ER ACC over CFG-Filter alone, while maintaining the same low WER.\nThese results demonstrate that SMG-CFG substantially enhances emotional expressiveness without compromising intelligibility, producing synthesized audio with both diverse and natural emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "medium",
                    "proposed",
                    "wer",
                    "smgcfg",
                    "low",
                    "high",
                    "acc",
                    "level",
                    "mismatch"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 4.1 Zero-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> presents the results of the CFG-Filter. We first observe that simply re-applying the CFG (denoted as Re-CFG) after the CFG-Filter yields trends similar to the Standard CFG: ER ACC continues to improve as the Re-CFG scale increases, but at the cost of intelligibility and naturalness. For example, with a CFG-Filter scale of 2.5, increasing the Re-CFG scale from 1.0 to 2.0 raises ER ACC from 76.4% to 78.6%, but also increases WER from 4.4% to 5.6%, while UTMOS drops from 3.65 to 3.53.\nThen, replacing the dropped style prompt with a random style produces consistently better results. When using a large Re-CFG scale of 2.0, the random style setting achieves 80.6% ER ACC while maintaining a WER of 5.1% and UTMOS at 3.60. Across other scales, random style generally provides higher ER ACC with comparable or even lower WER and stable UTMOS.\nFinally, adding our SMG-CFG on top of CFG-Filter and Re-CFG also yields gains, where it improves ER ACC by 1.6% relatively; however, the WER increases 5.5% relatively.</span>\n</p>\n\n",
                "matched_terms": [
                    "smgcfg",
                    "acc",
                    "style",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.13293v1#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2 Few-shot inference &#8227; 4 Results and Analysis &#8227; Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> summarizes the results after few-shot fine-tuning of the CosyVoice2 model. First, few-shot learning alone provides clear benefits: the model without CFG inference achieves a 2% absolute gain in ER ACC compared to the zero-shot counterpart, while maintaining similar UTMOS and WER (Z0 vs. F0).</span>\n</p>\n\n",
                "matched_terms": [
                    "acc",
                    "model",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Second, when comparing the same CFG strategies (Z1/2/3 vs. F1/2/3), the fine-tuned model consistently yields better ER ACC and WER than the zero-shot models. Notably, F3 achieves 82% ER ACC with a WER of only 5.5%, representing a 10.8% relative WER improvement over the best ER ACC (81.9%) obtained by the SMG-CFG system in zero-shot settings. This indicates that CFG applied to models trained with dropout leads to more stable generations.\nThen, applying SMG-CFG on F1 results in similar ER ACC and UTMOS to F1, but with an 8.2% relative WER improvement.\nFinally, the F3+SMG-CFG system delivers the most favorable overall performance, achieving 81% ER ACC, 3.54 UTMOS, and 4.61% WER. Compared to Z0, this corresponds to a 7.4% absolute gain in ER ACC with only a 0.33% absolute performance degradation in WER.</span>\n</p>\n\n",
                "matched_terms": [
                    "smgcfg",
                    "acc",
                    "model",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this work, we comprehensively studied classifier-free guidance (CFG) on Auto-regressive TTS models and examined its impact on emotional expressiveness, intelligibility, and naturalness. We proposed replacing the dropout condition with a random style, which yielded more stable improvements across settings. Additionally, we introduced a semantic mismatch discriminator-based CFG scale adjustment mechanism that dynamically decides the guidance strength based on the alignment between style prompts and content. These methods enhanced the performance of the zero-shot TTS system, and when combined with CFG-Filter and few-shot fine-tuning, these strategies further improved emotional expressiveness, preserving intelligibility and audio quality, offering practical advances for controllable expressive speech synthesis.</span>\n</p>\n\n",
                "matched_terms": [
                    "mismatch",
                    "proposed",
                    "style"
                ]
            }
        ]
    }
}