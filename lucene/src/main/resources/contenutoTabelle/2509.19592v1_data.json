{
    "S3.F2.sf7": {
        "source_file": "Frame-Stacked Local Transformers for Efficient Multi-Codebook Speech Generation",
        "caption": "(g) Metrics on LibriTTS. We report 95% CIs. Bold indicates the best mean score; no bolding is applied if CIs overlap.",
        "body": "Eval Set\n\n\n\n\nStack Factor\n\n\nLT Type\nWER(%)↓\\downarrow\n\nSSIM↑\\uparrow\n\nFD↓\\downarrow\n\nUTMOSv2 ↑\\uparrow\n\n\n\n\n\n \n\n\nSeen\n\nSpeakers\n \n\n\n\n\n1\n\n\nnone\n1.1 ±\\pm 0.2\n0.796 ±\\pm 0.002\n0.089 ±\\pm 0.003\n3.54 ±\\pm 0.06\n\n\n\n\n\n\n\n\n\n\n\n\nMaskGIT\n1.4 ±\\pm 0.2\n0.807 ±\\pm 0.002\n0.050 ±\\pm 0.002\n3.67 ±\\pm 0.06\n\n\n\n\n\n\n\n\n\n\n\n\nAR\n1.2 ±\\pm 0.3\n0.810 ±\\pm 0.003\n0.049 ±\\pm 0.002\n3.66 ±\\pm 0.05\n\n\n\n\n\n\n\n\n\n2\n\n\nnone\n1.1 ±\\pm 0.2\n0.754 ±\\pm 0.002\n0.161 ±\\pm 0.003\n3.47 ±\\pm 0.06\n\n\n\n\n\n\n\n\n\n\n\n\nMaskGIT\n1.1 ±\\pm 0.3\n0.790 ±\\pm 0.001\n0.055 ±\\pm 0.001\n3.63 ±\\pm 0.05\n\n\n\n\n\n\n\n\n\n\n\n\nAR\n1.1 ±\\pm 0.4\n\n0.799 ±\\pm 0.002\n0.057 ±\\pm 0.002\n3.70 ±\\pm 0.05\n\n\n\n\n\n\n\n\n\n4\n\n\nnone\n1.4 ±\\pm 0.2\n0.676 ±\\pm 0.003\n0.281 ±\\pm 0.004\n3.27 ±\\pm 0.06\n\n\n\n\n\n\n\n\n\n\n\n\nMaskGIT\n1.1 ±\\pm 0.2\n0.769 ±\\pm 0.002\n0.061 ±\\pm 0.002\n3.45 ±\\pm 0.06\n\n\n\n\n\n\n\n\n\n\n\n\nAR\n1.2 ±\\pm 0.1\n\n0.779 ±\\pm 0.001\n0.060 ±\\pm 0.003\n\n3.68 ±\\pm 0.05\n\n\n\n\n \n\n\nUnseen\n\nSpeakers\n \n\n\n\n\n1\n\n\nnone\n1.2 ±\\pm 0.1\n0.765 ±\\pm 0.001\n0.086 ±\\pm 0.003\n3.57 ±\\pm 0.05\n\n\n\n\n\n\n\n\n\n\n\n\nMaskGIT\n1.5 ±\\pm 0.4\n0.777 ±\\pm 0.005\n0.063 ±\\pm 0.004\n3.68 ±\\pm 0.05\n\n\n\n\n\n\n\n\n\n\n\n\nAR\n1.3 ±\\pm 0.3\n0.784 ±\\pm 0.002\n\n0.054 ±\\pm 0.003\n3.66 ±\\pm 0.05\n\n\n\n\n\n\n\n\n\n2\n\n\nnone\n1.2 ±\\pm 0.1\n0.695 ±\\pm 0.005\n0.144 ±\\pm 0.002\n3.46 ±\\pm 0.06\n\n\n\n\n\n\n\n\n\n\n\n\nMaskGIT\n1.3 ±\\pm 0.3\n0.741 ±\\pm 0.002\n\n0.053 ±\\pm 0.001\n3.63 ±\\pm 0.05\n\n\n\n\n\n\n\n\n\n\n\n\nAR\n1.0 ±\\pm 0.1\n\n0.757 ±\\pm 0.002\n0.056 ±\\pm 0.002\n3.70 ±\\pm 0.05\n\n\n\n\n\n\n\n\n\n4\n\n\nnone\n1.5 ±\\pm 0.5\n0.545 ±\\pm 0.004\n0.312 ±\\pm 0.004\n3.22 ±\\pm 0.06\n\n\n\n\n\n\n\n\n\n\n\n\nMaskGIT\n1.1 ±\\pm 0.1\n0.624 ±\\pm 0.005\n0.071 ±\\pm 0.002\n3.41 ±\\pm 0.06\n\n\n\n\n\n\n\n\n\n\n\n\nAR\n1.1 ±\\pm 0.3\n\n0.642 ±\\pm 0.002\n0.070 ±\\pm 0.004\n\n3.71 ±\\pm 0.05",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">Eval Set</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\">Stack Factor</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">LT Type</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">WER(%)<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m1\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">SSIM<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m2\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">FD<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">UTMOSv2 <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m4\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"><span class=\"ltx_text ltx_align_center\"/> <span class=\"ltx_text ltx_align_center\">\n<span class=\"ltx_tabular ltx_align_middle\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\">Seen</span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\">Speakers</span></span>\n</span></span> <span class=\"ltx_text ltx_align_center\"/></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"><span class=\"ltx_text ltx_align_center\">1</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">none</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">1.1 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m5\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.796 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m6\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.089 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m7\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.003</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">3.54 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m8\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.06</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">MaskGIT</td>\n<td class=\"ltx_td ltx_align_center\">1.4 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m9\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.2</td>\n<td class=\"ltx_td ltx_align_center\">0.807 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m10\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">0.050 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m11\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">3.67 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m12\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.06</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">AR</td>\n<td class=\"ltx_td ltx_align_center\">1.2 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m13\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.3</td>\n<td class=\"ltx_td ltx_align_center\">0.810 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m14\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.003</td>\n<td class=\"ltx_td ltx_align_center\">0.049 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m15\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">3.66 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m16\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.05</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"><span class=\"ltx_text ltx_align_center\">2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">none</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">1.1 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m17\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.754 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m18\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.161 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m19\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.003</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">3.47 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m20\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.06</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">MaskGIT</td>\n<td class=\"ltx_td ltx_align_center\">1.1 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m21\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.3</td>\n<td class=\"ltx_td ltx_align_center\">0.790 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m22\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.001</td>\n<td class=\"ltx_td ltx_align_center\">0.055 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m23\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.001</td>\n<td class=\"ltx_td ltx_align_center\">3.63 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m24\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.05</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">AR</td>\n<td class=\"ltx_td ltx_align_center\">1.1 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m25\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.4</td>\n<td class=\"ltx_td ltx_align_center\">\n<span class=\"ltx_text ltx_font_bold\">0.799</span> <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m26\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">0.057 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m27\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">3.70 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m28\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.05</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"><span class=\"ltx_text ltx_align_center\">4</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">none</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">1.4 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m29\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.2</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.676 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m30\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.003</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.281 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m31\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.004</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">3.27 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m32\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.06</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">MaskGIT</td>\n<td class=\"ltx_td ltx_align_center\">1.1 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m33\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.2</td>\n<td class=\"ltx_td ltx_align_center\">0.769 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m34\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">0.061 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m35\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">3.45 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m36\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.06</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">AR</td>\n<td class=\"ltx_td ltx_align_center\">1.2 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m37\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.1</td>\n<td class=\"ltx_td ltx_align_center\">\n<span class=\"ltx_text ltx_font_bold\">0.779</span> <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m38\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.001</td>\n<td class=\"ltx_td ltx_align_center\">0.060 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m39\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.003</td>\n<td class=\"ltx_td ltx_align_center\">\n<span class=\"ltx_text ltx_font_bold\">3.68</span> <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m40\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.05</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"><span class=\"ltx_text ltx_align_center\"/> <span class=\"ltx_text ltx_align_center\">\n<span class=\"ltx_tabular ltx_align_middle\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\">Unseen</span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\">Speakers</span></span>\n</span></span> <span class=\"ltx_text ltx_align_center\"/></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"><span class=\"ltx_text ltx_align_center\">1</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">none</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">1.2 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m41\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.765 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m42\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.001</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.086 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m43\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.003</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">3.57 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m44\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.05</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">MaskGIT</td>\n<td class=\"ltx_td ltx_align_center\">1.5 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m45\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.4</td>\n<td class=\"ltx_td ltx_align_center\">0.777 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m46\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.005</td>\n<td class=\"ltx_td ltx_align_center\">0.063 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m47\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.004</td>\n<td class=\"ltx_td ltx_align_center\">3.68 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m48\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.05</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">AR</td>\n<td class=\"ltx_td ltx_align_center\">1.3 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m49\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.3</td>\n<td class=\"ltx_td ltx_align_center\">0.784 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m50\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">\n<span class=\"ltx_text ltx_font_bold\">0.054</span> <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m51\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.003</td>\n<td class=\"ltx_td ltx_align_center\">3.66 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m52\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.05</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"><span class=\"ltx_text ltx_align_center\">2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">none</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">1.2 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m53\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.695 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m54\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.005</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.144 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m55\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">3.46 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m56\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.06</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">MaskGIT</td>\n<td class=\"ltx_td ltx_align_center\">1.3 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m57\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.3</td>\n<td class=\"ltx_td ltx_align_center\">0.741 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m58\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">\n<span class=\"ltx_text ltx_font_bold\">0.053</span> <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m59\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.001</td>\n<td class=\"ltx_td ltx_align_center\">3.63 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m60\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.05</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">AR</td>\n<td class=\"ltx_td ltx_align_center\">1.0 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m61\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.1</td>\n<td class=\"ltx_td ltx_align_center\">\n<span class=\"ltx_text ltx_font_bold\">0.757</span> <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m62\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">0.056 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m63\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">3.70 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m64\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.05</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"><span class=\"ltx_text ltx_align_center\">4</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">none</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">1.5 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m65\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.5</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.545 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m66\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.004</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.312 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m67\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.004</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">3.22 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m68\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.06</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">MaskGIT</td>\n<td class=\"ltx_td ltx_align_center\">1.1 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m69\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.1</td>\n<td class=\"ltx_td ltx_align_center\">0.624 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m70\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.005</td>\n<td class=\"ltx_td ltx_align_center\">0.071 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m71\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center\">3.41 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m72\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.06</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:25.6pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">AR</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">1.1 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m73\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">\n<span class=\"ltx_text ltx_font_bold\">0.642</span> <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m74\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.002</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.070 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m75\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.004</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">\n<span class=\"ltx_text ltx_font_bold\">3.71</span> <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S3.F2.sf7.m76\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.05</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "libritts",
            "maskgit",
            "type",
            "ssim↑uparrow",
            "±pm",
            "seen",
            "↑uparrow",
            "bolding",
            "utmosv2",
            "best",
            "stack",
            "none",
            "bold",
            "metrics",
            "indicates",
            "unseen",
            "wer↓downarrow",
            "score",
            "speakers",
            "overlap",
            "eval",
            "applied",
            "cis",
            "fd↓downarrow",
            "report",
            "set",
            "factor",
            "mean"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19592v1#S3.F2.sf7\" title=\"In Figure 2 &#8227; 3 Experiments &#8227; Frame-Stacked Local Transformers for Efficient Multi-Codebook Speech Generation\"><span class=\"ltx_text ltx_ref_tag\">2(g)</span></a> provides a full set of evaluation metrics on LibriTTS.\nIn all reported results, <em class=\"ltx_emph ltx_font_italic\">baseline</em> denotes the non-stacked model (1x-stacked) with no LT, parallel-sampled across all codebooks of a single frame. Speeds are reported in Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19592v1#S3.F2.sf6\" title=\"In Figure 2 &#8227; 3 Experiments &#8227; Frame-Stacked Local Transformers for Efficient Multi-Codebook Speech Generation\"><span class=\"ltx_text ltx_ref_tag\">2(f)</span></a>. We next review these results.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">The hierarchical setup of the primary decoder and LT gives us an opportunity to offload work to the LT and let the primary decoder operate at a lower frame rate, further improving efficiency. We call this <em class=\"ltx_emph ltx_font_italic\">frame stacking</em>. Concretely, the primary decoder is trained to predict <math alttext=\"S\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS4.p1.m1\" intent=\":literal\"><semantics><mi>S</mi><annotation encoding=\"application/x-tex\">S</annotation></semantics></math> frames, i.e. <math alttext=\"S\\times N\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS4.p1.m2\" intent=\":literal\"><semantics><mrow><mi>S</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">S\\times N</annotation></semantics></math> codebooks, in one step. We pass the hidden state from the primary decoder into the LT. The LT then predicts all <math alttext=\"S\\times N\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS4.p1.m3\" intent=\":literal\"><semantics><mrow><mi>S</mi><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">S\\times N</annotation></semantics></math> codebooks. We study both variants of the LT combined with frame-stacking. We use separate embedding tables for codebooks at different frame indices within the frame stack to disambiguate between them; these embeddings are shared between the primary decoder and the LT. At the input to the primary decoder they are averaged across both the frame stack and codebooks. The frame-stacking setup is faster than the baseline for two reasons. First, the LT is much <em class=\"ltx_emph ltx_font_italic\">smaller</em> than the primary decoder. Second, <em class=\"ltx_emph ltx_font_italic\">it operates on a short sequence</em> of up to &#160;<math alttext=\"N+1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS4.p1.m4\" intent=\":literal\"><semantics><mrow><mi>N</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">N+1</annotation></semantics></math> elements, compared to the primary decoder which must self-attend to the entire generation history and also cross-attend to the text encoder. These speed benefits increase with the stacking factor <math alttext=\"S\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS4.p1.m5\" intent=\":literal\"><semantics><mi>S</mi><annotation encoding=\"application/x-tex\">S</annotation></semantics></math>, as explored in section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19592v1#S3\" title=\"3 Experiments &#8227; Frame-Stacked Local Transformers for Efficient Multi-Codebook Speech Generation\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>.</p>\n\n",
                "matched_terms": [
                    "factor",
                    "stack"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate the model on the same seen and unseen-speaker subsets of LibriTTS <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19592v1#bib.bib17\" title=\"\">17</a>]</cite> as <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19592v1#bib.bib3\" title=\"\">3</a>]</cite>, containing 180 utterances each. To assess text adherence, we report the Word Error Rate (<span class=\"ltx_text ltx_font_bold\">WER</span>) computed with the Parakeet-TDT-1.1b ASR model <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19592v1#bib.bib18\" title=\"\">18</a>]</cite>. For <em class=\"ltx_emph ltx_font_italic\">Speaker Similarity</em> (<span class=\"ltx_text ltx_font_bold\">SSIM</span>) , we extract speaker embeddings using TitaNet-Large <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19592v1#bib.bib19\" title=\"\">19</a>]</cite> and compute the cosine similarity between the generated and reference (context) audio. Following <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19592v1#bib.bib20\" title=\"\">20</a>]</cite> and others, we compute a Fr&#233;chet Distance (<span class=\"ltx_text ltx_font_bold\">FD</span>) in the codec&#8217;s 32-dimensional embedding space. We use model-generated frames as the generated distribution and the ground truth LibriTTS codec frames of the same utterances as the real distribution. This metric measures how closely the distribution of generated and real codec frames match, capturing both fidelity and diversity. If a sampling method yields implausible codebook token combinations, this metric should detect it. We report speech quality using <span class=\"ltx_text ltx_font_bold\">UTMOSv2</span> <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19592v1#bib.bib21\" title=\"\">21</a>]</cite>, a state-of-the-art neural estimator of naturalness mean opinion scores (MOS). Inference speed (i.e., throughput) is reported relative to the baseline&#8217;s speed.<span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>To ensure our quality comparisons were fair, the baseline model was designed with 16 decoder layers to match the total layer count (12+4) of the LT models. While this establishes an equitable footing for quality metrics, it slightly inflates speedup figures. A baseline with only 12 layers would be roughly 14% faster, which would proportionally lower the speedup figures we report. Nevertheless, the fundamental conclusion that frame-stacked models offer significant throughput gains remains valid.</span></span></span></p>\n\n",
                "matched_terms": [
                    "libritts",
                    "mean",
                    "report",
                    "seen",
                    "metrics",
                    "utmosv2"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19592v1#S3.F2.sf5\" title=\"In Figure 2 &#8227; 3 Experiments &#8227; Frame-Stacked Local Transformers for Efficient Multi-Codebook Speech Generation\"><span class=\"ltx_text ltx_ref_tag\">2(e)</span></a> shows the FDs for unseen speakers (trends for seen speakers are similar). At each stacking factor, the LT-based models have a lower (better) FD than the no-LT (parallel-sampled) model. In fact, remarkably, all LT-based models, at all stacking factors, have a lower FD than all parallel models, even the unstacked one. This result supports the hypothesis that iterative sampling generates a distribution that is closer to the ground truth than parallel sampling.</p>\n\n",
                "matched_terms": [
                    "speakers",
                    "factor",
                    "seen",
                    "unseen"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">At a frame stacking factor of 1</span>, SSIMs and MOS estimates for both LT-based models outperform baseline for both seen and unseen speakers. WERs are slightly higher for LT models compared to baseline, but the difference is not statistically significant. Speeds are similar across the three models. Overall, the LT-based models are a better choice at this stacking factor, producing better SSIM, MOS and FD at similar speed.\n<span class=\"ltx_text ltx_font_bold\">At a frame stacking factor of 2</span>, we start observing major speed benefits from frame stacking. The AR LT is <span class=\"ltx_text ltx_font_bold\">2.1x</span> faster and the MaskGIT LT <span class=\"ltx_text ltx_font_bold\">3.1x</span> faster than the unstacked parallel baseline. SSIMs are similar to baseline for seen speakers and nearly as good for unseen speakers. MOS scores are better or within CI of baseline. If we try to <em class=\"ltx_emph ltx_font_italic\">parallel</em>-sample from a 2x-stacked model, the sampling starts to degrade substantially, with FDs in particular worsening by 67% for unseen speakers and MOS decreasing. This is not surprising as parallel sampling two frames, rather than one, can only exacerbate the issues with parallel sampling discussed earlier. Overall, even at a stacking factor of 2, the LT-based models are a better choice than the baseline. <span class=\"ltx_text ltx_font_bold\">At a frame stacking factor of 4,</span> there are large speedups of 2.9x (LT) and 5.5x (MaskGIT) vs baseline but with some cost in quality and robustness: SSIMs drop a little for seen speakers but substantially for unseen speakers. WER confidence intervals remain overlapping with baseline. FDs remain better than baseline. MOS for the AR LT remains similar to baseline but for MaskGit there is a significant drop. We attribute this drop to our use of only 3 sampling steps&#8212;a constraint likely too severe for sampling <math alttext=\"8\\times 4=32\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mn>8</mn><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><mn>4</mn></mrow><mo>=</mo><mn>32</mn></mrow><annotation encoding=\"application/x-tex\">8\\times 4=32</annotation></semantics></math> tokens&#8212;and expect that relaxing it could mitigate the degradation. Parallel sampling breaks at this stacking factor, with large large degradations in both FD and SSIM. Based on these results, <span class=\"ltx_text ltx_font_bold\">we propose the following practical guidelines:</span></p>\n\n",
                "matched_terms": [
                    "maskgit",
                    "speakers",
                    "seen",
                    "factor",
                    "unseen"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">A good balance between quality and complexity can be achieved by using frame stacking factor of 2 with an autoregressive LT. This works as well as baseline but is 2.1x faster. MaskGIT also achieves good performance at a 3.1x speedup.</p>\n\n",
                "matched_terms": [
                    "maskgit",
                    "factor"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">When aggressively seeking speedup, and not needing zero-shot functionality, use a high stacking factor (e.g. 4) with a LT (either AR or MaskGIT).</p>\n\n",
                "matched_terms": [
                    "maskgit",
                    "factor"
                ]
            }
        ]
    }
}