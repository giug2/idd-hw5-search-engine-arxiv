{
    "S3.T1": {
        "source_file": "Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation",
        "caption": "Table 1: Text2Mel results on Seed-TTS test-en and test-zh. Bold indicates the best result, underlined the second-best. All methods are based on F5-TTS. IMF stands for IntMeanFlow. Medium models have 592M parameters, base models 336M, and small models 158M.",
        "body": "#\nModel (NFE)\nData (hrs)\nTeacher (NFE)\nWER(%)↓\nSIM-o↑\nUTMOS↑\nUV.MOS↑\nCMOS↑\nSMOS↑\nRTF↓\n\n\nSeed-TTS test-en\n\n\n\n1\nHuman\nN/A\nN/A\n2.14\n0.73\n3.52\n3.86\n0.00\n3.96\nN/A\n\n\n2\nMedium (32)\nEmilia (95K)\nN/A\n1.72\n0.70\n3.63\n4.03\n-0.23\n3.92\n0.284\n\n\n3\nBase (32)\nEmilia (95K)\nN/A\n1.87\n0.67\n3.70\n4.06\n-0.48\n3.88\n0.243\n\n\n4\nSmall (32)\nLibriTTS (585)\nN/A\n2.29\n0.58\n3.97\n4.16\n-0.46\n3.23\n0.171\n\n\n5\nBase + IMF (1)\nEmilia (95K)\nBase (16)\n7.27\n0.48\n1.84\n2.33\n-\n-\n0.009\n\n\n6\nBase + IMF (2)\nEmilia (95K)\nBase (16)\n4.48\n0.59\n3.35\n3.65\n-1.11\n3.44\n0.013\n\n\n7\nBase + IMF + O3S (2)\nEmilia (95K)\nBase (16)\n2.04\n0.63\n3.24\n3.58\n-0.86\n3.52\n0.013\n\n\n8\nBase + IMF + O3S (3)\nEmilia (95K)\nBase (16)\n1.60\n0.65\n3.79\n3.94\n-0.61\n3.73\n0.021\n\n\n9\nBase + IMF + O3S (3)\nEmilia (95K)\nBase (4)\n1.71\n0.64\n3.76\n3.89\n-0.62\n3.57\n0.021\n\n\n10\nBase + IMF + O3S (3)\nEmilia (95K)\nBase (2)\n1.83\n0.64\n3.58\n3.87\n-1.00\n3.62\n0.021\n\n\n11\nSmall + IMF + O3S (3)\nLibriTTS (585)\nBase (16)\n1.97\n0.63\n3.63\n3.89\n-0.51\n3.46\n0.018\n\n\n12\nSmall + IMF + O3S (3)\nLibriTTS (585)\nMedium (16)\n1.83\n0.63\n3.73\n3.98\n-0.72\n3.65\n0.018\n\n\nSeed-TTS test-zh\n\n\n\n13\nHuman\nN/A\nN/A\n1.25\n0.76\n2.78\n4.50\n0.00\n3.94\nN/A\n\n\n14\nBase (32)\nEmilia (95K)\nN/A\n1.52\n0.76\n2.96\n4.56\n+0.13\n3.87\n0.243\n\n\n15\nBase + IMF (1)\nEmilia (95K)\nBase (16)\n8.75\n0.55\n1.42\n2.79\n-\n-\n0.009\n\n\n16\nBase + IMF (2)\nEmilia (95K)\nBase (16)\n5.97\n0.69\n2.09\n3.72\n-0.26\n3.33\n0.013\n\n\n17\nBase + IMF + O3S (2)\nEmilia (95K)\nBase (16)\n1.73\n0.72\n2.47\n4.18\n0.00\n3.65\n0.013\n\n\n18\nBase + IMF + O3S (3)\nEmilia (95K)\nBase (16)\n1.67\n0.74\n3.03\n4.48\n+0.07\n3.83\n0.021\n\n\n19\nBase + IMF + O3S (3)\nEmilia (95K)\nBase (4)\n1.74\n0.73\n2.97\n4.45\n-0.20\n3.68\n0.021\n\n\n20\nBase + IMF + O3S (3)\nEmilia (95K)\nBase (2)\n1.67\n0.74\n2.84\n4.41\n-0.29\n3.78\n0.021",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">#</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Model (NFE)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Data (hrs)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Teacher (NFE)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">WER(%)&#8595;</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SIM-o&#8593;</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">UTMOS&#8593;</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">UV.MOS&#8593;</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">CMOS&#8593;</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SMOS&#8593;</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">RTF&#8595;</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"10\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Seed-TTS <span class=\"ltx_text ltx_font_italic\">test-en</span></span></td>\n<td class=\"ltx_td ltx_border_t\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Human</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.14</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.73</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.52</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.86</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.96</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">2</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Medium (32)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.72</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.70</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.63</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.03</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.23</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.92</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.284</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">3</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (32)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.87</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.67</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.70</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.06</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.48</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.88</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.243</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">4</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Small (32)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">LibriTTS (585)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.29</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.58</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.97</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.16</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.46</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.23</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.171</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">5</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF (1)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (16)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">7.27</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.48</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.84</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.33</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.009</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">6</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF (2)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (16)</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.48</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.59</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.35</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.65</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-1.11</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.44</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.013</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">7</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF + O3S (2)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (16)</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.04</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.63</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.24</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.58</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.86</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.52</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.013</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">8</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF + O3S (3)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (16)</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">1.60</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.65</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.79</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">3.94</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">-0.61</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.73</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.021</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">9</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF + O3S (3)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (4)</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">1.71</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">0.64</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">3.76</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.89</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.62</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.57</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.021</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">10</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF + O3S (3)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (2)</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.83</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">0.64</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.58</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.87</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-1.00</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.62</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.021</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">11</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Small + IMF + O3S (3)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">LibriTTS (585)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (16)</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.97</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.63</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.63</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.89</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">-0.51</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.46</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.018</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">12</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Small + IMF + O3S (3)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">LibriTTS (585)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Medium (16)</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.83</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.63</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.73</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.98</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.72</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">3.65</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.018</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"10\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Seed-TTS <span class=\"ltx_text ltx_font_italic\">test-zh</span></span></td>\n<td class=\"ltx_td ltx_border_t\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">13</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Human</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.25</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.76</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.78</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.50</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.94</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">14</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (32)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.52</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.76</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.96</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.56</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">+0.13</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.87</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.243</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">15</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF (1)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (16)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">8.75</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.55</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.42</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.79</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.009</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">16</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF (2)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (16)</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.97</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.69</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.09</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.72</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.26</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.33</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.013</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">17</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF + O3S (2)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (16)</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.73</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.72</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.47</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.18</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.65</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.013</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">18</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF + O3S (3)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (16)</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">1.67</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.74</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.03</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">4.48</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">+0.07</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.83</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.021</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">19</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF + O3S (3)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (4)</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.74</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.73</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">2.97</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">4.45</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.20</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.68</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.021</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">20</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base + IMF + O3S (3)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">Emilia (95K)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base (2)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">1.67</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.74</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.84</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.41</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.29</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">3.78</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.021</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "intmeanflow",
            "592m",
            "medium",
            "seedtts",
            "utmos↑",
            "f5tts",
            "testzh",
            "nfe",
            "imf",
            "cmos↑",
            "all",
            "rtf↓",
            "uvmos↑",
            "base",
            "methods",
            "human",
            "results",
            "158m",
            "simo↑",
            "text2mel",
            "have",
            "model",
            "smos↑",
            "95k",
            "stands",
            "result",
            "emilia",
            "hrs",
            "bold",
            "testen",
            "indicates",
            "underlined",
            "models",
            "o3s",
            "wer↓",
            "libritts",
            "small",
            "best",
            "336m",
            "teacher",
            "data",
            "parameters",
            "based",
            "secondbest"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">F5-TTS maps text embeddings to mel spectrograms in the text2mel task using a diffusion transformer. Following </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib3\" title=\"\">3</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, We train small models on the LibriTTS&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib31\" title=\"\">31</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> dataset and base and medium models on the processed 95k-hour Emilia&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib32\" title=\"\">32</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> dataset. Teachers&#8217; inference has a CFG rate of 3.0 while student does not apply CFG during inference.\nExperimental results, shown in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S3.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 3.3 Initialization Strategy for IntMeanFlow &#8227; 3 Methodology &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, demonstrate that distillation with IntMeanFlow significantly improves NFE and RTF, with only a slight compromise in performance. The relationship between NFE and speech quality are illustrated in Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S4.F3\" style=\"font-size:90%;\" title=\"Figure 3 &#8227; 4.2 Results on Text2Mel Task &#8227; 4 Experiments &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nWe do not compare with MeanFlow for the text2mel task, as F5-TTS requires training with a batch size of 1 due to JVP overhead. Performance of MeanFlow is discussed in Section&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S4.SS3\" style=\"font-size:90%;\" title=\"4.3 Results on Token2Mel Task &#8227; 4 Experiments &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">4.3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Flow-based generative models have greatly improved text-to-speech (TTS) synthesis quality, but inference speed remains limited by the iterative sampling process and multiple function evaluations (NFE). The recent MeanFlow model accelerates generation by modeling average velocity instead of instantaneous velocity. However, its direct application to TTS encounters challenges, including GPU memory overhead from Jacobian-vector products (JVP) and training instability due to self-bootstrap processes.\nTo address these issues, we introduce IntMeanFlow, a framework for few-step speech generation with integral velocity distillation. By approximating average velocity with the teacher&#8217;s instantaneous velocity over a temporal interval, IntMeanFlow eliminates the need for JVPs and self-bootstrap, improving stability and reducing GPU memory usage. We also propose the Optimal Step Sampling Search (O3S) algorithm, which identifies the model-specific optimal sampling steps, improving speech synthesis without additional inference overhead. Experiments show that IntMeanFlow achieves 1-NFE inference for token-to-spectrogram and 3-NFE for text-to-spectrogram tasks while maintaining high-quality synthesis. Demo samples are available<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\"><span class=\"ltx_text\" style=\"font-size:111%;\">1</span></span><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://vvwangvv.github.io/intmeanflow/\" style=\"font-size:111%;\" title=\"\">https://vvwangvv.github.io/intmeanflow/</a></span></span></span>.</span>\n</p>\n\n",
                "matched_terms": [
                    "have",
                    "intmeanflow",
                    "model",
                    "models",
                    "o3s",
                    "nfe"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Text-to-speech (TTS) generation has made significant progress in recent years, with models achieving near-human-level, zero-shot synthesis capabilities&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib4\" title=\"\">4</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib5\" title=\"\">5</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib6\" title=\"\">6</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib7\" title=\"\">7</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The rise of flow-based generative models&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib8\" title=\"\">8</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> has contributed to this advancement, offering promising results across various fields, including image synthesis&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib9\" title=\"\">9</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib10\" title=\"\">10</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, video&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib11\" title=\"\">11</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and music generation&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThese models learn to map data distributions to a latent space, enabling high-quality generation. However, flow-based models often face a trade-off between sampling quality and efficiency, as their iterative sampling process can lead to slow inference and high computational costs. To address this, recent efforts in the image domain, such as consistency models&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib15\" title=\"\">15</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib16\" title=\"\">16</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib17\" title=\"\">17</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib18\" title=\"\">18</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and shortcut models&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, have been proposed to reduce the number of function evaluations&#160;(NFE) while maintaining high-quality generation results.</span>\n</p>\n\n",
                "matched_terms": [
                    "have",
                    "models",
                    "data",
                    "nfe",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Among these approaches, MeanFlow&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib20\" title=\"\">20</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> has emerged as a promising solution to the trade-off between sampling quality and efficiency. By modeling averaged velocity instead of instantaneous velocity, MeanFlow enables more efficient sampling without compromising output quality. While it has shown success in image generation and audio generation&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib21\" title=\"\">21</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, applying MeanFlow to TTS introduces several challenges. First, the training process of MeanFlow relies on a self-bootstrap mechanism, which requires mixing with instantaneous velocity guidance similar to flow matching. The strength of this guidance can significantly impact model performance, and without it, the model is prone to collapse. Second, MeanFlow involves the Jacobian-vector product (JVP), a computationally intensive operation that consumes substantial GPU memory. Additionally, JVP is not natively supported by certain custom CUDA operators or torch-native operations, such as flash attention, complicating the adaptation of existing models to the MeanFlow framework. These memory and compatibility challenges make training large-scale TTS models with MeanFlow infeasible.</span>\n</p>\n\n",
                "matched_terms": [
                    "models",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To address these challenges, we propose IntMeanFlow, a framework for few-step speech generation that leverages integral velocity distillation. Building on the core motivation of MeanFlow, IntMeanFlow enables the model to learn averaged velocity instead of instantaneous velocity. Motivated by the observation that the quality of speech generated by flow-based models plateaus after a certain NFE, we approximate the average velocity over a temporal interval </span>\n  <math alttext=\"[t,r]\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">[t,r]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> by dividing the accumulated displacement between discrete time steps by the interval duration. We further introduce an initialization strategy to leverage pretrained flow-matching models, enabling smoother migration from existing models. By eliminating the need for self-bootstrap and reliance on the Jacobian-vector product (JVP), IntMeanFlow ensures improved stability, reduced GPU memory consumption during training, and better compatibility with existing models, simplifying the adaptation process.</span>\n</p>\n\n",
                "matched_terms": [
                    "models",
                    "nfe",
                    "intmeanflow",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Additionally, based on the empirical observation that denser sampling near noisier timesteps leads to better generation quality, we introduce the Optimal Step Sampling Search (O3S) algorithm. O3S automatically identifies model-specific near-optimal sampling steps, using a customizable quality metric and a ternary search algorithm. This improves the generation quality without introducing additional inference overhead.</span>\n</p>\n\n",
                "matched_terms": [
                    "o3s",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We conduct experiments on models from two widely used approaches in flow-based TTS: (1) CosyVoice2&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib1\" title=\"\">1</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which integrates a language model (LM) followed by a flow model converting time-aligned tokens into mel-spectrograms (token2mel), and (2) F5-TTS&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib3\" title=\"\">3</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where a flow model directly converts raw text embeddings into mel-spectrograms (text2mel), learning time alignment inherently. Experimental results show that IntMeanFlow achieves 1-NFE inference for the token2mel task in CosyVoice2 and 3-NFE for the text2mel task in F5-TTS, maintaining high-quality synthesis.</span>\n</p>\n\n",
                "matched_terms": [
                    "text2mel",
                    "intmeanflow",
                    "model",
                    "models",
                    "f5tts",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We evaluate our method on two popular flow-based TTS models, achieving 1-NFE inference for token2mel and 3-NFE for text2mel tasks, while maintaining high-quality synthesis.</span>\n</p>\n\n",
                "matched_terms": [
                    "models",
                    "text2mel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Consistency and shortcut models are commonly used to reduce NFE while maintaining output quality. However, applying these methods to text-to-speech (TTS) has shown limited success due to task differences. Notable exceptions, such as DMOSpeech&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and DMOSpeech2&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, reduce NFE in TTS through distillation and reinforcement learning.\nHowever, these methods rely on auxiliary models that complicate the training process, as well as a fixed time sampling schedule during distillation, which reduces flexibility during inference. In contrast, our approach eliminates the need for auxiliary models and additional loss functions. And we do not employ a fixed step sampling strategy during training, which simplifies the training process, and improves flexibility during inference.</span>\n</p>\n\n",
                "matched_terms": [
                    "models",
                    "nfe",
                    "methods"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In the distillation process, the student model is guided by a flow-matching teacher model. The teacher model transforms an initial distribution </span>\n  <math alttext=\"p_{0}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m1\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">p</mi>\n        <mn mathsize=\"0.900em\">0</mn>\n      </msub>\n      <annotation encoding=\"application/x-tex\">p_{0}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (e.g., Gaussian noise) into a target distribution </span>\n  <math alttext=\"p_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">p</mi>\n        <mn mathsize=\"0.900em\">1</mn>\n      </msub>\n      <annotation encoding=\"application/x-tex\">p_{1}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> using a time-dependent vector field </span>\n  <math alttext=\"v(z_{t},t;\\theta)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">v</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">z</mi>\n            <mi mathsize=\"0.900em\">t</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo mathsize=\"0.900em\">;</mo>\n          <mi mathsize=\"0.900em\">&#952;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">v(z_{t},t;\\theta)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The state evolution </span>\n  <math alttext=\"z_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m4\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">z</mi>\n        <mi mathsize=\"0.900em\">t</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">z_{t}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is governed by the following ordinary differential equation (ODE):</span>\n</p>\n\n",
                "matched_terms": [
                    "teacher",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">While the teacher learns to model the instantaneous velocity </span>\n  <math alttext=\"v(z_{t},t;\\theta)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p6.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">v</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">z</mi>\n            <mi mathsize=\"0.900em\">t</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo mathsize=\"0.900em\">;</mo>\n          <mi mathsize=\"0.900em\">&#952;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">v(z_{t},t;\\theta)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, the student model is tasked with learning the averaged velocity over a time interval </span>\n  <math alttext=\"[t,r]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p6.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">[t,r]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, defined as:</span>\n</p>\n\n",
                "matched_terms": [
                    "teacher",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The student model is trained to approximate this averaged velocity using the teacher&#8217;s instantaneous velocity. To achieve this, we perform iterative sampling during distillation. The interval </span>\n  <math alttext=\"[t,r]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p9.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">[t,r]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is discretized into </span>\n  <math alttext=\"n\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p9.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">n</mi>\n      <annotation encoding=\"application/x-tex\">n</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> subintervals, with time steps </span>\n  <math alttext=\"t_{0}=t,t_{1},\\dots,t_{n}=r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p9.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">t</mi>\n            <mn mathsize=\"0.900em\">0</mn>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mrow>\n            <mi mathsize=\"0.900em\">t</mi>\n            <mo mathsize=\"0.900em\">,</mo>\n            <msub>\n              <mi mathsize=\"0.900em\">t</mi>\n              <mn mathsize=\"0.900em\">1</mn>\n            </msub>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#8230;</mi>\n          </mrow>\n        </mrow>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">t</mi>\n            <mi mathsize=\"0.900em\">n</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mi mathsize=\"0.900em\">r</mi>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t_{0}=t,t_{1},\\dots,t_{n}=r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. At each step, the teacher model evolves the state according to the discrete approximation of the ODE:</span>\n</p>\n\n",
                "matched_terms": [
                    "teacher",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">where </span>\n  <math alttext=\"u_{\\text{student}}(z_{t},t,r)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p19.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <msub>\n          <mi mathsize=\"0.900em\">u</mi>\n          <mtext mathsize=\"0.900em\">student</mtext>\n        </msub>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">z</mi>\n            <mi mathsize=\"0.900em\">t</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">r</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">u_{\\text{student}}(z_{t},t,r)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the predicted velocity from the student model, and </span>\n  <math alttext=\"\\bar{v}_{\\text{teacher}}(z_{t},t,r)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p19.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <msub>\n          <mover accent=\"true\">\n            <mi mathsize=\"0.900em\">v</mi>\n            <mo mathsize=\"0.900em\">&#175;</mo>\n          </mover>\n          <mtext mathsize=\"0.900em\">teacher</mtext>\n        </msub>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">z</mi>\n            <mi mathsize=\"0.900em\">t</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">r</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">\\bar{v}_{\\text{teacher}}(z_{t},t,r)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the target velocity from the teacher. The student model learns to predict the averaged velocity by following the teacher&#8217;s guidance, which approximates the integral of the instantaneous velocity via iterative sampling.</span>\n</p>\n\n",
                "matched_terms": [
                    "teacher",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In flow-based speech generation, previous work has shown that denser sampling at noisier steps leads to improved speech quality&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib24\" title=\"\">24</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. To satisfy varying NFE requirements, earlier methods have used continuous functions or hard-coded discrete step schedules. However, instead of relying on a fixed schedule, this work optimizes the steps sampling specifically for each model&#8217;s inference process. As shown in Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3.2 Optimal Step Sampling Searching (O3S) &#8227; 3 Methodology &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we observe through experiments that speech quality, as a function of sampling step position, exhibits near-convex behavior. This finding motivates the introduction of the Optimal Sampling Step Search (O3S) algorithm, which optimizes the distribution of a fixed number of sampling steps across the inference interval </span>\n  <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n        <mn mathsize=\"0.900em\">0</mn>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mn mathsize=\"0.900em\">1</mn>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">[0,1]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "have",
                    "nfe",
                    "methods",
                    "o3s"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The core idea behind O3S is to optimize the placement of each sampling step using ternary search. To achieve this, we fix all but one of the sampling steps and apply ternary search to optimize the remaining one. This process is repeated for each step, and the optimization continues until no further improvement is observed on a development set. O3S thus identifies the optimal distribution of sampling steps, enhancing speech quality without increasing NFE.</span>\n</p>\n\n",
                "matched_terms": [
                    "all",
                    "nfe",
                    "o3s"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To adapt flow-matching models to IntMeanFlow, we introduce an additional parameter </span>\n  <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">r</mi>\n      <annotation encoding=\"application/x-tex\">r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Both </span>\n  <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">t</mi>\n      <annotation encoding=\"application/x-tex\">t</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">r</mi>\n      <annotation encoding=\"application/x-tex\">r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> are passed through the same embedding network, concatenated, and projected back to the feature space of </span>\n  <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">t</mi>\n      <annotation encoding=\"application/x-tex\">t</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> using a linear mapping </span>\n  <math alttext=\"\\mathbf{W}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119830;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{W}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "models",
                    "intmeanflow"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">where </span>\n  <math alttext=\"D_{diag}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p6.m1\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">D</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">d</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">a</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">g</mi>\n        </mrow>\n      </msub>\n      <annotation encoding=\"application/x-tex\">D_{diag}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> indicates a diagonal matrix. This ensures the model to behave like the original model at initialization.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "indicates"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We conduct experiments based on F5-TTS for the text2mel task and CosyVoice2 for the token2mel task. During distillation with IntMeanFlow, the student model learns the vector field from the teacher with classifier-free guidance (CFG)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib25\" title=\"\">25</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while the student avoids using CFG during training to reduce inference overhead. For F5-TTS, we use the SeedTTS test set&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib6\" title=\"\">6</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\">\n    <sup class=\"ltx_note_mark\">2</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">2</sup>\n        <span class=\"ltx_tag ltx_tag_note\">2</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/BytedanceSpeech/seed-tts-eval\" title=\"\">https://github.com/BytedanceSpeech/seed-tts-eval</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">; for CosyVoice2, we use the LibriSpeech-PC test set&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib26\" title=\"\">26</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "text2mel",
                    "intmeanflow",
                    "model",
                    "seedtts",
                    "f5tts",
                    "teacher",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Performance is evaluated on a cross-sentence task using a variety of metrics. For objective evaluation, we report Word Error Rate (WER) and SIM-o (speaker similarity). WER is computed using Whisperlarge-v3 for English transcription and Paraformer-zh&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> for Chinese transcription. For SIM-o, we extract speaker embeddings using a WavLM-based&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib28\" title=\"\">28</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> speaker verification model and compute the cosine similarity between synthesized and prompt human speech. Real-time factors(RTF) are measured on NVIDIA A100 GPU.\nFor CMOS, speech quality is rated from 3 (worse) to + 3 (better) compared to human reference. For SMOS, similarity between synthesized and prompt speech is rated on a 1&#8211;5 scale, with higher scores indicating better quality.\nAdditionally, we report UTMOS&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib29\" title=\"\">29</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> scores, which are evaluated using an open-source MOS prediction model. To complement UTMOS, we also apply the recent Uni-Versa-Ext (UV.MOS)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib30\" title=\"\">30</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which has demonstrated a high correlation with human-provided MOS scores&#160;</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\">\n    <sup class=\"ltx_note_mark\">3</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">3</sup>\n        <span class=\"ltx_tag ltx_tag_note\">3</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/vvwangvv/universa-ext_wavlm-base_5metric\" title=\"\">https://huggingface.co/vvwangvv/universa-ext_wavlm-base_5metric</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "human"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The comparison between lines 6 and 7 on </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">test-en</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and lines 16 and 17 on </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">test-zh</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrates the effectiveness of applying the sampling steps optimized by O3S. O3S consistently leads to improvements in both subjective and objective metrics by a large margin.</span>\n</p>\n\n",
                "matched_terms": [
                    "testzh",
                    "o3s",
                    "testen"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Using a larger teacher NFE during distillation can significantly increase training time, as shown in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2.2 Impact of Teacher NFE on Training Time and Performance &#8227; 4.2 Results on Text2Mel Task &#8227; 4 Experiments &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. To examine the trade-off between teacher NFE and student performance, we conduct ablation experiments. A comparison of lines 10, 11, and 12 on </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">test-en</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and lines 18, 19, and 20 on </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">test-zh</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, reveals that while a smaller teacher NFE results in minimal degradation in subjective metrics, objective metrics show noticeable performance loss, which is a common challenge in TTS evaluation. Synthesized speech from lines 10 and 20 demonstrates unnatural pronunciation and degraded fluency due to the excessively small teacher NFE.</span>\n</p>\n\n",
                "matched_terms": [
                    "testen",
                    "small",
                    "teacher",
                    "testzh",
                    "nfe",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The size of the teacher model does not affect the inference efficiency of the student model. Therefore, we examine whether a larger teacher can improve student performance, particularly when paired with a smaller, more practically efficient student model. Comparing lines 11 and 12, we observe that increasing the teacher&#8217;s size leads to improvements in both objective and subjective metrics for the student. These improvements significantly surpass the baseline performance reported in line 4.</span>\n</p>\n\n",
                "matched_terms": [
                    "teacher",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this experiment, we use the CosyVoice 2 architecture for flow-based speech generation. Unlike F5-TTS, where the flow operates on raw text embeddings, the flow in CosyVoice 2 processes time-aligned semantics, simplifying the task and enabling 1-NFE inference after distillation. We perform distillation using the default model configuration from the official repository</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote4\">\n    <sup class=\"ltx_note_mark\">4</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">4</sup>\n        <span class=\"ltx_tag ltx_tag_note\">4</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/FunAudioLLM/CosyVoice\" title=\"\">https://github.com/FunAudioLLM/CosyVoice</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nand its pre-trained checkpoint as the teacher model. Since CosyVoice 2 is trained on a proprietary dataset that is unavailable to us, we use LibriTTS for distillation. The vanilla MeanFlow model, as shown in line 18, yields good WER and SIM-o results but leads to degraded speech quality in both neural and human MOS evaluations, likely due to the absence of a teacher model and instability in the training process. The results in line 9 demonstrate that IntMeanFlow effectively distills the teacher&#8217;s capabilities while reducing NFE, even when trained on a significantly smaller dataset.</span>\n</p>\n\n",
                "matched_terms": [
                    "intmeanflow",
                    "model",
                    "libritts",
                    "f5tts",
                    "teacher",
                    "human",
                    "nfe",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this work, we introduce the IntMeanFlow framework for efficient few-step speech generation through distillation. We also propose an optimal step sampling search algorithm to identify model-specific sampling steps during inference. Our experiments, conducted on two widely used TTS models, F5-TTS for the text2mel task and CosyVoice2 for the token2mel task. Results demonstrate that IntMeanFlow achieves 3-NFE for the text2mel task and 1-NFE for the token2mel task. This results in 10 times acceleration in terms of RTF, with only minimal degradation in performance. Additionally, we propose an efficient initialization strategy that facilitates the seamless adaptation of existing flow-matching models to IntMeanFlow, improving both the practical applicability of the framework.</span>\n</p>\n\n",
                "matched_terms": [
                    "text2mel",
                    "intmeanflow",
                    "models",
                    "f5tts",
                    "results"
                ]
            }
        ]
    },
    "S3.T2": {
        "source_file": "Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation",
        "caption": "Table 2: Token2Mel Results on LibriSpeech-PC: RTF values are reported only for the flow module.",
        "body": "#\nModel (NFE)\nData (hrs)\nTeacher (NFE)\nWER(%)↓\nSIM-o↑\nUTMOS↑\nUV.MOS↑\nCMOS↑\nSMOS↑\nRTF↓\n\n\n\n\n1\nHuman\nN/A\nN/A\n2.23\n0.69\n4.09\n4.20\n0.00\n3.93\nN/A\n\n\n2\nCosyVoice2 (32)\nProprietary (170K)\nN/A\n2.17\n0.66\n4.36\n4.48\n-0.01\n3.71\n0.510\n\n\n3\nCosyVoice2 + MF (1)\nLibriTTS (585)\nN/A\n2.11\n0.62\n3.96\n3.85\n-0.73\n3.42\n0.026\n\n\n4\nCosyVoice2 + IMF (1)\nLibriTTS (585)\nofficial (16)\n2.18\n0.63\n4.28\n4.47\n-0.03\n3.39\n0.026",
        "html_code": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">#</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Model (NFE)</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Data (hrs)</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Teacher (NFE)</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">WER(%)&#8595;</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SIM-o&#8593;</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">UTMOS&#8593;</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">UV.MOS&#8593;</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">CMOS&#8593;</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SMOS&#8593;</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">RTF&#8595;</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Human</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.23</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.69</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.09</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.20</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.00</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.93</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">2</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">CosyVoice2 (32)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Proprietary (170K)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.17</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.66</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.36</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.48</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.01</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.71</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.510</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">3</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">CosyVoice2 + MF (1)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">LibriTTS (585)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.11</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.62</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.96</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.85</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.73</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.42</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.026</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">4</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">CosyVoice2 + IMF (1)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">LibriTTS (585)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">official (16)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.18</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.63</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.28</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.47</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">-0.03</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.39</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.026</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "librispeechpc",
            "utmos↑",
            "nfe",
            "cmos↑",
            "flow",
            "proprietary",
            "imf",
            "uvmos↑",
            "human",
            "results",
            "rtf",
            "simo↑",
            "smos↑",
            "model",
            "token2mel",
            "module",
            "values",
            "hrs",
            "only",
            "cosyvoice2",
            "reported",
            "170k",
            "wer↓",
            "libritts",
            "teacher",
            "official",
            "data",
            "rtf↓"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Flow-based generative models have greatly improved text-to-speech (TTS) synthesis quality, but inference speed remains limited by the iterative sampling process and multiple function evaluations (NFE). The recent MeanFlow model accelerates generation by modeling average velocity instead of instantaneous velocity. However, its direct application to TTS encounters challenges, including GPU memory overhead from Jacobian-vector products (JVP) and training instability due to self-bootstrap processes.\nTo address these issues, we introduce IntMeanFlow, a framework for few-step speech generation with integral velocity distillation. By approximating average velocity with the teacher&#8217;s instantaneous velocity over a temporal interval, IntMeanFlow eliminates the need for JVPs and self-bootstrap, improving stability and reducing GPU memory usage. We also propose the Optimal Step Sampling Search (O3S) algorithm, which identifies the model-specific optimal sampling steps, improving speech synthesis without additional inference overhead. Experiments show that IntMeanFlow achieves 1-NFE inference for token-to-spectrogram and 3-NFE for text-to-spectrogram tasks while maintaining high-quality synthesis. Demo samples are available<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\"><span class=\"ltx_text\" style=\"font-size:111%;\">1</span></span><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://vvwangvv.github.io/intmeanflow/\" style=\"font-size:111%;\" title=\"\">https://vvwangvv.github.io/intmeanflow/</a></span></span></span>.</span>\n</p>\n\n",
                "matched_terms": [
                    "nfe",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Text-to-speech (TTS) generation has made significant progress in recent years, with models achieving near-human-level, zero-shot synthesis capabilities&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib4\" title=\"\">4</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib5\" title=\"\">5</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib6\" title=\"\">6</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib7\" title=\"\">7</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The rise of flow-based generative models&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib8\" title=\"\">8</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> has contributed to this advancement, offering promising results across various fields, including image synthesis&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib9\" title=\"\">9</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib10\" title=\"\">10</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, video&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib11\" title=\"\">11</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and music generation&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThese models learn to map data distributions to a latent space, enabling high-quality generation. However, flow-based models often face a trade-off between sampling quality and efficiency, as their iterative sampling process can lead to slow inference and high computational costs. To address this, recent efforts in the image domain, such as consistency models&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib15\" title=\"\">15</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib16\" title=\"\">16</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib17\" title=\"\">17</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib18\" title=\"\">18</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and shortcut models&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, have been proposed to reduce the number of function evaluations&#160;(NFE) while maintaining high-quality generation results.</span>\n</p>\n\n",
                "matched_terms": [
                    "data",
                    "nfe",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Among these approaches, MeanFlow&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib20\" title=\"\">20</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> has emerged as a promising solution to the trade-off between sampling quality and efficiency. By modeling averaged velocity instead of instantaneous velocity, MeanFlow enables more efficient sampling without compromising output quality. While it has shown success in image generation and audio generation&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib21\" title=\"\">21</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, applying MeanFlow to TTS introduces several challenges. First, the training process of MeanFlow relies on a self-bootstrap mechanism, which requires mixing with instantaneous velocity guidance similar to flow matching. The strength of this guidance can significantly impact model performance, and without it, the model is prone to collapse. Second, MeanFlow involves the Jacobian-vector product (JVP), a computationally intensive operation that consumes substantial GPU memory. Additionally, JVP is not natively supported by certain custom CUDA operators or torch-native operations, such as flash attention, complicating the adaptation of existing models to the MeanFlow framework. These memory and compatibility challenges make training large-scale TTS models with MeanFlow infeasible.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "flow"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To address these challenges, we propose IntMeanFlow, a framework for few-step speech generation that leverages integral velocity distillation. Building on the core motivation of MeanFlow, IntMeanFlow enables the model to learn averaged velocity instead of instantaneous velocity. Motivated by the observation that the quality of speech generated by flow-based models plateaus after a certain NFE, we approximate the average velocity over a temporal interval </span>\n  <math alttext=\"[t,r]\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">[t,r]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> by dividing the accumulated displacement between discrete time steps by the interval duration. We further introduce an initialization strategy to leverage pretrained flow-matching models, enabling smoother migration from existing models. By eliminating the need for self-bootstrap and reliance on the Jacobian-vector product (JVP), IntMeanFlow ensures improved stability, reduced GPU memory consumption during training, and better compatibility with existing models, simplifying the adaptation process.</span>\n</p>\n\n",
                "matched_terms": [
                    "nfe",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We conduct experiments on models from two widely used approaches in flow-based TTS: (1) CosyVoice2&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib1\" title=\"\">1</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which integrates a language model (LM) followed by a flow model converting time-aligned tokens into mel-spectrograms (token2mel), and (2) F5-TTS&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib3\" title=\"\">3</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where a flow model directly converts raw text embeddings into mel-spectrograms (text2mel), learning time alignment inherently. Experimental results show that IntMeanFlow achieves 1-NFE inference for the token2mel task in CosyVoice2 and 3-NFE for the text2mel task in F5-TTS, maintaining high-quality synthesis.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "token2mel",
                    "cosyvoice2",
                    "results",
                    "flow"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In the distillation process, the student model is guided by a flow-matching teacher model. The teacher model transforms an initial distribution </span>\n  <math alttext=\"p_{0}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m1\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">p</mi>\n        <mn mathsize=\"0.900em\">0</mn>\n      </msub>\n      <annotation encoding=\"application/x-tex\">p_{0}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (e.g., Gaussian noise) into a target distribution </span>\n  <math alttext=\"p_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">p</mi>\n        <mn mathsize=\"0.900em\">1</mn>\n      </msub>\n      <annotation encoding=\"application/x-tex\">p_{1}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> using a time-dependent vector field </span>\n  <math alttext=\"v(z_{t},t;\\theta)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">v</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">z</mi>\n            <mi mathsize=\"0.900em\">t</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo mathsize=\"0.900em\">;</mo>\n          <mi mathsize=\"0.900em\">&#952;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">v(z_{t},t;\\theta)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The state evolution </span>\n  <math alttext=\"z_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m4\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">z</mi>\n        <mi mathsize=\"0.900em\">t</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">z_{t}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is governed by the following ordinary differential equation (ODE):</span>\n</p>\n\n",
                "matched_terms": [
                    "teacher",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">While the teacher learns to model the instantaneous velocity </span>\n  <math alttext=\"v(z_{t},t;\\theta)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p6.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">v</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">z</mi>\n            <mi mathsize=\"0.900em\">t</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo mathsize=\"0.900em\">;</mo>\n          <mi mathsize=\"0.900em\">&#952;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">v(z_{t},t;\\theta)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, the student model is tasked with learning the averaged velocity over a time interval </span>\n  <math alttext=\"[t,r]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p6.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">[t,r]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, defined as:</span>\n</p>\n\n",
                "matched_terms": [
                    "teacher",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The student model is trained to approximate this averaged velocity using the teacher&#8217;s instantaneous velocity. To achieve this, we perform iterative sampling during distillation. The interval </span>\n  <math alttext=\"[t,r]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p9.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">[t,r]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is discretized into </span>\n  <math alttext=\"n\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p9.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">n</mi>\n      <annotation encoding=\"application/x-tex\">n</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> subintervals, with time steps </span>\n  <math alttext=\"t_{0}=t,t_{1},\\dots,t_{n}=r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p9.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">t</mi>\n            <mn mathsize=\"0.900em\">0</mn>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mrow>\n            <mi mathsize=\"0.900em\">t</mi>\n            <mo mathsize=\"0.900em\">,</mo>\n            <msub>\n              <mi mathsize=\"0.900em\">t</mi>\n              <mn mathsize=\"0.900em\">1</mn>\n            </msub>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#8230;</mi>\n          </mrow>\n        </mrow>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">t</mi>\n            <mi mathsize=\"0.900em\">n</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mi mathsize=\"0.900em\">r</mi>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t_{0}=t,t_{1},\\dots,t_{n}=r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. At each step, the teacher model evolves the state according to the discrete approximation of the ODE:</span>\n</p>\n\n",
                "matched_terms": [
                    "teacher",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">where </span>\n  <math alttext=\"u_{\\text{student}}(z_{t},t,r)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p19.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <msub>\n          <mi mathsize=\"0.900em\">u</mi>\n          <mtext mathsize=\"0.900em\">student</mtext>\n        </msub>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">z</mi>\n            <mi mathsize=\"0.900em\">t</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">r</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">u_{\\text{student}}(z_{t},t,r)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the predicted velocity from the student model, and </span>\n  <math alttext=\"\\bar{v}_{\\text{teacher}}(z_{t},t,r)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p19.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <msub>\n          <mover accent=\"true\">\n            <mi mathsize=\"0.900em\">v</mi>\n            <mo mathsize=\"0.900em\">&#175;</mo>\n          </mover>\n          <mtext mathsize=\"0.900em\">teacher</mtext>\n        </msub>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">z</mi>\n            <mi mathsize=\"0.900em\">t</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">r</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">\\bar{v}_{\\text{teacher}}(z_{t},t,r)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the target velocity from the teacher. The student model learns to predict the averaged velocity by following the teacher&#8217;s guidance, which approximates the integral of the instantaneous velocity via iterative sampling.</span>\n</p>\n\n",
                "matched_terms": [
                    "teacher",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We conduct experiments based on F5-TTS for the text2mel task and CosyVoice2 for the token2mel task. During distillation with IntMeanFlow, the student model learns the vector field from the teacher with classifier-free guidance (CFG)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib25\" title=\"\">25</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while the student avoids using CFG during training to reduce inference overhead. For F5-TTS, we use the SeedTTS test set&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib6\" title=\"\">6</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\">\n    <sup class=\"ltx_note_mark\">2</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">2</sup>\n        <span class=\"ltx_tag ltx_tag_note\">2</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/BytedanceSpeech/seed-tts-eval\" title=\"\">https://github.com/BytedanceSpeech/seed-tts-eval</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">; for CosyVoice2, we use the LibriSpeech-PC test set&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib26\" title=\"\">26</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "librispeechpc",
                    "model",
                    "token2mel",
                    "teacher",
                    "cosyvoice2"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Performance is evaluated on a cross-sentence task using a variety of metrics. For objective evaluation, we report Word Error Rate (WER) and SIM-o (speaker similarity). WER is computed using Whisperlarge-v3 for English transcription and Paraformer-zh&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> for Chinese transcription. For SIM-o, we extract speaker embeddings using a WavLM-based&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib28\" title=\"\">28</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> speaker verification model and compute the cosine similarity between synthesized and prompt human speech. Real-time factors(RTF) are measured on NVIDIA A100 GPU.\nFor CMOS, speech quality is rated from 3 (worse) to + 3 (better) compared to human reference. For SMOS, similarity between synthesized and prompt speech is rated on a 1&#8211;5 scale, with higher scores indicating better quality.\nAdditionally, we report UTMOS&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib29\" title=\"\">29</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> scores, which are evaluated using an open-source MOS prediction model. To complement UTMOS, we also apply the recent Uni-Versa-Ext (UV.MOS)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib30\" title=\"\">30</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which has demonstrated a high correlation with human-provided MOS scores&#160;</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\">\n    <sup class=\"ltx_note_mark\">3</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">3</sup>\n        <span class=\"ltx_tag ltx_tag_note\">3</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/vvwangvv/universa-ext_wavlm-base_5metric\" title=\"\">https://huggingface.co/vvwangvv/universa-ext_wavlm-base_5metric</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "human"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">F5-TTS maps text embeddings to mel spectrograms in the text2mel task using a diffusion transformer. Following </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib3\" title=\"\">3</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, We train small models on the LibriTTS&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib31\" title=\"\">31</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> dataset and base and medium models on the processed 95k-hour Emilia&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib32\" title=\"\">32</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> dataset. Teachers&#8217; inference has a CFG rate of 3.0 while student does not apply CFG during inference.\nExperimental results, shown in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S3.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 3.3 Initialization Strategy for IntMeanFlow &#8227; 3 Methodology &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, demonstrate that distillation with IntMeanFlow significantly improves NFE and RTF, with only a slight compromise in performance. The relationship between NFE and speech quality are illustrated in Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S4.F3\" style=\"font-size:90%;\" title=\"Figure 3 &#8227; 4.2 Results on Text2Mel Task &#8227; 4 Experiments &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nWe do not compare with MeanFlow for the text2mel task, as F5-TTS requires training with a batch size of 1 due to JVP overhead. Performance of MeanFlow is discussed in Section&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S4.SS3\" style=\"font-size:90%;\" title=\"4.3 Results on Token2Mel Task &#8227; 4 Experiments &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">4.3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "nfe",
                    "libritts",
                    "only",
                    "results",
                    "rtf"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Using a larger teacher NFE during distillation can significantly increase training time, as shown in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2.2 Impact of Teacher NFE on Training Time and Performance &#8227; 4.2 Results on Text2Mel Task &#8227; 4 Experiments &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. To examine the trade-off between teacher NFE and student performance, we conduct ablation experiments. A comparison of lines 10, 11, and 12 on </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">test-en</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and lines 18, 19, and 20 on </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">test-zh</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, reveals that while a smaller teacher NFE results in minimal degradation in subjective metrics, objective metrics show noticeable performance loss, which is a common challenge in TTS evaluation. Synthesized speech from lines 10 and 20 demonstrates unnatural pronunciation and degraded fluency due to the excessively small teacher NFE.</span>\n</p>\n\n",
                "matched_terms": [
                    "nfe",
                    "teacher",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The size of the teacher model does not affect the inference efficiency of the student model. Therefore, we examine whether a larger teacher can improve student performance, particularly when paired with a smaller, more practically efficient student model. Comparing lines 11 and 12, we observe that increasing the teacher&#8217;s size leads to improvements in both objective and subjective metrics for the student. These improvements significantly surpass the baseline performance reported in line 4.</span>\n</p>\n\n",
                "matched_terms": [
                    "reported",
                    "teacher",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this experiment, we use the CosyVoice 2 architecture for flow-based speech generation. Unlike F5-TTS, where the flow operates on raw text embeddings, the flow in CosyVoice 2 processes time-aligned semantics, simplifying the task and enabling 1-NFE inference after distillation. We perform distillation using the default model configuration from the official repository</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote4\">\n    <sup class=\"ltx_note_mark\">4</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">4</sup>\n        <span class=\"ltx_tag ltx_tag_note\">4</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/FunAudioLLM/CosyVoice\" title=\"\">https://github.com/FunAudioLLM/CosyVoice</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nand its pre-trained checkpoint as the teacher model. Since CosyVoice 2 is trained on a proprietary dataset that is unavailable to us, we use LibriTTS for distillation. The vanilla MeanFlow model, as shown in line 18, yields good WER and SIM-o results but leads to degraded speech quality in both neural and human MOS evaluations, likely due to the absence of a teacher model and instability in the training process. The results in line 9 demonstrate that IntMeanFlow effectively distills the teacher&#8217;s capabilities while reducing NFE, even when trained on a significantly smaller dataset.</span>\n</p>\n\n",
                "matched_terms": [
                    "proprietary",
                    "model",
                    "libritts",
                    "teacher",
                    "human",
                    "official",
                    "nfe",
                    "results",
                    "flow"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this work, we introduce the IntMeanFlow framework for efficient few-step speech generation through distillation. We also propose an optimal step sampling search algorithm to identify model-specific sampling steps during inference. Our experiments, conducted on two widely used TTS models, F5-TTS for the text2mel task and CosyVoice2 for the token2mel task. Results demonstrate that IntMeanFlow achieves 3-NFE for the text2mel task and 1-NFE for the token2mel task. This results in 10 times acceleration in terms of RTF, with only minimal degradation in performance. Additionally, we propose an efficient initialization strategy that facilitates the seamless adaptation of existing flow-matching models to IntMeanFlow, improving both the practical applicability of the framework.</span>\n</p>\n\n",
                "matched_terms": [
                    "token2mel",
                    "only",
                    "cosyvoice2",
                    "results",
                    "rtf"
                ]
            }
        ]
    },
    "S4.T3": {
        "source_file": "Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation",
        "caption": "Table 3: Teacher NFE and training time per step",
        "body": "Teacher NFE\nN/A\n2\n4\n8\n16\n\n\n\n\nTime per step (seconds)\n0.93\n1.12\n1.74\n2.91\n5.17",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">Teacher NFE</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">N/A</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">2</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">4</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">8</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">16</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Time per step (seconds)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.93</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.12</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.74</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.91</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.17</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "time",
            "training",
            "step",
            "seconds",
            "teacher",
            "nfe"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Using a larger teacher NFE during distillation can significantly increase training time, as shown in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2.2 Impact of Teacher NFE on Training Time and Performance &#8227; 4.2 Results on Text2Mel Task &#8227; 4 Experiments &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. To examine the trade-off between teacher NFE and student performance, we conduct ablation experiments. A comparison of lines 10, 11, and 12 on </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">test-en</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and lines 18, 19, and 20 on </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">test-zh</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, reveals that while a smaller teacher NFE results in minimal degradation in subjective metrics, objective metrics show noticeable performance loss, which is a common challenge in TTS evaluation. Synthesized speech from lines 10 and 20 demonstrates unnatural pronunciation and degraded fluency due to the excessively small teacher NFE.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Flow-based generative models have greatly improved text-to-speech (TTS) synthesis quality, but inference speed remains limited by the iterative sampling process and multiple function evaluations (NFE). The recent MeanFlow model accelerates generation by modeling average velocity instead of instantaneous velocity. However, its direct application to TTS encounters challenges, including GPU memory overhead from Jacobian-vector products (JVP) and training instability due to self-bootstrap processes.\nTo address these issues, we introduce IntMeanFlow, a framework for few-step speech generation with integral velocity distillation. By approximating average velocity with the teacher&#8217;s instantaneous velocity over a temporal interval, IntMeanFlow eliminates the need for JVPs and self-bootstrap, improving stability and reducing GPU memory usage. We also propose the Optimal Step Sampling Search (O3S) algorithm, which identifies the model-specific optimal sampling steps, improving speech synthesis without additional inference overhead. Experiments show that IntMeanFlow achieves 1-NFE inference for token-to-spectrogram and 3-NFE for text-to-spectrogram tasks while maintaining high-quality synthesis. Demo samples are available<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\"><span class=\"ltx_text\" style=\"font-size:111%;\">1</span></span><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://vvwangvv.github.io/intmeanflow/\" style=\"font-size:111%;\" title=\"\">https://vvwangvv.github.io/intmeanflow/</a></span></span></span>.</span>\n</p>\n\n",
                "matched_terms": [
                    "step",
                    "nfe",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To address these challenges, we propose IntMeanFlow, a framework for few-step speech generation that leverages integral velocity distillation. Building on the core motivation of MeanFlow, IntMeanFlow enables the model to learn averaged velocity instead of instantaneous velocity. Motivated by the observation that the quality of speech generated by flow-based models plateaus after a certain NFE, we approximate the average velocity over a temporal interval </span>\n  <math alttext=\"[t,r]\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">[t,r]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> by dividing the accumulated displacement between discrete time steps by the interval duration. We further introduce an initialization strategy to leverage pretrained flow-matching models, enabling smoother migration from existing models. By eliminating the need for self-bootstrap and reliance on the Jacobian-vector product (JVP), IntMeanFlow ensures improved stability, reduced GPU memory consumption during training, and better compatibility with existing models, simplifying the adaptation process.</span>\n</p>\n\n",
                "matched_terms": [
                    "nfe",
                    "time",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Consistency and shortcut models are commonly used to reduce NFE while maintaining output quality. However, applying these methods to text-to-speech (TTS) has shown limited success due to task differences. Notable exceptions, such as DMOSpeech&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and DMOSpeech2&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, reduce NFE in TTS through distillation and reinforcement learning.\nHowever, these methods rely on auxiliary models that complicate the training process, as well as a fixed time sampling schedule during distillation, which reduces flexibility during inference. In contrast, our approach eliminates the need for auxiliary models and additional loss functions. And we do not employ a fixed step sampling strategy during training, which simplifies the training process, and improves flexibility during inference.</span>\n</p>\n\n",
                "matched_terms": [
                    "step",
                    "nfe",
                    "time",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">MeanFlow introduces a framework for one-step generative modeling by defining average velocity as displacement over a time interval. Unlike Flow Matching, which models instantaneous velocity, MeanFlow focuses on learning average velocity and establishes an analytical relationship between average and instantaneous velocities through the MeanFlow Identity. This approach provides a clear training objective without relying on heuristic constraints, and it operates independently of score estimation, pretraining, or distillation. However, its dependence on Jacobian-vector products (JVPs) to compute the time derivative introduces computational overhead and limits scalability, especially with custom operators lacking JVP support.</span>\n</p>\n\n",
                "matched_terms": [
                    "time",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">IntMeanFlow extends the principles of MeanFlow by focusing on learning the averaged velocity over a time interval, rather than the instantaneous velocity at individual time steps. This approach retains the coarse-to-fine nature of MeanFlow, where smaller intervals are emphasized during training to capture fine-grained details, while broader temporal dynamics are learned more gradually.</span>\n</p>\n\n",
                "matched_terms": [
                    "time",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">While the teacher learns to model the instantaneous velocity </span>\n  <math alttext=\"v(z_{t},t;\\theta)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p6.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">v</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">z</mi>\n            <mi mathsize=\"0.900em\">t</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo mathsize=\"0.900em\">;</mo>\n          <mi mathsize=\"0.900em\">&#952;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">v(z_{t},t;\\theta)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, the student model is tasked with learning the averaged velocity over a time interval </span>\n  <math alttext=\"[t,r]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p6.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">[t,r]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, defined as:</span>\n</p>\n\n",
                "matched_terms": [
                    "teacher",
                    "time"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The student model is trained to approximate this averaged velocity using the teacher&#8217;s instantaneous velocity. To achieve this, we perform iterative sampling during distillation. The interval </span>\n  <math alttext=\"[t,r]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p9.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">[t,r]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is discretized into </span>\n  <math alttext=\"n\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p9.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">n</mi>\n      <annotation encoding=\"application/x-tex\">n</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> subintervals, with time steps </span>\n  <math alttext=\"t_{0}=t,t_{1},\\dots,t_{n}=r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p9.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">t</mi>\n            <mn mathsize=\"0.900em\">0</mn>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mrow>\n            <mi mathsize=\"0.900em\">t</mi>\n            <mo mathsize=\"0.900em\">,</mo>\n            <msub>\n              <mi mathsize=\"0.900em\">t</mi>\n              <mn mathsize=\"0.900em\">1</mn>\n            </msub>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#8230;</mi>\n          </mrow>\n        </mrow>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mrow>\n          <msub>\n            <mi mathsize=\"0.900em\">t</mi>\n            <mi mathsize=\"0.900em\">n</mi>\n          </msub>\n          <mo mathsize=\"0.900em\">=</mo>\n          <mi mathsize=\"0.900em\">r</mi>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t_{0}=t,t_{1},\\dots,t_{n}=r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. At each step, the teacher model evolves the state according to the discrete approximation of the ODE:</span>\n</p>\n\n",
                "matched_terms": [
                    "step",
                    "teacher",
                    "time"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In flow-based speech generation, previous work has shown that denser sampling at noisier steps leads to improved speech quality&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib24\" title=\"\">24</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. To satisfy varying NFE requirements, earlier methods have used continuous functions or hard-coded discrete step schedules. However, instead of relying on a fixed schedule, this work optimizes the steps sampling specifically for each model&#8217;s inference process. As shown in Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3.2 Optimal Step Sampling Searching (O3S) &#8227; 3 Methodology &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we observe through experiments that speech quality, as a function of sampling step position, exhibits near-convex behavior. This finding motivates the introduction of the Optimal Sampling Step Search (O3S) algorithm, which optimizes the distribution of a fixed number of sampling steps across the inference interval </span>\n  <math alttext=\"[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n        <mn mathsize=\"0.900em\">0</mn>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mn mathsize=\"0.900em\">1</mn>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">[0,1]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "step",
                    "nfe"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The core idea behind O3S is to optimize the placement of each sampling step using ternary search. To achieve this, we fix all but one of the sampling steps and apply ternary search to optimize the remaining one. This process is repeated for each step, and the optimization continues until no further improvement is observed on a development set. O3S thus identifies the optimal distribution of sampling steps, enhancing speech quality without increasing NFE.</span>\n</p>\n\n",
                "matched_terms": [
                    "step",
                    "nfe"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We conduct experiments based on F5-TTS for the text2mel task and CosyVoice2 for the token2mel task. During distillation with IntMeanFlow, the student model learns the vector field from the teacher with classifier-free guidance (CFG)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib25\" title=\"\">25</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while the student avoids using CFG during training to reduce inference overhead. For F5-TTS, we use the SeedTTS test set&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib6\" title=\"\">6</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\">\n    <sup class=\"ltx_note_mark\">2</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">2</sup>\n        <span class=\"ltx_tag ltx_tag_note\">2</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/BytedanceSpeech/seed-tts-eval\" title=\"\">https://github.com/BytedanceSpeech/seed-tts-eval</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">; for CosyVoice2, we use the LibriSpeech-PC test set&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib26\" title=\"\">26</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "teacher",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">F5-TTS maps text embeddings to mel spectrograms in the text2mel task using a diffusion transformer. Following </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib3\" title=\"\">3</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, We train small models on the LibriTTS&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib31\" title=\"\">31</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> dataset and base and medium models on the processed 95k-hour Emilia&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#bib.bib32\" title=\"\">32</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> dataset. Teachers&#8217; inference has a CFG rate of 3.0 while student does not apply CFG during inference.\nExperimental results, shown in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S3.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 3.3 Initialization Strategy for IntMeanFlow &#8227; 3 Methodology &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, demonstrate that distillation with IntMeanFlow significantly improves NFE and RTF, with only a slight compromise in performance. The relationship between NFE and speech quality are illustrated in Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S4.F3\" style=\"font-size:90%;\" title=\"Figure 3 &#8227; 4.2 Results on Text2Mel Task &#8227; 4 Experiments &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nWe do not compare with MeanFlow for the text2mel task, as F5-TTS requires training with a batch size of 1 due to JVP overhead. Performance of MeanFlow is discussed in Section&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.07979v1#S4.SS3\" style=\"font-size:90%;\" title=\"4.3 Results on Token2Mel Task &#8227; 4 Experiments &#8227; Int-MeanFlow: Few-step Speech Generation with Integral Velocity Distillation\">\n    <span class=\"ltx_text ltx_ref_tag\">4.3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "nfe",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this experiment, we use the CosyVoice 2 architecture for flow-based speech generation. Unlike F5-TTS, where the flow operates on raw text embeddings, the flow in CosyVoice 2 processes time-aligned semantics, simplifying the task and enabling 1-NFE inference after distillation. We perform distillation using the default model configuration from the official repository</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote4\">\n    <sup class=\"ltx_note_mark\">4</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">4</sup>\n        <span class=\"ltx_tag ltx_tag_note\">4</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/FunAudioLLM/CosyVoice\" title=\"\">https://github.com/FunAudioLLM/CosyVoice</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nand its pre-trained checkpoint as the teacher model. Since CosyVoice 2 is trained on a proprietary dataset that is unavailable to us, we use LibriTTS for distillation. The vanilla MeanFlow model, as shown in line 18, yields good WER and SIM-o results but leads to degraded speech quality in both neural and human MOS evaluations, likely due to the absence of a teacher model and instability in the training process. The results in line 9 demonstrate that IntMeanFlow effectively distills the teacher&#8217;s capabilities while reducing NFE, even when trained on a significantly smaller dataset.</span>\n</p>\n\n",
                "matched_terms": [
                    "nfe",
                    "teacher",
                    "training"
                ]
            }
        ]
    }
}