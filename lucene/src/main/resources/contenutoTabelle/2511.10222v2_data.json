{
    "S5.T2": {
        "source_file": "Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard",
        "caption": "Table 2: Impact of acoustic hyperparameters on the Speech Overlap attack. All results are ASR% against Gemini 2.5 Pro, evaluated on a 100-sample subset of SACRED-Bench.",
        "body": "Overlap (ms)\nSpeed\nVolume (dB)\nASR (%)\n\n\n500500\n1.31.3\n−8-8\n47.0047.00\n\n\n500500\n1.51.5\n−8-8\n61.0061.00\n\n\n500500\n1.11.1\n−8-8\n42.0042.00\n\n\n300300\n1.31.3\n−8-8\n41.0041.00\n\n\n700700\n1.31.3\n−8-8\n47.0047.00\n\n\n500500\n1.31.3\n−6-6\n47.0047.00\n\n\n500500\n1.31.3\n−10-10\n51.0051.00",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Overlap (ms)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Speed</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Volume (dB)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"500\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m1\" intent=\":literal\"><semantics><mn>500</mn><annotation encoding=\"application/x-tex\">500</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"1.3\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m2\" intent=\":literal\"><semantics><mn>1.3</mn><annotation encoding=\"application/x-tex\">1.3</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"-8\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m3\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">-8</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"47.00\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m4\" intent=\":literal\"><semantics><mn>47.00</mn><annotation encoding=\"application/x-tex\">47.00</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"500\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m5\" intent=\":literal\"><semantics><mn>500</mn><annotation encoding=\"application/x-tex\">500</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"1.5\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m6\" intent=\":literal\"><semantics><mn>1.5</mn><annotation encoding=\"application/x-tex\">1.5</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"-8\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m7\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">-8</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"61.00\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m8\" intent=\":literal\"><semantics><mn>61.00</mn><annotation encoding=\"application/x-tex\">61.00</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"500\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m9\" intent=\":literal\"><semantics><mn>500</mn><annotation encoding=\"application/x-tex\">500</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"1.1\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m10\" intent=\":literal\"><semantics><mn>1.1</mn><annotation encoding=\"application/x-tex\">1.1</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"-8\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m11\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">-8</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"42.00\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m12\" intent=\":literal\"><semantics><mn>42.00</mn><annotation encoding=\"application/x-tex\">42.00</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"300\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m13\" intent=\":literal\"><semantics><mn>300</mn><annotation encoding=\"application/x-tex\">300</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"1.3\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m14\" intent=\":literal\"><semantics><mn>1.3</mn><annotation encoding=\"application/x-tex\">1.3</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"-8\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m15\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">-8</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"41.00\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m16\" intent=\":literal\"><semantics><mn>41.00</mn><annotation encoding=\"application/x-tex\">41.00</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"700\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m17\" intent=\":literal\"><semantics><mn>700</mn><annotation encoding=\"application/x-tex\">700</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"1.3\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m18\" intent=\":literal\"><semantics><mn>1.3</mn><annotation encoding=\"application/x-tex\">1.3</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"-8\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m19\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">-8</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"47.00\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m20\" intent=\":literal\"><semantics><mn>47.00</mn><annotation encoding=\"application/x-tex\">47.00</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"500\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m21\" intent=\":literal\"><semantics><mn>500</mn><annotation encoding=\"application/x-tex\">500</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"1.3\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m22\" intent=\":literal\"><semantics><mn>1.3</mn><annotation encoding=\"application/x-tex\">1.3</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"-6\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m23\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>6</mn></mrow><annotation encoding=\"application/x-tex\">-6</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"47.00\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m24\" intent=\":literal\"><semantics><mn>47.00</mn><annotation encoding=\"application/x-tex\">47.00</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><math alttext=\"500\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m25\" intent=\":literal\"><semantics><mn>500</mn><annotation encoding=\"application/x-tex\">500</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><math alttext=\"1.3\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m26\" intent=\":literal\"><semantics><mn>1.3</mn><annotation encoding=\"application/x-tex\">1.3</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><math alttext=\"-10\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m27\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>10</mn></mrow><annotation encoding=\"application/x-tex\">-10</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><math alttext=\"51.00\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T2.m28\" intent=\":literal\"><semantics><mn>51.00</mn><annotation encoding=\"application/x-tex\">51.00</annotation></semantics></math></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "overlap",
            "subset",
            "volume",
            "against",
            "100sample",
            "speech",
            "hyperparameters",
            "gemini",
            "evaluated",
            "all",
            "attack",
            "results",
            "speed",
            "−1010",
            "impact",
            "−88",
            "asr",
            "−66",
            "acoustic",
            "pro",
            "sacredbench"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">The ablation results, shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T2\" title=\"Table 2 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, reveal that attack efficacy is most sensitive to parameters that increase the subtlety of the harmful instruction. We observe that a higher playback speed, a lower volume, and a longer overlap duration all correlate with a higher Attack Success Rate. This supports our hypothesis that the attack is most potent when the malicious content is acoustically framed as subliminal information&#8212;clearly perceived by the model, yet subtle enough to bypass its safety filters.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Recent progress in large language models (LLMs) has enabled understanding of both speech and non-speech audio, but exposing new safety risks emerging from complex audio inputs that are inadequately handled by current safeguards. We introduce SACRED-Bench (Speech&#8211;Audio Composition for RED-teaming) to evaluate the robustness of LLMs under complex audio-based attacks. Unlike existing perturbation-based methods that rely on noise optimization or white-box access, SACRED-Bench exploits speech&#8211;audio composition mechanisms. SACRED-Bench adopts three mechanisms: (a) speech overlap and multi-speaker dialogue, which embeds harmful prompts beneath or alongside benign speech; (b) speech-audio mixture, which imply unsafe intent via non-speech audio alongside benign speech or audio; and (c) diverse spoken instruction formats (open-ended QA, yes/no) that evade text-only filters. Experiments show that, even Gemini 2.5 Pro, the state-of-the-art proprietary LLM, still exhibits 66% attack success rate in SACRED-Bench test set, exposing vulnerabilities under cross-modal, speech&#8211;audio composition attacks. To bridge this gap, we propose SALMONN-Guard, the first guard model that jointly inspects speech, audio, and text for safety judgments, reducing attack success down to 20%. Our results highlight the need for audio-aware defenses for the safety of multimodal LLMs. The benchmark and SALMONN-Guard checkpoints can be found at <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/tsinghua-ee/SACRED-Bench\" title=\"\">https://huggingface.co/datasets/tsinghua-ee/SACRED-Bench</a>. <span class=\"ltx_text\" style=\"--ltx-fg-color:#FF0000;\">Warning: this paper includes examples that may be offensive or harmful.</span></p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "overlap",
                    "pro",
                    "attack",
                    "results",
                    "sacredbench"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we introduce Speech-Audio Composition for RED-teaming Benchmark (<span class=\"ltx_text ltx_font_bold\">SACRED-Bench</span>), a new highly effective audio jailbreaking approach to extensively exploit the complexity of audio signals for red-teaming. Instead of relying on artificial signal manipulations or adversarial training, SACRED-Bench leverages the composition of speech and audio cues to jailbreak multimodal models. Specifically, harmful audio signals are constructed using the following three types of composition mechanisms: (a). <em class=\"ltx_emph ltx_font_italic\">Speech overlap and multi-speaker dialogue</em>: Embedding harmful speech beneath or alongside benign utterances, or within a long spoken dialogue to bypass safety filters. (b). <em class=\"ltx_emph ltx_font_italic\">Speech-audio mixture</em>: Implying harmful intent or content through non-verbal sound events rather than explicit speech content, and (c). <em class=\"ltx_emph ltx_font_italic\">Diverse spoken question format</em>: Using not only open-ended question answering (QA), but also binary Yes-No questions in the instructions, which can not be detected or prevented by text-only guard models.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench",
                    "overlap"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Based on the construction principles, we curate the SACRED-Bench dataset containing 30 hours of training audio and 7 hours of test data. Our experiments show that even state-of-the-art proprietary LLMs such as Google Gemini 2.5 pro, still has over 66% attack success rates (ASR) under attacks in SACRED-Bench test set. Such vulnerability is particularly attribute to the insufficiency of text-only safeguard mechanisms that are prevailing among current LLM providers, where the guard only examines the safety of the output text content. To mitigate this gap, we propose SALMONN-Guard, a safeguarding LLM designed to incorporate speech and audio as input in addition to text for safety judgments. SALMONN-Guard drastically reduced ASR on SACRED-Bench test set down to around 20%, effectively mitigating speech-audio-composition attacks. The main contributions of our paper can be summarized as follows.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "pro",
                    "attack",
                    "sacredbench",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Experiments show that as high as 66% ASR are achieved even under the guardrails of Gemini 2.5 Pro using SACRED-Bench test set, highlighting the vulnerability of current safeguarding methods under complex speech-audio composition and cross-modal attacks.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "pro",
                    "sacredbench",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SALMONN-Guard, the first guard model that jointly examines speech, audio and text to mitigate SACRED-based attacks, which effectively reduces the attack success rate down to 20%.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "attack"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Audio-based red-teaming and jailbreaking work has been developed more recently. Specifically, harmful speech synthesis and speech-text interleaved attack methods <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite> have been developed as earlier examples, showing alarming attack success rate on widely-used LLMs. More recently, audio-manipulation-based attacks combined with dedicated optimization loops have been developed <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cheng2025jailbreakaudiobenchindepthevaluationanalysis</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>)</cite>. A comprehensive benchmark aggregating aforementioned attack methods is provided in <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peng2025jalmbenchbenchmarkingjailbreakvulnerabilities</span>)</cite>.\nHowever, these attack only explore speech without non-speech audio, basic audio manipulations such as speed perturbation or noise injection, and single-speaker speech. In contrast, SACRED-Bench focuses on the complex nature of audio signals and incorporates much richer audio elements. On the other hand, not much work has been done on the defense side for audio LLMs, except for the noise-injection defense approach was adopted <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peri2024speechguardexploringadversarialrobustness</span>)</cite>. This paper proposes the first general audio guard model to ensure safety of audio LLMs.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench",
                    "attack",
                    "speed"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Explore complexity of speech signal.</span> The construction of SACRED-Bench systematically incorporates multi-speaker and overlapped speech. This principle ensures that our benchmark evaluates a model&#8217;s ability to process complex speech signals instead of just understanding clean, single-source speech, thereby reflecting the richness and ambiguity of real-world audio inputs.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Exploiting non-speech audio.</span> While previous work predominantly focuses on speech content <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite>, non-speech audio often carries harmful content beyond words, such as violence and pornography. SACRED-Bench exploits harmful audio by embedding them in the benign speech stream. This approach crafts audio capable of bypassing unimodal safety filters that are not attuned to speech-audio mixture complexities.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To create a comprehensive and challenging set of prompts, we aggregated harmful instructions from a wide array of established red-teaming benchmarks. Specifically, our collection is drawn from AdvBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">zou2023AdvBench</span>)</cite>, MM-SafetyBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mmsafety</span>)</cite>, and HarmBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mazeika2024harmbench</span>)</cite>. By combining prompts from these diverse sources, we ensure our test cases cover an extensive spectrum of risk categories. This aggregated pool serves as the textual basis for generating the harmful speech and conversational content used in our benchmark. The distribution of harmful content in SACRED-Bench test set is shown in Fig. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.F2\" title=\"Figure 2 &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. To create harmful speech instructions, ChatTTS engine was adopted to synthesize from these text instructions.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For attacks requiring a benign audio carrier, such as the speech overlap and spoken dialogue methods, we utilized the VoiceBank-DEMAND dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voicebank</span>)</cite>. As a widely-used corpus known for its high-quality clean speech from a variety of speakers, its public accessibility and high-quality audio make it an ideal source of harmless speech to serve as the background or conversational filler in our synthesized audio samples.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "overlap"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Speech Overlap technique is engineered to exploit the principles of auditory stream fusion, embedding a harmful instruction within a benign utterance so seamlessly to create confusion to the LLM. The process is shown in Fig. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.F3.sf1\" title=\"Figure 3(a) &#8227; Figure 3 &#8227; 3.1.3 Harmful Audio Events &#8227; 3.1 Source Material Preparation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">3(a)</span></a>. The goal is to create a single and coherent audio stream where the malicious payload is carefully obscured by both its context and its acoustic properties, while maintaining the malicious content to be perceptible by human beings.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "overlap",
                    "acoustic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">With the semantic stage set, we then apply the second layer of deception at the signal level: acoustic masking. After synthesizing both the benign carrier and the harmful payload using the ChatTTS engine, we manipulate the harmful audio to reduce its perceptual salience by adjusting key acoustic parameters, including its volume, playback speed, and temporal overlap. The two streams are then composed using a cross-fade into a single, fluid utterance. Crucially, the chosen parameters ensure that the harmful content, while subtle, remains fully perceptible to the model, as we validate in our analysis. A detailed empirical justification for our choice of these hyperparameters is provided in our ablation study (Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.SS3\" title=\"5.3 Ablation Studies &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">5.3</span></a>). The final composition results in an utterance where the malicious instruction is both contextually justified and acoustically concealed.</p>\n\n",
                "matched_terms": [
                    "hyperparameters",
                    "overlap",
                    "volume",
                    "acoustic",
                    "results",
                    "speed"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This format is designed to test the model&#8217;s fundamental ability to detect harmful content. For each adversarial audio sample, we pose the direct textual question: &#8220;Does this audio contain harmful content?&#8221;. The evaluation metric is the Attack Success Rate (ASR %). Since every audio sample in our benchmark is inherently harmful, an attack is considered successful if the model incorrectly responds with &#8220;No&#8221;. This ASR provides a clear measure of the model&#8217;s failure rate in its most basic threat identification capabilities.</p>\n\n",
                "matched_terms": [
                    "attack",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This format is designed to test a model&#8217;s ability to comprehend and act upon (or refuse to act upon) the harmful content identified in the audio. After providing the adversarial audio, we submit a textual prompt that asks the model to engage with the malicious information directly. The prompts typically ask the model to identify, extract, or elaborate on the harmful aspects of the audio. The evaluation of the model&#8217;s response is automated using Gemini 2.5 Pro as an independent judge. We measure the Attack Success Rate (ASR %) by providing the model&#8217;s generated text to a Gemini 2.5 Pro based classifier, which determines if the response complied with the harmful request or successfully refused it. The specific prompts and detailed scoring rubric used for this automated evaluation are provided in Appendix.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "pro",
                    "attack",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:679.9pt;height:158pt;vertical-align:-76.5pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<span class=\"ltx_p\">\n<span class=\"ltx_tabular ltx_align_middle\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Models</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Speech Overlap (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Dialogue (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Contextual Audio Cues (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Overall (%)</span></span></span>\n<span class=\"ltx_tr\" style=\"--ltx-bg-color:#E6E6E6;\">\n<span class=\"ltx_td ltx_align_left ltx_border_t ltx_colspan ltx_colspan_5\"><span class=\"ltx_text\" style=\"font-size:90%;--ltx-bg-color:#E6E6E6;\">Open-source Models</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2-Audio-7B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2-audio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">96.48</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.16</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2.5-Omni-7B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2.5_omni</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.78</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">87.02</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">92.83</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen3-Omni-30B-A3B-Instruct </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">xu2025qwen3</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">49.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">84.82</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">93.17</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.50</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Step-Audio 2 mini Base </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025step-audio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">90.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.49</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.33</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.57</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">MiniCPM-o 2.6 8B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yao2024minicpm</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.84</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">69.87</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.95</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Kimi-Audio-7B-Instruct </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025kimiaudio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">69.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">61.36</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">87.17</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.05</span></span></span>\n<span class=\"ltx_tr\" style=\"--ltx-bg-color:#E6E6E6;\">\n<span class=\"ltx_td ltx_align_left ltx_border_t ltx_colspan ltx_colspan_5\"><span class=\"ltx_text\" style=\"font-size:90%;--ltx-bg-color:#E6E6E6;\">Proprietary Models</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini 1.5 Pro </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gemini1.5pro</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">83.50</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.47</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.12</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini 2.5 Pro </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025gemini2.5</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">37.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">63.93</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">88.56</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">66.75</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">GPT-4o </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gpt4o</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">73.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">53.67</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.05</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SALMONN-Guard (ours)</span><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">12.93</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">14.08</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">5.16</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">11.32</span></span></span>\n</span><span class=\"ltx_text\" style=\"font-size:90%;\"/></span>\n</span></span></p>\n\n",
                "matched_terms": [
                    "speech",
                    "pro",
                    "gemini",
                    "overlap"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Acknowledging the scarcity of ethically-sourced harmful data, we synthesized our training corpus by leveraging established red-teaming benchmarks&#8212;AdvBench, MM-SafetyBench, and HarmBench&#8212;as a conceptual foundation. Instead of using the original prompts directly, we employ GPT-4o to generate a new, distinct set of harmful instructions, ensuring no direct data leakage. This process yields a training corpus of approximately <span class=\"ltx_text ltx_font_bold\">10k</span> instances (8,545 harmful, 1,828 benign), with the harmful data distributed across speech overlap (6,640), speech-audio mixture (986), and multi-speaker dialogue (919) instances. The benign samples are used to prevent model collapse to only outputting the unsafe class. To ensure a rigorous evaluation of generalization, we enforced a strict cross-dataset validation protocol: for any given attack category, the source benchmark used to inspire the training prompts was held out from the test set.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "attack",
                    "overlap"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We employed a two-stage fine-tuning curriculum to first build general robustness and then specialize in complex threats. In Stage 1, the model was trained for three epochs on the entire dataset. In Stage 2, we conducted five additional epochs of training exclusively on the multi-speaker dialogue subset to bolster the model&#8217;s capabilities against this cross-modal attacks that is particularly challenging for the model to learn. For parameter-efficient fine-tuning, we utilized Low-Rank Adaptation (LoRA), applying updates concurrently to the large language model, the audio encoder, and the aligner module. A comprehensive list of hyperparameters is provided in the Appendix.</p>\n\n",
                "matched_terms": [
                    "hyperparameters",
                    "against",
                    "subset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Evaluated Models</span>: Our evaluation includes several top-tier multimodal models, encompassing proprietary systems like Gemini 2.5 Pro <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025gemini2.5</span>)</cite>, Gemini 1.5 Pro <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gemini1.5pro</span>)</cite>, GPT-4o <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gpt4o</span>)</cite> and Kimi Audio <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025kimiaudio</span>)</cite>. Concurrently, we evaluate prominent open-source models, such as Qwen3-Omni <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">xu2025qwen3</span>)</cite>, Qwen2.5-Omni-7B <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2.5_omni</span>)</cite>, Qwen2-Audio-7B <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2-audio</span>)</cite>, MiniCPM-o 2.6 <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yao2024minicpm</span>)</cite>, and Step-Audio2 <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025step-audio</span>)</cite>. Furthermore, we include our proposed guard model, <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span>, in the evaluation to validate its effectiveness.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "pro",
                    "evaluated"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Benchmark and Metrics:</span> All experiments are conducted on our SACRED-Bench, which evaluates models against three attack methods: speech overlap, multi-speaker dialogue, and speech-audio mixture. Our major evaluation metric is the Attack Success Rate (ASR %), which quantifies the percentage of times a model fails to adhere to its safety alignment and complies with the malicious prompt. The classification of a successful attack varies by task format. For the binary classification task, an attack is successful if the model fails to correctly identify there is harmful content in the audio. For the Open-Ended task, we employ an automated evaluation pipeline where Gemini 2.5 Pro serves as a judge, classifying the target model&#8217;s generated response as either &#8220;harmful&#8221; (a successful attack) or &#8220;harmless&#8221;. Therefore, in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, higher ASR values consistently indicate a greater degree of vulnerability.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "overlap",
                    "all",
                    "pro",
                    "attack",
                    "against",
                    "sacredbench",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Proprietary Models Exhibit Exploitable Loopholes.</span>\nAs seen in the results, while top-tier models like Gemini 2.5 Pro demonstrate some defensive capabilities, they are far from infallible. Particularly under the speech-audio mixture attack, Gemini 2.5 Pro shows a high attack success rate of 88.56%, and its success rate for the Multi-speaker Dialogue attack is also significant at 63.93%. This suggests that current safety mechanisms may be more focused on analyzing explicit textual instructions, while being less capable of identifying implicit malicious intent conveyed through non-speech audio or complex conversational structures.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "pro",
                    "attack",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Open-Source Models Largely Lack Effective Audio Safeguards.</span>\nThe results indicate that multimodal models from the open-source community are almost entirely defenseless against SACRED attacks. For instance, Qwen2.5-Omni-7B and Qwen2-Audio-7B have attack success rates approaching 100% in most tests. This reflects a critical gap in the current open-source ecosystem: while the pursuit of performance and functionality is paramount, insufficient attention has been paid to the security of multimodal inputs, especially the robustness against complex audio scenarios.</p>\n\n",
                "matched_terms": [
                    "attack",
                    "against",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Analysis of Different Attack Strategies&#8217; Efficacy.</span>\nAn analysis of the individual attack strategies reveals that each method successfully exploits distinct architectural weaknesses. The <span class=\"ltx_text ltx_font_bold\">speech-audio mixture</span> method proved the most potent, with a staggering 88.56% ASR against Gemini 2.5 Pro and nearly 100% on several open-source models, underscoring a critical &#8217;cross-modal blindness.&#8217; Models adeptly transcribe a benign spoken query while completely ignoring the malicious intent conveyed by background audio. Similarly effective, the <span class=\"ltx_text ltx_font_bold\">Multi-speaker Dialogue</span> method demonstrates how requests can be obfuscated within a natural conversation, successfully bypassing safety filters that may only detect direct, command-like instructions. The high ASR of 63.93% against Gemini 2.5 Pro highlights the difficulty even advanced models face in assessing risks distributed throughout a long-form dialogue. Lastly, the <span class=\"ltx_text ltx_font_bold\">Speech Overlap</span> attack targeted the models&#8217; information processing in complex acoustic environments. Although Gemini 2.5 Pro showed improved resistance, high success rates against Gemini 1.5 Pro (74.89%) and the Qwen series confirm that for most models, disentangling overlapping audio remains a significant security flaw.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "overlap",
                    "acoustic",
                    "pro",
                    "attack",
                    "against",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Effectiveness of SALMONN-Guard as a Guard Model.</span>\nIn stark contrast to other models, our proposed <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span> demonstrates exceptional defensive performance. As shown in the last row of Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, SALMONN-Guard drastically reduces the success rate for all types of attacks. It slashes the ASR for speech-audio mixture from Gemini 2.5 Pro&#8217;s 88.56% to a mere 5.16%, and suppresses the ASRs for Speech Overlap and Multi-speaker Dialogue to 12.93% and 28.09%, respectively. <span class=\"ltx_text ltx_font_italic\">We also test SALMONN-Guard on all the benign audios used to composite SACRED-Bench as shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T5\" title=\"Table 5 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, and an 100% classification accuracy was achieved where none of them were flagged as harmful.</span> This result fully validates the effectiveness of our proposed approach: training a specialized, lightweight guard model to preemptively identify and intercept malicious audio inputs is a viable and highly efficient path to protecting downstream LLMs from complex audio-based attacks.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "overlap",
                    "all",
                    "sacredbench",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, we conducted an ablation study on the acoustic attributes of the speech overlap attack. To ensure intelligibility of audio mixture, in addition to manual listening check conducted among co-authors, we prompt Gemini 2.5 Pro to describe the audio content. If the description matches both parts of the speech, or refuses to generate one side due to safety reasons, we consider it as perceptible. As a results, 93% of the samples in the speech overlap partition can be clearly perceived by Gemini 2.5 pro. This ensures that the speech overlap is sufficiently intelligible given that Gemini 2.5 pro is imperfect in understanding overlapped speech.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "overlap",
                    "acoustic",
                    "pro",
                    "attack",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Furthermore, we conducted an ablation study on the Multi-speaker Dialogue attack to isolate the source of its efficacy. As shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T3\" title=\"Table 3 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, we evaluated Gemini 1.5 Pro against unimodal baselines. The results demonstrate that our cross-modal Text + Audio approach (78.58% ASR) is significantly more potent than either a Text-Only (57.96% ASR) or Audio-Only (65.03% ASR) attack. This confirms that the attack&#8217;s high success rate stems from the synergistic effect of pairing a benign text prompt with a malicious audio context, a strategy that effectively bypasses unimodal safety checks.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "evaluated",
                    "pro",
                    "attack",
                    "against",
                    "results",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To highlight the unique nature of our speech-audio composition-based attacks and evaluate the generalization of our defense, we compare model performance against two recent perturbation-based audio jailbreaking methods: Speech Insertion <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite> and Speech Editing <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cheng2025jailbreakaudiobenchindepthevaluationanalysis</span>)</cite>. The evaluation data for these methods is sourced from JALMBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peng2025jalmbenchbenchmarkingjailbreakvulnerabilities</span>)</cite>. For Speech Insertion, we use the 246 samples from the SSJ subset. For Speech Editing, we use a 100-sample subset from AMSE, which involves 18 distinct edits per sample, resulting in 1,800 total audio inputs. The results, presented in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T4\" title=\"Table 4 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, reveal that our methods exploit a fundamentally different class of vulnerabilities for which current models are largely unprepared. This analysis leads to two critical findings.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "subset",
                    "against",
                    "results",
                    "100sample"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, the results demonstrate that our speech-audio composition-based attacks pose a far greater challenge to state-of-the-art LLMs than prior methods. For instance, while Gemini 2.5 Pro shows some resilience to Speech Insertion (13.41% ASR) and Speech Editing (23.00% ASR), its vulnerability skyrockets to 65.41% ASR on SACRED-Bench. This trend is even more pronounced for open-source models like Qwen3-Omni, whose ASR jumps from 8.94% on Speech Insertion to 81.50% on our benchmark. This disparity underscores that our methods, which manipulate semantic and contextual cues, are fundamentally more effective at bypassing modern safety alignments than attacks that rely on signal-level perturbations.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "pro",
                    "results",
                    "sacredbench",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, and more importantly, the results reveal the remarkable generalization of SALMONN-Guard. It is crucial to note that SALMONN-Guard was trained exclusively on our SACRED-Bench data and was never fine-tuned on samples from these other attack distributions. Despite this, it demonstrates near-perfect defensive capabilities, reducing the ASR for Speech Insertion to 0.00% and for Speech Editing to just 3.00%. This indicates that by training on our diverse and complex composition-based attacks, SALMONN-Guard has learned to recognize the underlying principles of malicious audio manipulation, rather than merely overfitting to the patterns in its training set. Its ability to neutralize entirely unseen attack vectors validates it not just as a defense against SACRED, but as a robust and generalizable safeguard for the broader audio modality.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench",
                    "attack",
                    "against",
                    "results",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We introduced SACRED-Bench, a benchmark demonstrating that compositional audio attacks can effectively bypass existing safeguards. Our experiments revealed significant vulnerabilities in state-of-the-art LLMs, with an Attack Success Rate exceeding 66% on Gemini 2.5 Pro, exposing the critical limitations of text-centric safety filters. As a countermeasure, our proposed SALMONN-Guard successfully reduced the ASR to approximately 20% by performing holistic multimodal safety checks. This paper underscores the urgent need to develop robust, truly multimodal safety paradigms for the next generation of audio LLMs.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "pro",
                    "attack",
                    "sacredbench",
                    "asr"
                ]
            }
        ]
    },
    "S5.T3": {
        "source_file": "Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard",
        "caption": "Table 3: Ablation study on the Multi-speaker Dialogue attack, evaluated on Gemini 1.5 Pro. We compare our proposed method against unimodal baselines: an “Audio-Only” setup with harmful speech and a “Text-Only” setup with a direct harmful instruction.",
        "body": "Attack Method\nASR (%)\n\n\nText-Only (Harmful Instruction)\n57.9657.96\n\n\nAudio-Only (Harmful Speech)\n65.0365.03\n\n\nText + Audio (Our Dialogue Method)\n78.5878.58",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Attack Method</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">ASR (%)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">Text-Only (Harmful Instruction)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"57.96\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m1\" intent=\":literal\"><semantics><mn>57.96</mn><annotation encoding=\"application/x-tex\">57.96</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Audio-Only (Harmful Speech)</td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"65.03\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m2\" intent=\":literal\"><semantics><mn>65.03</mn><annotation encoding=\"application/x-tex\">65.03</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\">Text + Audio (Our Dialogue Method)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><math alttext=\"78.58\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m3\" intent=\":literal\"><semantics><mn>78.58</mn><annotation encoding=\"application/x-tex\">78.58</annotation></semantics></math></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "compare",
            "ablation",
            "text",
            "textonly",
            "multispeaker",
            "proposed",
            "against",
            "our",
            "gemini",
            "speech",
            "unimodal",
            "audio",
            "evaluated",
            "audioonly",
            "harmful",
            "instruction",
            "attack",
            "dialogue",
            "“textonly”",
            "“audioonly”",
            "asr",
            "study",
            "direct",
            "method",
            "pro",
            "baselines",
            "setup"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Furthermore, we conducted an ablation study on the Multi-speaker Dialogue attack to isolate the source of its efficacy. As shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T3\" title=\"Table 3 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, we evaluated Gemini 1.5 Pro against unimodal baselines. The results demonstrate that our cross-modal Text + Audio approach (78.58% ASR) is significantly more potent than either a Text-Only (57.96% ASR) or Audio-Only (65.03% ASR) attack. This confirms that the attack&#8217;s high success rate stems from the synergistic effect of pairing a benign text prompt with a malicious audio context, a strategy that effectively bypasses unimodal safety checks.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Recent progress in large language models (LLMs) has enabled understanding of both speech and non-speech audio, but exposing new safety risks emerging from complex audio inputs that are inadequately handled by current safeguards. We introduce SACRED-Bench (Speech&#8211;Audio Composition for RED-teaming) to evaluate the robustness of LLMs under complex audio-based attacks. Unlike existing perturbation-based methods that rely on noise optimization or white-box access, SACRED-Bench exploits speech&#8211;audio composition mechanisms. SACRED-Bench adopts three mechanisms: (a) speech overlap and multi-speaker dialogue, which embeds harmful prompts beneath or alongside benign speech; (b) speech-audio mixture, which imply unsafe intent via non-speech audio alongside benign speech or audio; and (c) diverse spoken instruction formats (open-ended QA, yes/no) that evade text-only filters. Experiments show that, even Gemini 2.5 Pro, the state-of-the-art proprietary LLM, still exhibits 66% attack success rate in SACRED-Bench test set, exposing vulnerabilities under cross-modal, speech&#8211;audio composition attacks. To bridge this gap, we propose SALMONN-Guard, the first guard model that jointly inspects speech, audio, and text for safety judgments, reducing attack success down to 20%. Our results highlight the need for audio-aware defenses for the safety of multimodal LLMs. The benchmark and SALMONN-Guard checkpoints can be found at <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/tsinghua-ee/SACRED-Bench\" title=\"\">https://huggingface.co/datasets/tsinghua-ee/SACRED-Bench</a>. <span class=\"ltx_text\" style=\"--ltx-fg-color:#FF0000;\">Warning: this paper includes examples that may be offensive or harmful.</span></p>\n\n",
                "matched_terms": [
                    "gemini",
                    "speech",
                    "dialogue",
                    "text",
                    "textonly",
                    "multispeaker",
                    "harmful",
                    "instruction",
                    "pro",
                    "attack",
                    "audio",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Large language models (LLMs) nowadays are capable of understanding speech and non-speech audio, enabling natural and convenient modes of interaction. However, alongside these advancements come significant safety and reliability challenges. Preliminary efforts have been made recently to discover potential risks of audio LLMs by designing various jailbreaking methods <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">audiotrust</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">chen2025audiojailbreakjailbreakattacksendtoend</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">roh2025multilingualmultiaccentjailbreakingaudio</span>)</cite>. In particular, perturbation-based attacks have been the dominant type of jailbreaking approach, which includes injecting learned noise <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">archilles</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">sadasivan2025attackersnoisemanipulateaudiobased</span>)</cite> or applying selected transformations to the audio input <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>)</cite>. These methods heavily rely on optimizing the noise or perturbation, often limited to white-box open-source models or requiring intensive computation for optimization iterations.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we introduce Speech-Audio Composition for RED-teaming Benchmark (<span class=\"ltx_text ltx_font_bold\">SACRED-Bench</span>), a new highly effective audio jailbreaking approach to extensively exploit the complexity of audio signals for red-teaming. Instead of relying on artificial signal manipulations or adversarial training, SACRED-Bench leverages the composition of speech and audio cues to jailbreak multimodal models. Specifically, harmful audio signals are constructed using the following three types of composition mechanisms: (a). <em class=\"ltx_emph ltx_font_italic\">Speech overlap and multi-speaker dialogue</em>: Embedding harmful speech beneath or alongside benign utterances, or within a long spoken dialogue to bypass safety filters. (b). <em class=\"ltx_emph ltx_font_italic\">Speech-audio mixture</em>: Implying harmful intent or content through non-verbal sound events rather than explicit speech content, and (c). <em class=\"ltx_emph ltx_font_italic\">Diverse spoken question format</em>: Using not only open-ended question answering (QA), but also binary Yes-No questions in the instructions, which can not be detected or prevented by text-only guard models.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "dialogue",
                    "textonly",
                    "multispeaker",
                    "harmful",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Based on the construction principles, we curate the SACRED-Bench dataset containing 30 hours of training audio and 7 hours of test data. Our experiments show that even state-of-the-art proprietary LLMs such as Google Gemini 2.5 pro, still has over 66% attack success rates (ASR) under attacks in SACRED-Bench test set. Such vulnerability is particularly attribute to the insufficiency of text-only safeguard mechanisms that are prevailing among current LLM providers, where the guard only examines the safety of the output text content. To mitigate this gap, we propose SALMONN-Guard, a safeguarding LLM designed to incorporate speech and audio as input in addition to text for safety judgments. SALMONN-Guard drastically reduced ASR on SACRED-Bench test set down to around 20%, effectively mitigating speech-audio-composition attacks. The main contributions of our paper can be summarized as follows.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "speech",
                    "text",
                    "textonly",
                    "pro",
                    "attack",
                    "audio",
                    "our",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SACRED-Bench, the first audio red-teaming benchmark that extensively exploits the complexity of audio inputs, crafting effective jailbreaking attacks without requiring adversarial training loops. SACRED-Bench additionally leverages different QA formats to bypass text-only guardrails.</p>\n\n",
                "matched_terms": [
                    "textonly",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Experiments show that as high as 66% ASR are achieved even under the guardrails of Gemini 2.5 Pro using SACRED-Bench test set, highlighting the vulnerability of current safeguarding methods under complex speech-audio composition and cross-modal attacks.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "pro",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SALMONN-Guard, the first guard model that jointly examines speech, audio and text to mitigate SACRED-based attacks, which effectively reduces the attack success rate down to 20%.</p>\n\n",
                "matched_terms": [
                    "text",
                    "speech",
                    "attack",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Audio-based red-teaming and jailbreaking work has been developed more recently. Specifically, harmful speech synthesis and speech-text interleaved attack methods <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite> have been developed as earlier examples, showing alarming attack success rate on widely-used LLMs. More recently, audio-manipulation-based attacks combined with dedicated optimization loops have been developed <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cheng2025jailbreakaudiobenchindepthevaluationanalysis</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>)</cite>. A comprehensive benchmark aggregating aforementioned attack methods is provided in <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peng2025jalmbenchbenchmarkingjailbreakvulnerabilities</span>)</cite>.\nHowever, these attack only explore speech without non-speech audio, basic audio manipulations such as speed perturbation or noise injection, and single-speaker speech. In contrast, SACRED-Bench focuses on the complex nature of audio signals and incorporates much richer audio elements. On the other hand, not much work has been done on the defense side for audio LLMs, except for the noise-injection defense approach was adopted <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peri2024speechguardexploringadversarialrobustness</span>)</cite>. This paper proposes the first general audio guard model to ensure safety of audio LLMs.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "attack",
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Explore complexity of speech signal.</span> The construction of SACRED-Bench systematically incorporates multi-speaker and overlapped speech. This principle ensures that our benchmark evaluates a model&#8217;s ability to process complex speech signals instead of just understanding clean, single-source speech, thereby reflecting the richness and ambiguity of real-world audio inputs.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "multispeaker",
                    "audio",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Exploiting non-speech audio.</span> While previous work predominantly focuses on speech content <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite>, non-speech audio often carries harmful content beyond words, such as violence and pornography. SACRED-Bench exploits harmful audio by embedding them in the benign speech stream. This approach crafts audio capable of bypassing unimodal safety filters that are not attuned to speech-audio mixture complexities.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "unimodal",
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Employing indirect question formats.</span> Hiding part of harmful content in the audio can potentially bypass the text-based guardrails adopted in many proprietary LLMs. On one hand, we prompt the model to acknowledge the harmlessness of the audio by asking whether the audio has harmful content. On the other hand, we partially hide harmful information in the audio by tasking the model to engage in a harmful conversation where the text content are mostly benign. Both can bypass text-based guardrails.</p>\n\n",
                "matched_terms": [
                    "text",
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To create a comprehensive and challenging set of prompts, we aggregated harmful instructions from a wide array of established red-teaming benchmarks. Specifically, our collection is drawn from AdvBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">zou2023AdvBench</span>)</cite>, MM-SafetyBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mmsafety</span>)</cite>, and HarmBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mazeika2024harmbench</span>)</cite>. By combining prompts from these diverse sources, we ensure our test cases cover an extensive spectrum of risk categories. This aggregated pool serves as the textual basis for generating the harmful speech and conversational content used in our benchmark. The distribution of harmful content in SACRED-Bench test set is shown in Fig. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.F2\" title=\"Figure 2 &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. To create harmful speech instructions, ChatTTS engine was adopted to synthesize from these text instructions.</p>\n\n",
                "matched_terms": [
                    "text",
                    "speech",
                    "harmful",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For attacks requiring a benign audio carrier, such as the speech overlap and spoken dialogue methods, we utilized the VoiceBank-DEMAND dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voicebank</span>)</cite>. As a widely-used corpus known for its high-quality clean speech from a variety of speakers, its public accessibility and high-quality audio make it an ideal source of harmless speech to serve as the background or conversational filler in our synthesized audio samples.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "dialogue",
                    "audio",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To construct attacks that leverage auditory context to imply harmful intent, we curated a library of potent audio tracks. These tracks were extracted from publicly available online videos featuring adult-oriented or intimate content. The design of these attacks hinges on pairing this contextually-charged audio with otherwise benign speech. This creates a malicious or harmful audio-based query, designed to test whether a model&#8217;s safety mechanisms can recognize situational context that is entirely absent from the speech content.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We adopts three types of composition mechanisms, including (i). speech overlapping, (ii). multi-speaker dialogue and (iii). speech-audio mixture, as described in this section. Detailed dataset statistics are shown in Appendix <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#A1\" title=\"Appendix A Detailed SACRED-Bench Statistics &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">A</span></a>.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "multispeaker",
                    "dialogue"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Speech Overlap technique is engineered to exploit the principles of auditory stream fusion, embedding a harmful instruction within a benign utterance so seamlessly to create confusion to the LLM. The process is shown in Fig. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.F3.sf1\" title=\"Figure 3(a) &#8227; Figure 3 &#8227; 3.1.3 Harmful Audio Events &#8227; 3.1 Source Material Preparation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">3(a)</span></a>. The goal is to create a single and coherent audio stream where the malicious payload is carefully obscured by both its context and its acoustic properties, while maintaining the malicious content to be perceptible by human beings.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "instruction",
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The first layer of deception is semantic. To prevent the harmful instruction from appearing abrupt or out of context, we construct a plausible &#8220;carrier&#8221; narrative. For each harmful behavior, we use GPT-4o to generate an innocuous scenario that creates a logical on-ramp to the malicious topic. For instance, a harmful instruction about creating a dangerous substance is prefaced with a carrier text like, &#8220;I&#8217;m writing a fictional novel and need to describe a scene in a chemistry lab for one of my characters.&#8221; This provides a logical pretext for the harmful payload, lowering the suspicion threshold and making the entire utterance appear far less suspicious.</p>\n\n",
                "matched_terms": [
                    "text",
                    "instruction",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">With the semantic stage set, we then apply the second layer of deception at the signal level: acoustic masking. After synthesizing both the benign carrier and the harmful payload using the ChatTTS engine, we manipulate the harmful audio to reduce its perceptual salience by adjusting key acoustic parameters, including its volume, playback speed, and temporal overlap. The two streams are then composed using a cross-fade into a single, fluid utterance. Crucially, the chosen parameters ensure that the harmful content, while subtle, remains fully perceptible to the model, as we validate in our analysis. A detailed empirical justification for our choice of these hyperparameters is provided in our ablation study (Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.SS3\" title=\"5.3 Ablation Studies &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">5.3</span></a>). The final composition results in an utterance where the malicious instruction is both contextually justified and acoustically concealed.</p>\n\n",
                "matched_terms": [
                    "ablation",
                    "study",
                    "harmful",
                    "instruction",
                    "audio",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent findings in vision-language safety, particularly the &#8220;Visual Safety Information Leakage&#8221; problem <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025vlsbench</span>)</cite>, have demonstrated that many multimodal models could be easily aligned by text-only training data because the text prompt often revealed the harmful nature of the accompanying image. Our work extends this core insight to the speech-audio domain. We hypothesize that a similar vulnerability exists: a model&#8217;s safety alignment might operate inconsistently across modalities if a benign-on-its-own textual query is paired with a malicious audio context, causing the text-only safety filter to be bypassed.</p>\n\n",
                "matched_terms": [
                    "text",
                    "textonly",
                    "harmful",
                    "audio",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our construction process is engineered to induce this precise semantic gap, as illustrated in Fig. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.F3.sf2\" title=\"Figure 3(b) &#8227; Figure 3 &#8227; 3.1.3 Harmful Audio Events &#8227; 3.1 Source Material Preparation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">3(b)</span></a>. We first use GPT-4o to transform a direct harmful instruction, such as a question on how to develop nuclear weapons, into a plausible, multi-turn dialogue script between two speakers. This script rephrases the malicious request into a conversation, touching upon its complexities and design considerations, thereby cloaking the harmful intent in a conversational structure that lacks the clear, directive markers of a direct command.</p>\n\n",
                "matched_terms": [
                    "dialogue",
                    "harmful",
                    "instruction",
                    "direct",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In parallel, we craft the textual component of the attack: a completely innocuous and referential query. This question, also generated by GPT-4o, is semantically neutral on its own but is designed to act as a pointer, or a semantic trigger, to the content within the audio. For example, a corresponding query might be, &#8220;How would I create the device mentioned in the discussion?&#8221; In isolation, this question is safe. However, when paired with the dialogue, it becomes a direct prompt for the model to synthesize and present the harmful information it has just heard.</p>\n\n",
                "matched_terms": [
                    "dialogue",
                    "harmful",
                    "attack",
                    "direct",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The final step is to bring these two components together into a cohesive auditory scene. We utilize the multi-speaker capabilities of the ChatTTS engine to synthesize the dialogue script into a realistic audio file, assigning distinct vocal characteristics to each speaker. The final attack prompt is the combination of this harmful conversational audio with the benign textual trigger. This presents the model with a complex jailbreaking challenge, forcing it to reconcile a harmless-looking text instruction with a clearly malicious audio payload, thereby testing the true depth of its cross-modal safety reasoning.</p>\n\n",
                "matched_terms": [
                    "dialogue",
                    "text",
                    "multispeaker",
                    "harmful",
                    "instruction",
                    "attack",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This method pivots the attack vector from explicit linguistic content to the more subtle realm of implicit environmental context. The central premise is to test whether a model&#8217;s safety mechanisms are merely sophisticated textual processors or if they possess a genuine multimodal understanding of an auditory scene. We achieve this by pairing an safe spoken question with an audio event that carries a harmful intention. The entire sample is designed to appear benign to a system that only transcribes and analyzes the spoken words, while being obviously unsafe to one that comprehends the full context.</p>\n\n",
                "matched_terms": [
                    "attack",
                    "method",
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To construct these attacks, we curated a library of harmful audio tracks. These tracks were extracted directly from publicly available videos on online platforms featuring adult-oriented, violence or criminal content. This process yielded a collection of audio files that, while not containing explicit instructions, carry a strong and inherently inappropriate contextual meaning from their source.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The final stage involves mixing auditory scene. We take a benign &#8220;carrier&#8221; track from the VoiceBank-DEMAND dataset and overlay one of the harmful contextual audio tracks from our curated library as a background layer. The background sound is mixed at a clearly audible volume. This creates a powerful conflict: for instance, an academic lecture playing over the distinct sounds of an intimate scenario. A model with a text-centric safety filter would likely transcribe the harmless lecture and clear the input. However, a truly multimodal safety system is challenged to detect the disturbing nature of the background context and correctly flag the entire sample as unsafe. This method directly probes the model&#8217;s ability to reason about situational appropriateness.</p>\n\n",
                "matched_terms": [
                    "method",
                    "audio",
                    "our",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This format is designed to test the model&#8217;s fundamental ability to detect harmful content. For each adversarial audio sample, we pose the direct textual question: &#8220;Does this audio contain harmful content?&#8221;. The evaluation metric is the Attack Success Rate (ASR %). Since every audio sample in our benchmark is inherently harmful, an attack is considered successful if the model incorrectly responds with &#8220;No&#8221;. This ASR provides a clear measure of the model&#8217;s failure rate in its most basic threat identification capabilities.</p>\n\n",
                "matched_terms": [
                    "harmful",
                    "attack",
                    "direct",
                    "audio",
                    "our",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This format is designed to test a model&#8217;s ability to comprehend and act upon (or refuse to act upon) the harmful content identified in the audio. After providing the adversarial audio, we submit a textual prompt that asks the model to engage with the malicious information directly. The prompts typically ask the model to identify, extract, or elaborate on the harmful aspects of the audio. The evaluation of the model&#8217;s response is automated using Gemini 2.5 Pro as an independent judge. We measure the Attack Success Rate (ASR %) by providing the model&#8217;s generated text to a Gemini 2.5 Pro based classifier, which determines if the response complied with the harmful request or successfully refused it. The specific prompts and detailed scoring rubric used for this automated evaluation are provided in Appendix.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "text",
                    "harmful",
                    "pro",
                    "attack",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:679.9pt;height:158pt;vertical-align:-76.5pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<span class=\"ltx_p\">\n<span class=\"ltx_tabular ltx_align_middle\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Models</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Speech Overlap (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Dialogue (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Contextual Audio Cues (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Overall (%)</span></span></span>\n<span class=\"ltx_tr\" style=\"--ltx-bg-color:#E6E6E6;\">\n<span class=\"ltx_td ltx_align_left ltx_border_t ltx_colspan ltx_colspan_5\"><span class=\"ltx_text\" style=\"font-size:90%;--ltx-bg-color:#E6E6E6;\">Open-source Models</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2-Audio-7B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2-audio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">96.48</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.16</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2.5-Omni-7B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2.5_omni</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.78</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">87.02</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">92.83</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen3-Omni-30B-A3B-Instruct </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">xu2025qwen3</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">49.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">84.82</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">93.17</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.50</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Step-Audio 2 mini Base </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025step-audio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">90.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.49</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.33</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.57</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">MiniCPM-o 2.6 8B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yao2024minicpm</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.84</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">69.87</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.95</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Kimi-Audio-7B-Instruct </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025kimiaudio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">69.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">61.36</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">87.17</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.05</span></span></span>\n<span class=\"ltx_tr\" style=\"--ltx-bg-color:#E6E6E6;\">\n<span class=\"ltx_td ltx_align_left ltx_border_t ltx_colspan ltx_colspan_5\"><span class=\"ltx_text\" style=\"font-size:90%;--ltx-bg-color:#E6E6E6;\">Proprietary Models</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini 1.5 Pro </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gemini1.5pro</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">83.50</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.47</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.12</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini 2.5 Pro </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025gemini2.5</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">37.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">63.93</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">88.56</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">66.75</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">GPT-4o </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gpt4o</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">73.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">53.67</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.05</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SALMONN-Guard (ours)</span><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">12.93</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">14.08</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">5.16</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">11.32</span></span></span>\n</span><span class=\"ltx_text\" style=\"font-size:90%;\"/></span>\n</span></span></p>\n\n",
                "matched_terms": [
                    "gemini",
                    "speech",
                    "dialogue",
                    "pro",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Acknowledging the scarcity of ethically-sourced harmful data, we synthesized our training corpus by leveraging established red-teaming benchmarks&#8212;AdvBench, MM-SafetyBench, and HarmBench&#8212;as a conceptual foundation. Instead of using the original prompts directly, we employ GPT-4o to generate a new, distinct set of harmful instructions, ensuring no direct data leakage. This process yields a training corpus of approximately <span class=\"ltx_text ltx_font_bold\">10k</span> instances (8,545 harmful, 1,828 benign), with the harmful data distributed across speech overlap (6,640), speech-audio mixture (986), and multi-speaker dialogue (919) instances. The benign samples are used to prevent model collapse to only outputting the unsafe class. To ensure a rigorous evaluation of generalization, we enforced a strict cross-dataset validation protocol: for any given attack category, the source benchmark used to inspire the training prompts was held out from the test set.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "dialogue",
                    "multispeaker",
                    "harmful",
                    "attack",
                    "direct",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The foundation of <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span> is the <span class=\"ltx_text ltx_font_bold\">Qwen2.5-Omni-7B</span> model. As a state-of-the-art open-source multimodal model at this parameter scale, its strong native capabilities in comprehending both audio and text make it an ideal backbone for our proposed guard model.</p>\n\n",
                "matched_terms": [
                    "text",
                    "proposed",
                    "audio",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">There are two output modes in SALMONN-Guard. When tasked with assessing a standalone audio input, it can function as a conventional binary classifier, yielding a discrete label such as &#8220;harmful&#8221; or &#8220;harmless&#8221;. However, for its primary role in the holistic evaluation of joint text-audio queries, it directly intercepts harmful requests by generating a refusal like, &#8220;I&#8217;m sorry, I cannot assist with that request,&#8221; while allowing benign prompts to proceed for processing by a downstream task-specific LLM.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our primary objective is to adapt the powerful base model into a specialized guard model through Supervised Fine-Tuning (SFT) with standard cross-entropy loss. Concretely, SALMONN-Guard is trained to perform safety assessments for each sample by jointly processing both the audio input and any accompanying text prompt. This multimodal training scheme directly overcomes the vulnerability of text-only or spoken-content-only guardrails, yielding high efficacy in combating attacks in SACRED-Bench.</p>\n\n",
                "matched_terms": [
                    "text",
                    "textonly",
                    "audio",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We employed a two-stage fine-tuning curriculum to first build general robustness and then specialize in complex threats. In Stage 1, the model was trained for three epochs on the entire dataset. In Stage 2, we conducted five additional epochs of training exclusively on the multi-speaker dialogue subset to bolster the model&#8217;s capabilities against this cross-modal attacks that is particularly challenging for the model to learn. For parameter-efficient fine-tuning, we utilized Low-Rank Adaptation (LoRA), applying updates concurrently to the large language model, the audio encoder, and the aligner module. A comprehensive list of hyperparameters is provided in the Appendix.</p>\n\n",
                "matched_terms": [
                    "multispeaker",
                    "against",
                    "audio",
                    "dialogue"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Evaluated Models</span>: Our evaluation includes several top-tier multimodal models, encompassing proprietary systems like Gemini 2.5 Pro <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025gemini2.5</span>)</cite>, Gemini 1.5 Pro <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gemini1.5pro</span>)</cite>, GPT-4o <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gpt4o</span>)</cite> and Kimi Audio <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025kimiaudio</span>)</cite>. Concurrently, we evaluate prominent open-source models, such as Qwen3-Omni <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">xu2025qwen3</span>)</cite>, Qwen2.5-Omni-7B <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2.5_omni</span>)</cite>, Qwen2-Audio-7B <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2-audio</span>)</cite>, MiniCPM-o 2.6 <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yao2024minicpm</span>)</cite>, and Step-Audio2 <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025step-audio</span>)</cite>. Furthermore, we include our proposed guard model, <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span>, in the evaluation to validate its effectiveness.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "evaluated",
                    "proposed",
                    "pro",
                    "audio",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Benchmark and Metrics:</span> All experiments are conducted on our SACRED-Bench, which evaluates models against three attack methods: speech overlap, multi-speaker dialogue, and speech-audio mixture. Our major evaluation metric is the Attack Success Rate (ASR %), which quantifies the percentage of times a model fails to adhere to its safety alignment and complies with the malicious prompt. The classification of a successful attack varies by task format. For the binary classification task, an attack is successful if the model fails to correctly identify there is harmful content in the audio. For the Open-Ended task, we employ an automated evaluation pipeline where Gemini 2.5 Pro serves as a judge, classifying the target model&#8217;s generated response as either &#8220;harmful&#8221; (a successful attack) or &#8220;harmless&#8221;. Therefore, in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, higher ASR values consistently indicate a greater degree of vulnerability.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "speech",
                    "dialogue",
                    "multispeaker",
                    "harmful",
                    "pro",
                    "attack",
                    "against",
                    "audio",
                    "our",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We present the detailed experimental results in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>. Overall, the results shows that both leading proprietary and major open-source models unfortunately exhibit significant vulnerabilities when confronted with our proposed speech-audio composition attacks.</p>\n\n",
                "matched_terms": [
                    "proposed",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Proprietary Models Exhibit Exploitable Loopholes.</span>\nAs seen in the results, while top-tier models like Gemini 2.5 Pro demonstrate some defensive capabilities, they are far from infallible. Particularly under the speech-audio mixture attack, Gemini 2.5 Pro shows a high attack success rate of 88.56%, and its success rate for the Multi-speaker Dialogue attack is also significant at 63.93%. This suggests that current safety mechanisms may be more focused on analyzing explicit textual instructions, while being less capable of identifying implicit malicious intent conveyed through non-speech audio or complex conversational structures.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "dialogue",
                    "multispeaker",
                    "pro",
                    "attack",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Open-Source Models Largely Lack Effective Audio Safeguards.</span>\nThe results indicate that multimodal models from the open-source community are almost entirely defenseless against SACRED attacks. For instance, Qwen2.5-Omni-7B and Qwen2-Audio-7B have attack success rates approaching 100% in most tests. This reflects a critical gap in the current open-source ecosystem: while the pursuit of performance and functionality is paramount, insufficient attention has been paid to the security of multimodal inputs, especially the robustness against complex audio scenarios.</p>\n\n",
                "matched_terms": [
                    "attack",
                    "against",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Analysis of Different Attack Strategies&#8217; Efficacy.</span>\nAn analysis of the individual attack strategies reveals that each method successfully exploits distinct architectural weaknesses. The <span class=\"ltx_text ltx_font_bold\">speech-audio mixture</span> method proved the most potent, with a staggering 88.56% ASR against Gemini 2.5 Pro and nearly 100% on several open-source models, underscoring a critical &#8217;cross-modal blindness.&#8217; Models adeptly transcribe a benign spoken query while completely ignoring the malicious intent conveyed by background audio. Similarly effective, the <span class=\"ltx_text ltx_font_bold\">Multi-speaker Dialogue</span> method demonstrates how requests can be obfuscated within a natural conversation, successfully bypassing safety filters that may only detect direct, command-like instructions. The high ASR of 63.93% against Gemini 2.5 Pro highlights the difficulty even advanced models face in assessing risks distributed throughout a long-form dialogue. Lastly, the <span class=\"ltx_text ltx_font_bold\">Speech Overlap</span> attack targeted the models&#8217; information processing in complex acoustic environments. Although Gemini 2.5 Pro showed improved resistance, high success rates against Gemini 1.5 Pro (74.89%) and the Qwen series confirm that for most models, disentangling overlapping audio remains a significant security flaw.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "speech",
                    "dialogue",
                    "multispeaker",
                    "method",
                    "pro",
                    "attack",
                    "direct",
                    "against",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Effectiveness of SALMONN-Guard as a Guard Model.</span>\nIn stark contrast to other models, our proposed <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span> demonstrates exceptional defensive performance. As shown in the last row of Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, SALMONN-Guard drastically reduces the success rate for all types of attacks. It slashes the ASR for speech-audio mixture from Gemini 2.5 Pro&#8217;s 88.56% to a mere 5.16%, and suppresses the ASRs for Speech Overlap and Multi-speaker Dialogue to 12.93% and 28.09%, respectively. <span class=\"ltx_text ltx_font_italic\">We also test SALMONN-Guard on all the benign audios used to composite SACRED-Bench as shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T5\" title=\"Table 5 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, and an 100% classification accuracy was achieved where none of them were flagged as harmful.</span> This result fully validates the effectiveness of our proposed approach: training a specialized, lightweight guard model to preemptively identify and intercept malicious audio inputs is a viable and highly efficient path to protecting downstream LLMs from complex audio-based attacks.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "speech",
                    "dialogue",
                    "multispeaker",
                    "proposed",
                    "harmful",
                    "audio",
                    "our",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, we conducted an ablation study on the acoustic attributes of the speech overlap attack. To ensure intelligibility of audio mixture, in addition to manual listening check conducted among co-authors, we prompt Gemini 2.5 Pro to describe the audio content. If the description matches both parts of the speech, or refuses to generate one side due to safety reasons, we consider it as perceptible. As a results, 93% of the samples in the speech overlap partition can be clearly perceived by Gemini 2.5 pro. This ensures that the speech overlap is sufficiently intelligible given that Gemini 2.5 pro is imperfect in understanding overlapped speech.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "speech",
                    "ablation",
                    "study",
                    "pro",
                    "attack",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The ablation results, shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T2\" title=\"Table 2 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, reveal that attack efficacy is most sensitive to parameters that increase the subtlety of the harmful instruction. We observe that a higher playback speed, a lower volume, and a longer overlap duration all correlate with a higher Attack Success Rate. This supports our hypothesis that the attack is most potent when the malicious content is acoustically framed as subliminal information&#8212;clearly perceived by the model, yet subtle enough to bypass its safety filters.</p>\n\n",
                "matched_terms": [
                    "ablation",
                    "harmful",
                    "instruction",
                    "attack",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To highlight the unique nature of our speech-audio composition-based attacks and evaluate the generalization of our defense, we compare model performance against two recent perturbation-based audio jailbreaking methods: Speech Insertion <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite> and Speech Editing <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cheng2025jailbreakaudiobenchindepthevaluationanalysis</span>)</cite>. The evaluation data for these methods is sourced from JALMBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peng2025jalmbenchbenchmarkingjailbreakvulnerabilities</span>)</cite>. For Speech Insertion, we use the 246 samples from the SSJ subset. For Speech Editing, we use a 100-sample subset from AMSE, which involves 18 distinct edits per sample, resulting in 1,800 total audio inputs. The results, presented in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T4\" title=\"Table 4 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, reveal that our methods exploit a fundamentally different class of vulnerabilities for which current models are largely unprepared. This analysis leads to two critical findings.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "compare",
                    "against",
                    "audio",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, the results demonstrate that our speech-audio composition-based attacks pose a far greater challenge to state-of-the-art LLMs than prior methods. For instance, while Gemini 2.5 Pro shows some resilience to Speech Insertion (13.41% ASR) and Speech Editing (23.00% ASR), its vulnerability skyrockets to 65.41% ASR on SACRED-Bench. This trend is even more pronounced for open-source models like Qwen3-Omni, whose ASR jumps from 8.94% on Speech Insertion to 81.50% on our benchmark. This disparity underscores that our methods, which manipulate semantic and contextual cues, are fundamentally more effective at bypassing modern safety alignments than attacks that rely on signal-level perturbations.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "speech",
                    "pro",
                    "our",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, and more importantly, the results reveal the remarkable generalization of SALMONN-Guard. It is crucial to note that SALMONN-Guard was trained exclusively on our SACRED-Bench data and was never fine-tuned on samples from these other attack distributions. Despite this, it demonstrates near-perfect defensive capabilities, reducing the ASR for Speech Insertion to 0.00% and for Speech Editing to just 3.00%. This indicates that by training on our diverse and complex composition-based attacks, SALMONN-Guard has learned to recognize the underlying principles of malicious audio manipulation, rather than merely overfitting to the patterns in its training set. Its ability to neutralize entirely unseen attack vectors validates it not just as a defense against SACRED, but as a robust and generalizable safeguard for the broader audio modality.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "attack",
                    "against",
                    "audio",
                    "our",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We introduced SACRED-Bench, a benchmark demonstrating that compositional audio attacks can effectively bypass existing safeguards. Our experiments revealed significant vulnerabilities in state-of-the-art LLMs, with an Attack Success Rate exceeding 66% on Gemini 2.5 Pro, exposing the critical limitations of text-centric safety filters. As a countermeasure, our proposed SALMONN-Guard successfully reduced the ASR to approximately 20% by performing holistic multimodal safety checks. This paper underscores the urgent need to develop robust, truly multimodal safety paradigms for the next generation of audio LLMs.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "proposed",
                    "pro",
                    "attack",
                    "audio",
                    "our",
                    "asr"
                ]
            }
        ]
    },
    "S5.T4": {
        "source_file": "Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard",
        "caption": "Table 4: Attack Success Rate (ASR %) across different audio jailbreaking methods. Speech Insertion and Speech Editing are evaluated on the SSJ and AMSE subsets of JALMBench, respectively. The ASR for SACRED-Bench refers to the overall performance.",
        "body": "Jailbreaking\nQwen2.5-Omni\nQwen3-Omni\nGemini 2.5 pro\nSALMONN-Guard\n\n\nSpeech Insertion (archilles)\n\n23.17%\n8.94%\n13.41%\n0.00%\n\n\nSpeech Editing (cheng2025jailbreakaudiobenchindepthevaluationanalysis)\n\n33.00%\n12.00%\n23.00%\n3.00%\n\n\nSACRED-Bench (ours)\n92.83%\n81.50%\n65.41%\n11.32%",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\">Jailbreaking</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">Qwen2.5-Omni</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">Qwen3-Omni</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">Gemini 2.5 pro</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">SALMONN-Guard</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">Speech Insertion <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">archilles</span>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">23.17%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">8.94%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">13.41%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.00%</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Speech Editing <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cheng2025jailbreakaudiobenchindepthevaluationanalysis</span>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_center\">33.00%</td>\n<td class=\"ltx_td ltx_align_center\">12.00%</td>\n<td class=\"ltx_td ltx_align_center\">23.00%</td>\n<td class=\"ltx_td ltx_align_center\">3.00%</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\">SACRED-Bench (ours)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\">92.83%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\">81.50%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\">65.41%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\">11.32%</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "overall",
            "archilles",
            "rate",
            "ours",
            "editing",
            "qwen25omni",
            "refers",
            "speech",
            "jalmbench",
            "gemini",
            "success",
            "evaluated",
            "across",
            "salmonnguard",
            "qwen3omni",
            "methods",
            "cheng2025jailbreakaudiobenchindepthevaluationanalysis",
            "attack",
            "amse",
            "ssj",
            "pro",
            "subsets",
            "insertion",
            "performance",
            "asr",
            "different",
            "jailbreaking",
            "sacredbench",
            "respectively",
            "audio"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">To highlight the unique nature of our speech-audio composition-based attacks and evaluate the generalization of our defense, we compare model performance against two recent perturbation-based audio jailbreaking methods: Speech Insertion <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite> and Speech Editing <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cheng2025jailbreakaudiobenchindepthevaluationanalysis</span>)</cite>. The evaluation data for these methods is sourced from JALMBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peng2025jalmbenchbenchmarkingjailbreakvulnerabilities</span>)</cite>. For Speech Insertion, we use the 246 samples from the SSJ subset. For Speech Editing, we use a 100-sample subset from AMSE, which involves 18 distinct edits per sample, resulting in 1,800 total audio inputs. The results, presented in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T4\" title=\"Table 4 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, reveal that our methods exploit a fundamentally different class of vulnerabilities for which current models are largely unprepared. This analysis leads to two critical findings.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Recent progress in large language models (LLMs) has enabled understanding of both speech and non-speech audio, but exposing new safety risks emerging from complex audio inputs that are inadequately handled by current safeguards. We introduce SACRED-Bench (Speech&#8211;Audio Composition for RED-teaming) to evaluate the robustness of LLMs under complex audio-based attacks. Unlike existing perturbation-based methods that rely on noise optimization or white-box access, SACRED-Bench exploits speech&#8211;audio composition mechanisms. SACRED-Bench adopts three mechanisms: (a) speech overlap and multi-speaker dialogue, which embeds harmful prompts beneath or alongside benign speech; (b) speech-audio mixture, which imply unsafe intent via non-speech audio alongside benign speech or audio; and (c) diverse spoken instruction formats (open-ended QA, yes/no) that evade text-only filters. Experiments show that, even Gemini 2.5 Pro, the state-of-the-art proprietary LLM, still exhibits 66% attack success rate in SACRED-Bench test set, exposing vulnerabilities under cross-modal, speech&#8211;audio composition attacks. To bridge this gap, we propose SALMONN-Guard, the first guard model that jointly inspects speech, audio, and text for safety judgments, reducing attack success down to 20%. Our results highlight the need for audio-aware defenses for the safety of multimodal LLMs. The benchmark and SALMONN-Guard checkpoints can be found at <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/tsinghua-ee/SACRED-Bench\" title=\"\">https://huggingface.co/datasets/tsinghua-ee/SACRED-Bench</a>. <span class=\"ltx_text\" style=\"--ltx-fg-color:#FF0000;\">Warning: this paper includes examples that may be offensive or harmful.</span></p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "audio",
                    "success",
                    "salmonnguard",
                    "rate",
                    "methods",
                    "pro",
                    "attack",
                    "sacredbench"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Large language models (LLMs) nowadays are capable of understanding speech and non-speech audio, enabling natural and convenient modes of interaction. However, alongside these advancements come significant safety and reliability challenges. Preliminary efforts have been made recently to discover potential risks of audio LLMs by designing various jailbreaking methods <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">audiotrust</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">chen2025audiojailbreakjailbreakattacksendtoend</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">roh2025multilingualmultiaccentjailbreakingaudio</span>)</cite>. In particular, perturbation-based attacks have been the dominant type of jailbreaking approach, which includes injecting learned noise <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">archilles</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">sadasivan2025attackersnoisemanipulateaudiobased</span>)</cite> or applying selected transformations to the audio input <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>)</cite>. These methods heavily rely on optimizing the noise or perturbation, often limited to white-box open-source models or requiring intensive computation for optimization iterations.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "archilles",
                    "jailbreaking",
                    "methods",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we introduce Speech-Audio Composition for RED-teaming Benchmark (<span class=\"ltx_text ltx_font_bold\">SACRED-Bench</span>), a new highly effective audio jailbreaking approach to extensively exploit the complexity of audio signals for red-teaming. Instead of relying on artificial signal manipulations or adversarial training, SACRED-Bench leverages the composition of speech and audio cues to jailbreak multimodal models. Specifically, harmful audio signals are constructed using the following three types of composition mechanisms: (a). <em class=\"ltx_emph ltx_font_italic\">Speech overlap and multi-speaker dialogue</em>: Embedding harmful speech beneath or alongside benign utterances, or within a long spoken dialogue to bypass safety filters. (b). <em class=\"ltx_emph ltx_font_italic\">Speech-audio mixture</em>: Implying harmful intent or content through non-verbal sound events rather than explicit speech content, and (c). <em class=\"ltx_emph ltx_font_italic\">Diverse spoken question format</em>: Using not only open-ended question answering (QA), but also binary Yes-No questions in the instructions, which can not be detected or prevented by text-only guard models.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench",
                    "jailbreaking",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Based on the construction principles, we curate the SACRED-Bench dataset containing 30 hours of training audio and 7 hours of test data. Our experiments show that even state-of-the-art proprietary LLMs such as Google Gemini 2.5 pro, still has over 66% attack success rates (ASR) under attacks in SACRED-Bench test set. Such vulnerability is particularly attribute to the insufficiency of text-only safeguard mechanisms that are prevailing among current LLM providers, where the guard only examines the safety of the output text content. To mitigate this gap, we propose SALMONN-Guard, a safeguarding LLM designed to incorporate speech and audio as input in addition to text for safety judgments. SALMONN-Guard drastically reduced ASR on SACRED-Bench test set down to around 20%, effectively mitigating speech-audio-composition attacks. The main contributions of our paper can be summarized as follows.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "audio",
                    "success",
                    "salmonnguard",
                    "pro",
                    "attack",
                    "sacredbench",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SACRED-Bench, the first audio red-teaming benchmark that extensively exploits the complexity of audio inputs, crafting effective jailbreaking attacks without requiring adversarial training loops. SACRED-Bench additionally leverages different QA formats to bypass text-only guardrails.</p>\n\n",
                "matched_terms": [
                    "sacredbench",
                    "jailbreaking",
                    "different",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Experiments show that as high as 66% ASR are achieved even under the guardrails of Gemini 2.5 Pro using SACRED-Bench test set, highlighting the vulnerability of current safeguarding methods under complex speech-audio composition and cross-modal attacks.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "methods",
                    "pro",
                    "sacredbench",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SALMONN-Guard, the first guard model that jointly examines speech, audio and text to mitigate SACRED-based attacks, which effectively reduces the attack success rate down to 20%.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "success",
                    "salmonnguard",
                    "rate",
                    "attack",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Red-teaming and jailbreaking LLMs has been a curcial yet popular research topic for LLM safety. Systematic jailbreaking benchmarks were developed, such as MaliciousInstruct and later standardized benchmarks (HarmBench; JailbreakBench) enabled reproducible attack/defense comparisons and leaderboards <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">huang2023catastrophic</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mazeika2024harmbench</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">chao2024jailbreakbench</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">anil2024manyshot</span>)</cite>. More recently, automated red-teaming frameworks move from prompt lists to agentic, dialogue-level search with RL and strategy libraries, improving failure discovery in realistic, adaptive conversations <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">zhang2024harm</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">belaire2025automatic</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">singhania2025mmart</span>)</cite>. To defend these challenges, LLM safeguarding techniques have been adopted at training time, inference time and deployment time. Training-time methods include reinforcement learning with human or AI feedbacks for alignment <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">ouyang2022instructgpt</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">saferlhf</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">lee2024rlaifvsrlhfscaling</span>)</cite>. During inference, approaches such as self-reflection <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">madaan2023selfrefine</span>)</cite> and activation steering <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cao2024scansmitigatingexaggeratedsafety</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">lee2024programmingrefusalconditionalactivation</span>)</cite> have been developed. Guard models, on the other hand, are a stream of policy-grounded text classifiers to enforce safety after model deployment, such as LlamaGuard series <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">Inan2023LlamaGL</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "jailbreaking",
                    "methods"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Audio-based red-teaming and jailbreaking work has been developed more recently. Specifically, harmful speech synthesis and speech-text interleaved attack methods <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite> have been developed as earlier examples, showing alarming attack success rate on widely-used LLMs. More recently, audio-manipulation-based attacks combined with dedicated optimization loops have been developed <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cheng2025jailbreakaudiobenchindepthevaluationanalysis</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>)</cite>. A comprehensive benchmark aggregating aforementioned attack methods is provided in <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peng2025jalmbenchbenchmarkingjailbreakvulnerabilities</span>)</cite>.\nHowever, these attack only explore speech without non-speech audio, basic audio manipulations such as speed perturbation or noise injection, and single-speaker speech. In contrast, SACRED-Bench focuses on the complex nature of audio signals and incorporates much richer audio elements. On the other hand, not much work has been done on the defense side for audio LLMs, except for the noise-injection defense approach was adopted <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peri2024speechguardexploringadversarialrobustness</span>)</cite>. This paper proposes the first general audio guard model to ensure safety of audio LLMs.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "audio",
                    "success",
                    "rate",
                    "jailbreaking",
                    "methods",
                    "sacredbench",
                    "attack",
                    "cheng2025jailbreakaudiobenchindepthevaluationanalysis"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Explore complexity of speech signal.</span> The construction of SACRED-Bench systematically incorporates multi-speaker and overlapped speech. This principle ensures that our benchmark evaluates a model&#8217;s ability to process complex speech signals instead of just understanding clean, single-source speech, thereby reflecting the richness and ambiguity of real-world audio inputs.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Exploiting non-speech audio.</span> While previous work predominantly focuses on speech content <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite>, non-speech audio often carries harmful content beyond words, such as violence and pornography. SACRED-Bench exploits harmful audio by embedding them in the benign speech stream. This approach crafts audio capable of bypassing unimodal safety filters that are not attuned to speech-audio mixture complexities.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To create a comprehensive and challenging set of prompts, we aggregated harmful instructions from a wide array of established red-teaming benchmarks. Specifically, our collection is drawn from AdvBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">zou2023AdvBench</span>)</cite>, MM-SafetyBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mmsafety</span>)</cite>, and HarmBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mazeika2024harmbench</span>)</cite>. By combining prompts from these diverse sources, we ensure our test cases cover an extensive spectrum of risk categories. This aggregated pool serves as the textual basis for generating the harmful speech and conversational content used in our benchmark. The distribution of harmful content in SACRED-Bench test set is shown in Fig. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.F2\" title=\"Figure 2 &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. To create harmful speech instructions, ChatTTS engine was adopted to synthesize from these text instructions.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For attacks requiring a benign audio carrier, such as the speech overlap and spoken dialogue methods, we utilized the VoiceBank-DEMAND dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voicebank</span>)</cite>. As a widely-used corpus known for its high-quality clean speech from a variety of speakers, its public accessibility and high-quality audio make it an ideal source of harmless speech to serve as the background or conversational filler in our synthesized audio samples.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "audio",
                    "methods"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To construct attacks that leverage auditory context to imply harmful intent, we curated a library of potent audio tracks. These tracks were extracted from publicly available online videos featuring adult-oriented or intimate content. The design of these attacks hinges on pairing this contextually-charged audio with otherwise benign speech. This creates a malicious or harmful audio-based query, designed to test whether a model&#8217;s safety mechanisms can recognize situational context that is entirely absent from the speech content.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Speech Overlap technique is engineered to exploit the principles of auditory stream fusion, embedding a harmful instruction within a benign utterance so seamlessly to create confusion to the LLM. The process is shown in Fig. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.F3.sf1\" title=\"Figure 3(a) &#8227; Figure 3 &#8227; 3.1.3 Harmful Audio Events &#8227; 3.1 Source Material Preparation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">3(a)</span></a>. The goal is to create a single and coherent audio stream where the malicious payload is carefully obscured by both its context and its acoustic properties, while maintaining the malicious content to be perceptible by human beings.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent findings in vision-language safety, particularly the &#8220;Visual Safety Information Leakage&#8221; problem <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025vlsbench</span>)</cite>, have demonstrated that many multimodal models could be easily aligned by text-only training data because the text prompt often revealed the harmful nature of the accompanying image. Our work extends this core insight to the speech-audio domain. We hypothesize that a similar vulnerability exists: a model&#8217;s safety alignment might operate inconsistently across modalities if a benign-on-its-own textual query is paired with a malicious audio context, causing the text-only safety filter to be bypassed.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In parallel, we craft the textual component of the attack: a completely innocuous and referential query. This question, also generated by GPT-4o, is semantically neutral on its own but is designed to act as a pointer, or a semantic trigger, to the content within the audio. For example, a corresponding query might be, &#8220;How would I create the device mentioned in the discussion?&#8221; In isolation, this question is safe. However, when paired with the dialogue, it becomes a direct prompt for the model to synthesize and present the harmful information it has just heard.</p>\n\n",
                "matched_terms": [
                    "attack",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The final step is to bring these two components together into a cohesive auditory scene. We utilize the multi-speaker capabilities of the ChatTTS engine to synthesize the dialogue script into a realistic audio file, assigning distinct vocal characteristics to each speaker. The final attack prompt is the combination of this harmful conversational audio with the benign textual trigger. This presents the model with a complex jailbreaking challenge, forcing it to reconcile a harmless-looking text instruction with a clearly malicious audio payload, thereby testing the true depth of its cross-modal safety reasoning.</p>\n\n",
                "matched_terms": [
                    "attack",
                    "audio",
                    "jailbreaking"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This method pivots the attack vector from explicit linguistic content to the more subtle realm of implicit environmental context. The central premise is to test whether a model&#8217;s safety mechanisms are merely sophisticated textual processors or if they possess a genuine multimodal understanding of an auditory scene. We achieve this by pairing an safe spoken question with an audio event that carries a harmful intention. The entire sample is designed to appear benign to a system that only transcribes and analyzes the spoken words, while being obviously unsafe to one that comprehends the full context.</p>\n\n",
                "matched_terms": [
                    "attack",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This format is designed to test the model&#8217;s fundamental ability to detect harmful content. For each adversarial audio sample, we pose the direct textual question: &#8220;Does this audio contain harmful content?&#8221;. The evaluation metric is the Attack Success Rate (ASR %). Since every audio sample in our benchmark is inherently harmful, an attack is considered successful if the model incorrectly responds with &#8220;No&#8221;. This ASR provides a clear measure of the model&#8217;s failure rate in its most basic threat identification capabilities.</p>\n\n",
                "matched_terms": [
                    "success",
                    "rate",
                    "attack",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This format is designed to test a model&#8217;s ability to comprehend and act upon (or refuse to act upon) the harmful content identified in the audio. After providing the adversarial audio, we submit a textual prompt that asks the model to engage with the malicious information directly. The prompts typically ask the model to identify, extract, or elaborate on the harmful aspects of the audio. The evaluation of the model&#8217;s response is automated using Gemini 2.5 Pro as an independent judge. We measure the Attack Success Rate (ASR %) by providing the model&#8217;s generated text to a Gemini 2.5 Pro based classifier, which determines if the response complied with the harmful request or successfully refused it. The specific prompts and detailed scoring rubric used for this automated evaluation are provided in Appendix.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "success",
                    "rate",
                    "pro",
                    "attack",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:679.9pt;height:158pt;vertical-align:-76.5pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<span class=\"ltx_p\">\n<span class=\"ltx_tabular ltx_align_middle\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Models</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Speech Overlap (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Dialogue (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Contextual Audio Cues (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Overall (%)</span></span></span>\n<span class=\"ltx_tr\" style=\"--ltx-bg-color:#E6E6E6;\">\n<span class=\"ltx_td ltx_align_left ltx_border_t ltx_colspan ltx_colspan_5\"><span class=\"ltx_text\" style=\"font-size:90%;--ltx-bg-color:#E6E6E6;\">Open-source Models</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2-Audio-7B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2-audio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">96.48</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.16</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2.5-Omni-7B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2.5_omni</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.78</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">87.02</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">92.83</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen3-Omni-30B-A3B-Instruct </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">xu2025qwen3</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">49.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">84.82</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">93.17</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.50</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Step-Audio 2 mini Base </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025step-audio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">90.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.49</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.33</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.57</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">MiniCPM-o 2.6 8B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yao2024minicpm</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.84</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">69.87</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.95</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Kimi-Audio-7B-Instruct </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025kimiaudio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">69.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">61.36</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">87.17</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.05</span></span></span>\n<span class=\"ltx_tr\" style=\"--ltx-bg-color:#E6E6E6;\">\n<span class=\"ltx_td ltx_align_left ltx_border_t ltx_colspan ltx_colspan_5\"><span class=\"ltx_text\" style=\"font-size:90%;--ltx-bg-color:#E6E6E6;\">Proprietary Models</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini 1.5 Pro </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gemini1.5pro</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">83.50</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.47</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.12</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini 2.5 Pro </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025gemini2.5</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">37.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">63.93</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">88.56</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">66.75</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">GPT-4o </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gpt4o</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">73.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">53.67</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.05</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SALMONN-Guard (ours)</span><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">12.93</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">14.08</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">5.16</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">11.32</span></span></span>\n</span><span class=\"ltx_text\" style=\"font-size:90%;\"/></span>\n</span></span></p>\n\n",
                "matched_terms": [
                    "speech",
                    "overall",
                    "gemini",
                    "salmonnguard",
                    "ours",
                    "pro",
                    "qwen25omni",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To counter the new speech-audio composition attacks introduced in this paper, we propose and develop <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span>, a dedicated audio guard model. SALMONN-Guard is designed to serve as a proactive defensive layer, identifying and intercepting malicious audio inputs before they can reach a target LLM. This section details its architecture, the curation of its training data and specifications.</p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Acknowledging the scarcity of ethically-sourced harmful data, we synthesized our training corpus by leveraging established red-teaming benchmarks&#8212;AdvBench, MM-SafetyBench, and HarmBench&#8212;as a conceptual foundation. Instead of using the original prompts directly, we employ GPT-4o to generate a new, distinct set of harmful instructions, ensuring no direct data leakage. This process yields a training corpus of approximately <span class=\"ltx_text ltx_font_bold\">10k</span> instances (8,545 harmful, 1,828 benign), with the harmful data distributed across speech overlap (6,640), speech-audio mixture (986), and multi-speaker dialogue (919) instances. The benign samples are used to prevent model collapse to only outputting the unsafe class. To ensure a rigorous evaluation of generalization, we enforced a strict cross-dataset validation protocol: for any given attack category, the source benchmark used to inspire the training prompts was held out from the test set.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "attack",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The foundation of <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span> is the <span class=\"ltx_text ltx_font_bold\">Qwen2.5-Omni-7B</span> model. As a state-of-the-art open-source multimodal model at this parameter scale, its strong native capabilities in comprehending both audio and text make it an ideal backbone for our proposed guard model.</p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">There are two output modes in SALMONN-Guard. When tasked with assessing a standalone audio input, it can function as a conventional binary classifier, yielding a discrete label such as &#8220;harmful&#8221; or &#8220;harmless&#8221;. However, for its primary role in the holistic evaluation of joint text-audio queries, it directly intercepts harmful requests by generating a refusal like, &#8220;I&#8217;m sorry, I cannot assist with that request,&#8221; while allowing benign prompts to proceed for processing by a downstream task-specific LLM.</p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our primary objective is to adapt the powerful base model into a specialized guard model through Supervised Fine-Tuning (SFT) with standard cross-entropy loss. Concretely, SALMONN-Guard is trained to perform safety assessments for each sample by jointly processing both the audio input and any accompanying text prompt. This multimodal training scheme directly overcomes the vulnerability of text-only or spoken-content-only guardrails, yielding high efficacy in combating attacks in SACRED-Bench.</p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "sacredbench",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Evaluated Models</span>: Our evaluation includes several top-tier multimodal models, encompassing proprietary systems like Gemini 2.5 Pro <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025gemini2.5</span>)</cite>, Gemini 1.5 Pro <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gemini1.5pro</span>)</cite>, GPT-4o <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gpt4o</span>)</cite> and Kimi Audio <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025kimiaudio</span>)</cite>. Concurrently, we evaluate prominent open-source models, such as Qwen3-Omni <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">xu2025qwen3</span>)</cite>, Qwen2.5-Omni-7B <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2.5_omni</span>)</cite>, Qwen2-Audio-7B <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2-audio</span>)</cite>, MiniCPM-o 2.6 <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yao2024minicpm</span>)</cite>, and Step-Audio2 <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025step-audio</span>)</cite>. Furthermore, we include our proposed guard model, <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span>, in the evaluation to validate its effectiveness.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "evaluated",
                    "salmonnguard",
                    "qwen3omni",
                    "pro",
                    "qwen25omni",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Benchmark and Metrics:</span> All experiments are conducted on our SACRED-Bench, which evaluates models against three attack methods: speech overlap, multi-speaker dialogue, and speech-audio mixture. Our major evaluation metric is the Attack Success Rate (ASR %), which quantifies the percentage of times a model fails to adhere to its safety alignment and complies with the malicious prompt. The classification of a successful attack varies by task format. For the binary classification task, an attack is successful if the model fails to correctly identify there is harmful content in the audio. For the Open-Ended task, we employ an automated evaluation pipeline where Gemini 2.5 Pro serves as a judge, classifying the target model&#8217;s generated response as either &#8220;harmful&#8221; (a successful attack) or &#8220;harmless&#8221;. Therefore, in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, higher ASR values consistently indicate a greater degree of vulnerability.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "audio",
                    "success",
                    "rate",
                    "methods",
                    "pro",
                    "attack",
                    "sacredbench",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Proprietary Models Exhibit Exploitable Loopholes.</span>\nAs seen in the results, while top-tier models like Gemini 2.5 Pro demonstrate some defensive capabilities, they are far from infallible. Particularly under the speech-audio mixture attack, Gemini 2.5 Pro shows a high attack success rate of 88.56%, and its success rate for the Multi-speaker Dialogue attack is also significant at 63.93%. This suggests that current safety mechanisms may be more focused on analyzing explicit textual instructions, while being less capable of identifying implicit malicious intent conveyed through non-speech audio or complex conversational structures.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "success",
                    "rate",
                    "pro",
                    "attack",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Open-Source Models Largely Lack Effective Audio Safeguards.</span>\nThe results indicate that multimodal models from the open-source community are almost entirely defenseless against SACRED attacks. For instance, Qwen2.5-Omni-7B and Qwen2-Audio-7B have attack success rates approaching 100% in most tests. This reflects a critical gap in the current open-source ecosystem: while the pursuit of performance and functionality is paramount, insufficient attention has been paid to the security of multimodal inputs, especially the robustness against complex audio scenarios.</p>\n\n",
                "matched_terms": [
                    "performance",
                    "attack",
                    "success",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Analysis of Different Attack Strategies&#8217; Efficacy.</span>\nAn analysis of the individual attack strategies reveals that each method successfully exploits distinct architectural weaknesses. The <span class=\"ltx_text ltx_font_bold\">speech-audio mixture</span> method proved the most potent, with a staggering 88.56% ASR against Gemini 2.5 Pro and nearly 100% on several open-source models, underscoring a critical &#8217;cross-modal blindness.&#8217; Models adeptly transcribe a benign spoken query while completely ignoring the malicious intent conveyed by background audio. Similarly effective, the <span class=\"ltx_text ltx_font_bold\">Multi-speaker Dialogue</span> method demonstrates how requests can be obfuscated within a natural conversation, successfully bypassing safety filters that may only detect direct, command-like instructions. The high ASR of 63.93% against Gemini 2.5 Pro highlights the difficulty even advanced models face in assessing risks distributed throughout a long-form dialogue. Lastly, the <span class=\"ltx_text ltx_font_bold\">Speech Overlap</span> attack targeted the models&#8217; information processing in complex acoustic environments. Although Gemini 2.5 Pro showed improved resistance, high success rates against Gemini 1.5 Pro (74.89%) and the Qwen series confirm that for most models, disentangling overlapping audio remains a significant security flaw.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "success",
                    "different",
                    "pro",
                    "attack",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Effectiveness of SALMONN-Guard as a Guard Model.</span>\nIn stark contrast to other models, our proposed <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span> demonstrates exceptional defensive performance. As shown in the last row of Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, SALMONN-Guard drastically reduces the success rate for all types of attacks. It slashes the ASR for speech-audio mixture from Gemini 2.5 Pro&#8217;s 88.56% to a mere 5.16%, and suppresses the ASRs for Speech Overlap and Multi-speaker Dialogue to 12.93% and 28.09%, respectively. <span class=\"ltx_text ltx_font_italic\">We also test SALMONN-Guard on all the benign audios used to composite SACRED-Bench as shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T5\" title=\"Table 5 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, and an 100% classification accuracy was achieved where none of them were flagged as harmful.</span> This result fully validates the effectiveness of our proposed approach: training a specialized, lightweight guard model to preemptively identify and intercept malicious audio inputs is a viable and highly efficient path to protecting downstream LLMs from complex audio-based attacks.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "respectively",
                    "success",
                    "salmonnguard",
                    "rate",
                    "sacredbench",
                    "performance",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, we conducted an ablation study on the acoustic attributes of the speech overlap attack. To ensure intelligibility of audio mixture, in addition to manual listening check conducted among co-authors, we prompt Gemini 2.5 Pro to describe the audio content. If the description matches both parts of the speech, or refuses to generate one side due to safety reasons, we consider it as perceptible. As a results, 93% of the samples in the speech overlap partition can be clearly perceived by Gemini 2.5 pro. This ensures that the speech overlap is sufficiently intelligible given that Gemini 2.5 pro is imperfect in understanding overlapped speech.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "pro",
                    "attack",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The ablation results, shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T2\" title=\"Table 2 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, reveal that attack efficacy is most sensitive to parameters that increase the subtlety of the harmful instruction. We observe that a higher playback speed, a lower volume, and a longer overlap duration all correlate with a higher Attack Success Rate. This supports our hypothesis that the attack is most potent when the malicious content is acoustically framed as subliminal information&#8212;clearly perceived by the model, yet subtle enough to bypass its safety filters.</p>\n\n",
                "matched_terms": [
                    "attack",
                    "success",
                    "rate"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Furthermore, we conducted an ablation study on the Multi-speaker Dialogue attack to isolate the source of its efficacy. As shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T3\" title=\"Table 3 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, we evaluated Gemini 1.5 Pro against unimodal baselines. The results demonstrate that our cross-modal Text + Audio approach (78.58% ASR) is significantly more potent than either a Text-Only (57.96% ASR) or Audio-Only (65.03% ASR) attack. This confirms that the attack&#8217;s high success rate stems from the synergistic effect of pairing a benign text prompt with a malicious audio context, a strategy that effectively bypasses unimodal safety checks.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "success",
                    "evaluated",
                    "rate",
                    "pro",
                    "attack",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, the results demonstrate that our speech-audio composition-based attacks pose a far greater challenge to state-of-the-art LLMs than prior methods. For instance, while Gemini 2.5 Pro shows some resilience to Speech Insertion (13.41% ASR) and Speech Editing (23.00% ASR), its vulnerability skyrockets to 65.41% ASR on SACRED-Bench. This trend is even more pronounced for open-source models like Qwen3-Omni, whose ASR jumps from 8.94% on Speech Insertion to 81.50% on our benchmark. This disparity underscores that our methods, which manipulate semantic and contextual cues, are fundamentally more effective at bypassing modern safety alignments than attacks that rely on signal-level perturbations.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "gemini",
                    "qwen3omni",
                    "methods",
                    "insertion",
                    "editing",
                    "pro",
                    "sacredbench",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, and more importantly, the results reveal the remarkable generalization of SALMONN-Guard. It is crucial to note that SALMONN-Guard was trained exclusively on our SACRED-Bench data and was never fine-tuned on samples from these other attack distributions. Despite this, it demonstrates near-perfect defensive capabilities, reducing the ASR for Speech Insertion to 0.00% and for Speech Editing to just 3.00%. This indicates that by training on our diverse and complex composition-based attacks, SALMONN-Guard has learned to recognize the underlying principles of malicious audio manipulation, rather than merely overfitting to the patterns in its training set. Its ability to neutralize entirely unseen attack vectors validates it not just as a defense against SACRED, but as a robust and generalizable safeguard for the broader audio modality.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "salmonnguard",
                    "insertion",
                    "editing",
                    "sacredbench",
                    "attack",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We introduced SACRED-Bench, a benchmark demonstrating that compositional audio attacks can effectively bypass existing safeguards. Our experiments revealed significant vulnerabilities in state-of-the-art LLMs, with an Attack Success Rate exceeding 66% on Gemini 2.5 Pro, exposing the critical limitations of text-centric safety filters. As a countermeasure, our proposed SALMONN-Guard successfully reduced the ASR to approximately 20% by performing holistic multimodal safety checks. This paper underscores the urgent need to develop robust, truly multimodal safety paradigms for the next generation of audio LLMs.</p>\n\n",
                "matched_terms": [
                    "gemini",
                    "audio",
                    "success",
                    "salmonnguard",
                    "rate",
                    "pro",
                    "attack",
                    "sacredbench",
                    "asr"
                ]
            }
        ]
    },
    "S5.T5": {
        "source_file": "Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard",
        "caption": "Table 5: Performance of SALMONN-Guard on harmful (measured by ASR) and benign audios (classification accuracy), where the benign audios are audios used to create SACRED-Bench test set.",
        "body": "Model\nASR(%)\nBenign Audio Acc(%)\n\n\nSALMONN-Guard\n11.32\n100.00",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">ASR(%)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">Benign Audio Acc(%)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">SALMONN-Guard</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">11.32</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "classification",
            "audio",
            "acc",
            "model",
            "measured",
            "test",
            "salmonnguard",
            "where",
            "harmful",
            "audios",
            "create",
            "sacredbench",
            "performance",
            "used",
            "accuracy",
            "set",
            "benign",
            "asr"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Effectiveness of SALMONN-Guard as a Guard Model.</span>\nIn stark contrast to other models, our proposed <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span> demonstrates exceptional defensive performance. As shown in the last row of Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, SALMONN-Guard drastically reduces the success rate for all types of attacks. It slashes the ASR for speech-audio mixture from Gemini 2.5 Pro&#8217;s 88.56% to a mere 5.16%, and suppresses the ASRs for Speech Overlap and Multi-speaker Dialogue to 12.93% and 28.09%, respectively. <span class=\"ltx_text ltx_font_italic\">We also test SALMONN-Guard on all the benign audios used to composite SACRED-Bench as shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T5\" title=\"Table 5 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, and an 100% classification accuracy was achieved where none of them were flagged as harmful.</span> This result fully validates the effectiveness of our proposed approach: training a specialized, lightweight guard model to preemptively identify and intercept malicious audio inputs is a viable and highly efficient path to protecting downstream LLMs from complex audio-based attacks.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Recent progress in large language models (LLMs) has enabled understanding of both speech and non-speech audio, but exposing new safety risks emerging from complex audio inputs that are inadequately handled by current safeguards. We introduce SACRED-Bench (Speech&#8211;Audio Composition for RED-teaming) to evaluate the robustness of LLMs under complex audio-based attacks. Unlike existing perturbation-based methods that rely on noise optimization or white-box access, SACRED-Bench exploits speech&#8211;audio composition mechanisms. SACRED-Bench adopts three mechanisms: (a) speech overlap and multi-speaker dialogue, which embeds harmful prompts beneath or alongside benign speech; (b) speech-audio mixture, which imply unsafe intent via non-speech audio alongside benign speech or audio; and (c) diverse spoken instruction formats (open-ended QA, yes/no) that evade text-only filters. Experiments show that, even Gemini 2.5 Pro, the state-of-the-art proprietary LLM, still exhibits 66% attack success rate in SACRED-Bench test set, exposing vulnerabilities under cross-modal, speech&#8211;audio composition attacks. To bridge this gap, we propose SALMONN-Guard, the first guard model that jointly inspects speech, audio, and text for safety judgments, reducing attack success down to 20%. Our results highlight the need for audio-aware defenses for the safety of multimodal LLMs. The benchmark and SALMONN-Guard checkpoints can be found at <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/tsinghua-ee/SACRED-Bench\" title=\"\">https://huggingface.co/datasets/tsinghua-ee/SACRED-Bench</a>. <span class=\"ltx_text\" style=\"--ltx-fg-color:#FF0000;\">Warning: this paper includes examples that may be offensive or harmful.</span></p>\n\n",
                "matched_terms": [
                    "model",
                    "test",
                    "salmonnguard",
                    "set",
                    "harmful",
                    "sacredbench",
                    "audio",
                    "benign"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we introduce Speech-Audio Composition for RED-teaming Benchmark (<span class=\"ltx_text ltx_font_bold\">SACRED-Bench</span>), a new highly effective audio jailbreaking approach to extensively exploit the complexity of audio signals for red-teaming. Instead of relying on artificial signal manipulations or adversarial training, SACRED-Bench leverages the composition of speech and audio cues to jailbreak multimodal models. Specifically, harmful audio signals are constructed using the following three types of composition mechanisms: (a). <em class=\"ltx_emph ltx_font_italic\">Speech overlap and multi-speaker dialogue</em>: Embedding harmful speech beneath or alongside benign utterances, or within a long spoken dialogue to bypass safety filters. (b). <em class=\"ltx_emph ltx_font_italic\">Speech-audio mixture</em>: Implying harmful intent or content through non-verbal sound events rather than explicit speech content, and (c). <em class=\"ltx_emph ltx_font_italic\">Diverse spoken question format</em>: Using not only open-ended question answering (QA), but also binary Yes-No questions in the instructions, which can not be detected or prevented by text-only guard models.</p>\n\n",
                "matched_terms": [
                    "sacredbench",
                    "audio",
                    "benign",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Based on the construction principles, we curate the SACRED-Bench dataset containing 30 hours of training audio and 7 hours of test data. Our experiments show that even state-of-the-art proprietary LLMs such as Google Gemini 2.5 pro, still has over 66% attack success rates (ASR) under attacks in SACRED-Bench test set. Such vulnerability is particularly attribute to the insufficiency of text-only safeguard mechanisms that are prevailing among current LLM providers, where the guard only examines the safety of the output text content. To mitigate this gap, we propose SALMONN-Guard, a safeguarding LLM designed to incorporate speech and audio as input in addition to text for safety judgments. SALMONN-Guard drastically reduced ASR on SACRED-Bench test set down to around 20%, effectively mitigating speech-audio-composition attacks. The main contributions of our paper can be summarized as follows.</p>\n\n",
                "matched_terms": [
                    "test",
                    "salmonnguard",
                    "where",
                    "set",
                    "sacredbench",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SACRED-Bench, the first audio red-teaming benchmark that extensively exploits the complexity of audio inputs, crafting effective jailbreaking attacks without requiring adversarial training loops. SACRED-Bench additionally leverages different QA formats to bypass text-only guardrails.</p>\n\n",
                "matched_terms": [
                    "sacredbench",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Experiments show that as high as 66% ASR are achieved even under the guardrails of Gemini 2.5 Pro using SACRED-Bench test set, highlighting the vulnerability of current safeguarding methods under complex speech-audio composition and cross-modal attacks.</p>\n\n",
                "matched_terms": [
                    "sacredbench",
                    "set",
                    "test",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SALMONN-Guard, the first guard model that jointly examines speech, audio and text to mitigate SACRED-based attacks, which effectively reduces the attack success rate down to 20%.</p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "model",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Audio-based red-teaming and jailbreaking work has been developed more recently. Specifically, harmful speech synthesis and speech-text interleaved attack methods <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite> have been developed as earlier examples, showing alarming attack success rate on widely-used LLMs. More recently, audio-manipulation-based attacks combined with dedicated optimization loops have been developed <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cheng2025jailbreakaudiobenchindepthevaluationanalysis</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>)</cite>. A comprehensive benchmark aggregating aforementioned attack methods is provided in <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peng2025jalmbenchbenchmarkingjailbreakvulnerabilities</span>)</cite>.\nHowever, these attack only explore speech without non-speech audio, basic audio manipulations such as speed perturbation or noise injection, and single-speaker speech. In contrast, SACRED-Bench focuses on the complex nature of audio signals and incorporates much richer audio elements. On the other hand, not much work has been done on the defense side for audio LLMs, except for the noise-injection defense approach was adopted <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peri2024speechguardexploringadversarialrobustness</span>)</cite>. This paper proposes the first general audio guard model to ensure safety of audio LLMs.</p>\n\n",
                "matched_terms": [
                    "sacredbench",
                    "model",
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Explore complexity of speech signal.</span> The construction of SACRED-Bench systematically incorporates multi-speaker and overlapped speech. This principle ensures that our benchmark evaluates a model&#8217;s ability to process complex speech signals instead of just understanding clean, single-source speech, thereby reflecting the richness and ambiguity of real-world audio inputs.</p>\n\n",
                "matched_terms": [
                    "sacredbench",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Exploiting non-speech audio.</span> While previous work predominantly focuses on speech content <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite>, non-speech audio often carries harmful content beyond words, such as violence and pornography. SACRED-Bench exploits harmful audio by embedding them in the benign speech stream. This approach crafts audio capable of bypassing unimodal safety filters that are not attuned to speech-audio mixture complexities.</p>\n\n",
                "matched_terms": [
                    "sacredbench",
                    "audio",
                    "benign",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Employing indirect question formats.</span> Hiding part of harmful content in the audio can potentially bypass the text-based guardrails adopted in many proprietary LLMs. On one hand, we prompt the model to acknowledge the harmlessness of the audio by asking whether the audio has harmful content. On the other hand, we partially hide harmful information in the audio by tasking the model to engage in a harmful conversation where the text content are mostly benign. Both can bypass text-based guardrails.</p>\n\n",
                "matched_terms": [
                    "model",
                    "where",
                    "harmful",
                    "audio",
                    "benign"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To create a comprehensive and challenging set of prompts, we aggregated harmful instructions from a wide array of established red-teaming benchmarks. Specifically, our collection is drawn from AdvBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">zou2023AdvBench</span>)</cite>, MM-SafetyBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mmsafety</span>)</cite>, and HarmBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mazeika2024harmbench</span>)</cite>. By combining prompts from these diverse sources, we ensure our test cases cover an extensive spectrum of risk categories. This aggregated pool serves as the textual basis for generating the harmful speech and conversational content used in our benchmark. The distribution of harmful content in SACRED-Bench test set is shown in Fig. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.F2\" title=\"Figure 2 &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. To create harmful speech instructions, ChatTTS engine was adopted to synthesize from these text instructions.</p>\n\n",
                "matched_terms": [
                    "test",
                    "harmful",
                    "create",
                    "sacredbench",
                    "used",
                    "set"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For attacks requiring a benign audio carrier, such as the speech overlap and spoken dialogue methods, we utilized the VoiceBank-DEMAND dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voicebank</span>)</cite>. As a widely-used corpus known for its high-quality clean speech from a variety of speakers, its public accessibility and high-quality audio make it an ideal source of harmless speech to serve as the background or conversational filler in our synthesized audio samples.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "benign"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To construct attacks that leverage auditory context to imply harmful intent, we curated a library of potent audio tracks. These tracks were extracted from publicly available online videos featuring adult-oriented or intimate content. The design of these attacks hinges on pairing this contextually-charged audio with otherwise benign speech. This creates a malicious or harmful audio-based query, designed to test whether a model&#8217;s safety mechanisms can recognize situational context that is entirely absent from the speech content.</p>\n\n",
                "matched_terms": [
                    "benign",
                    "audio",
                    "test",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Speech Overlap technique is engineered to exploit the principles of auditory stream fusion, embedding a harmful instruction within a benign utterance so seamlessly to create confusion to the LLM. The process is shown in Fig. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.F3.sf1\" title=\"Figure 3(a) &#8227; Figure 3 &#8227; 3.1.3 Harmful Audio Events &#8227; 3.1 Source Material Preparation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">3(a)</span></a>. The goal is to create a single and coherent audio stream where the malicious payload is carefully obscured by both its context and its acoustic properties, while maintaining the malicious content to be perceptible by human beings.</p>\n\n",
                "matched_terms": [
                    "where",
                    "harmful",
                    "create",
                    "audio",
                    "benign"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">With the semantic stage set, we then apply the second layer of deception at the signal level: acoustic masking. After synthesizing both the benign carrier and the harmful payload using the ChatTTS engine, we manipulate the harmful audio to reduce its perceptual salience by adjusting key acoustic parameters, including its volume, playback speed, and temporal overlap. The two streams are then composed using a cross-fade into a single, fluid utterance. Crucially, the chosen parameters ensure that the harmful content, while subtle, remains fully perceptible to the model, as we validate in our analysis. A detailed empirical justification for our choice of these hyperparameters is provided in our ablation study (Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.SS3\" title=\"5.3 Ablation Studies &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">5.3</span></a>). The final composition results in an utterance where the malicious instruction is both contextually justified and acoustically concealed.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "model",
                    "where",
                    "harmful",
                    "set",
                    "benign"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent findings in vision-language safety, particularly the &#8220;Visual Safety Information Leakage&#8221; problem <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025vlsbench</span>)</cite>, have demonstrated that many multimodal models could be easily aligned by text-only training data because the text prompt often revealed the harmful nature of the accompanying image. Our work extends this core insight to the speech-audio domain. We hypothesize that a similar vulnerability exists: a model&#8217;s safety alignment might operate inconsistently across modalities if a benign-on-its-own textual query is paired with a malicious audio context, causing the text-only safety filter to be bypassed.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In parallel, we craft the textual component of the attack: a completely innocuous and referential query. This question, also generated by GPT-4o, is semantically neutral on its own but is designed to act as a pointer, or a semantic trigger, to the content within the audio. For example, a corresponding query might be, &#8220;How would I create the device mentioned in the discussion?&#8221; In isolation, this question is safe. However, when paired with the dialogue, it becomes a direct prompt for the model to synthesize and present the harmful information it has just heard.</p>\n\n",
                "matched_terms": [
                    "create",
                    "model",
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The final step is to bring these two components together into a cohesive auditory scene. We utilize the multi-speaker capabilities of the ChatTTS engine to synthesize the dialogue script into a realistic audio file, assigning distinct vocal characteristics to each speaker. The final attack prompt is the combination of this harmful conversational audio with the benign textual trigger. This presents the model with a complex jailbreaking challenge, forcing it to reconcile a harmless-looking text instruction with a clearly malicious audio payload, thereby testing the true depth of its cross-modal safety reasoning.</p>\n\n",
                "matched_terms": [
                    "model",
                    "audio",
                    "benign",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This method pivots the attack vector from explicit linguistic content to the more subtle realm of implicit environmental context. The central premise is to test whether a model&#8217;s safety mechanisms are merely sophisticated textual processors or if they possess a genuine multimodal understanding of an auditory scene. We achieve this by pairing an safe spoken question with an audio event that carries a harmful intention. The entire sample is designed to appear benign to a system that only transcribes and analyzes the spoken words, while being obviously unsafe to one that comprehends the full context.</p>\n\n",
                "matched_terms": [
                    "benign",
                    "audio",
                    "test",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To construct these attacks, we curated a library of harmful audio tracks. These tracks were extracted directly from publicly available videos on online platforms featuring adult-oriented, violence or criminal content. This process yielded a collection of audio files that, while not containing explicit instructions, carry a strong and inherently inappropriate contextual meaning from their source.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The final stage involves mixing auditory scene. We take a benign &#8220;carrier&#8221; track from the VoiceBank-DEMAND dataset and overlay one of the harmful contextual audio tracks from our curated library as a background layer. The background sound is mixed at a clearly audible volume. This creates a powerful conflict: for instance, an academic lecture playing over the distinct sounds of an intimate scenario. A model with a text-centric safety filter would likely transcribe the harmless lecture and clear the input. However, a truly multimodal safety system is challenged to detect the disturbing nature of the background context and correctly flag the entire sample as unsafe. This method directly probes the model&#8217;s ability to reason about situational appropriateness.</p>\n\n",
                "matched_terms": [
                    "model",
                    "audio",
                    "benign",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To conduct a comprehensive and granular assessment of model vulnerabilities, we designed two distinct question formats for each synthesized adversarial audio sample. This evaluation strategy allows us to probe a model&#8217;s safety architecture from basic detection to detailed comprehension.</p>\n\n",
                "matched_terms": [
                    "model",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This format is designed to test the model&#8217;s fundamental ability to detect harmful content. For each adversarial audio sample, we pose the direct textual question: &#8220;Does this audio contain harmful content?&#8221;. The evaluation metric is the Attack Success Rate (ASR %). Since every audio sample in our benchmark is inherently harmful, an attack is considered successful if the model incorrectly responds with &#8220;No&#8221;. This ASR provides a clear measure of the model&#8217;s failure rate in its most basic threat identification capabilities.</p>\n\n",
                "matched_terms": [
                    "model",
                    "test",
                    "harmful",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This format is designed to test a model&#8217;s ability to comprehend and act upon (or refuse to act upon) the harmful content identified in the audio. After providing the adversarial audio, we submit a textual prompt that asks the model to engage with the malicious information directly. The prompts typically ask the model to identify, extract, or elaborate on the harmful aspects of the audio. The evaluation of the model&#8217;s response is automated using Gemini 2.5 Pro as an independent judge. We measure the Attack Success Rate (ASR %) by providing the model&#8217;s generated text to a Gemini 2.5 Pro based classifier, which determines if the response complied with the harmful request or successfully refused it. The specific prompts and detailed scoring rubric used for this automated evaluation are provided in Appendix.</p>\n\n",
                "matched_terms": [
                    "model",
                    "test",
                    "harmful",
                    "used",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:679.9pt;height:158pt;vertical-align:-76.5pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<span class=\"ltx_p\">\n<span class=\"ltx_tabular ltx_align_middle\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Models</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Speech Overlap (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Dialogue (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Contextual Audio Cues (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Overall (%)</span></span></span>\n<span class=\"ltx_tr\" style=\"--ltx-bg-color:#E6E6E6;\">\n<span class=\"ltx_td ltx_align_left ltx_border_t ltx_colspan ltx_colspan_5\"><span class=\"ltx_text\" style=\"font-size:90%;--ltx-bg-color:#E6E6E6;\">Open-source Models</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2-Audio-7B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2-audio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">96.48</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.16</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2.5-Omni-7B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2.5_omni</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.78</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">87.02</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">92.83</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen3-Omni-30B-A3B-Instruct </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">xu2025qwen3</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">49.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">84.82</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">93.17</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.50</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Step-Audio 2 mini Base </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025step-audio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">90.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.49</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.33</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.57</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">MiniCPM-o 2.6 8B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yao2024minicpm</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.84</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">69.87</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.95</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Kimi-Audio-7B-Instruct </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025kimiaudio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">69.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">61.36</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">87.17</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.05</span></span></span>\n<span class=\"ltx_tr\" style=\"--ltx-bg-color:#E6E6E6;\">\n<span class=\"ltx_td ltx_align_left ltx_border_t ltx_colspan ltx_colspan_5\"><span class=\"ltx_text\" style=\"font-size:90%;--ltx-bg-color:#E6E6E6;\">Proprietary Models</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini 1.5 Pro </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gemini1.5pro</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">83.50</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.47</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.12</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini 2.5 Pro </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025gemini2.5</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">37.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">63.93</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">88.56</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">66.75</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">GPT-4o </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gpt4o</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">73.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">53.67</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.05</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SALMONN-Guard (ours)</span><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">12.93</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">14.08</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">5.16</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">11.32</span></span></span>\n</span><span class=\"ltx_text\" style=\"font-size:90%;\"/></span>\n</span></span></p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To counter the new speech-audio composition attacks introduced in this paper, we propose and develop <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span>, a dedicated audio guard model. SALMONN-Guard is designed to serve as a proactive defensive layer, identifying and intercepting malicious audio inputs before they can reach a target LLM. This section details its architecture, the curation of its training data and specifications.</p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "model",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Acknowledging the scarcity of ethically-sourced harmful data, we synthesized our training corpus by leveraging established red-teaming benchmarks&#8212;AdvBench, MM-SafetyBench, and HarmBench&#8212;as a conceptual foundation. Instead of using the original prompts directly, we employ GPT-4o to generate a new, distinct set of harmful instructions, ensuring no direct data leakage. This process yields a training corpus of approximately <span class=\"ltx_text ltx_font_bold\">10k</span> instances (8,545 harmful, 1,828 benign), with the harmful data distributed across speech overlap (6,640), speech-audio mixture (986), and multi-speaker dialogue (919) instances. The benign samples are used to prevent model collapse to only outputting the unsafe class. To ensure a rigorous evaluation of generalization, we enforced a strict cross-dataset validation protocol: for any given attack category, the source benchmark used to inspire the training prompts was held out from the test set.</p>\n\n",
                "matched_terms": [
                    "model",
                    "test",
                    "harmful",
                    "used",
                    "set",
                    "benign"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The foundation of <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span> is the <span class=\"ltx_text ltx_font_bold\">Qwen2.5-Omni-7B</span> model. As a state-of-the-art open-source multimodal model at this parameter scale, its strong native capabilities in comprehending both audio and text make it an ideal backbone for our proposed guard model.</p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "model",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">There are two output modes in SALMONN-Guard. When tasked with assessing a standalone audio input, it can function as a conventional binary classifier, yielding a discrete label such as &#8220;harmful&#8221; or &#8220;harmless&#8221;. However, for its primary role in the holistic evaluation of joint text-audio queries, it directly intercepts harmful requests by generating a refusal like, &#8220;I&#8217;m sorry, I cannot assist with that request,&#8221; while allowing benign prompts to proceed for processing by a downstream task-specific LLM.</p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "audio",
                    "benign",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our primary objective is to adapt the powerful base model into a specialized guard model through Supervised Fine-Tuning (SFT) with standard cross-entropy loss. Concretely, SALMONN-Guard is trained to perform safety assessments for each sample by jointly processing both the audio input and any accompanying text prompt. This multimodal training scheme directly overcomes the vulnerability of text-only or spoken-content-only guardrails, yielding high efficacy in combating attacks in SACRED-Bench.</p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "sacredbench",
                    "model",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We employed a two-stage fine-tuning curriculum to first build general robustness and then specialize in complex threats. In Stage 1, the model was trained for three epochs on the entire dataset. In Stage 2, we conducted five additional epochs of training exclusively on the multi-speaker dialogue subset to bolster the model&#8217;s capabilities against this cross-modal attacks that is particularly challenging for the model to learn. For parameter-efficient fine-tuning, we utilized Low-Rank Adaptation (LoRA), applying updates concurrently to the large language model, the audio encoder, and the aligner module. A comprehensive list of hyperparameters is provided in the Appendix.</p>\n\n",
                "matched_terms": [
                    "model",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Evaluated Models</span>: Our evaluation includes several top-tier multimodal models, encompassing proprietary systems like Gemini 2.5 Pro <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025gemini2.5</span>)</cite>, Gemini 1.5 Pro <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gemini1.5pro</span>)</cite>, GPT-4o <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gpt4o</span>)</cite> and Kimi Audio <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025kimiaudio</span>)</cite>. Concurrently, we evaluate prominent open-source models, such as Qwen3-Omni <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">xu2025qwen3</span>)</cite>, Qwen2.5-Omni-7B <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2.5_omni</span>)</cite>, Qwen2-Audio-7B <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2-audio</span>)</cite>, MiniCPM-o 2.6 <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yao2024minicpm</span>)</cite>, and Step-Audio2 <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025step-audio</span>)</cite>. Furthermore, we include our proposed guard model, <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span>, in the evaluation to validate its effectiveness.</p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "model",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Benchmark and Metrics:</span> All experiments are conducted on our SACRED-Bench, which evaluates models against three attack methods: speech overlap, multi-speaker dialogue, and speech-audio mixture. Our major evaluation metric is the Attack Success Rate (ASR %), which quantifies the percentage of times a model fails to adhere to its safety alignment and complies with the malicious prompt. The classification of a successful attack varies by task format. For the binary classification task, an attack is successful if the model fails to correctly identify there is harmful content in the audio. For the Open-Ended task, we employ an automated evaluation pipeline where Gemini 2.5 Pro serves as a judge, classifying the target model&#8217;s generated response as either &#8220;harmful&#8221; (a successful attack) or &#8220;harmless&#8221;. Therefore, in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, higher ASR values consistently indicate a greater degree of vulnerability.</p>\n\n",
                "matched_terms": [
                    "classification",
                    "model",
                    "where",
                    "harmful",
                    "sacredbench",
                    "audio",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Open-Source Models Largely Lack Effective Audio Safeguards.</span>\nThe results indicate that multimodal models from the open-source community are almost entirely defenseless against SACRED attacks. For instance, Qwen2.5-Omni-7B and Qwen2-Audio-7B have attack success rates approaching 100% in most tests. This reflects a critical gap in the current open-source ecosystem: while the pursuit of performance and functionality is paramount, insufficient attention has been paid to the security of multimodal inputs, especially the robustness against complex audio scenarios.</p>\n\n",
                "matched_terms": [
                    "performance",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Analysis of Different Attack Strategies&#8217; Efficacy.</span>\nAn analysis of the individual attack strategies reveals that each method successfully exploits distinct architectural weaknesses. The <span class=\"ltx_text ltx_font_bold\">speech-audio mixture</span> method proved the most potent, with a staggering 88.56% ASR against Gemini 2.5 Pro and nearly 100% on several open-source models, underscoring a critical &#8217;cross-modal blindness.&#8217; Models adeptly transcribe a benign spoken query while completely ignoring the malicious intent conveyed by background audio. Similarly effective, the <span class=\"ltx_text ltx_font_bold\">Multi-speaker Dialogue</span> method demonstrates how requests can be obfuscated within a natural conversation, successfully bypassing safety filters that may only detect direct, command-like instructions. The high ASR of 63.93% against Gemini 2.5 Pro highlights the difficulty even advanced models face in assessing risks distributed throughout a long-form dialogue. Lastly, the <span class=\"ltx_text ltx_font_bold\">Speech Overlap</span> attack targeted the models&#8217; information processing in complex acoustic environments. Although Gemini 2.5 Pro showed improved resistance, high success rates against Gemini 1.5 Pro (74.89%) and the Qwen series confirm that for most models, disentangling overlapping audio remains a significant security flaw.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "benign",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The ablation results, shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T2\" title=\"Table 2 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, reveal that attack efficacy is most sensitive to parameters that increase the subtlety of the harmful instruction. We observe that a higher playback speed, a lower volume, and a longer overlap duration all correlate with a higher Attack Success Rate. This supports our hypothesis that the attack is most potent when the malicious content is acoustically framed as subliminal information&#8212;clearly perceived by the model, yet subtle enough to bypass its safety filters.</p>\n\n",
                "matched_terms": [
                    "model",
                    "harmful"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Furthermore, we conducted an ablation study on the Multi-speaker Dialogue attack to isolate the source of its efficacy. As shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T3\" title=\"Table 3 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, we evaluated Gemini 1.5 Pro against unimodal baselines. The results demonstrate that our cross-modal Text + Audio approach (78.58% ASR) is significantly more potent than either a Text-Only (57.96% ASR) or Audio-Only (65.03% ASR) attack. This confirms that the attack&#8217;s high success rate stems from the synergistic effect of pairing a benign text prompt with a malicious audio context, a strategy that effectively bypasses unimodal safety checks.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "benign",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To highlight the unique nature of our speech-audio composition-based attacks and evaluate the generalization of our defense, we compare model performance against two recent perturbation-based audio jailbreaking methods: Speech Insertion <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite> and Speech Editing <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cheng2025jailbreakaudiobenchindepthevaluationanalysis</span>)</cite>. The evaluation data for these methods is sourced from JALMBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peng2025jalmbenchbenchmarkingjailbreakvulnerabilities</span>)</cite>. For Speech Insertion, we use the 246 samples from the SSJ subset. For Speech Editing, we use a 100-sample subset from AMSE, which involves 18 distinct edits per sample, resulting in 1,800 total audio inputs. The results, presented in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T4\" title=\"Table 4 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, reveal that our methods exploit a fundamentally different class of vulnerabilities for which current models are largely unprepared. This analysis leads to two critical findings.</p>\n\n",
                "matched_terms": [
                    "performance",
                    "model",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, the results demonstrate that our speech-audio composition-based attacks pose a far greater challenge to state-of-the-art LLMs than prior methods. For instance, while Gemini 2.5 Pro shows some resilience to Speech Insertion (13.41% ASR) and Speech Editing (23.00% ASR), its vulnerability skyrockets to 65.41% ASR on SACRED-Bench. This trend is even more pronounced for open-source models like Qwen3-Omni, whose ASR jumps from 8.94% on Speech Insertion to 81.50% on our benchmark. This disparity underscores that our methods, which manipulate semantic and contextual cues, are fundamentally more effective at bypassing modern safety alignments than attacks that rely on signal-level perturbations.</p>\n\n",
                "matched_terms": [
                    "sacredbench",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, and more importantly, the results reveal the remarkable generalization of SALMONN-Guard. It is crucial to note that SALMONN-Guard was trained exclusively on our SACRED-Bench data and was never fine-tuned on samples from these other attack distributions. Despite this, it demonstrates near-perfect defensive capabilities, reducing the ASR for Speech Insertion to 0.00% and for Speech Editing to just 3.00%. This indicates that by training on our diverse and complex composition-based attacks, SALMONN-Guard has learned to recognize the underlying principles of malicious audio manipulation, rather than merely overfitting to the patterns in its training set. Its ability to neutralize entirely unseen attack vectors validates it not just as a defense against SACRED, but as a robust and generalizable safeguard for the broader audio modality.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "salmonnguard",
                    "sacredbench",
                    "set",
                    "asr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We introduced SACRED-Bench, a benchmark demonstrating that compositional audio attacks can effectively bypass existing safeguards. Our experiments revealed significant vulnerabilities in state-of-the-art LLMs, with an Attack Success Rate exceeding 66% on Gemini 2.5 Pro, exposing the critical limitations of text-centric safety filters. As a countermeasure, our proposed SALMONN-Guard successfully reduced the ASR to approximately 20% by performing holistic multimodal safety checks. This paper underscores the urgent need to develop robust, truly multimodal safety paradigms for the next generation of audio LLMs.</p>\n\n",
                "matched_terms": [
                    "salmonnguard",
                    "sacredbench",
                    "audio",
                    "asr"
                ]
            }
        ]
    },
    "A1.T6": {
        "source_file": "Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard",
        "caption": "Table 6: Distribution of types of composition in SACRED-Bench train and test set.",
        "body": "Composition\nTrain\nTest\n\n\nSpeech Overlapping\n6640\n400\n\n\nMulti-speaker Dialogue\n919\n1364\n\n\nSpeech-Audio Mixture\n986\n717\n\n\nOverall\n8545\n2481",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\">Composition</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">Train</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">Test</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">Speech Overlapping</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">6640</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">400</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Multi-speaker Dialogue</td>\n<td class=\"ltx_td ltx_align_center\">919</td>\n<td class=\"ltx_td ltx_align_center\">1364</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Speech-Audio Mixture</td>\n<td class=\"ltx_td ltx_align_center\">986</td>\n<td class=\"ltx_td ltx_align_center\">717</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">Overall</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">8545</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">2481</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "speech",
            "overlapping",
            "overall",
            "composition",
            "test",
            "dialogue",
            "mixture",
            "train",
            "distribution",
            "speechaudio",
            "multispeaker",
            "types",
            "sacredbench",
            "set"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Recent progress in large language models (LLMs) has enabled understanding of both speech and non-speech audio, but exposing new safety risks emerging from complex audio inputs that are inadequately handled by current safeguards. We introduce SACRED-Bench (Speech&#8211;Audio Composition for RED-teaming) to evaluate the robustness of LLMs under complex audio-based attacks. Unlike existing perturbation-based methods that rely on noise optimization or white-box access, SACRED-Bench exploits speech&#8211;audio composition mechanisms. SACRED-Bench adopts three mechanisms: (a) speech overlap and multi-speaker dialogue, which embeds harmful prompts beneath or alongside benign speech; (b) speech-audio mixture, which imply unsafe intent via non-speech audio alongside benign speech or audio; and (c) diverse spoken instruction formats (open-ended QA, yes/no) that evade text-only filters. Experiments show that, even Gemini 2.5 Pro, the state-of-the-art proprietary LLM, still exhibits 66% attack success rate in SACRED-Bench test set, exposing vulnerabilities under cross-modal, speech&#8211;audio composition attacks. To bridge this gap, we propose SALMONN-Guard, the first guard model that jointly inspects speech, audio, and text for safety judgments, reducing attack success down to 20%. Our results highlight the need for audio-aware defenses for the safety of multimodal LLMs. The benchmark and SALMONN-Guard checkpoints can be found at <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/tsinghua-ee/SACRED-Bench\" title=\"\">https://huggingface.co/datasets/tsinghua-ee/SACRED-Bench</a>. <span class=\"ltx_text\" style=\"--ltx-fg-color:#FF0000;\">Warning: this paper includes examples that may be offensive or harmful.</span></p>\n\n",
                "matched_terms": [
                    "speech",
                    "composition",
                    "dialogue",
                    "test",
                    "mixture",
                    "speechaudio",
                    "multispeaker",
                    "sacredbench",
                    "set"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we introduce Speech-Audio Composition for RED-teaming Benchmark (<span class=\"ltx_text ltx_font_bold\">SACRED-Bench</span>), a new highly effective audio jailbreaking approach to extensively exploit the complexity of audio signals for red-teaming. Instead of relying on artificial signal manipulations or adversarial training, SACRED-Bench leverages the composition of speech and audio cues to jailbreak multimodal models. Specifically, harmful audio signals are constructed using the following three types of composition mechanisms: (a). <em class=\"ltx_emph ltx_font_italic\">Speech overlap and multi-speaker dialogue</em>: Embedding harmful speech beneath or alongside benign utterances, or within a long spoken dialogue to bypass safety filters. (b). <em class=\"ltx_emph ltx_font_italic\">Speech-audio mixture</em>: Implying harmful intent or content through non-verbal sound events rather than explicit speech content, and (c). <em class=\"ltx_emph ltx_font_italic\">Diverse spoken question format</em>: Using not only open-ended question answering (QA), but also binary Yes-No questions in the instructions, which can not be detected or prevented by text-only guard models.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "composition",
                    "dialogue",
                    "mixture",
                    "speechaudio",
                    "multispeaker",
                    "types",
                    "sacredbench"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Based on the construction principles, we curate the SACRED-Bench dataset containing 30 hours of training audio and 7 hours of test data. Our experiments show that even state-of-the-art proprietary LLMs such as Google Gemini 2.5 pro, still has over 66% attack success rates (ASR) under attacks in SACRED-Bench test set. Such vulnerability is particularly attribute to the insufficiency of text-only safeguard mechanisms that are prevailing among current LLM providers, where the guard only examines the safety of the output text content. To mitigate this gap, we propose SALMONN-Guard, a safeguarding LLM designed to incorporate speech and audio as input in addition to text for safety judgments. SALMONN-Guard drastically reduced ASR on SACRED-Bench test set down to around 20%, effectively mitigating speech-audio-composition attacks. The main contributions of our paper can be summarized as follows.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench",
                    "set",
                    "test"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Experiments show that as high as 66% ASR are achieved even under the guardrails of Gemini 2.5 Pro using SACRED-Bench test set, highlighting the vulnerability of current safeguarding methods under complex speech-audio composition and cross-modal attacks.</p>\n\n",
                "matched_terms": [
                    "composition",
                    "test",
                    "speechaudio",
                    "sacredbench",
                    "set"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Audio-based red-teaming and jailbreaking work has been developed more recently. Specifically, harmful speech synthesis and speech-text interleaved attack methods <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite> have been developed as earlier examples, showing alarming attack success rate on widely-used LLMs. More recently, audio-manipulation-based attacks combined with dedicated optimization loops have been developed <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cheng2025jailbreakaudiobenchindepthevaluationanalysis</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>)</cite>. A comprehensive benchmark aggregating aforementioned attack methods is provided in <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peng2025jalmbenchbenchmarkingjailbreakvulnerabilities</span>)</cite>.\nHowever, these attack only explore speech without non-speech audio, basic audio manipulations such as speed perturbation or noise injection, and single-speaker speech. In contrast, SACRED-Bench focuses on the complex nature of audio signals and incorporates much richer audio elements. On the other hand, not much work has been done on the defense side for audio LLMs, except for the noise-injection defense approach was adopted <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peri2024speechguardexploringadversarialrobustness</span>)</cite>. This paper proposes the first general audio guard model to ensure safety of audio LLMs.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Explore complexity of speech signal.</span> The construction of SACRED-Bench systematically incorporates multi-speaker and overlapped speech. This principle ensures that our benchmark evaluates a model&#8217;s ability to process complex speech signals instead of just understanding clean, single-source speech, thereby reflecting the richness and ambiguity of real-world audio inputs.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "multispeaker",
                    "sacredbench"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Exploiting non-speech audio.</span> While previous work predominantly focuses on speech content <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">song2025audiojailbreakopencomprehensive</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite>, non-speech audio often carries harmful content beyond words, such as violence and pornography. SACRED-Bench exploits harmful audio by embedding them in the benign speech stream. This approach crafts audio capable of bypassing unimodal safety filters that are not attuned to speech-audio mixture complexities.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench",
                    "speechaudio",
                    "mixture"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To create a comprehensive and challenging set of prompts, we aggregated harmful instructions from a wide array of established red-teaming benchmarks. Specifically, our collection is drawn from AdvBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">zou2023AdvBench</span>)</cite>, MM-SafetyBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mmsafety</span>)</cite>, and HarmBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">mazeika2024harmbench</span>)</cite>. By combining prompts from these diverse sources, we ensure our test cases cover an extensive spectrum of risk categories. This aggregated pool serves as the textual basis for generating the harmful speech and conversational content used in our benchmark. The distribution of harmful content in SACRED-Bench test set is shown in Fig. <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.F2\" title=\"Figure 2 &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. To create harmful speech instructions, ChatTTS engine was adopted to synthesize from these text instructions.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "test",
                    "distribution",
                    "sacredbench",
                    "set"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For attacks requiring a benign audio carrier, such as the speech overlap and spoken dialogue methods, we utilized the VoiceBank-DEMAND dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voicebank</span>)</cite>. As a widely-used corpus known for its high-quality clean speech from a variety of speakers, its public accessibility and high-quality audio make it an ideal source of harmless speech to serve as the background or conversational filler in our synthesized audio samples.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "dialogue"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To construct attacks that leverage auditory context to imply harmful intent, we curated a library of potent audio tracks. These tracks were extracted from publicly available online videos featuring adult-oriented or intimate content. The design of these attacks hinges on pairing this contextually-charged audio with otherwise benign speech. This creates a malicious or harmful audio-based query, designed to test whether a model&#8217;s safety mechanisms can recognize situational context that is entirely absent from the speech content.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "test"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We adopts three types of composition mechanisms, including (i). speech overlapping, (ii). multi-speaker dialogue and (iii). speech-audio mixture, as described in this section. Detailed dataset statistics are shown in Appendix <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#A1\" title=\"Appendix A Detailed SACRED-Bench Statistics &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">A</span></a>.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "overlapping",
                    "composition",
                    "dialogue",
                    "mixture",
                    "speechaudio",
                    "multispeaker",
                    "types"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">With the semantic stage set, we then apply the second layer of deception at the signal level: acoustic masking. After synthesizing both the benign carrier and the harmful payload using the ChatTTS engine, we manipulate the harmful audio to reduce its perceptual salience by adjusting key acoustic parameters, including its volume, playback speed, and temporal overlap. The two streams are then composed using a cross-fade into a single, fluid utterance. Crucially, the chosen parameters ensure that the harmful content, while subtle, remains fully perceptible to the model, as we validate in our analysis. A detailed empirical justification for our choice of these hyperparameters is provided in our ablation study (Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.SS3\" title=\"5.3 Ablation Studies &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">5.3</span></a>). The final composition results in an utterance where the malicious instruction is both contextually justified and acoustically concealed.</p>\n\n",
                "matched_terms": [
                    "composition",
                    "set"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The final step is to bring these two components together into a cohesive auditory scene. We utilize the multi-speaker capabilities of the ChatTTS engine to synthesize the dialogue script into a realistic audio file, assigning distinct vocal characteristics to each speaker. The final attack prompt is the combination of this harmful conversational audio with the benign textual trigger. This presents the model with a complex jailbreaking challenge, forcing it to reconcile a harmless-looking text instruction with a clearly malicious audio payload, thereby testing the true depth of its cross-modal safety reasoning.</p>\n\n",
                "matched_terms": [
                    "multispeaker",
                    "dialogue"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:679.9pt;height:158pt;vertical-align:-76.5pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<span class=\"ltx_p\">\n<span class=\"ltx_tabular ltx_align_middle\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Models</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Speech Overlap (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Dialogue (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Contextual Audio Cues (%)</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Overall (%)</span></span></span>\n<span class=\"ltx_tr\" style=\"--ltx-bg-color:#E6E6E6;\">\n<span class=\"ltx_td ltx_align_left ltx_border_t ltx_colspan ltx_colspan_5\"><span class=\"ltx_text\" style=\"font-size:90%;--ltx-bg-color:#E6E6E6;\">Open-source Models</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2-Audio-7B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2-audio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">96.48</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.16</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2.5-Omni-7B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">qwen2.5_omni</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.78</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">87.02</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">100.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">92.83</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen3-Omni-30B-A3B-Instruct </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">xu2025qwen3</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">49.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">84.82</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">93.17</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.50</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Step-Audio 2 mini Base </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025step-audio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">90.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.49</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.33</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.57</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">MiniCPM-o 2.6 8B </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yao2024minicpm</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.84</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">69.87</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">77.95</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Kimi-Audio-7B-Instruct </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025kimiaudio</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">69.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">61.36</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">87.17</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.05</span></span></span>\n<span class=\"ltx_tr\" style=\"--ltx-bg-color:#E6E6E6;\">\n<span class=\"ltx_td ltx_align_left ltx_border_t ltx_colspan ltx_colspan_5\"><span class=\"ltx_text\" style=\"font-size:90%;--ltx-bg-color:#E6E6E6;\">Proprietary Models</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini 1.5 Pro </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gemini1.5pro</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">83.50</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">98.47</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.12</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini 2.5 Pro </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2025gemini2.5</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">37.25</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">63.93</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">88.56</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">66.75</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">GPT-4o </span><cite class=\"ltx_cite ltx_citemacro_citeyearpar\"><span class=\"ltx_text\" style=\"font-size:90%;\">(</span><span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">2024gpt4o</span><span class=\"ltx_text\" style=\"font-size:90%;\">)</span></cite><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">73.00</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">53.67</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">99.58</span></span>\n<span class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.05</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SALMONN-Guard (ours)</span><span class=\"ltx_text\" style=\"font-size:90%;\"> &#8194;&#8202;</span><span class=\"ltx_rule\" style=\"width:0.5pt;--ltx-bg-color:black;display:inline-block;\">&#160;</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">12.93</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">14.08</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">5.16</span></span>\n<span class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">11.32</span></span></span>\n</span><span class=\"ltx_text\" style=\"font-size:90%;\"/></span>\n</span></span></p>\n\n",
                "matched_terms": [
                    "speech",
                    "overall",
                    "dialogue"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To counter the new speech-audio composition attacks introduced in this paper, we propose and develop <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span>, a dedicated audio guard model. SALMONN-Guard is designed to serve as a proactive defensive layer, identifying and intercepting malicious audio inputs before they can reach a target LLM. This section details its architecture, the curation of its training data and specifications.</p>\n\n",
                "matched_terms": [
                    "speechaudio",
                    "composition"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Acknowledging the scarcity of ethically-sourced harmful data, we synthesized our training corpus by leveraging established red-teaming benchmarks&#8212;AdvBench, MM-SafetyBench, and HarmBench&#8212;as a conceptual foundation. Instead of using the original prompts directly, we employ GPT-4o to generate a new, distinct set of harmful instructions, ensuring no direct data leakage. This process yields a training corpus of approximately <span class=\"ltx_text ltx_font_bold\">10k</span> instances (8,545 harmful, 1,828 benign), with the harmful data distributed across speech overlap (6,640), speech-audio mixture (986), and multi-speaker dialogue (919) instances. The benign samples are used to prevent model collapse to only outputting the unsafe class. To ensure a rigorous evaluation of generalization, we enforced a strict cross-dataset validation protocol: for any given attack category, the source benchmark used to inspire the training prompts was held out from the test set.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "dialogue",
                    "test",
                    "mixture",
                    "speechaudio",
                    "multispeaker",
                    "set"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We employed a two-stage fine-tuning curriculum to first build general robustness and then specialize in complex threats. In Stage 1, the model was trained for three epochs on the entire dataset. In Stage 2, we conducted five additional epochs of training exclusively on the multi-speaker dialogue subset to bolster the model&#8217;s capabilities against this cross-modal attacks that is particularly challenging for the model to learn. For parameter-efficient fine-tuning, we utilized Low-Rank Adaptation (LoRA), applying updates concurrently to the large language model, the audio encoder, and the aligner module. A comprehensive list of hyperparameters is provided in the Appendix.</p>\n\n",
                "matched_terms": [
                    "multispeaker",
                    "dialogue"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Benchmark and Metrics:</span> All experiments are conducted on our SACRED-Bench, which evaluates models against three attack methods: speech overlap, multi-speaker dialogue, and speech-audio mixture. Our major evaluation metric is the Attack Success Rate (ASR %), which quantifies the percentage of times a model fails to adhere to its safety alignment and complies with the malicious prompt. The classification of a successful attack varies by task format. For the binary classification task, an attack is successful if the model fails to correctly identify there is harmful content in the audio. For the Open-Ended task, we employ an automated evaluation pipeline where Gemini 2.5 Pro serves as a judge, classifying the target model&#8217;s generated response as either &#8220;harmful&#8221; (a successful attack) or &#8220;harmless&#8221;. Therefore, in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, higher ASR values consistently indicate a greater degree of vulnerability.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "dialogue",
                    "mixture",
                    "speechaudio",
                    "multispeaker",
                    "sacredbench"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We present the detailed experimental results in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>. Overall, the results shows that both leading proprietary and major open-source models unfortunately exhibit significant vulnerabilities when confronted with our proposed speech-audio composition attacks.</p>\n\n",
                "matched_terms": [
                    "overall",
                    "speechaudio",
                    "composition"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Proprietary Models Exhibit Exploitable Loopholes.</span>\nAs seen in the results, while top-tier models like Gemini 2.5 Pro demonstrate some defensive capabilities, they are far from infallible. Particularly under the speech-audio mixture attack, Gemini 2.5 Pro shows a high attack success rate of 88.56%, and its success rate for the Multi-speaker Dialogue attack is also significant at 63.93%. This suggests that current safety mechanisms may be more focused on analyzing explicit textual instructions, while being less capable of identifying implicit malicious intent conveyed through non-speech audio or complex conversational structures.</p>\n\n",
                "matched_terms": [
                    "multispeaker",
                    "speechaudio",
                    "dialogue",
                    "mixture"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Analysis of Different Attack Strategies&#8217; Efficacy.</span>\nAn analysis of the individual attack strategies reveals that each method successfully exploits distinct architectural weaknesses. The <span class=\"ltx_text ltx_font_bold\">speech-audio mixture</span> method proved the most potent, with a staggering 88.56% ASR against Gemini 2.5 Pro and nearly 100% on several open-source models, underscoring a critical &#8217;cross-modal blindness.&#8217; Models adeptly transcribe a benign spoken query while completely ignoring the malicious intent conveyed by background audio. Similarly effective, the <span class=\"ltx_text ltx_font_bold\">Multi-speaker Dialogue</span> method demonstrates how requests can be obfuscated within a natural conversation, successfully bypassing safety filters that may only detect direct, command-like instructions. The high ASR of 63.93% against Gemini 2.5 Pro highlights the difficulty even advanced models face in assessing risks distributed throughout a long-form dialogue. Lastly, the <span class=\"ltx_text ltx_font_bold\">Speech Overlap</span> attack targeted the models&#8217; information processing in complex acoustic environments. Although Gemini 2.5 Pro showed improved resistance, high success rates against Gemini 1.5 Pro (74.89%) and the Qwen series confirm that for most models, disentangling overlapping audio remains a significant security flaw.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "overlapping",
                    "dialogue",
                    "mixture",
                    "speechaudio",
                    "multispeaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Effectiveness of SALMONN-Guard as a Guard Model.</span>\nIn stark contrast to other models, our proposed <span class=\"ltx_text ltx_font_bold\">SALMONN-Guard</span> demonstrates exceptional defensive performance. As shown in the last row of Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S3.T1\" title=\"Table 1 &#8227; 3.3.2 Open-Ended Questions &#8227; 3.3 Question-Answer Pair Formulation &#8227; 3 SACRED-Bench &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, SALMONN-Guard drastically reduces the success rate for all types of attacks. It slashes the ASR for speech-audio mixture from Gemini 2.5 Pro&#8217;s 88.56% to a mere 5.16%, and suppresses the ASRs for Speech Overlap and Multi-speaker Dialogue to 12.93% and 28.09%, respectively. <span class=\"ltx_text ltx_font_italic\">We also test SALMONN-Guard on all the benign audios used to composite SACRED-Bench as shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T5\" title=\"Table 5 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, and an 100% classification accuracy was achieved where none of them were flagged as harmful.</span> This result fully validates the effectiveness of our proposed approach: training a specialized, lightweight guard model to preemptively identify and intercept malicious audio inputs is a viable and highly efficient path to protecting downstream LLMs from complex audio-based attacks.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "dialogue",
                    "test",
                    "mixture",
                    "speechaudio",
                    "multispeaker",
                    "types",
                    "sacredbench"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, we conducted an ablation study on the acoustic attributes of the speech overlap attack. To ensure intelligibility of audio mixture, in addition to manual listening check conducted among co-authors, we prompt Gemini 2.5 Pro to describe the audio content. If the description matches both parts of the speech, or refuses to generate one side due to safety reasons, we consider it as perceptible. As a results, 93% of the samples in the speech overlap partition can be clearly perceived by Gemini 2.5 pro. This ensures that the speech overlap is sufficiently intelligible given that Gemini 2.5 pro is imperfect in understanding overlapped speech.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "mixture"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Furthermore, we conducted an ablation study on the Multi-speaker Dialogue attack to isolate the source of its efficacy. As shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T3\" title=\"Table 3 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, we evaluated Gemini 1.5 Pro against unimodal baselines. The results demonstrate that our cross-modal Text + Audio approach (78.58% ASR) is significantly more potent than either a Text-Only (57.96% ASR) or Audio-Only (65.03% ASR) attack. This confirms that the attack&#8217;s high success rate stems from the synergistic effect of pairing a benign text prompt with a malicious audio context, a strategy that effectively bypasses unimodal safety checks.</p>\n\n",
                "matched_terms": [
                    "multispeaker",
                    "dialogue"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To highlight the unique nature of our speech-audio composition-based attacks and evaluate the generalization of our defense, we compare model performance against two recent perturbation-based audio jailbreaking methods: Speech Insertion <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">yang2024audioachillesheelred</span>)</cite> and Speech Editing <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">cheng2025jailbreakaudiobenchindepthevaluationanalysis</span>)</cite>. The evaluation data for these methods is sourced from JALMBench <cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">peng2025jalmbenchbenchmarkingjailbreakvulnerabilities</span>)</cite>. For Speech Insertion, we use the 246 samples from the SSJ subset. For Speech Editing, we use a 100-sample subset from AMSE, which involves 18 distinct edits per sample, resulting in 1,800 total audio inputs. The results, presented in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.10222v2#S5.T4\" title=\"Table 4 &#8227; 5.2 Main Results and Analysis &#8227; 5 Experiment &#8227; Speech-Audio Compositional Attacks on Multimodal LLMs and Their Defense with SALMONN-Guard\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, reveal that our methods exploit a fundamentally different class of vulnerabilities for which current models are largely unprepared. This analysis leads to two critical findings.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "speechaudio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, the results demonstrate that our speech-audio composition-based attacks pose a far greater challenge to state-of-the-art LLMs than prior methods. For instance, while Gemini 2.5 Pro shows some resilience to Speech Insertion (13.41% ASR) and Speech Editing (23.00% ASR), its vulnerability skyrockets to 65.41% ASR on SACRED-Bench. This trend is even more pronounced for open-source models like Qwen3-Omni, whose ASR jumps from 8.94% on Speech Insertion to 81.50% on our benchmark. This disparity underscores that our methods, which manipulate semantic and contextual cues, are fundamentally more effective at bypassing modern safety alignments than attacks that rely on signal-level perturbations.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench",
                    "speechaudio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, and more importantly, the results reveal the remarkable generalization of SALMONN-Guard. It is crucial to note that SALMONN-Guard was trained exclusively on our SACRED-Bench data and was never fine-tuned on samples from these other attack distributions. Despite this, it demonstrates near-perfect defensive capabilities, reducing the ASR for Speech Insertion to 0.00% and for Speech Editing to just 3.00%. This indicates that by training on our diverse and complex composition-based attacks, SALMONN-Guard has learned to recognize the underlying principles of malicious audio manipulation, rather than merely overfitting to the patterns in its training set. Its ability to neutralize entirely unseen attack vectors validates it not just as a defense against SACRED, but as a robust and generalizable safeguard for the broader audio modality.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sacredbench",
                    "set"
                ]
            }
        ]
    }
}