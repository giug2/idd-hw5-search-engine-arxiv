{
    "S4.T1": {
        "caption": "Table 1: Word error rate (WER%) and real-time factor (RTF) for all proposed frameworks on LibriSpeech test-clean and test-other datasets.",
        "body": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt\" rowspan=\"2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:11.4pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">\n<span class=\"ltx_tabular ltx_align_middle\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Sys</span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">No.</span></span>\n</span> </span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Model &amp; Setting</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">WER</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">RTF</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">clean</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">other</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">clean</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">other</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:11.4pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Whisper-LLaMA 3.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.24</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.63</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.253</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.253</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:11.4pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Whisper-Vicuna</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.40</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.82</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.472</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.459</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:11.4pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">3</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Whisper-Large v2</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.87</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.16</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.196</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.216</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:11.4pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">4</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Whisper-Large v3</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.03</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">3.90</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.186</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.195</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Whisper-LLaDA</span></td>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_top ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8195;Step 1</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">11.04</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">17.56</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.033</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.039</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_top ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8195;Step 4</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.37</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">10.72</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.046</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.052</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_top ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8195;Step 8</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">3.78</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">7.39</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.055</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.063</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:11.4pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8195;Step 16</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">3.13</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">6.32</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.073</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.080</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_top ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8195;Step 32</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.96</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.80</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.112</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.122</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_top ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8195;Step 64</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">2.82</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.79</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.185</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.194</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_top ltx_border_bb ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8195;Step 128</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.96</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">5.75</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.333</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.343</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "testclean",
            "word",
            "wer",
            "librispeech",
            "setting",
            "error",
            "whisperllada",
            "step",
            "sys",
            "rate",
            "whisperllama",
            "whispervicuna",
            "whisperlarge",
            "realtime",
            "testother",
            "factor",
            "datasets",
            "proposed",
            "frameworks",
            "clean",
            "model",
            "all",
            "other",
            "rtf"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 4.1 Baseline &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> summarizes the baseline results on LibriSpeech benchmark. We primarily consider two LLM-based ASR systems, Whisper-LLaMA and Whisper-Vicuna&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib43\" title=\"\">43</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, as our baselines. Both systems achieve strong recognition accuracy, with Whisper-LLaMA (Sys.&#160;1) reaching 2.24%/5.63% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">/</span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Whisper-Vicuna (Sys.&#160;2) showing slightly higher WER and a larger real-time factor (RTF).</span>\n</p>\n\n",
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We observe the following trends for diffusion decoding (Sys.&#160;5) in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 4.1 Baseline &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\n(a) Increasing the number of denoising steps steadily reduces WER, albeit with higher RTF. The best result on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (2.82%) is achieved with 64 steps, while the lowest WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (5.75%) is obtained with 128 steps. These gains, however, diminish as the step count grows, indicating a saturation effect.\n(b) The RTFs for 1&#8211;64 steps remain consistently lower than those of AR baselines. Notably, the 64-step setting achieves a favorable trade-off, with 2.82%/5.79% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">testclean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">/</span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, surpassing Sys.&#160;2 on the latter. It also runs about </span>\n  <math alttext=\"1.3\\times\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S4.SS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">1.3</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\">&#215;</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">1.3\\times</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> faster than Sys.&#160;1 and </span>\n  <math alttext=\"2.4\\times\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S4.SS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">2.4</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\">&#215;</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">2.4\\times</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> faster than Sys.&#160;2, offering more efficient inference with a moderate accuracy loss relative to most AR frameworks.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Diffusion-based large language models (DLLMs) have recently attracted growing interest as an alternative to autoregressive decoders. In this work, we present an empirical study on using the diffusion-based large language model LLaDA for automatic speech recognition (ASR). We first investigate its use as an external deliberation-based processing module for Whisper-LLaMA transcripts. By leveraging the bidirectional attention and denoising capabilities of LLaDA, we explore random masking, low-confidence masking, and semi-autoregressive strategies, showing that Whisper-LLaDA substantially reduces WER compared with the baseline. On LibriSpeech, the best cascade system achieves 2.25%/4.94% WER on test-clean/test-other, representing a 12.3% relative improvement over the Whisper-LLaMA baseline on the test-other split. In contrast, a plain-text LLaDA without acoustic features fails to improve accuracy, highlighting the importance of audio-conditioned embeddings. We further evaluate Whisper-LLaDA as a standalone decoder for ASR with diffusion-based and semi-autoregressive decoding. Most experimental configurations achieve faster inference than the Whisper-LLaMA baseline, although recognition accuracy is slightly lower. These findings offer an empirical view of diffusion-based LLMs for ASR and point to promising directions for improvements.</span>\n</p>\n\n",
                "matched_terms": [
                    "whisperllada",
                    "wer",
                    "librispeech",
                    "model",
                    "testother",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Prior studies have explored external deliberation-based processing mechanisms that refine original hypotheses or N-best lists&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib34\" title=\"\">34</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib35\" title=\"\">35</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib36\" title=\"\">36</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib37\" title=\"\">37</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, showing notable error reductions. Building upon these observations and inspired by recent progress in deliberation-based refinement, our study makes the following contributions: </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">(i)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> A systematic investigation on utilizing LLaDA as an external language model within ASR systems, demonstrating significant improvements in\nrecognition accuracy compared to conventional autoregressive (AR) baselines.\n</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">(ii)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> A novel exploration of employing LLaDA internally as a diffusion-based decoder within end-to-end ASR frameworks, highlighting substantial gains in parallel decoding capabilities and efficiency while maintaining competitive recognition performance relative to both AR and existing non-autoregressive (NAR) approaches.\n</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">(iii)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> A systematic investigation of decoding strategies is conducted on the LibriSpeech corpus through extensive hyperparameter studies, specifically investigating a semi-autoregressive decoding strategy.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "librispeech",
                    "frameworks",
                    "error"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Diffusion-based large language models are defined by a generative process over discrete token sequences through a forward masking process and a learned reverse process.\n</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">The forward process</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> gradually replaces tokens in a clean sequence </span>\n  <math alttext=\"x_{0}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">x</mi>\n        <mn mathsize=\"0.900em\">0</mn>\n      </msub>\n      <annotation encoding=\"application/x-tex\">x_{0}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with a mask token </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">[MASK]</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as a function of continuous time </span>\n  <math alttext=\"t\\in[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">&#8712;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n          <mn mathsize=\"0.900em\">0</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">1</mn>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t\\in[0,1]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where the sequence is fully revealed at given </span>\n  <math alttext=\"t=0\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">0</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t=0</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">; each token is independently masked with probability </span>\n  <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">t</mi>\n      <annotation encoding=\"application/x-tex\">t</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as </span>\n  <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">t</mi>\n      <annotation encoding=\"application/x-tex\">t</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> increases, and all tokens are masked at </span>\n  <math alttext=\"t=1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m6\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">1</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t=1</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\n</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">The reverse process</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> starts from a fully masked sequence and iteratively predicts masked tokens conditioned on the unmasked ones, recovering a coherent sample at </span>\n  <math alttext=\"t\\to 0\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m7\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\" stretchy=\"false\">&#8594;</mo>\n        <mn mathsize=\"0.900em\">0</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t\\to 0</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "all",
                    "clean"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">where </span>\n  <math alttext=\"x_{0}=[x_{0}^{1},\\cdots,x_{0}^{i},\\cdots,x_{0}^{L}]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <msub>\n          <mi mathsize=\"0.900em\">x</mi>\n          <mn mathsize=\"0.900em\">0</mn>\n        </msub>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n          <msubsup>\n            <mi mathsize=\"0.900em\">x</mi>\n            <mn mathsize=\"0.900em\">0</mn>\n            <mn mathsize=\"0.900em\">1</mn>\n          </msubsup>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#8943;</mi>\n          <mo mathsize=\"0.900em\">,</mo>\n          <msubsup>\n            <mi mathsize=\"0.900em\">x</mi>\n            <mn mathsize=\"0.900em\">0</mn>\n            <mi mathsize=\"0.900em\">i</mi>\n          </msubsup>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#8943;</mi>\n          <mo mathsize=\"0.900em\">,</mo>\n          <msubsup>\n            <mi mathsize=\"0.900em\">x</mi>\n            <mn mathsize=\"0.900em\">0</mn>\n            <mi mathsize=\"0.900em\">L</mi>\n          </msubsup>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">x_{0}=[x_{0}^{1},\\cdots,x_{0}^{i},\\cdots,x_{0}^{L}]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> represents the clean sequence, </span>\n  <math alttext=\"x_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p3.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">x</mi>\n        <mi mathsize=\"0.900em\">t</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">x_{t}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is obtained by independently masking each position with probability </span>\n  <math alttext=\"t\\sim U(0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p3.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">&#8764;</mo>\n        <mrow>\n          <mi mathsize=\"0.900em\">U</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mrow>\n            <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n            <mn mathsize=\"0.900em\">0</mn>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mn mathsize=\"0.900em\">1</mn>\n            <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n          </mrow>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t\\sim U(0,1]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and </span>\n  <math alttext=\"S_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p3.m4\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">S</mi>\n        <mi mathsize=\"0.900em\">t</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">S_{t}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the set consists of the positions of all masked tokens.\nWhile the supervised fine-tuning (SFT) is implemented using the following loss function:</span>\n</p>\n\n",
                "matched_terms": [
                    "all",
                    "clean"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We propose </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Whisper-LLaDA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, a model that integrates the Whisper-Large-v3 encoder&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib5\" title=\"\">5</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with the diffusion-based large language model LLaDA-8B-Instruct&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib33\" title=\"\">33</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The Whisper encoder extracts speech representations, which are passed through a window-level query Transformer (Q-Former)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib38\" title=\"\">38</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib6\" title=\"\">6</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which utilizes </span>\n  <math alttext=\"4\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">4</mn>\n      <annotation encoding=\"application/x-tex\">4</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> trainable queries with a </span>\n  <math alttext=\"0.33\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">0.33</mn>\n      <annotation encoding=\"application/x-tex\">0.33</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">-second window, and a projection layer to align modalities.</span>\n</p>\n\n",
                "matched_terms": [
                    "whisperllada",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The text decoder is LLaDA-8B-Instruct model, with LoRA&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib39\" title=\"\">39</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> applied to the query, key, and value projection layers of its self-attention blocks (rank </span>\n  <math alttext=\"8\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m1\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">8</mn>\n      <annotation encoding=\"application/x-tex\">8</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, scaling factor </span>\n  <math alttext=\"4.0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m2\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">4.0</mn>\n      <annotation encoding=\"application/x-tex\">4.0</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, dropout </span>\n  <math alttext=\"0.1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m3\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">0.1</mn>\n      <annotation encoding=\"application/x-tex\">0.1</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">). Only LoRA, the Q-Former, and the projection layer are trainable with about </span>\n  <math alttext=\"87\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m4\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">87</mn>\n      <annotation encoding=\"application/x-tex\">87</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">M parameters.</span>\n</p>\n\n",
                "matched_terms": [
                    "factor",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We trained both Whisper-LLaMA and Whisper-LLaDA on the LibriSpeech corpus&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib41\" title=\"\">41</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which contains 960 hours of English audiobooks. Speed perturbation was performed with factors of 0.9 and 1.1. During training, the Whisper encoder is frozen, while LLaMA/LLaDA are fine-tuned with LoRA. The resulting speech embeddings are concatenated with the textual prompt and ground-truth response embeddings. Following the diffusion formulation, the response block is randomly masked with probability </span>\n  <math alttext=\"t\\sim U(0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">&#8764;</mo>\n        <mrow>\n          <mi mathsize=\"0.900em\">U</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mrow>\n            <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n            <mn mathsize=\"0.900em\">0</mn>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mn mathsize=\"0.900em\">1</mn>\n            <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n          </mrow>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t\\sim U(0,1]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and LLaDA predicts the masked tokens conditioned on the remaining context. The model is optimized using cross-entropy loss over masked positions:</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "whisperllada",
                    "librispeech",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We organize the inputs into three components: a textual instruction, the acoustic features, and a response block. The textual instruction specifies the ASR task. The acoustic features are obtained by passing audio through the Whisper encoder, the Q-Former, and a projection layer, yielding 4096-dimensional embeddings aligned with LLaDA. For direct decoding, the response block is initialized with </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">[MASK]</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> tokens of length 128, which covers all LibriSpeech utterances as their lengths are shorter than 128 tokens. For deliberation-based processing, the response block is initialized with the Whisper-LLaMA transcript, and its length exactly matches that of the transcript sequence. LLaDA then performs the denoising process on this response block. Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3 Methods &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrates the two decoding strategies considered in our work: diffusion-based and semi-autoregressive decoding, as well as two general deliberation-based processing strategies: diffusion-based and semi-autoregressive deliberation.</span>\n</p>\n\n",
                "matched_terms": [
                    "all",
                    "librispeech",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Due to the denoising nature and bidirectional attention mechanism of the diffusion large language model, we explored a novel cascade framework for deliberation-based processing in ASR. We first obtain a transcript from the Whisper-LLaMA system to initialize the response block of Whisper-LLaDA. A proportion </span>\n  <math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS1.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">p</mi>\n      <annotation encoding=\"application/x-tex\">p</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> of response tokens are then selected and replaced with </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">[MASK]</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> based on the following strategies: (1) random selection; (2) select the lowest-confidence tokens, where confidence is yielded from a forward step of Whisper-LLaDA based on prompt and audio embedding; and (3) semi-autoregressive deliberation-based processing: dividing the transcript into several sub-blocks and remasking sequentially. After remasking, Whisper-LLaDA recovers the masked positions conditioned on the input prompt, the speech embeddings, and the unmasked tokens of the transcript. The reconstruction under the first two strategies is completed in one pass and the last entails one pass per sub-block, closely aligning with our training procedures. For completeness, we also attempted a plain-text version of LLaDA without Whisper embeddings.</span>\n</p>\n\n",
                "matched_terms": [
                    "whisperllada",
                    "model",
                    "step",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our experiments were conducted on LibriSpeech </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> sets&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib41\" title=\"\">41</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. All models were trained with the AdamW&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib42\" title=\"\">42</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> optimizer using a weight decay of 0.05. The learning rate followed a linear warmup&#8211;cosine decay schedule, starting from </span>\n  <math alttext=\"1\\times 10^{-6}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">1</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">6</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">1\\times 10^{-6}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, increasing to </span>\n  <math alttext=\"3\\times 10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">3</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">5</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">3\\times 10^{-5}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> within 3000 steps, and decaying to a minimum of </span>\n  <math alttext=\"1\\times 10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">1</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">5</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">1\\times 10^{-5}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The best checkpoint was selected based on the WER on the </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">dev-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> set in each run.</span>\n</p>\n\n",
                "matched_terms": [
                    "testclean",
                    "wer",
                    "rate",
                    "librispeech",
                    "all",
                    "testother"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">For reference, we also report the performance of Whisper-Large-v2/v3 (Sys.&#160;3&#8211;4). These systems achieve very competitive results (e.g., 3.90% WER on test-other with Whisper-Large v3). We expect their larger proprietary training datasets (up to </span>\n  <math alttext=\"\\sim\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">&#8764;</mo>\n      <annotation encoding=\"application/x-tex\">\\sim</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">5M hours) attribute to this. Therefore they are not directly comparable to our baselines.</span>\n</p>\n\n",
                "matched_terms": [
                    "sys",
                    "wer",
                    "whisperlarge",
                    "testother",
                    "datasets"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">First, we applied plain-text LLaDA to correct errors from Whisper-LLaMA. We initialized LLaDA with the LLaDA-8B-Instruct checkpoint and fine-tuned it on paired data consisting of Whisper-LLaMA transcripts and ground-truth text. The fine-tuned text-based LLaDA was then used to refine Whisper-LLaMA outputs. Notably, the response block length was set to match the length of the Whisper-LLaMA transcript. However, this approach introduced more errors, yielding 3.89% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and 6.91% on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, indicating that audio embeddings are essential for effective deliberation-based processing with LLaDA.</span>\n</p>\n\n",
                "matched_terms": [
                    "testclean",
                    "whisperllama",
                    "testother",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Subsequently, we turned to Whisper-LLaDA for deliberation-based processing on Whisper-LLaMA transcripts. In this setting, we directly used the end-to-end Whisper-LLaDA checkpoint without any additional training on Whisper-LLaMA outputs. Specifically, we investigated three strategies: (1) random masking; (2) lowest-confidence tokens masking; and (3) semi-autoregressive paradigm. The results for strategies (1) and (2) are presented in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 4.2 Deliberation-basd Processing &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while the results for strategy (3) are summarized in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2 Deliberation-basd Processing &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "whisperllada",
                    "setting",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The deliberation-based processing results demonstrate that Whisper-LLaDA yields consistent improvements over the Whisper-LLaMA baseline, confirming the effectiveness of diffusion-based refinement in recovering tokens that are challenging for autoregressive counterparts. Random masking achieves the best results when the mask ratio is 90%, while low-confidence masking brings only marginal improvements. In addition, semi-autoregressive deliberation-based processing with sub-block partition further improves recognition accuracy, suggesting that the bidirectional attention of LLaDA provides a useful supplement to the unidirectional attention in the Whisper-LLaMA model. Overall, these findings highlight the potential of Whisper-LLaDA as a complementary deliberation-based processing module for ASR systems.</span>\n</p>\n\n",
                "matched_terms": [
                    "whisperllada",
                    "model",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We investigate an alternative decoding strategy, namely semi-autoregressive decoding. The 128-token generation block is evenly divided into </span>\n  <math alttext=\"M\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">M</mi>\n      <annotation encoding=\"application/x-tex\">M</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> sub-blocks, within which LLaDA performs diffusion-based denoising, while proceeding in an autoregressive manner across sub-blocks. Up to 128 denoising steps are allocated and uniformly distributed among the sub-blocks. Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.F3\" style=\"font-size:90%;\" title=\"Figure 3 &#8227; 4.3 Diffusion-based Decoding &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> shows the effect of the number of denoising steps and the number of sub-blocks on overall performance:\n(a) Increasing the number of denoising steps per sub-block reduces WER, though the improvement saturates after roughly 16 steps per sub-block.\n(b) As the total number of steps grows, the performance gaps among settings become negligible.\n(c) The 4-block setting with 32 steps per sub-block achieves the best performance, with 2.40%/4.96% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The performance on the latter is significantly better than the LLaMA/Vicuna-based ASR baselines.</span>\n</p>\n\n",
                "matched_terms": [
                    "testclean",
                    "setting",
                    "testother",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This work presented a comprehensive empirical study of employing the diffusion-based language model LLaDA for automatic speech recognition. We examined three complementary perspectives: (i) applying plain-text LLaDA for transcript refinement, (ii) leveraging Whisper-LLaDA for cascade deliberation-based processing, and (iii) using LLaDA as a standalone decoder. Our findings reveal clear contrasts across these settings. Plain-text LLaDA fails to improve Whisper-LLaMA outputs, underscoring the necessity of audio embeddings for effective deliberation-based processing. In contrast, Whisper-LLaDA consistently enhances recognition quality, with random masking at high ratios and the semi-autoregressive framework delivering the largest gains. When used directly as a decoder, LLaDA enables faster inference than autoregressive baselines but with slightly higher WER in most settings.</span>\n</p>\n\n",
                "matched_terms": [
                    "whisperllada",
                    "model",
                    "whisperllama",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Overall, these results highlight both the potential and the current limitations of diffusion-based models in ASR. LLaDA offers effective deliberation-based processing and efficient decoding when conditioned on acoustic features, yet its accuracy still lags behind extensively pretrained autoregressive systems. Future work should scale Whisper-LLaDA with larger and more diverse training data beyond LibriSpeech and systematically explore more advanced masking/remasking policies to narrow the gap while preserving efficiency.</span>\n</p>\n\n",
                "matched_terms": [
                    "whisperllada",
                    "librispeech"
                ]
            }
        ]
    },
    "S4.T2": {
        "caption": "Table 2: WER (%) of cascade deliberation-based processing with random/low-confidence masking on LibriSpeech dev/test sets. Whisper-LLaMA is the Whisper-LLaMA transcript baseline.",
        "body": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mask ratio <math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.m1\" intent=\":literal\"><semantics><mi>p</mi><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Random masking</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Dev-clean</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Dev-other</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Test-clean</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Test-other</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Whisper-LLaMA</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.24</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.07</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.24</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.63</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">10%</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.25</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.05</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.23</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.59</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">30%</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">2.21</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.02</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.23</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.59</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">50%</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.28</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.05</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">2.21</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.55</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">70%</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.31</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">4.98</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.22</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.37</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">90%</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.32</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">4.92</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.23</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">5.24</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">100%</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.91</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.02</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.54</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.32</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mask ratio <math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T2.m2\" intent=\":literal\"><semantics><mi>p</mi><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Low-confidence masking</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Dev-clean</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Dev-other</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Test-clean</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Test-other</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Whisper-LLaMA</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">2.24</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.07</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.24</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.63</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">10%</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.27</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.06</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.24</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.63</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">30%</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.28</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.03</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.21</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.52</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">50%</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.32</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.02</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">2.18</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.43</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">70%</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.34</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">4.97</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">2.18</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.34</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">90%</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.31</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">4.96</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.26</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">5.23</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">100%</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.91</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.02</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.54</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.32</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "mask",
            "testclean",
            "processing",
            "wer",
            "deliberationbased",
            "librispeech",
            "devclean",
            "lowconfidence",
            "randomlowconfidence",
            "cascade",
            "devtest",
            "ratio",
            "whisperllama",
            "sets",
            "masking",
            "transcript",
            "devother",
            "testother",
            "random",
            "whisperllama",
            "baseline"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Subsequently, we turned to Whisper-LLaDA for deliberation-based processing on Whisper-LLaMA transcripts. In this setting, we directly used the end-to-end Whisper-LLaDA checkpoint without any additional training on Whisper-LLaMA outputs. Specifically, we investigated three strategies: (1) random masking; (2) lowest-confidence tokens masking; and (3) semi-autoregressive paradigm. The results for strategies (1) and (2) are presented in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 4.2 Deliberation-basd Processing &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while the results for strategy (3) are summarized in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2 Deliberation-basd Processing &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Diffusion-based large language models (DLLMs) have recently attracted growing interest as an alternative to autoregressive decoders. In this work, we present an empirical study on using the diffusion-based large language model LLaDA for automatic speech recognition (ASR). We first investigate its use as an external deliberation-based processing module for Whisper-LLaMA transcripts. By leveraging the bidirectional attention and denoising capabilities of LLaDA, we explore random masking, low-confidence masking, and semi-autoregressive strategies, showing that Whisper-LLaDA substantially reduces WER compared with the baseline. On LibriSpeech, the best cascade system achieves 2.25%/4.94% WER on test-clean/test-other, representing a 12.3% relative improvement over the Whisper-LLaMA baseline on the test-other split. In contrast, a plain-text LLaDA without acoustic features fails to improve accuracy, highlighting the importance of audio-conditioned embeddings. We further evaluate Whisper-LLaDA as a standalone decoder for ASR with diffusion-based and semi-autoregressive decoding. Most experimental configurations achieve faster inference than the Whisper-LLaMA baseline, although recognition accuracy is slightly lower. These findings offer an empirical view of diffusion-based LLMs for ASR and point to promising directions for improvements.</span>\n</p>\n\n",
                "matched_terms": [
                    "random",
                    "processing",
                    "wer",
                    "deliberationbased",
                    "librispeech",
                    "lowconfidence",
                    "masking",
                    "cascade",
                    "testother",
                    "baseline",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold ltx_font_italic\" style=\"font-size:90%;\">Index Terms<span class=\"ltx_text ltx_font_upright\">&#8212;&#8201;<span class=\"ltx_text ltx_font_medium\">\nAutomatic Speech Recognition, Diffusion Large Language Model, Non-Autoregressive, Deliberation-based Processing</span></span></span>\n</p>\n\n",
                "matched_terms": [
                    "deliberationbased",
                    "processing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">However, despite substantially reducing decoding latency, existing NAR approaches generally suffer from a slight degradation in recognition accuracy compared to AR methods, reflecting an inherent trade-off between efficiency and performance. This motivates the search for alternative paradigms that have the potential to mitigate this trade-off. Recent advances in diffusion-based large language models (DLLMs)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib29\" title=\"\">29</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib30\" title=\"\">30</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib31\" title=\"\">31</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib32\" title=\"\">32</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, exemplified by LLaDA&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib33\" title=\"\">33</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, offer a promising direction. By combining powerful self-attention mechanisms with strong semantic modeling capabilities, DLLMs provide new opportunities for enhancing ASR. In this work, we present an empirical study on integrating DLLMs into ASR in two ways: (1) as external deliberation-based processing modules, where DLLMs refine preliminary hypotheses generated by a base recognizer; and (2) as internal decoders, directly replacing the conventional AR/NAR decoding backbone. These explorations highlight both the potential of DLLMs to reshape ASR decoding and the limitations that remain, pointing to important directions for future research.</span>\n</p>\n\n",
                "matched_terms": [
                    "deliberationbased",
                    "processing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Prior studies have explored external deliberation-based processing mechanisms that refine original hypotheses or N-best lists&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib34\" title=\"\">34</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib35\" title=\"\">35</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib36\" title=\"\">36</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib37\" title=\"\">37</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, showing notable error reductions. Building upon these observations and inspired by recent progress in deliberation-based refinement, our study makes the following contributions: </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">(i)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> A systematic investigation on utilizing LLaDA as an external language model within ASR systems, demonstrating significant improvements in\nrecognition accuracy compared to conventional autoregressive (AR) baselines.\n</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">(ii)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> A novel exploration of employing LLaDA internally as a diffusion-based decoder within end-to-end ASR frameworks, highlighting substantial gains in parallel decoding capabilities and efficiency while maintaining competitive recognition performance relative to both AR and existing non-autoregressive (NAR) approaches.\n</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">(iii)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> A systematic investigation of decoding strategies is conducted on the LibriSpeech corpus through extensive hyperparameter studies, specifically investigating a semi-autoregressive decoding strategy.</span>\n</p>\n\n",
                "matched_terms": [
                    "deliberationbased",
                    "librispeech",
                    "processing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Diffusion-based large language models are defined by a generative process over discrete token sequences through a forward masking process and a learned reverse process.\n</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">The forward process</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> gradually replaces tokens in a clean sequence </span>\n  <math alttext=\"x_{0}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">x</mi>\n        <mn mathsize=\"0.900em\">0</mn>\n      </msub>\n      <annotation encoding=\"application/x-tex\">x_{0}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with a mask token </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">[MASK]</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as a function of continuous time </span>\n  <math alttext=\"t\\in[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">&#8712;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">[</mo>\n          <mn mathsize=\"0.900em\">0</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">1</mn>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t\\in[0,1]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where the sequence is fully revealed at given </span>\n  <math alttext=\"t=0\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">0</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t=0</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">; each token is independently masked with probability </span>\n  <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">t</mi>\n      <annotation encoding=\"application/x-tex\">t</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as </span>\n  <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">t</mi>\n      <annotation encoding=\"application/x-tex\">t</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> increases, and all tokens are masked at </span>\n  <math alttext=\"t=1\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m6\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">1</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t=1</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\n</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">The reverse process</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> starts from a fully masked sequence and iteratively predicts masked tokens conditioned on the unmasked ones, recovering a coherent sample at </span>\n  <math alttext=\"t\\to 0\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p1.m7\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\" stretchy=\"false\">&#8594;</mo>\n        <mn mathsize=\"0.900em\">0</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t\\to 0</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "mask",
                    "masking"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">As shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, Whisper-LLaDA supports both direct ASR from audio and deliberation-based processing of transcripts from external ASR systems, conditioned either on acoustic features alone or jointly on acoustic features and the given transcripts. We investigate this deliberation functionality on transcripts produced by a fine-tuned LLaMA-3.1-based&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib40\" title=\"\">40</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> ASR system.</span>\n</p>\n\n",
                "matched_terms": [
                    "deliberationbased",
                    "processing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We trained both Whisper-LLaMA and Whisper-LLaDA on the LibriSpeech corpus&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib41\" title=\"\">41</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which contains 960 hours of English audiobooks. Speed perturbation was performed with factors of 0.9 and 1.1. During training, the Whisper encoder is frozen, while LLaMA/LLaDA are fine-tuned with LoRA. The resulting speech embeddings are concatenated with the textual prompt and ground-truth response embeddings. Following the diffusion formulation, the response block is randomly masked with probability </span>\n  <math alttext=\"t\\sim U(0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">&#8764;</mo>\n        <mrow>\n          <mi mathsize=\"0.900em\">U</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mrow>\n            <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n            <mn mathsize=\"0.900em\">0</mn>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mn mathsize=\"0.900em\">1</mn>\n            <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n          </mrow>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t\\sim U(0,1]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and LLaDA predicts the masked tokens conditioned on the remaining context. The model is optimized using cross-entropy loss over masked positions:</span>\n</p>\n\n",
                "matched_terms": [
                    "librispeech",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We organize the inputs into three components: a textual instruction, the acoustic features, and a response block. The textual instruction specifies the ASR task. The acoustic features are obtained by passing audio through the Whisper encoder, the Q-Former, and a projection layer, yielding 4096-dimensional embeddings aligned with LLaDA. For direct decoding, the response block is initialized with </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">[MASK]</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> tokens of length 128, which covers all LibriSpeech utterances as their lengths are shorter than 128 tokens. For deliberation-based processing, the response block is initialized with the Whisper-LLaMA transcript, and its length exactly matches that of the transcript sequence. LLaDA then performs the denoising process on this response block. Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3 Methods &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrates the two decoding strategies considered in our work: diffusion-based and semi-autoregressive decoding, as well as two general deliberation-based processing strategies: diffusion-based and semi-autoregressive deliberation.</span>\n</p>\n\n",
                "matched_terms": [
                    "mask",
                    "processing",
                    "deliberationbased",
                    "librispeech",
                    "transcript",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Due to the denoising nature and bidirectional attention mechanism of the diffusion large language model, we explored a novel cascade framework for deliberation-based processing in ASR. We first obtain a transcript from the Whisper-LLaMA system to initialize the response block of Whisper-LLaDA. A proportion </span>\n  <math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS1.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">p</mi>\n      <annotation encoding=\"application/x-tex\">p</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> of response tokens are then selected and replaced with </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">[MASK]</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> based on the following strategies: (1) random selection; (2) select the lowest-confidence tokens, where confidence is yielded from a forward step of Whisper-LLaDA based on prompt and audio embedding; and (3) semi-autoregressive deliberation-based processing: dividing the transcript into several sub-blocks and remasking sequentially. After remasking, Whisper-LLaDA recovers the masked positions conditioned on the input prompt, the speech embeddings, and the unmasked tokens of the transcript. The reconstruction under the first two strategies is completed in one pass and the last entails one pass per sub-block, closely aligning with our training procedures. For completeness, we also attempted a plain-text version of LLaDA without Whisper embeddings.</span>\n</p>\n\n",
                "matched_terms": [
                    "mask",
                    "random",
                    "processing",
                    "deliberationbased",
                    "cascade",
                    "transcript",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our experiments were conducted on LibriSpeech </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> sets&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib41\" title=\"\">41</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. All models were trained with the AdamW&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib42\" title=\"\">42</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> optimizer using a weight decay of 0.05. The learning rate followed a linear warmup&#8211;cosine decay schedule, starting from </span>\n  <math alttext=\"1\\times 10^{-6}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">1</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">6</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">1\\times 10^{-6}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, increasing to </span>\n  <math alttext=\"3\\times 10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">3</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">5</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">3\\times 10^{-5}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> within 3000 steps, and decaying to a minimum of </span>\n  <math alttext=\"1\\times 10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">1</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">5</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">1\\times 10^{-5}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The best checkpoint was selected based on the WER on the </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">dev-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> set in each run.</span>\n</p>\n\n",
                "matched_terms": [
                    "testclean",
                    "devclean",
                    "wer",
                    "sets",
                    "librispeech",
                    "testother"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 4.1 Baseline &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> summarizes the baseline results on LibriSpeech benchmark. We primarily consider two LLM-based ASR systems, Whisper-LLaMA and Whisper-Vicuna&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib43\" title=\"\">43</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, as our baselines. Both systems achieve strong recognition accuracy, with Whisper-LLaMA (Sys.&#160;1) reaching 2.24%/5.63% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">/</span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Whisper-Vicuna (Sys.&#160;2) showing slightly higher WER and a larger real-time factor (RTF).</span>\n</p>\n\n",
                "matched_terms": [
                    "baseline",
                    "librispeech",
                    "whisperllama",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">For reference, we also report the performance of Whisper-Large-v2/v3 (Sys.&#160;3&#8211;4). These systems achieve very competitive results (e.g., 3.90% WER on test-other with Whisper-Large v3). We expect their larger proprietary training datasets (up to </span>\n  <math alttext=\"\\sim\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">&#8764;</mo>\n      <annotation encoding=\"application/x-tex\">\\sim</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">5M hours) attribute to this. Therefore they are not directly comparable to our baselines.</span>\n</p>\n\n",
                "matched_terms": [
                    "testother",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We explored the use of LLaDA as an external deliberation processing module for transcripts generated by Whisper-LLaMA as follows.</span>\n</p>\n\n",
                "matched_terms": [
                    "processing",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">First, we applied plain-text LLaDA to correct errors from Whisper-LLaMA. We initialized LLaDA with the LLaDA-8B-Instruct checkpoint and fine-tuned it on paired data consisting of Whisper-LLaMA transcripts and ground-truth text. The fine-tuned text-based LLaDA was then used to refine Whisper-LLaMA outputs. Notably, the response block length was set to match the length of the Whisper-LLaMA transcript. However, this approach introduced more errors, yielding 3.89% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and 6.91% on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, indicating that audio embeddings are essential for effective deliberation-based processing with LLaDA.</span>\n</p>\n\n",
                "matched_terms": [
                    "testclean",
                    "processing",
                    "wer",
                    "deliberationbased",
                    "transcript",
                    "testother",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The deliberation-based processing results demonstrate that Whisper-LLaDA yields consistent improvements over the Whisper-LLaMA baseline, confirming the effectiveness of diffusion-based refinement in recovering tokens that are challenging for autoregressive counterparts. Random masking achieves the best results when the mask ratio is 90%, while low-confidence masking brings only marginal improvements. In addition, semi-autoregressive deliberation-based processing with sub-block partition further improves recognition accuracy, suggesting that the bidirectional attention of LLaDA provides a useful supplement to the unidirectional attention in the Whisper-LLaMA model. Overall, these findings highlight the potential of Whisper-LLaDA as a complementary deliberation-based processing module for ASR systems.</span>\n</p>\n\n",
                "matched_terms": [
                    "mask",
                    "random",
                    "baseline",
                    "processing",
                    "deliberationbased",
                    "lowconfidence",
                    "masking",
                    "ratio",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We observe the following trends for diffusion decoding (Sys.&#160;5) in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 4.1 Baseline &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\n(a) Increasing the number of denoising steps steadily reduces WER, albeit with higher RTF. The best result on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (2.82%) is achieved with 64 steps, while the lowest WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (5.75%) is obtained with 128 steps. These gains, however, diminish as the step count grows, indicating a saturation effect.\n(b) The RTFs for 1&#8211;64 steps remain consistently lower than those of AR baselines. Notably, the 64-step setting achieves a favorable trade-off, with 2.82%/5.79% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">testclean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">/</span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, surpassing Sys.&#160;2 on the latter. It also runs about </span>\n  <math alttext=\"1.3\\times\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S4.SS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">1.3</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\">&#215;</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">1.3\\times</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> faster than Sys.&#160;1 and </span>\n  <math alttext=\"2.4\\times\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S4.SS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">2.4</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\">&#215;</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">2.4\\times</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> faster than Sys.&#160;2, offering more efficient inference with a moderate accuracy loss relative to most AR frameworks.</span>\n</p>\n\n",
                "matched_terms": [
                    "testclean",
                    "testother",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We investigate an alternative decoding strategy, namely semi-autoregressive decoding. The 128-token generation block is evenly divided into </span>\n  <math alttext=\"M\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">M</mi>\n      <annotation encoding=\"application/x-tex\">M</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> sub-blocks, within which LLaDA performs diffusion-based denoising, while proceeding in an autoregressive manner across sub-blocks. Up to 128 denoising steps are allocated and uniformly distributed among the sub-blocks. Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.F3\" style=\"font-size:90%;\" title=\"Figure 3 &#8227; 4.3 Diffusion-based Decoding &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> shows the effect of the number of denoising steps and the number of sub-blocks on overall performance:\n(a) Increasing the number of denoising steps per sub-block reduces WER, though the improvement saturates after roughly 16 steps per sub-block.\n(b) As the total number of steps grows, the performance gaps among settings become negligible.\n(c) The 4-block setting with 32 steps per sub-block achieves the best performance, with 2.40%/4.96% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The performance on the latter is significantly better than the LLaMA/Vicuna-based ASR baselines.</span>\n</p>\n\n",
                "matched_terms": [
                    "testclean",
                    "testother",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This work presented a comprehensive empirical study of employing the diffusion-based language model LLaDA for automatic speech recognition. We examined three complementary perspectives: (i) applying plain-text LLaDA for transcript refinement, (ii) leveraging Whisper-LLaDA for cascade deliberation-based processing, and (iii) using LLaDA as a standalone decoder. Our findings reveal clear contrasts across these settings. Plain-text LLaDA fails to improve Whisper-LLaMA outputs, underscoring the necessity of audio embeddings for effective deliberation-based processing. In contrast, Whisper-LLaDA consistently enhances recognition quality, with random masking at high ratios and the semi-autoregressive framework delivering the largest gains. When used directly as a decoder, LLaDA enables faster inference than autoregressive baselines but with slightly higher WER in most settings.</span>\n</p>\n\n",
                "matched_terms": [
                    "random",
                    "processing",
                    "wer",
                    "deliberationbased",
                    "masking",
                    "cascade",
                    "transcript",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Overall, these results highlight both the potential and the current limitations of diffusion-based models in ASR. LLaDA offers effective deliberation-based processing and efficient decoding when conditioned on acoustic features, yet its accuracy still lags behind extensively pretrained autoregressive systems. Future work should scale Whisper-LLaDA with larger and more diverse training data beyond LibriSpeech and systematically explore more advanced masking/remasking policies to narrow the gap while preserving efficiency.</span>\n</p>\n\n",
                "matched_terms": [
                    "deliberationbased",
                    "librispeech",
                    "processing"
                ]
            }
        ]
    },
    "S4.T3": {
        "caption": "Table 3: WER (%) of cascade deliberation-based processing with different sub-block partitions on LibriSpeech dev/test sets. Whisper-LLaMA is the Whisper-LLaMA transcript baseline.",
        "body": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">\n<span class=\"ltx_tabular ltx_align_middle\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">Number of</span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\">sub-blocks</span></span>\n</span> </span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"4\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">WER (%)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Dev-clean</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Dev-other</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Test-clean</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Test-other</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Whisper-LLaMA</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.24</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.07</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.24</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.63</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">2.21</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">4.83</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.25</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">4.94</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">4</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">2.21</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">4.84</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.22</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.21</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">6</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.26</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">4.86</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.23</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.26</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">8</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.30</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">4.86</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">2.20</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.25</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">10</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.27</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">4.81</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">2.21</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.0pt;padding-right:5.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">5.25</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "testclean",
            "processing",
            "wer",
            "deliberationbased",
            "librispeech",
            "devclean",
            "cascade",
            "devtest",
            "whisperllama",
            "subblocks",
            "sets",
            "partitions",
            "transcript",
            "devother",
            "testother",
            "number",
            "subblock",
            "whisperllama",
            "baseline",
            "different"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Subsequently, we turned to Whisper-LLaDA for deliberation-based processing on Whisper-LLaMA transcripts. In this setting, we directly used the end-to-end Whisper-LLaDA checkpoint without any additional training on Whisper-LLaMA outputs. Specifically, we investigated three strategies: (1) random masking; (2) lowest-confidence tokens masking; and (3) semi-autoregressive paradigm. The results for strategies (1) and (2) are presented in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 4.2 Deliberation-basd Processing &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while the results for strategy (3) are summarized in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 4.2 Deliberation-basd Processing &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Diffusion-based large language models (DLLMs) have recently attracted growing interest as an alternative to autoregressive decoders. In this work, we present an empirical study on using the diffusion-based large language model LLaDA for automatic speech recognition (ASR). We first investigate its use as an external deliberation-based processing module for Whisper-LLaMA transcripts. By leveraging the bidirectional attention and denoising capabilities of LLaDA, we explore random masking, low-confidence masking, and semi-autoregressive strategies, showing that Whisper-LLaDA substantially reduces WER compared with the baseline. On LibriSpeech, the best cascade system achieves 2.25%/4.94% WER on test-clean/test-other, representing a 12.3% relative improvement over the Whisper-LLaMA baseline on the test-other split. In contrast, a plain-text LLaDA without acoustic features fails to improve accuracy, highlighting the importance of audio-conditioned embeddings. We further evaluate Whisper-LLaDA as a standalone decoder for ASR with diffusion-based and semi-autoregressive decoding. Most experimental configurations achieve faster inference than the Whisper-LLaMA baseline, although recognition accuracy is slightly lower. These findings offer an empirical view of diffusion-based LLMs for ASR and point to promising directions for improvements.</span>\n</p>\n\n",
                "matched_terms": [
                    "processing",
                    "wer",
                    "deliberationbased",
                    "librispeech",
                    "cascade",
                    "testother",
                    "baseline",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold ltx_font_italic\" style=\"font-size:90%;\">Index Terms<span class=\"ltx_text ltx_font_upright\">&#8212;&#8201;<span class=\"ltx_text ltx_font_medium\">\nAutomatic Speech Recognition, Diffusion Large Language Model, Non-Autoregressive, Deliberation-based Processing</span></span></span>\n</p>\n\n",
                "matched_terms": [
                    "deliberationbased",
                    "processing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">However, despite substantially reducing decoding latency, existing NAR approaches generally suffer from a slight degradation in recognition accuracy compared to AR methods, reflecting an inherent trade-off between efficiency and performance. This motivates the search for alternative paradigms that have the potential to mitigate this trade-off. Recent advances in diffusion-based large language models (DLLMs)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib29\" title=\"\">29</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib30\" title=\"\">30</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib31\" title=\"\">31</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib32\" title=\"\">32</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, exemplified by LLaDA&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib33\" title=\"\">33</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, offer a promising direction. By combining powerful self-attention mechanisms with strong semantic modeling capabilities, DLLMs provide new opportunities for enhancing ASR. In this work, we present an empirical study on integrating DLLMs into ASR in two ways: (1) as external deliberation-based processing modules, where DLLMs refine preliminary hypotheses generated by a base recognizer; and (2) as internal decoders, directly replacing the conventional AR/NAR decoding backbone. These explorations highlight both the potential of DLLMs to reshape ASR decoding and the limitations that remain, pointing to important directions for future research.</span>\n</p>\n\n",
                "matched_terms": [
                    "deliberationbased",
                    "processing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Prior studies have explored external deliberation-based processing mechanisms that refine original hypotheses or N-best lists&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib34\" title=\"\">34</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib35\" title=\"\">35</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib36\" title=\"\">36</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib37\" title=\"\">37</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, showing notable error reductions. Building upon these observations and inspired by recent progress in deliberation-based refinement, our study makes the following contributions: </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">(i)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> A systematic investigation on utilizing LLaDA as an external language model within ASR systems, demonstrating significant improvements in\nrecognition accuracy compared to conventional autoregressive (AR) baselines.\n</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">(ii)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> A novel exploration of employing LLaDA internally as a diffusion-based decoder within end-to-end ASR frameworks, highlighting substantial gains in parallel decoding capabilities and efficiency while maintaining competitive recognition performance relative to both AR and existing non-autoregressive (NAR) approaches.\n</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">(iii)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> A systematic investigation of decoding strategies is conducted on the LibriSpeech corpus through extensive hyperparameter studies, specifically investigating a semi-autoregressive decoding strategy.</span>\n</p>\n\n",
                "matched_terms": [
                    "deliberationbased",
                    "librispeech",
                    "processing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">As shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, Whisper-LLaDA supports both direct ASR from audio and deliberation-based processing of transcripts from external ASR systems, conditioned either on acoustic features alone or jointly on acoustic features and the given transcripts. We investigate this deliberation functionality on transcripts produced by a fine-tuned LLaMA-3.1-based&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib40\" title=\"\">40</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> ASR system.</span>\n</p>\n\n",
                "matched_terms": [
                    "deliberationbased",
                    "processing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We trained both Whisper-LLaMA and Whisper-LLaDA on the LibriSpeech corpus&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib41\" title=\"\">41</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which contains 960 hours of English audiobooks. Speed perturbation was performed with factors of 0.9 and 1.1. During training, the Whisper encoder is frozen, while LLaMA/LLaDA are fine-tuned with LoRA. The resulting speech embeddings are concatenated with the textual prompt and ground-truth response embeddings. Following the diffusion formulation, the response block is randomly masked with probability </span>\n  <math alttext=\"t\\sim U(0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">t</mi>\n        <mo mathsize=\"0.900em\">&#8764;</mo>\n        <mrow>\n          <mi mathsize=\"0.900em\">U</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mrow>\n            <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n            <mn mathsize=\"0.900em\">0</mn>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mn mathsize=\"0.900em\">1</mn>\n            <mo maxsize=\"0.900em\" minsize=\"0.900em\">]</mo>\n          </mrow>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">t\\sim U(0,1]</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and LLaDA predicts the masked tokens conditioned on the remaining context. The model is optimized using cross-entropy loss over masked positions:</span>\n</p>\n\n",
                "matched_terms": [
                    "librispeech",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We organize the inputs into three components: a textual instruction, the acoustic features, and a response block. The textual instruction specifies the ASR task. The acoustic features are obtained by passing audio through the Whisper encoder, the Q-Former, and a projection layer, yielding 4096-dimensional embeddings aligned with LLaDA. For direct decoding, the response block is initialized with </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">[MASK]</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> tokens of length 128, which covers all LibriSpeech utterances as their lengths are shorter than 128 tokens. For deliberation-based processing, the response block is initialized with the Whisper-LLaMA transcript, and its length exactly matches that of the transcript sequence. LLaDA then performs the denoising process on this response block. Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S3.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 3 Methods &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrates the two decoding strategies considered in our work: diffusion-based and semi-autoregressive decoding, as well as two general deliberation-based processing strategies: diffusion-based and semi-autoregressive deliberation.</span>\n</p>\n\n",
                "matched_terms": [
                    "processing",
                    "deliberationbased",
                    "librispeech",
                    "transcript",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Due to the denoising nature and bidirectional attention mechanism of the diffusion large language model, we explored a novel cascade framework for deliberation-based processing in ASR. We first obtain a transcript from the Whisper-LLaMA system to initialize the response block of Whisper-LLaDA. A proportion </span>\n  <math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS1.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">p</mi>\n      <annotation encoding=\"application/x-tex\">p</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> of response tokens are then selected and replaced with </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">[MASK]</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> based on the following strategies: (1) random selection; (2) select the lowest-confidence tokens, where confidence is yielded from a forward step of Whisper-LLaDA based on prompt and audio embedding; and (3) semi-autoregressive deliberation-based processing: dividing the transcript into several sub-blocks and remasking sequentially. After remasking, Whisper-LLaDA recovers the masked positions conditioned on the input prompt, the speech embeddings, and the unmasked tokens of the transcript. The reconstruction under the first two strategies is completed in one pass and the last entails one pass per sub-block, closely aligning with our training procedures. For completeness, we also attempted a plain-text version of LLaDA without Whisper embeddings.</span>\n</p>\n\n",
                "matched_terms": [
                    "subblocks",
                    "processing",
                    "deliberationbased",
                    "subblock",
                    "cascade",
                    "transcript",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Beyond setting the maximum number of denoising steps </span>\n  <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">N</mi>\n      <annotation encoding=\"application/x-tex\">N</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, the response block is divided equally into </span>\n  <math alttext=\"M\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">M</mi>\n      <annotation encoding=\"application/x-tex\">M</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> sub-blocks. Unlike the fully parallel strategy, the semi-autoregressive method performs diffusion-based decoding within each sub-block for up to </span>\n  <math alttext=\"N/M\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">N</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\" stretchy=\"true\" symmetric=\"true\">/</mo>\n        <mi mathsize=\"0.900em\">M</mi>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">N/M</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> steps, while proceeding autoregressively across sub-blocks. Specifically, we experiment with </span>\n  <math alttext=\"M\\in\\{1,2,4,8,16\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">M</mi>\n        <mo mathsize=\"0.900em\">&#8712;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">{</mo>\n          <mn mathsize=\"0.900em\">1</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">2</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">4</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">8</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">16</mn>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">}</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">M\\in\\{1,2,4,8,16\\}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"N\\in\\{1,4,8,16,32,64,128\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">N</mi>\n        <mo mathsize=\"0.900em\">&#8712;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">{</mo>\n          <mn mathsize=\"0.900em\">1</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">4</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">8</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">16</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">32</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">64</mn>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mn mathsize=\"0.900em\">128</mn>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">}</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">N\\in\\{1,4,8,16,32,64,128\\}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The number of denoising steps per sub-block is constrained between 1 and </span>\n  <math alttext=\"128/M\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m6\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">128</mn>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\" stretchy=\"true\" symmetric=\"true\">/</mo>\n        <mi mathsize=\"0.900em\">M</mi>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">128/M</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The same early-stopping criterion is applied to improve efficiency.</span>\n</p>\n\n",
                "matched_terms": [
                    "subblock",
                    "number",
                    "subblocks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our experiments were conducted on LibriSpeech </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> sets&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib41\" title=\"\">41</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. All models were trained with the AdamW&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib42\" title=\"\">42</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> optimizer using a weight decay of 0.05. The learning rate followed a linear warmup&#8211;cosine decay schedule, starting from </span>\n  <math alttext=\"1\\times 10^{-6}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">1</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">6</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">1\\times 10^{-6}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, increasing to </span>\n  <math alttext=\"3\\times 10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">3</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">5</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">3\\times 10^{-5}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> within 3000 steps, and decaying to a minimum of </span>\n  <math alttext=\"1\\times 10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">1</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">5</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">1\\times 10^{-5}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The best checkpoint was selected based on the WER on the </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">dev-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> set in each run.</span>\n</p>\n\n",
                "matched_terms": [
                    "testclean",
                    "devclean",
                    "wer",
                    "sets",
                    "librispeech",
                    "testother"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 4.1 Baseline &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> summarizes the baseline results on LibriSpeech benchmark. We primarily consider two LLM-based ASR systems, Whisper-LLaMA and Whisper-Vicuna&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#bib.bib43\" title=\"\">43</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, as our baselines. Both systems achieve strong recognition accuracy, with Whisper-LLaMA (Sys.&#160;1) reaching 2.24%/5.63% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">/</span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Whisper-Vicuna (Sys.&#160;2) showing slightly higher WER and a larger real-time factor (RTF).</span>\n</p>\n\n",
                "matched_terms": [
                    "baseline",
                    "librispeech",
                    "whisperllama",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">For reference, we also report the performance of Whisper-Large-v2/v3 (Sys.&#160;3&#8211;4). These systems achieve very competitive results (e.g., 3.90% WER on test-other with Whisper-Large v3). We expect their larger proprietary training datasets (up to </span>\n  <math alttext=\"\\sim\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">&#8764;</mo>\n      <annotation encoding=\"application/x-tex\">\\sim</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">5M hours) attribute to this. Therefore they are not directly comparable to our baselines.</span>\n</p>\n\n",
                "matched_terms": [
                    "testother",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We explored the use of LLaDA as an external deliberation processing module for transcripts generated by Whisper-LLaMA as follows.</span>\n</p>\n\n",
                "matched_terms": [
                    "processing",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">First, we applied plain-text LLaDA to correct errors from Whisper-LLaMA. We initialized LLaDA with the LLaDA-8B-Instruct checkpoint and fine-tuned it on paired data consisting of Whisper-LLaMA transcripts and ground-truth text. The fine-tuned text-based LLaDA was then used to refine Whisper-LLaMA outputs. Notably, the response block length was set to match the length of the Whisper-LLaMA transcript. However, this approach introduced more errors, yielding 3.89% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and 6.91% on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, indicating that audio embeddings are essential for effective deliberation-based processing with LLaDA.</span>\n</p>\n\n",
                "matched_terms": [
                    "testclean",
                    "processing",
                    "wer",
                    "deliberationbased",
                    "transcript",
                    "testother",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The deliberation-based processing results demonstrate that Whisper-LLaDA yields consistent improvements over the Whisper-LLaMA baseline, confirming the effectiveness of diffusion-based refinement in recovering tokens that are challenging for autoregressive counterparts. Random masking achieves the best results when the mask ratio is 90%, while low-confidence masking brings only marginal improvements. In addition, semi-autoregressive deliberation-based processing with sub-block partition further improves recognition accuracy, suggesting that the bidirectional attention of LLaDA provides a useful supplement to the unidirectional attention in the Whisper-LLaMA model. Overall, these findings highlight the potential of Whisper-LLaDA as a complementary deliberation-based processing module for ASR systems.</span>\n</p>\n\n",
                "matched_terms": [
                    "processing",
                    "deliberationbased",
                    "subblock",
                    "baseline",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We observe the following trends for diffusion decoding (Sys.&#160;5) in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 4.1 Baseline &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\n(a) Increasing the number of denoising steps steadily reduces WER, albeit with higher RTF. The best result on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (2.82%) is achieved with 64 steps, while the lowest WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (5.75%) is obtained with 128 steps. These gains, however, diminish as the step count grows, indicating a saturation effect.\n(b) The RTFs for 1&#8211;64 steps remain consistently lower than those of AR baselines. Notably, the 64-step setting achieves a favorable trade-off, with 2.82%/5.79% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">testclean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">/</span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, surpassing Sys.&#160;2 on the latter. It also runs about </span>\n  <math alttext=\"1.3\\times\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S4.SS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">1.3</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\">&#215;</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">1.3\\times</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> faster than Sys.&#160;1 and </span>\n  <math alttext=\"2.4\\times\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S4.SS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">2.4</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\">&#215;</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">2.4\\times</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> faster than Sys.&#160;2, offering more efficient inference with a moderate accuracy loss relative to most AR frameworks.</span>\n</p>\n\n",
                "matched_terms": [
                    "testclean",
                    "number",
                    "testother",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We investigate an alternative decoding strategy, namely semi-autoregressive decoding. The 128-token generation block is evenly divided into </span>\n  <math alttext=\"M\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">M</mi>\n      <annotation encoding=\"application/x-tex\">M</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> sub-blocks, within which LLaDA performs diffusion-based denoising, while proceeding in an autoregressive manner across sub-blocks. Up to 128 denoising steps are allocated and uniformly distributed among the sub-blocks. Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16622v2#S4.F3\" style=\"font-size:90%;\" title=\"Figure 3 &#8227; 4.3 Diffusion-based Decoding &#8227; 4 Experiments &#8227; Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> shows the effect of the number of denoising steps and the number of sub-blocks on overall performance:\n(a) Increasing the number of denoising steps per sub-block reduces WER, though the improvement saturates after roughly 16 steps per sub-block.\n(b) As the total number of steps grows, the performance gaps among settings become negligible.\n(c) The 4-block setting with 32 steps per sub-block achieves the best performance, with 2.40%/4.96% WER on </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-clean</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">test-other</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The performance on the latter is significantly better than the LLaMA/Vicuna-based ASR baselines.</span>\n</p>\n\n",
                "matched_terms": [
                    "testclean",
                    "subblocks",
                    "wer",
                    "subblock",
                    "testother",
                    "number"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This work presented a comprehensive empirical study of employing the diffusion-based language model LLaDA for automatic speech recognition. We examined three complementary perspectives: (i) applying plain-text LLaDA for transcript refinement, (ii) leveraging Whisper-LLaDA for cascade deliberation-based processing, and (iii) using LLaDA as a standalone decoder. Our findings reveal clear contrasts across these settings. Plain-text LLaDA fails to improve Whisper-LLaMA outputs, underscoring the necessity of audio embeddings for effective deliberation-based processing. In contrast, Whisper-LLaDA consistently enhances recognition quality, with random masking at high ratios and the semi-autoregressive framework delivering the largest gains. When used directly as a decoder, LLaDA enables faster inference than autoregressive baselines but with slightly higher WER in most settings.</span>\n</p>\n\n",
                "matched_terms": [
                    "processing",
                    "wer",
                    "deliberationbased",
                    "cascade",
                    "transcript",
                    "whisperllama"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Overall, these results highlight both the potential and the current limitations of diffusion-based models in ASR. LLaDA offers effective deliberation-based processing and efficient decoding when conditioned on acoustic features, yet its accuracy still lags behind extensively pretrained autoregressive systems. Future work should scale Whisper-LLaDA with larger and more diverse training data beyond LibriSpeech and systematically explore more advanced masking/remasking policies to narrow the gap while preserving efficiency.</span>\n</p>\n\n",
                "matched_terms": [
                    "deliberationbased",
                    "librispeech",
                    "processing"
                ]
            }
        ]
    }
}