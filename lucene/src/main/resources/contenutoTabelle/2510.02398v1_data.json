{
    "S4.T1": {
        "source_file": "When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs",
        "caption": "Table 1: Summary of χ2\\chi^{2} test between male female voice-input response distributions and effect sizes at various temperatures",
        "body": "Temperature\n0.01\n0.1\n0.5\n0.75\n1.0\n\n\n\n\n\npp-value\n2.54×10−52.54\\times 10^{-5}\n1.43×10−51.43\\times 10^{-5}\n1.06×10−31.06\\times 10^{-3}\n1.07×10−21.07\\times 10^{-2}\n1.21×10−21.21\\times 10^{-2}\n\n\nCramér’s VV\n\n0.098\n0.101\n0.079\n0.064\n0.063",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Temperature</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.01</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.1</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.5</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">0.75</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">1.0</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">\n<math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m3\" intent=\":literal\"><semantics><mi>p</mi><annotation encoding=\"application/x-tex\">p</annotation></semantics></math>-value</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"2.54\\times 10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m4\" intent=\":literal\"><semantics><mrow><mn>2.54</mn><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>5</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">2.54\\times 10^{-5}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"1.43\\times 10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m5\" intent=\":literal\"><semantics><mrow><mn>1.43</mn><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>5</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">1.43\\times 10^{-5}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"1.06\\times 10^{-3}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m6\" intent=\":literal\"><semantics><mrow><mn>1.06</mn><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>3</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">1.06\\times 10^{-3}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"1.07\\times 10^{-2}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m7\" intent=\":literal\"><semantics><mrow><mn>1.07</mn><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>2</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">1.07\\times 10^{-2}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"1.21\\times 10^{-2}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m8\" intent=\":literal\"><semantics><mrow><mn>1.21</mn><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>2</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">1.21\\times 10^{-2}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">Cram&#233;r&#8217;s <math alttext=\"V\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T1.m9\" intent=\":literal\"><semantics><mi>V</mi><annotation encoding=\"application/x-tex\">V</annotation></semantics></math>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.098</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.101</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.079</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.064</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.063</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "cramér’s",
            "sizes",
            "χ2chi2",
            "summary",
            "effect",
            "temperature",
            "female",
            "response",
            "voiceinput",
            "143×10−5143times",
            "106×10−3106times",
            "various",
            "254×10−5254times",
            "ppvalue",
            "distributions",
            "test",
            "121×10−2121times",
            "temperatures",
            "male",
            "between",
            "107×10−2107times"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">reflects the strength of association between voice position and selection outcomes. They indicate modest practical effects despite the statistical significance. The findings are summarized in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S4.T1\" title=\"Table 1 &#8227; 4 Results and Discussion &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>. We expand on these findings in the conclusion. This significance remains with slightly larger, but still modest, effect sizes for zero-shot prompts. Similar results occur when setting <math alttext=\"top\\_K=100\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p7.m2\" intent=\":literal\"><semantics><mrow><mrow><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi mathvariant=\"normal\">_</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>K</mi></mrow><mo>=</mo><mn>100</mn></mrow><annotation encoding=\"application/x-tex\">top\\_K=100</annotation></semantics></math>. <span class=\"ltx_text ltx_font_bold\">RQ2 Answer:</span> Positional bias not only persists but exhibits asymmetric behaviour when interacting with gendered voice inputs.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">The rapid development of SpeechLLM-based conversational AI systems has created a need for robustly benchmarking these efforts, including aspects of fairness and bias. At present, such benchmarks typically rely on multiple choice question answering (MCQA). In this paper, we present the first token-level probabilistic evaluation and response-based study of several issues affecting the use of MCQA in SpeechLLM benchmarking: 1) we examine how model temperature and prompt design affect gender and positional bias on an MCQA gender-bias benchmark; 2) we examine how these biases are affected by the gender of the input voice; and 3) we study to what extent observed trends carry over to a second gender-bias benchmark. Our results show that concerns about positional bias from the text domain are equally valid in the speech domain. We also find the effect to be stronger for female voices than for male voices. To our knowledge, this is the first study to isolate positional bias effects in SpeechLLM-based gender-bias benchmarks. We conclude that current MCQA benchmarks do not account for speech-based bias and alternative strategies are needed to ensure fairness towards all users.</p>\n\n",
                "matched_terms": [
                    "effect",
                    "temperature",
                    "male",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">If benchmark performance is strongly influenced by prompt phrasing, inference temperature, and option ordering between male and female voices, then claims suggesting minimal bias <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib15\" title=\"\">15</a>]</cite> in SpeechLLMs may be unfounded and even misleading. Our findings confirm these concerns, demonstrating not only substantial positional bias in SpeechLLM responses but also revealing that the extent of this bias differs depending on voice gender.</p>\n\n",
                "matched_terms": [
                    "male",
                    "temperature",
                    "female",
                    "between"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Benchmarks that rely heavily on MCQA formats may present an overly simplified view of model capabilities and limitations <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib16\" title=\"\">16</a>]</cite>, especially with SpeechLLMs, where speaker voice also needs to be taken into account.\nThis narrow framing compromises the credibility of evaluations that claim to assess understanding, generalisation, and fairness <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib18\" title=\"\">18</a>]</cite>. While previous studies have explored the impact of prompting and temperature settings on LLM performance in MCQA tasks <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib26\" title=\"\">26</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib21\" title=\"\">21</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib22\" title=\"\">22</a>]</cite>, these strategies have yet to be examined in the context of SpeechLLMs &#8211; particularly with respect to positional bias in response options.</p>\n\n",
                "matched_terms": [
                    "temperature",
                    "response"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We perform experiments on the Qwen2-Audio-7B-Instruct <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib5\" title=\"\">5</a>]</cite> model.\nBy focusing on a single model, we spend computational effort on studying the effect of prompting and inference temperature in depth. We select Qwen2-Audio-7B-Instruct over models like SpeechT5 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib1\" title=\"\">1</a>]</cite>, SpeechLLaMA <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib29\" title=\"\">29</a>]</cite>, SALMONN <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib27\" title=\"\">27</a>]</cite>, Pengi <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib9\" title=\"\">9</a>]</cite>, and SpeechVerse <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib8\" title=\"\">8</a>]</cite> because it is fine-tuned for instruction following, unlike models which are focused on general generation or broader multimodal tasks. Also, it is relatively lightweight compared to many high-performing models, making it easy to wield for multiple inference runs, and achieves notably high performance on the MMAU test subset <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib23\" title=\"\">23</a>]</cite>.\nTo explore model behaviour, our benchmark B1 employs a multiple-choice continuation task, where the model is prompted to <em class=\"ltx_emph ltx_font_italic\">&#8220;&#8230;pick an appropriate continuation from one of three options, given an audio clip&#8221;</em>, similar to that of the one described in Spoken StereoSet <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib15\" title=\"\">15</a>]</cite>. The audio clip provides the spoken context, while the text prompt presents the completion choices.</p>\n\n",
                "matched_terms": [
                    "effect",
                    "temperature",
                    "test"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">B1:</span> We select a subset of 732 examples from the gender section of the Spoken StereoSet dataset <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib15\" title=\"\">15</a>]</cite>. We restrict our selection to examples where at least five annotators agreed on the labelling of the continuation options as irrelevant, stereotypical, or anti-stereotypical, in order to reduce ambiguity, particularly in the irrelevant category. Unlike the full dataset, this subset also has an equal count of male and female Azure TTS voices.</p>\n\n",
                "matched_terms": [
                    "male",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Audio prompt clip transcript: &#8220;<span class=\"ltx_text ltx_font_bold\">I am the twin&#8217;s parent</span>&#8221; in one of six Azure TTS voices (3 male and 3 female)</p>\n\n",
                "matched_terms": [
                    "male",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In the example above, we see that option A is stereotypical for female voices and B is stereotypical for male voices while option C is irrelevant to the context.</p>\n\n",
                "matched_terms": [
                    "male",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">An original sentence from <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib13\" title=\"\">13</a>]</cite>: &#8220;<em class=\"ltx_emph ltx_font_italic\">The doctor phoned the nurse because she was late.</em>&#8221; is rephrased as &#8220;<em class=\"ltx_emph ltx_font_italic\">This is a phone call that occurred between the doctor and the nurse because she was late. Who was late?</em>&#8221;. This becomes the textual prompt, while the corresponding audio input features a female voice saying &#8220;<em class=\"ltx_emph ltx_font_bold ltx_font_italic\">I&#8217;m going to be late</em>&#8221;. We generate male equivalents (by substituting <em class=\"ltx_emph ltx_font_italic\">she</em> to <em class=\"ltx_emph ltx_font_italic\">he</em>), and for each of the 15 unique scenarios we create four TTS renderings (two male and two female), resulting in a total of 60 examples.</p>\n\n",
                "matched_terms": [
                    "male",
                    "between",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Example prompts from B2</span>: Audio prompt clip transcript: &#8220;<span class=\"ltx_text ltx_font_bold\">I&#8217;m worried about her gums</span>&#8221; in one of four OrpheusTTS voices (two male and two female)</p>\n\n",
                "matched_terms": [
                    "male",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this example, picking option A would be stereotypical for a male voice and B is stereotypical for a female voice.</p>\n\n",
                "matched_terms": [
                    "male",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For our experiments, we use a hybrid evaluation approach that combines the token-level probabilities <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib16\" title=\"\">16</a>]</cite> assigned to discrete answer options/choices <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib15\" title=\"\">15</a>]</cite> to assess the preferences of the model across behaviourally meaningful options. For B1, we set <math alttext=\"top\\_K=4\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi mathvariant=\"normal\">_</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>K</mi></mrow><mo>=</mo><mn>4</mn></mrow><annotation encoding=\"application/x-tex\">top\\_K=4</annotation></semantics></math> and frame the task as a choice between four options: A, B, and C &#8211; each randomly assigned to irrelevant, anti-stereotypical, or stereotypical\nbehaviours &#8211; and a potential non-instruction-following response. Similarly, we set <math alttext=\"top\\_K=3\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m2\" intent=\":literal\"><semantics><mrow><mrow><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi mathvariant=\"normal\">_</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>K</mi></mrow><mo>=</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">top\\_K=3</annotation></semantics></math> for B2. We analyse model responses statistically and examine token probabilities across five temperature values, alongside two zero-shot and one-shot prompts each.</p>\n\n",
                "matched_terms": [
                    "between",
                    "temperature",
                    "response"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Qwen2-Audio-7B-Instruct exhibits substantial positional bias in slot selection, varying across prompt conditions. Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S2.F1\" title=\"Figure 1 &#8227; 2 Problem Statement &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> shows that in a zero-shot setting, when selecting between options A, B, C for B1 samples, the model consistently avoids the first option regardless of content, thus overriding behavioural preferences with positional bias. This effect persists with numerical labels (1, 2, 3), confirming position-based rather than notation-based bias.\nThe first slot also receives consistently lower probability scores even with uniformly distributed behaviours across all temperatures. The model rarely selects irrelevant options, suggesting some instruction-following capability, yet its strong avoidance of the first slot, coupled with randomised options, obscures any genuine preference between stereotypical and anti-stereotypical completions.\nTo isolate content preference from positional bias, we fix the positions of either stereotypical or anti-stereotypical options while randomising the remaining two options across other slots. The zero-shot prompting results in Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S4.F2\" title=\"Figure 2 &#8227; 4 Results and Discussion &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> (top row) reveal:</p>\n\n",
                "matched_terms": [
                    "effect",
                    "between",
                    "temperatures"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We also observe a noticeable rise in irrelevant option scores when option C is not fixed. This suggests that our one-shot prompting does not reinforce anti-stereotypical behaviour &#8211; and may even introduce new positional-bias instability &#8211; or that the benchmark itself (B1) contains ambiguities that become more salient with additional contextual framing. <span class=\"ltx_text ltx_font_bold\">RQ1 Answer:</span> Positional bias affects answer selection in distinct ways depending on the prompt format. Positional bias persists even at higher temperatures. This result also shows that few-fold randomisation of response options might be insufficient to overcome positional bias.</p>\n\n",
                "matched_terms": [
                    "temperatures",
                    "response"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">At all tested temperatures <math alttext=\"(0.01,0.1,0.5,0.75,1.0)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p5.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><mn>0.01</mn><mo>,</mo><mn>0.1</mn><mo>,</mo><mn>0.5</mn><mo>,</mo><mn>0.75</mn><mo>,</mo><mn>1.0</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(0.01,0.1,0.5,0.75,1.0)</annotation></semantics></math>, and after averaging across all prompts (with randomised behaviour slots and discarding samples where the model did not return A, B, or C), there is a significant difference between the male and female voice-input response distributions, with <math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p5.m2\" intent=\":literal\"><semantics><mi>p</mi><annotation encoding=\"application/x-tex\">p</annotation></semantics></math>-values</p>\n\n",
                "matched_terms": [
                    "response",
                    "distributions",
                    "male",
                    "temperatures",
                    "voiceinput",
                    "female",
                    "between"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">using a <math alttext=\"\\chi^{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p5.m3\" intent=\":literal\"><semantics><msup><mi>&#967;</mi><mn>2</mn></msup><annotation encoding=\"application/x-tex\">\\chi^{2}</annotation></semantics></math> test. Also of note is that this positional bias is more pronounced for female voices.</p>\n\n",
                "matched_terms": [
                    "test",
                    "female",
                    "χ2chi2"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We present the confusion matrices when different slots are fixed with either stereotypical or anti-stereotypical behaviours at the highest temperature (1.0) with a zero-shot prompt. Similar trends were observed at other tested temperatures and prompt settings. Rows may not sum exactly to <math alttext=\"100\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p6.m1\" intent=\":literal\"><semantics><mrow><mn>100</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">100\\%</annotation></semantics></math> due to occasional model failures in selecting A, B, or C in the zero-shot setting. The positional bias is most pronounced for female voices, as shown in Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S4.F4\" title=\"Figure 4 &#8227; 4 Results and Discussion &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> and Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S4.F5\" title=\"Figure 5 &#8227; 4 Results and Discussion &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, with the effect becoming even more salient at lower temperatures. Notably, while male voices exhibit greater variability across conditions in response to anti-stereotypical slot fixes, female voices show more stable choice patterns. This suggests that female voices are more susceptible to positional biases, especially under stereotypical conditions.</p>\n\n",
                "matched_terms": [
                    "effect",
                    "temperature",
                    "response",
                    "temperatures",
                    "female",
                    "male"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The corresponding effect sizes for the p-values, measured by Cram&#233;r&#8217;s <math alttext=\"V\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p7.m1\" intent=\":literal\"><semantics><mi>V</mi><annotation encoding=\"application/x-tex\">V</annotation></semantics></math>:</p>\n\n",
                "matched_terms": [
                    "cramér’s",
                    "sizes",
                    "effect"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">RQ3 Answer:</span> When evaluating the model on B2, we do not observe similarly strong positional or temperature effects, likely due to the binary choice format and limited sample size. However, we do observe emerging trends in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S4.T2\" title=\"Table 2 &#8227; 4 Results and Discussion &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> that may hint at underlying biases that are more pronounced than those in B1, although further validation is needed with larger datasets. This highlights that benchmark design, including the number of response options critically influences the sensitivity to bias effects.</p>\n\n",
                "matched_terms": [
                    "temperature",
                    "response"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this study, we investigated the influence of prompt design, temperature, and voice gender on MCQA benchmark performance for a single SpeechLLM. Despite a narrow experimental scope, we found consistently strong positional bias: the model disproportionately avoids selecting the first answer slot, even when it contains the most appropriate or unbiased content. This effect overrode the intended behavioural labels in many cases and persisted across temperatures and prompt types.</p>\n\n",
                "matched_terms": [
                    "effect",
                    "temperature",
                    "temperatures"
                ]
            }
        ]
    },
    "S4.T2": {
        "source_file": "When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs",
        "caption": "Table 2: Average probability scores split by gender, shot type, and temperature. S = Stereotypical, AS = Anti-Stereotypical.",
        "body": "Temp\n\n\n\n\nGender\n\n\n\n\nShot Type\n\n\n\n\nS\n\n\n\n\nAS\n\n\n\n\n\n\n\n\n0.01\n\n\n\n\nMale\n\n\n\n\nZero-shot\n\n\n\n\n0.600\n\n\n\n\n0.400\n\n\n\n\n\n\n\n\n\n\n\nFemale\n\n\n\n\nZero-shot\n\n\n\n\n0.767\n\n\n\n\n0.233\n\n\n\n\n\n\n\n\n\n\n\nMale\n\n\n\n\nOne-shot\n\n\n\n\n0.433\n\n\n\n\n0.567\n\n\n\n\n\n\n\n\n\n\n\nFemale\n\n\n\n\nOne-shot\n\n\n\n\n0.833\n\n\n\n\n0.167\n\n\n\n\n\n\n1.0\n\n\n\n\nMale\n\n\n\n\nZero-shot\n\n\n\n\n0.578\n\n\n\n\n0.418\n\n\n\n\n\n\n\n\n\n\n\nFemale\n\n\n\n\nZero-shot\n\n\n\n\n0.758\n\n\n\n\n0.237\n\n\n\n\n\n\n\n\n\n\n\nMale\n\n\n\n\nOne-shot\n\n\n\n\n0.431\n\n\n\n\n0.565\n\n\n\n\n\n\n\n\n\n\n\nFemale\n\n\n\n\nOne-shot\n\n\n\n\n0.781\n\n\n\n\n0.214",
        "html_code": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_center\">Temp</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:42.7pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_center\">Gender</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:71.1pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_center\">Shot Type</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_center\">S</span></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"><span class=\"ltx_text ltx_font_bold ltx_align_center\">AS</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"><span class=\"ltx_text ltx_align_center\">0.01</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:42.7pt;\">Male</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:71.1pt;\">Zero-shot</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.600</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.400</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:42.7pt;\">Female</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:71.1pt;\">Zero-shot</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.767</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.233</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:42.7pt;\">Male</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:71.1pt;\">One-shot</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.433</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.567</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:42.7pt;\">Female</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:71.1pt;\">One-shot</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.833</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.167</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"><span class=\"ltx_text ltx_align_center\">1.0</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:42.7pt;\">Male</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:71.1pt;\">Zero-shot</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.578</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.418</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:42.7pt;\">Female</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:71.1pt;\">Zero-shot</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.758</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.237</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:42.7pt;\">Male</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:71.1pt;\">One-shot</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.431</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.565</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\"/>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:42.7pt;\">Female</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:71.1pt;\">One-shot</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.781</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:34.1pt;\">0.214</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "antistereotypical",
            "probability",
            "shot",
            "stereotypical",
            "temperature",
            "oneshot",
            "average",
            "male",
            "gender",
            "female",
            "split",
            "temp",
            "zeroshot",
            "scores",
            "type"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">RQ3 Answer:</span> When evaluating the model on B2, we do not observe similarly strong positional or temperature effects, likely due to the binary choice format and limited sample size. However, we do observe emerging trends in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S4.T2\" title=\"Table 2 &#8227; 4 Results and Discussion &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> that may hint at underlying biases that are more pronounced than those in B1, although further validation is needed with larger datasets. This highlights that benchmark design, including the number of response options critically influences the sensitivity to bias effects.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">The rapid development of SpeechLLM-based conversational AI systems has created a need for robustly benchmarking these efforts, including aspects of fairness and bias. At present, such benchmarks typically rely on multiple choice question answering (MCQA). In this paper, we present the first token-level probabilistic evaluation and response-based study of several issues affecting the use of MCQA in SpeechLLM benchmarking: 1) we examine how model temperature and prompt design affect gender and positional bias on an MCQA gender-bias benchmark; 2) we examine how these biases are affected by the gender of the input voice; and 3) we study to what extent observed trends carry over to a second gender-bias benchmark. Our results show that concerns about positional bias from the text domain are equally valid in the speech domain. We also find the effect to be stronger for female voices than for male voices. To our knowledge, this is the first study to isolate positional bias effects in SpeechLLM-based gender-bias benchmarks. We conclude that current MCQA benchmarks do not account for speech-based bias and alternative strategies are needed to ensure fairness towards all users.</p>\n\n",
                "matched_terms": [
                    "male",
                    "temperature",
                    "gender",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We examine how prompt design and temperature settings influence the benchmark scores of a single SpeechLLM.</p>\n\n",
                "matched_terms": [
                    "temperature",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">If benchmark performance is strongly influenced by prompt phrasing, inference temperature, and option ordering between male and female voices, then claims suggesting minimal bias <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib15\" title=\"\">15</a>]</cite> in SpeechLLMs may be unfounded and even misleading. Our findings confirm these concerns, demonstrating not only substantial positional bias in SpeechLLM responses but also revealing that the extent of this bias differs depending on voice gender.</p>\n\n",
                "matched_terms": [
                    "male",
                    "temperature",
                    "gender",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We experiment with two zero-shot and two one-shot prompting formats to examine the effects. Both one-shot prompts include an explicit example and also encourage the model to select responses which challenge common stereotypes. While the overall task framing remains the same, our one-shot prompts are not conventional extensions of the zero-shot variants, they also enforce stereotype-resistant behaviour. Full prompt examples are provided in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S3.SS1.SSS1\" title=\"3.1.1 Example prompts from B1 &#8227; 3.1 Benchmarking Datasets &#8227; 3 Methodology &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">3.1.1</span></a>.</p>\n\n",
                "matched_terms": [
                    "oneshot",
                    "zeroshot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">B1:</span> We select a subset of 732 examples from the gender section of the Spoken StereoSet dataset <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib15\" title=\"\">15</a>]</cite>. We restrict our selection to examples where at least five annotators agreed on the labelling of the continuation options as irrelevant, stereotypical, or anti-stereotypical, in order to reduce ambiguity, particularly in the irrelevant category. Unlike the full dataset, this subset also has an equal count of male and female Azure TTS voices.</p>\n\n",
                "matched_terms": [
                    "antistereotypical",
                    "gender",
                    "female",
                    "male",
                    "stereotypical"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Audio prompt clip transcript: &#8220;<span class=\"ltx_text ltx_font_bold\">I am the twin&#8217;s parent</span>&#8221; in one of six Azure TTS voices (3 male and 3 female)</p>\n\n",
                "matched_terms": [
                    "male",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In the example above, we see that option A is stereotypical for female voices and B is stereotypical for male voices while option C is irrelevant to the context.</p>\n\n",
                "matched_terms": [
                    "male",
                    "stereotypical",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">An original sentence from <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib13\" title=\"\">13</a>]</cite>: &#8220;<em class=\"ltx_emph ltx_font_italic\">The doctor phoned the nurse because she was late.</em>&#8221; is rephrased as &#8220;<em class=\"ltx_emph ltx_font_italic\">This is a phone call that occurred between the doctor and the nurse because she was late. Who was late?</em>&#8221;. This becomes the textual prompt, while the corresponding audio input features a female voice saying &#8220;<em class=\"ltx_emph ltx_font_bold ltx_font_italic\">I&#8217;m going to be late</em>&#8221;. We generate male equivalents (by substituting <em class=\"ltx_emph ltx_font_italic\">she</em> to <em class=\"ltx_emph ltx_font_italic\">he</em>), and for each of the 15 unique scenarios we create four TTS renderings (two male and two female), resulting in a total of 60 examples.</p>\n\n",
                "matched_terms": [
                    "male",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Example prompts from B2</span>: Audio prompt clip transcript: &#8220;<span class=\"ltx_text ltx_font_bold\">I&#8217;m worried about her gums</span>&#8221; in one of four OrpheusTTS voices (two male and two female)</p>\n\n",
                "matched_terms": [
                    "male",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this example, picking option A would be stereotypical for a male voice and B is stereotypical for a female voice.</p>\n\n",
                "matched_terms": [
                    "male",
                    "stereotypical",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For our experiments, we use a hybrid evaluation approach that combines the token-level probabilities <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib16\" title=\"\">16</a>]</cite> assigned to discrete answer options/choices <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#bib.bib15\" title=\"\">15</a>]</cite> to assess the preferences of the model across behaviourally meaningful options. For B1, we set <math alttext=\"top\\_K=4\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi mathvariant=\"normal\">_</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>K</mi></mrow><mo>=</mo><mn>4</mn></mrow><annotation encoding=\"application/x-tex\">top\\_K=4</annotation></semantics></math> and frame the task as a choice between four options: A, B, and C &#8211; each randomly assigned to irrelevant, anti-stereotypical, or stereotypical\nbehaviours &#8211; and a potential non-instruction-following response. Similarly, we set <math alttext=\"top\\_K=3\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m2\" intent=\":literal\"><semantics><mrow><mrow><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>p</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi mathvariant=\"normal\">_</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>K</mi></mrow><mo>=</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">top\\_K=3</annotation></semantics></math> for B2. We analyse model responses statistically and examine token probabilities across five temperature values, alongside two zero-shot and one-shot prompts each.</p>\n\n",
                "matched_terms": [
                    "antistereotypical",
                    "temperature",
                    "oneshot",
                    "zeroshot",
                    "stereotypical"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Qwen2-Audio-7B-Instruct exhibits substantial positional bias in slot selection, varying across prompt conditions. Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S2.F1\" title=\"Figure 1 &#8227; 2 Problem Statement &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> shows that in a zero-shot setting, when selecting between options A, B, C for B1 samples, the model consistently avoids the first option regardless of content, thus overriding behavioural preferences with positional bias. This effect persists with numerical labels (1, 2, 3), confirming position-based rather than notation-based bias.\nThe first slot also receives consistently lower probability scores even with uniformly distributed behaviours across all temperatures. The model rarely selects irrelevant options, suggesting some instruction-following capability, yet its strong avoidance of the first slot, coupled with randomised options, obscures any genuine preference between stereotypical and anti-stereotypical completions.\nTo isolate content preference from positional bias, we fix the positions of either stereotypical or anti-stereotypical options while randomising the remaining two options across other slots. The zero-shot prompting results in Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S4.F2\" title=\"Figure 2 &#8227; 4 Results and Discussion &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> (top row) reveal:</p>\n\n",
                "matched_terms": [
                    "antistereotypical",
                    "probability",
                    "zeroshot",
                    "scores",
                    "stereotypical"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We find similar positional biases with the second zero-shot prompt but new patterns to the positional bias associated with the second one-shot prompt as seen in Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S4.F3\" title=\"Figure 3 &#8227; 4 Results and Discussion &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>. There is also less instruction following on the whole with these two prompts.</p>\n\n",
                "matched_terms": [
                    "oneshot",
                    "zeroshot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We also observe a noticeable rise in irrelevant option scores when option C is not fixed. This suggests that our one-shot prompting does not reinforce anti-stereotypical behaviour &#8211; and may even introduce new positional-bias instability &#8211; or that the benchmark itself (B1) contains ambiguities that become more salient with additional contextual framing. <span class=\"ltx_text ltx_font_bold\">RQ1 Answer:</span> Positional bias affects answer selection in distinct ways depending on the prompt format. Positional bias persists even at higher temperatures. This result also shows that few-fold randomisation of response options might be insufficient to overcome positional bias.</p>\n\n",
                "matched_terms": [
                    "oneshot",
                    "scores",
                    "antistereotypical"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">At all tested temperatures <math alttext=\"(0.01,0.1,0.5,0.75,1.0)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p5.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><mn>0.01</mn><mo>,</mo><mn>0.1</mn><mo>,</mo><mn>0.5</mn><mo>,</mo><mn>0.75</mn><mo>,</mo><mn>1.0</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(0.01,0.1,0.5,0.75,1.0)</annotation></semantics></math>, and after averaging across all prompts (with randomised behaviour slots and discarding samples where the model did not return A, B, or C), there is a significant difference between the male and female voice-input response distributions, with <math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p5.m2\" intent=\":literal\"><semantics><mi>p</mi><annotation encoding=\"application/x-tex\">p</annotation></semantics></math>-values</p>\n\n",
                "matched_terms": [
                    "male",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We present the confusion matrices when different slots are fixed with either stereotypical or anti-stereotypical behaviours at the highest temperature (1.0) with a zero-shot prompt. Similar trends were observed at other tested temperatures and prompt settings. Rows may not sum exactly to <math alttext=\"100\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.p6.m1\" intent=\":literal\"><semantics><mrow><mn>100</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">100\\%</annotation></semantics></math> due to occasional model failures in selecting A, B, or C in the zero-shot setting. The positional bias is most pronounced for female voices, as shown in Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S4.F4\" title=\"Figure 4 &#8227; 4 Results and Discussion &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> and Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.02398v1#S4.F5\" title=\"Figure 5 &#8227; 4 Results and Discussion &#8227; When Voice Matters: Evidence of Gender Disparity in Positional Bias of SpeechLLMs\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, with the effect becoming even more salient at lower temperatures. Notably, while male voices exhibit greater variability across conditions in response to anti-stereotypical slot fixes, female voices show more stable choice patterns. This suggests that female voices are more susceptible to positional biases, especially under stereotypical conditions.</p>\n\n",
                "matched_terms": [
                    "antistereotypical",
                    "temperature",
                    "female",
                    "male",
                    "zeroshot",
                    "stereotypical"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Limited prompt testing</span>:\nOur formulation of prompts is limited to a few zero-shot and one-shot versions, which may not fully capture the behaviour of the model under more complex prompting strategies such as: few-shot, chain-of-thought, or other prompt-tuning techniques. Exploring a wider range of prompting strategies is necessary to better understand the robustness and variability of the model&#8217;s responses with different prompts.</p>\n\n",
                "matched_terms": [
                    "oneshot",
                    "zeroshot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this study, we investigated the influence of prompt design, temperature, and voice gender on MCQA benchmark performance for a single SpeechLLM. Despite a narrow experimental scope, we found consistently strong positional bias: the model disproportionately avoids selecting the first answer slot, even when it contains the most appropriate or unbiased content. This effect overrode the intended behavioural labels in many cases and persisted across temperatures and prompt types.</p>\n\n",
                "matched_terms": [
                    "temperature",
                    "gender"
                ]
            }
        ]
    }
}