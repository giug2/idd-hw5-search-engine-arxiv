{
    "S3.T1": {
        "source_file": "Slot Filling as a Reasoning Task for SpeechLLMs",
        "caption": "Table 1:  Comparison of slot-filling performance between regular and reasoning speechLLMs.",
        "body": "Text Foundation LLM\nRegular SpeechLLM\nReasoning SpeechLLM\nRelative Gain, %\\%\n\n\n\n\n\nPrecision/Recall/F1\nPrecision/Recall/F1\n\nΔ\\DeltaF1\n\n\n\nLlama 3.1 8B Instruct\n0.6292/ 0.8726/ 0.7312\n\n0.6431/ 0.9319/ 0.7610\n\n+4.08\n\n\nLlama 3.1 8B Base\n0.5596/ 0.9073/ 0.6923\n\n0.6691/ 0.9168/ 0.7736\n\n+11.74\n\n\nLlama 3.2 1B Instruct\n0.5571/ 0.8541/ 0.6743\n0.5580/ 0.9156/ 0.6934\n+2.83\n\n\nDeepseek R1 Distill Llama 3.1 8B\n0.4296/ 0.8257/ 0.5652\n0.5616/ 0.9065/ 0.6936\n+22.72\n\n\nPhi4-mini reasoning 3.68B\n0.5359/ 0.8685/ 0.6628\n0.4957/ 0.8431/ 0.6243\n-5.81\n\n\nQwen3 4B (hybrid)\n\n0.6308/ 0.9400/ 0.7550\n\n0.4979/ 0.8717/ 0.6338\n-16.05\n\n\nQwen3 0.6B (hybrid)\n0.5176/ 0.8633/ 0.6472\n0.4889/ 0.7935/ 0.6050\n-6.52",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Text Foundation LLM</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Regular SpeechLLM</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Reasoning SpeechLLM</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Relative Gain, <math alttext=\"\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m1\" intent=\":literal\"><semantics><mo>%</mo><annotation encoding=\"application/x-tex\">\\%</annotation></semantics></math></span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td\"/>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span class=\"ltx_text\" style=\"font-size:90%;\">Precision/Recall/F1</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span class=\"ltx_text\" style=\"font-size:90%;\">Precision/Recall/F1</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">\n<math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m2\" intent=\":literal\"><semantics><mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi><annotation encoding=\"application/x-tex\">\\Delta</annotation></semantics></math><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">F1</span>\n</th>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Llama 3.1 8B Instruct</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.6292/ 0.8726/ 0.7312</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">0.6431/ </span><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.9319</span><span class=\"ltx_text\" style=\"font-size:90%;\">/ 0.7610</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">+4.08</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Llama 3.1 8B Base</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.5596/ 0.9073/ 0.6923</span></td>\n<td class=\"ltx_td ltx_align_left\">\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.6691</span><span class=\"ltx_text\" style=\"font-size:90%;\">/ 0.9168/ </span><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.7736</span>\n</td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">+11.74</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Llama 3.2 1B Instruct</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.5571/ 0.8541/ 0.6743</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.5580/ 0.9156/ 0.6934</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">+2.83</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Deepseek R1 Distill Llama 3.1 8B</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.4296/ 0.8257/ 0.5652</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.5616/ 0.9065/ 0.6936</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">+22.72</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Phi4-mini reasoning 3.68B</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.5359/ 0.8685/ 0.6628</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.4957/ 0.8431/ 0.6243</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">-5.81</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen3 4B (hybrid)</span></td>\n<td class=\"ltx_td ltx_align_left\">\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.6308</span><span class=\"ltx_text\" style=\"font-size:90%;\">/ </span><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.9400</span><span class=\"ltx_text\" style=\"font-size:90%;\">/ </span><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.7550</span>\n</td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.4979/ 0.8717/ 0.6338</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">-16.05</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen3 0.6B (hybrid)</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.5176/ 0.8633/ 0.6472</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.4889/ 0.7935/ 0.6050</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">-6.52</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "speechllm",
            "regular",
            "base",
            "deepseek",
            "06b",
            "reasoning",
            "text",
            "slotfilling",
            "llama",
            "precisionrecallf1",
            "llm",
            "δdeltaf1",
            "performance",
            "relative",
            "speechllms",
            "comparison",
            "distill",
            "foundation",
            "phi4mini",
            "hybrid",
            "gain",
            "instruct",
            "between",
            "368b",
            "qwen3"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">All text-based LLMs described above are integrated into speechLLMs as their text foundation models. They are fine-tuned using LoRA. The modality adapter is fully fine-tuned while keeping the speech encoder, from the Whisper-base model, frozen. Here, the fine-tuning is performed using the regular (non-reasoning) slot-filling dataset with speech-prompt-response triplets as described in Section&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S2.SS2\" style=\"font-size:90%;\" title=\"2.2 Instruction-based Dataset &#8227; 2 Data Preparation &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">2.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The response is a structured JSON object containing slot types and their corresponding values without any explicit multi-step reasoning traces. These results serve as our baseline prior to introducing COT supervision in the reasoning setup which we cover in the following section. Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S3.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 3.2 Text Foundation LLMs &#8227; 3 Experiments &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, &#8221;Regular SpeechLLM&#8221; column, summarizes performance of each regular speechLLM configuration determined by its text foundation LLM. We present results using partial-match precision, recall, and F1 scores. We adopt partial matching over exact match to better reflect the generative nature of the models, which may produce correct slot values with minor surface-level variations.</span>\n</p>\n\n",
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this section we consider reasoning speechLLMs, where the models are fine-tuned using multi-step, COT style supervision for the slot-filling task. This setup enables us to assess how various text foundation LLMs differing in scale, instruction-following ability, and reasoning specialization respond to the reasoning supervision of speechLLMs. Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S3.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 3.2 Text Foundation LLMs &#8227; 3 Experiments &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, &#8221;Reasoning SpeechLLM&#8221; column, presents the results.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We propose integration of reasoning into speech large language models (speechLLMs) for the end-to-end slot-filling task. Inspired by the recent development of reasoning LLMs, we use a chain-of-thought framework to decompose the slot-filling task into multiple reasoning steps, create a reasoning dataset and apply the supervised fine-tuning strategy to a speechLLM. We distinguish between regular and reasoning speechLLMs and experiment with different types and sizes of LLMs as their text foundation models. We demonstrate performance improvements by introducing reasoning (intermediate) steps. However, we show that a reasoning textual LLM developed mainly for math, logic and coding domains might be inferior as a foundation model for a reasoning speechLLM. We further show that hybrid speechLLMs, built on a hybrid text foundation LLM and fine-tuned to preserve both direct and reasoning modes of operation, have better performance than those fine-tuned employing only one mode of operation.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "slotfilling",
                    "speechllm",
                    "performance",
                    "regular",
                    "speechllms",
                    "llm",
                    "foundation",
                    "between",
                    "hybrid",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Emerging reasoning large language models (LLMs), such as Openai-o1 </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib1\" title=\"\">1</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Deepseek-r1 </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib2\" title=\"\">2</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nare typically used for tasks requiring multi-step problem solving, logical inference, and mathematical reasoning while &#8220;thinking&#8221; prior to providing their final answer. In contrast, regular (non-reasoning) LLMs, such as closed-source GPT-4 </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib3\" title=\"\">3</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and open-source LLama3 series </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib4\" title=\"\">4</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> focus on direct response generation without explicit chain-of-thought (CoT) reasoning traces. Prior work has demonstrated that reasoning capabilities in LLMs can be significantly enhanced by techniques such as CoT prompting </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib5\" title=\"\">5</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib6\" title=\"\">6</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, supervised fine tuning (SFT) and reinforcement learning (RL) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib7\" title=\"\">7</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib8\" title=\"\">8</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. In this work we adopt SFT as our primary method. With the rise of multimodal LLMs, in particular speechLLMs </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib9\" title=\"\">9</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib10\" title=\"\">10</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, spoken language understanding tasks are being addressed in a unified, end-to-end, generative, and instruction following manner, in either a single-task or a multi-task setting.</span>\n</p>\n\n",
                "matched_terms": [
                    "regular",
                    "speechllms",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Here we introduce a framework using CoT reasoning for slot filling, thereby transforming the single-step approaches </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib11\" title=\"\">11</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> into a multi-step approach.\nBy constructing a dataset with intermediate reasoning steps, we enable speechLLMs to learn multi-step slot filling through supervised fine-tuning. Among many possible speechLLM architectures </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib12\" title=\"\">12</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib15\" title=\"\">15</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib16\" title=\"\">16</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib17\" title=\"\">17</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib18\" title=\"\">18</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib19\" title=\"\">19</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib20\" title=\"\">20</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we considered and implemented one that has a structure very similar to SpeechVerse </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib21\" title=\"\">21</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nAs shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, it consists of three main components: a speech encoder, a modality adapter, and a pretrained large language model (LLM). This architecture is designed to jointly process speech signals and textual instructions, enabling it to perform a wide range of tasks that require understanding of both speech and text. The foundation models, pretrained at scale in their respective modalities, promise data-efficient development. Moreover, small-scale modality adapters for alignment and large-scale foundation models with parameter-efficient fine-tuning enable computationally efficient development. Importantly, the emergent abilities of LLMs, if preserved during fine-tuning, offer the potential for instruction-based zero-shot learning and improved generalization. Based on the nature of inputs and responses, we categorize speechLLMs into two broad types as shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S1.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 1 Introduction &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">: (a) regular (non-reasoning) speechLLM and (b) reasoning speechLLM. The former lacks COT traces at their outputs where the latter has its thought traces between special tags for &#8221;thinking&#8221; before they provide their final answer enclosed between special tags for &#8221;response&#8221;. In our study, we aim to explore whether a reasoning-capable LLM is useful, particularly, one that can emulate the multi-step thought processes humans might use when approaching the task. Traditionally, slot filling has been treated as a single-step prediction problem, but we investigate whether reframing it as a reasoning task might yield better performance. This brings us to key questions: What type of foundation LLM is most appropriate for this task: a base model, an instruction-tuned model, or one optimized for reasoning? And to what extent is model scale a prerequisite for reasoning capabilities to emerge? While larger models may offer improved reasoning performance, they come with increased cost, so we aim to understand whether smaller, more efficient models can achieve similar reasoning behaviors when fine-tuned effectively. Through this exploration, we seek to balance task formulation, model type, and compute efficiency to determine the most effective approach for slot filling. Our key contributions are:</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllm",
                    "performance",
                    "regular",
                    "speechllms",
                    "base",
                    "llm",
                    "foundation",
                    "between",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Implementation of this formulation using speechLLMs via supervised fine-tuning to generate reasoning traces followed by structured slot/value responses.</span>\n</p>\n\n",
                "matched_terms": [
                    "speechllms",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">A comprehensive analysis of the speechLLM performance across a diverse set of text foundation LLMs, varying in size and reasoning ability.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllm",
                    "performance",
                    "foundation",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">A new hybrid speechLLM fine-tuning method including both direct and reasoning-style supervision for better and balanced performance.</span>\n</p>\n\n",
                "matched_terms": [
                    "hybrid",
                    "speechllm",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The data for slot filling is a set of scripted call center conversations between agents and customers curated by DefinedAI</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\">\n    <sup class=\"ltx_note_mark\">1</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>https://www.defined.ai</span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This collection has approximately 31K calls with almost 1M turns and 2.1K hours of speech. The domains covered are banking, telecommunication, insurance and retail. We used GPT-4o to annotate our dataset with slot labels and values. To achieve broad, diverse and open-ended slot filling, we decided not to prime the LLM for any specific set of slot labels. Instead, given the entire call itself, we instructed the LLM to do slot filling turn-by-turn for mentions that reflect real world entities, events, dates, times and numerals while avoiding abstract notions of &#8220;entities&#8221; such as issues, solutions, broader concepts, advice or ideas.</span>\n</p>\n\n",
                "matched_terms": [
                    "between",
                    "llm"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Human listeners, much less annotators, do not necessarily assign slot labels directly upon hearing speech. Instead, they may first listen to the utterance, then mentally transcribe it into text using their language and world knowledge. After obtaining the transcript, they may then interpret its meaning and identify relevant spans or mentions of real world object types. Finally, following annotation guidelines, they assign appropriate slot labels and populate them with values, if present, based on contextual reasoning.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To reflect this process, we transform regular slot filling data into multi-step reasoning-style data. Each example is augmented with intermediate reasoning steps, including (1) transcription of the speech, (2) identification of potential spans or phrases associated with each slot type, and (3) justification for assigning each slot-value pair. This COT format allows models to simulate the human annotation workflow, encouraging deeper understanding and interpretability. By structuring the task this way, we shift from single-step prediction to a multi-step reasoning task, laying the foundation for training and evaluating reasoning-capable Speech LLMs for slot filling. The examples for regular and reasoning outputs are shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S2.F3.fig1\" style=\"font-size:90%;\" title=\"Figure 3 &#8227; 2.3 Reasoning Dataset &#8227; 2 Data Preparation &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "regular",
                    "foundation",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n<span class=\"ltx_tabular ltx_align_middle ltx_framed ltx_framed_rectangle\">\n<span class=\"ltx_tbody\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Prompt<span class=\"ltx_text ltx_font_medium\">: <math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m1\" intent=\":literal\"><semantics><mo>&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math>audio<math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m2\" intent=\":literal\"><semantics><mo>&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m3\" intent=\":literal\"><semantics><mo>&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math>bos<math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m4\" intent=\":literal\"><semantics><mo>&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math>Find slot values for new<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m5\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>limit, family<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m6\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>members<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m7\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>count, review<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m8\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>period, payment<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m9\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>frequency, payment<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m10\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>amount in the current audio. Format the output as JSON.</span></span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Regular response</span><span class=\"ltx_text\" style=\"font-size:80%;\">:</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">{&#8217;payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m11\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">frequency&#8217;: &#8217;monthly&#8217;, &#8217;payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m12\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">amount&#8217;: &#8217;&#8364;30&#8217;, &#8217;new</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m13\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">limit&#8217;: &#8217;None&#8217;, &#8217;family</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m14\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">members</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m15\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">count&#8217;: &#8217;None&#8217;, &#8217;review</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m16\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">period&#8217;: &#8217;None&#8217;}</span><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m17\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">\\eos</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m18\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Reasoning response</span><span class=\"ltx_text\" style=\"font-size:80%;\">:</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m19\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">thinking</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m20\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">I hear the utterance in the audio clip is</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8220;&#8216; Ok, thanks again for calling today, P&#776;atrick.&#776; And you are paying a month- you have a monthly payment set up for &#8364;30 a month. Is that correct? &#8220;&#8216;</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">I see that the information bearing mentions in the utterance are monthly </span><math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m21\" intent=\":literal\"><semantics><mo fence=\"false\" maxsize=\"0.800em\" minsize=\"0.800em\" stretchy=\"true\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> &#8364;30.</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">The labels queried for are payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m22\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">frequency, payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m23\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">amount, new</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m24\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">limit, family</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m25\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">members</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m26\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">count, review</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m27\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">period</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Based on the semantics of payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m28\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">frequency, payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m29\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">amount slots, the mentions in the utterance can be assigned to them. The others are all &#8217;None&#8217;</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m30\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">\\thinking</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m31\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m32\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">response</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m33\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">{&#8217;payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m34\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">frequency&#8217;: &#8217;monthly&#8217;, &#8217;payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m35\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">amount&#8217;: &#8217;&#8364;30&#8217;, &#8217;new</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m36\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">limit&#8217;: &#8217;None&#8217;, &#8217;family</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m37\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">members</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m38\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">count&#8217;: &#8217;None&#8217;, &#8217;review</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m39\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">period&#8217;: &#8217;None&#8217;}</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m40\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">\\response</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m41\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m42\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">\\eos</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m43\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math></span>\n</span></span></span>\n</span>\n</span><span class=\"ltx_text\" style=\"font-size:90%;\"/></p>\n\n",
                "matched_terms": [
                    "regular",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We construct several speechLLM systems that differ only in the underlying text foundation LLM, while keeping the speech encoder and modality adapter the same size and type. We use the encoder of Whisper-base </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and introduce a lightweight modality adapter consisting of a frame-stacked two-layer MLP that performs temporal stacking by a stack factor of 4 frames over the already 2x downsampled output of Whisper encoder, resulting in an effective 8x downsampling from the original audio frame rate. The final output dimension matches the embedding dimension of the target LLM and fed directly into the language model with the text prompt. We evaluate the following text foundation LLMs: </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Llama 3.2 1B Instruct</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">LlamA 3.1 8B Instruct</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Llama 3.1 8B</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">DeepSeek R1 Distilled Llama 3.1 8B</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Qwen3 0.6B, Qwen3 4B</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Phi-4-Mini-Reasoning 3.8B</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllm",
                    "llama",
                    "deepseek",
                    "llm",
                    "instruct",
                    "06b",
                    "foundation",
                    "qwen3"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This diverse selection of text LLMs spans a range of architectural scales and training specializations, including a base model, instruction-following variants, reasoning models, and hybrid configurations designed to balance instruction-following with reasoning. Our selection covers models of varying size classes (based on our size categorization), ranging from tiny (0.6-1B) to small (3&#8211;4B) and medium (8B) avoiding large and very-large LLMs for the efficiency of our experiments under limited compute resources. By choosing models from different families and training regimes, we aim to systematically investigate how model scale and capabilities influence the downstream slot-filling performance for regular (non-reasoning) and reasoning speechLLM setups. Each model was first used as the language backbone in a regular speechLLM and then incorporated into a reasoning speechLLM through supervised COT fine-tuning. This comparative approach allows us to isolate and interpret the contributions of instruction-following, reasoning ability, and model capacity to SLU performance, yielding insights into when and how reasoning capabilities translate to notable gains in SLU tasks.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "slotfilling",
                    "speechllm",
                    "performance",
                    "regular",
                    "base",
                    "hybrid",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our results in this regular (non-reasoning) slot-filling setup reveal several important trends concerning model scale, specialization, training strategy and its family-specific characteristics. First, within the Llama family, we observe a clear performance change with respect to model size and instruction following abilities. The medium sized instruction-following Llama 3.1 8B-Instruct model performs the best in the family. Its base variant, Llama 3.1 8B, while not as competitive, performs surprisingly close suggesting that capacity alone, without instruction tuning, contributes reasonably to the performance. On the other hand, the tiny instruction-tuned model, Llama 3.2 1B-Instruct, despite being a distilled version of the medium model, Llama 3.1 8B-Instruct, performs the worst in the Llama family. This suggests that distillation, while preserving some general capabilities, may lose general language knowledge for language understanding crucial for slot filling, especially with a smaller model size. Interestingly, the reasoning variant of Llama 3.1 8B (base), distilled from a high-performing large reasoning model (Deepseek R1), Deepseek R1 Distill Llama 3.1 8B, performs worse than all other family members, with a notable performance drop. This subpar performance is likely due to the model being over-specialized for abstract reasoning tasks such as math, logic and code, which may cause it to distort linguistic knowledge and language understanding capabilities required for SLU. This observation reinforces the idea that reasoning-optimized LLMs do not guarantee performance benefits in tasks that demand general language comprehension rather than symbolic manipulation. Similarly, in a recently published study </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> it is shown that instruction-following abilities are significantly deteriorated when the models are fine-tuned for reasoning.</span>\n</p>\n\n",
                "matched_terms": [
                    "slotfilling",
                    "performance",
                    "regular",
                    "llama",
                    "base",
                    "distill",
                    "deepseek",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In contrast, we find that the tiny hybrid model, Qwen3 0.6B, and small hybrid model, Qwen3 4B, which are trained for both reasoning and instruction-following across diverse domains, perform surprisingly well despite their relatively smaller size when compared to 8B models from the Llama series. Qwen3 4B achieved the best performance in regular speechLLMs. Their ability to balance both specializations (instruction-following and reasoning) likely lead to better generalization for the regular slot-filling task that demands some degree of implicit semantic interpretation for the direct generation of structured outputs from spoken language inputs. Notably, these hybrid models outperform the much larger reasoning-specialized model from the Llama family, Deepseek R1 Distill Llama 3.1 8B, indicating that balanced instruction-following and reasoning specialization can be more beneficial than the model size.\nWe also evaluated a small-size reasoning model, Phi4-mini reasoning 3.68B, from a different LLM family, Phi4, that is open-sourced by Microsoft and optimized for a math domain, but not heavily tuned for logic and coding domains. This model performs slightly better than the tiny hybrid model, Qwen3 0.6B, likely due to its larger size, despite being primarily specialized for reasoning tasks. It also outperforms the much larger reasoning-specialized model, Deepseek R1 Distill Llama 3.1 8B, which appears to suffer from domain overfitting since it has been fine-tuned on a broader range of domains including code and logic, compared to Phi4 model&#8217;s narrower focus on math. However, a similarly sized hybrid model, Qwen3 4B, significantly outperforms it, likely because it retains stronger instruction-following capabilities due to its hybrid training strategy.</span>\n</p>\n\n",
                "matched_terms": [
                    "slotfilling",
                    "performance",
                    "regular",
                    "speechllms",
                    "llama",
                    "distill",
                    "deepseek",
                    "llm",
                    "06b",
                    "phi4mini",
                    "hybrid",
                    "368b",
                    "reasoning",
                    "qwen3"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Overall, these results indicate that text foundation LLMs which are specialized solely for reasoning do not offer advantages in regular speechLLMs for slot-filling tasks that do not explicitly employ multi-step reasoning. These results also indicate the importance of model scale, balanced training objectives, and domain relevance when adapting LLMs to speech-based language understanding tasks. Notably, hybrid models trained on both reasoning and instruction data, even at smaller scales, appear to strike an effective balance between capability and generalization, making them particularly well-suited for regular SLU applications.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "slotfilling",
                    "regular",
                    "speechllms",
                    "foundation",
                    "between",
                    "hybrid",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We observe that the base, instruction-tuned, and 8B-parameters text foundation LLMs in reasoning speechLLMs demonstrate improvements over non-reasoning speechLLMs. However, the degree of improvement varies. Instruction-tuned foundation models show only moderate gains, suggesting that their existing alignment with instruction prompting and direct non-reasoning response generation may introduce some resistance to integrating high performant explicit multi-step reasoning traces. In contrast, the base model, which lacks prior specialization, exhibits notable improvements, and performs the best, indicating that models without post training may serve as more flexible candidates for incorporating reasoning capabilities in speechLLMs.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllms",
                    "base",
                    "foundation",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The most striking observation comes from the reasoning-specialized text foundation LLM, Deepseek R1 Distill Llama 3.1 8B, which has previously shown the worst performance in the regular slot-filling setup. When its corresponding speechLLM is trained with reasoning supervision, it exhibits the largest relative performance gain of 22.72</span>\n  <math alttext=\"\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">%</mo>\n      <annotation encoding=\"application/x-tex\">\\%</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> among all other configurations. This suggests that its reasoning-focused distillation is effective when reasoning supervison becomes explicitly part of speechLLM fine-tuning. Nevertheless, this model still lags behind other models of comparable size in absolute performance, particularly when it is compared to the base model that it was distilled from. This demonstrates the cost of overfitting to a few domains (math, logic, code) and potential degradation of general linguistic knowledge and understanding during reasoning specialization.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "slotfilling",
                    "speechllm",
                    "performance",
                    "relative",
                    "regular",
                    "gain",
                    "llama",
                    "base",
                    "distill",
                    "deepseek",
                    "llm",
                    "foundation",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Interestingly, smaller-scale reasoning text foundation LLMs (tiny and small) not only fail to provide benefits to the reasoning supervision of speechLLMs, but in fact cause performance degradation compared to regular speechLLMs. Despite being the top-performing model in the regular slot-filling setup, the hybrid model Qwen3 4B shows the most significant relative performance drop, approximately 16%, when adapted to the reasoning speechLLM. This suggests that while hybrid LLMs are effective for the regular task, benefiting from implicit semantic interpretation that is likely improved due to the reasoning training of LLMs, the introduction of explicit reasoning overwhelms speechLLMs with these smaller-scale LLMs. This could be due not only to limited capacity but also to potential overfitting to the reasoning traces or a lack of regularization. In the next section, we demonstrate how hybrid training of speechLLMs helps mitigate this issue and improves overall performance.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "slotfilling",
                    "speechllm",
                    "performance",
                    "relative",
                    "regular",
                    "speechllms",
                    "foundation",
                    "hybrid",
                    "reasoning",
                    "qwen3"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To explore the potential of combining regular and reasoning response generations as two different modes of operation in a single speechLLM, we conduct experiments using hybrid fine-tuning. Here, the speechLLM is trained on a merged dataset consisting of both direct and multi-step reasoning responses. The operation is switched between regular and reasoning modes using special tags in the prompt as </span>\n  <math alttext=\"\\backslash\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS5.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">\\</mo>\n      <annotation encoding=\"application/x-tex\">\\backslash</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">no_think or </span>\n  <math alttext=\"\\backslash\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS5.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">\\</mo>\n      <annotation encoding=\"application/x-tex\">\\backslash</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">think, respectively. We focus on tiny and small models from the hybrid LLM family, which previously demonstrated strong performance when compared to reasoning-only text foundation LLMs. The results are summarized in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3.3 Regular SpeechLLMs &#8227; 3 Experiments &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Our results show that the best-performing system is the hybrid speechLLM built on top of a hybrid text foundation LLM.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllm",
                    "performance",
                    "regular",
                    "llm",
                    "foundation",
                    "between",
                    "hybrid",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this paper, we have introduced a novel formulation of slot filling as a reasoning task and automatically created datasets supporting both regular and reasoning-style supervision. We fine-tuned speechLLMs using direct, reasoning-style, or hybrid supervision, enabling analyses across a diverse set of text foundation LLMs with varying types, sizes and prior abilities. Our findings highlight that speechLLMs with medium-scale text foundation LLMs can benefit most from reasoning supervision, while they struggle with smaller and tiny models due to lack of sufficient capacity. In general, we observed that reasoning-optimized text foundation models, focused on a single or few domains (math, logic, code), may have some loss of general language knowledge and comprehension. This degradation limits the performance of speechLLMs for slot filling, where general linguistic understanding is essential. However, we further demonstrated that hybrid fine-tuning by hybrid supervision has consistently improved the performance when using hybrid text foundation LLMs, suggesting that the hybrid training provides an effective alternative strategy for balanced fine-tuning that improves the generalization and flexibility of the models.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "performance",
                    "regular",
                    "speechllms",
                    "foundation",
                    "hybrid",
                    "reasoning"
                ]
            }
        ]
    },
    "S3.T2": {
        "source_file": "Slot Filling as a Reasoning Task for SpeechLLMs",
        "caption": "Table 2: Performance improvements achieved by hybrid speechLLMs, fine-tuned with hybrid supervision. Results are compared against previous smaller scale models (replicated here, see Table 1).",
        "body": "Text Foundation Model\nMode\nRegular SpeechLLM\nReasoning SpeechLLM\nHybrid SpeechLLM\nRelative Gain, %\\%\n\n\n\n\n\n\nPrecision/Recall/F1\nPrecision/Recall/F1\nPrecision/Recall/F1\n\nΔ\\DeltaF1\n\n\n\nQwen3 0.6B\nRegular\n0.5176/ 0.8633/ 0.6472\n-\n0.5600/ 0.8721/ 0.6821\n+5.39\n\n\n\nReasoning\n-\n0.4889/ 0.7935/ 0.6050\n0.5797/ 0.8700/ 0.6958\n+15.01\n\n\nQwen3 4B\nRegular\n0.6308/ 0.9400/ 0.7550\n-\n0.6821/ 0.9340/ 0.7884\n+4.42\n\n\n\nReasoning\n-\n0.4979/ 0.8717/ 0.6338\n0.6958/ 0.9377/ 0.7988\n+26.03",
        "html_code": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Text Foundation Model</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Mode</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Regular SpeechLLM</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Reasoning SpeechLLM</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Hybrid SpeechLLM</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Relative Gain, <math alttext=\"\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.m1\" intent=\":literal\"><semantics><mo>%</mo><annotation encoding=\"application/x-tex\">\\%</annotation></semantics></math></span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td\"/>\n<th class=\"ltx_td ltx_th ltx_th_column\"/>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span class=\"ltx_text\" style=\"font-size:90%;\">Precision/Recall/F1</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span class=\"ltx_text\" style=\"font-size:90%;\">Precision/Recall/F1</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span class=\"ltx_text\" style=\"font-size:90%;\">Precision/Recall/F1</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">\n<math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.m2\" intent=\":literal\"><semantics><mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi><annotation encoding=\"application/x-tex\">\\Delta</annotation></semantics></math><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">F1</span>\n</th>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen3 0.6B</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Regular</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.5176/ 0.8633/ 0.6472</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.5600/ 0.8721/ 0.6821</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">+5.39</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td\"/>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Reasoning</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.4889/ 0.7935/ 0.6050</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.5797/ 0.8700/ 0.6958</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">+15.01</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen3 4B</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Regular</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.6308/ 0.9400/ 0.7550</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.6821/ 0.9340/ 0.7884</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">+4.42</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_border_b\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">Reasoning</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.4979/ 0.8717/ 0.6338</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.6958/ 0.9377/ 0.7988</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">+26.03</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "smaller",
            "speechllm",
            "regular",
            "see",
            "here",
            "06b",
            "reasoning",
            "text",
            "replicated",
            "supervision",
            "results",
            "precisionrecallf1",
            "achieved",
            "compared",
            "δdeltaf1",
            "performance",
            "relative",
            "previous",
            "speechllms",
            "foundation",
            "mode",
            "scale",
            "hybrid",
            "finetuned",
            "gain",
            "against",
            "models",
            "model",
            "improvements",
            "qwen3"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To explore the potential of combining regular and reasoning response generations as two different modes of operation in a single speechLLM, we conduct experiments using hybrid fine-tuning. Here, the speechLLM is trained on a merged dataset consisting of both direct and multi-step reasoning responses. The operation is switched between regular and reasoning modes using special tags in the prompt as </span>\n  <math alttext=\"\\backslash\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS5.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">\\</mo>\n      <annotation encoding=\"application/x-tex\">\\backslash</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">no_think or </span>\n  <math alttext=\"\\backslash\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS5.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">\\</mo>\n      <annotation encoding=\"application/x-tex\">\\backslash</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">think, respectively. We focus on tiny and small models from the hybrid LLM family, which previously demonstrated strong performance when compared to reasoning-only text foundation LLMs. The results are summarized in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3.3 Regular SpeechLLMs &#8227; 3 Experiments &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Our results show that the best-performing system is the hybrid speechLLM built on top of a hybrid text foundation LLM.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We propose integration of reasoning into speech large language models (speechLLMs) for the end-to-end slot-filling task. Inspired by the recent development of reasoning LLMs, we use a chain-of-thought framework to decompose the slot-filling task into multiple reasoning steps, create a reasoning dataset and apply the supervised fine-tuning strategy to a speechLLM. We distinguish between regular and reasoning speechLLMs and experiment with different types and sizes of LLMs as their text foundation models. We demonstrate performance improvements by introducing reasoning (intermediate) steps. However, we show that a reasoning textual LLM developed mainly for math, logic and coding domains might be inferior as a foundation model for a reasoning speechLLM. We further show that hybrid speechLLMs, built on a hybrid text foundation LLM and fine-tuned to preserve both direct and reasoning modes of operation, have better performance than those fine-tuned employing only one mode of operation.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllm",
                    "performance",
                    "regular",
                    "models",
                    "model",
                    "speechllms",
                    "foundation",
                    "mode",
                    "hybrid",
                    "improvements",
                    "reasoning",
                    "finetuned"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold ltx_font_italic\" style=\"font-size:90%;\">Index Terms<span class=\"ltx_text ltx_font_upright\">&#8212;&#8201;</span></span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nspoken language understanding, slot filling, speech large language models, reasoning speech large language models</span>\n</p>\n\n",
                "matched_terms": [
                    "models",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Emerging reasoning large language models (LLMs), such as Openai-o1 </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib1\" title=\"\">1</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Deepseek-r1 </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib2\" title=\"\">2</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nare typically used for tasks requiring multi-step problem solving, logical inference, and mathematical reasoning while &#8220;thinking&#8221; prior to providing their final answer. In contrast, regular (non-reasoning) LLMs, such as closed-source GPT-4 </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib3\" title=\"\">3</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and open-source LLama3 series </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib4\" title=\"\">4</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> focus on direct response generation without explicit chain-of-thought (CoT) reasoning traces. Prior work has demonstrated that reasoning capabilities in LLMs can be significantly enhanced by techniques such as CoT prompting </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib5\" title=\"\">5</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib6\" title=\"\">6</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, supervised fine tuning (SFT) and reinforcement learning (RL) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib7\" title=\"\">7</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib8\" title=\"\">8</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. In this work we adopt SFT as our primary method. With the rise of multimodal LLMs, in particular speechLLMs </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib9\" title=\"\">9</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib10\" title=\"\">10</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, spoken language understanding tasks are being addressed in a unified, end-to-end, generative, and instruction following manner, in either a single-task or a multi-task setting.</span>\n</p>\n\n",
                "matched_terms": [
                    "regular",
                    "models",
                    "speechllms",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Here we introduce a framework using CoT reasoning for slot filling, thereby transforming the single-step approaches </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib11\" title=\"\">11</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> into a multi-step approach.\nBy constructing a dataset with intermediate reasoning steps, we enable speechLLMs to learn multi-step slot filling through supervised fine-tuning. Among many possible speechLLM architectures </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib12\" title=\"\">12</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib15\" title=\"\">15</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib16\" title=\"\">16</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib17\" title=\"\">17</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib18\" title=\"\">18</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib19\" title=\"\">19</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib20\" title=\"\">20</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we considered and implemented one that has a structure very similar to SpeechVerse </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib21\" title=\"\">21</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nAs shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, it consists of three main components: a speech encoder, a modality adapter, and a pretrained large language model (LLM). This architecture is designed to jointly process speech signals and textual instructions, enabling it to perform a wide range of tasks that require understanding of both speech and text. The foundation models, pretrained at scale in their respective modalities, promise data-efficient development. Moreover, small-scale modality adapters for alignment and large-scale foundation models with parameter-efficient fine-tuning enable computationally efficient development. Importantly, the emergent abilities of LLMs, if preserved during fine-tuning, offer the potential for instruction-based zero-shot learning and improved generalization. Based on the nature of inputs and responses, we categorize speechLLMs into two broad types as shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S1.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 1 Introduction &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">: (a) regular (non-reasoning) speechLLM and (b) reasoning speechLLM. The former lacks COT traces at their outputs where the latter has its thought traces between special tags for &#8221;thinking&#8221; before they provide their final answer enclosed between special tags for &#8221;response&#8221;. In our study, we aim to explore whether a reasoning-capable LLM is useful, particularly, one that can emulate the multi-step thought processes humans might use when approaching the task. Traditionally, slot filling has been treated as a single-step prediction problem, but we investigate whether reframing it as a reasoning task might yield better performance. This brings us to key questions: What type of foundation LLM is most appropriate for this task: a base model, an instruction-tuned model, or one optimized for reasoning? And to what extent is model scale a prerequisite for reasoning capabilities to emerge? While larger models may offer improved reasoning performance, they come with increased cost, so we aim to understand whether smaller, more efficient models can achieve similar reasoning behaviors when fine-tuned effectively. Through this exploration, we seek to balance task formulation, model type, and compute efficiency to determine the most effective approach for slot filling. Our key contributions are:</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "smaller",
                    "speechllm",
                    "performance",
                    "regular",
                    "models",
                    "speechllms",
                    "here",
                    "foundation",
                    "scale",
                    "model",
                    "reasoning",
                    "finetuned"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Implementation of this formulation using speechLLMs via supervised fine-tuning to generate reasoning traces followed by structured slot/value responses.</span>\n</p>\n\n",
                "matched_terms": [
                    "speechllms",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">A comprehensive analysis of the speechLLM performance across a diverse set of text foundation LLMs, varying in size and reasoning ability.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllm",
                    "performance",
                    "foundation",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">A new hybrid speechLLM fine-tuning method including both direct and reasoning-style supervision for better and balanced performance.</span>\n</p>\n\n",
                "matched_terms": [
                    "supervision",
                    "hybrid",
                    "speechllm",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We now describe the conversion of the slot filling dataset into an instruction-based training dataset. This dataset consists of three fields: audio, instruction, and desired output. Instructions are the most crucial part of the data preparation. It should consist of a description of the task in natural language. Although it is possible to use a fixed instruction, a diverse set of instructions is beneficial to generalize to novel prompts not seen in training. In addition, we introduced several strategies for improving coverage across a variety of use-cases of slot filling. We assume turn-by-turn slot filling with/without context, and with/without querying specific slots. The context is defined as the recognition results for the previous </span>\n  <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">T</mi>\n      <annotation encoding=\"application/x-tex\">T</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> turns. We randomize the context size in the range </span>\n  <math alttext=\"0\\leq T\\leq 3\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">0</mn>\n        <mo mathsize=\"0.900em\">&#8804;</mo>\n        <mi mathsize=\"0.900em\">T</mi>\n        <mo mathsize=\"0.900em\">&#8804;</mo>\n        <mn mathsize=\"0.900em\">3</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">0\\leq T\\leq 3</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. When we query specific slots in the prompt, we take the ground truth slots in the corresponding turn, if any, and then add a varying numbers </span>\n  <math alttext=\"S\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">S</mi>\n      <annotation encoding=\"application/x-tex\">S</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> of distractors. We also randomize the number of distractors, </span>\n  <math alttext=\"1\\leq S\\leq 5\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">1</mn>\n        <mo mathsize=\"0.900em\">&#8804;</mo>\n        <mi mathsize=\"0.900em\">S</mi>\n        <mo mathsize=\"0.900em\">&#8804;</mo>\n        <mn mathsize=\"0.900em\">5</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">1\\leq S\\leq 5</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. For each case, we randomly sample from a set of 10 prompts.</span>\n</p>\n\n",
                "matched_terms": [
                    "results",
                    "previous"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Human listeners, much less annotators, do not necessarily assign slot labels directly upon hearing speech. Instead, they may first listen to the utterance, then mentally transcribe it into text using their language and world knowledge. After obtaining the transcript, they may then interpret its meaning and identify relevant spans or mentions of real world object types. Finally, following annotation guidelines, they assign appropriate slot labels and populate them with values, if present, based on contextual reasoning.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To reflect this process, we transform regular slot filling data into multi-step reasoning-style data. Each example is augmented with intermediate reasoning steps, including (1) transcription of the speech, (2) identification of potential spans or phrases associated with each slot type, and (3) justification for assigning each slot-value pair. This COT format allows models to simulate the human annotation workflow, encouraging deeper understanding and interpretability. By structuring the task this way, we shift from single-step prediction to a multi-step reasoning task, laying the foundation for training and evaluating reasoning-capable Speech LLMs for slot filling. The examples for regular and reasoning outputs are shown in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S2.F3.fig1\" style=\"font-size:90%;\" title=\"Figure 3 &#8227; 2.3 Reasoning Dataset &#8227; 2 Data Preparation &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "regular",
                    "models",
                    "foundation",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n<span class=\"ltx_tabular ltx_align_middle ltx_framed ltx_framed_rectangle\">\n<span class=\"ltx_tbody\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Prompt<span class=\"ltx_text ltx_font_medium\">: <math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m1\" intent=\":literal\"><semantics><mo>&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math>audio<math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m2\" intent=\":literal\"><semantics><mo>&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m3\" intent=\":literal\"><semantics><mo>&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math>bos<math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m4\" intent=\":literal\"><semantics><mo>&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math>Find slot values for new<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m5\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>limit, family<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m6\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>members<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m7\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>count, review<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m8\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>period, payment<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m9\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>frequency, payment<math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m10\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math>amount in the current audio. Format the output as JSON.</span></span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Regular response</span><span class=\"ltx_text\" style=\"font-size:80%;\">:</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">{&#8217;payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m11\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">frequency&#8217;: &#8217;monthly&#8217;, &#8217;payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m12\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">amount&#8217;: &#8217;&#8364;30&#8217;, &#8217;new</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m13\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">limit&#8217;: &#8217;None&#8217;, &#8217;family</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m14\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">members</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m15\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">count&#8217;: &#8217;None&#8217;, &#8217;review</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m16\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">period&#8217;: &#8217;None&#8217;}</span><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m17\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">\\eos</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m18\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Reasoning response</span><span class=\"ltx_text\" style=\"font-size:80%;\">:</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m19\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">thinking</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m20\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">I hear the utterance in the audio clip is</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8220;&#8216; Ok, thanks again for calling today, P&#776;atrick.&#776; And you are paying a month- you have a monthly payment set up for &#8364;30 a month. Is that correct? &#8220;&#8216;</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">I see that the information bearing mentions in the utterance are monthly </span><math alttext=\"|\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m21\" intent=\":literal\"><semantics><mo fence=\"false\" maxsize=\"0.800em\" minsize=\"0.800em\" stretchy=\"true\">|</mo><annotation encoding=\"application/x-tex\">|</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> &#8364;30.</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">The labels queried for are payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m22\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">frequency, payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m23\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">amount, new</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m24\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">limit, family</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m25\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">members</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m26\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">count, review</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m27\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">period</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Based on the semantics of payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m28\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">frequency, payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m29\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">amount slots, the mentions in the utterance can be assigned to them. The others are all &#8217;None&#8217;</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m30\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">\\thinking</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m31\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m32\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">response</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m33\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">{&#8217;payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m34\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">frequency&#8217;: &#8217;monthly&#8217;, &#8217;payment</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m35\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">amount&#8217;: &#8217;&#8364;30&#8217;, &#8217;new</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m36\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">limit&#8217;: &#8217;None&#8217;, &#8217;family</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m37\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">members</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m38\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">count&#8217;: &#8217;None&#8217;, &#8217;review</span><math alttext=\"\\_\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m39\" intent=\":literal\"><semantics><mi mathsize=\"0.800em\" mathvariant=\"normal\">_</mi><annotation encoding=\"application/x-tex\">\\_</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">period&#8217;: &#8217;None&#8217;}</span></span>\n</span></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:391.3pt;\"><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m40\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">\\response</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m41\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math><math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m42\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\">\\eos</span><math alttext=\"&gt;\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.m43\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&gt;</mo><annotation encoding=\"application/x-tex\">&gt;</annotation></semantics></math></span>\n</span></span></span>\n</span>\n</span><span class=\"ltx_text\" style=\"font-size:90%;\"/></p>\n\n",
                "matched_terms": [
                    "regular",
                    "see",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We construct several speechLLM systems that differ only in the underlying text foundation LLM, while keeping the speech encoder and modality adapter the same size and type. We use the encoder of Whisper-base </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and introduce a lightweight modality adapter consisting of a frame-stacked two-layer MLP that performs temporal stacking by a stack factor of 4 frames over the already 2x downsampled output of Whisper encoder, resulting in an effective 8x downsampling from the original audio frame rate. The final output dimension matches the embedding dimension of the target LLM and fed directly into the language model with the text prompt. We evaluate the following text foundation LLMs: </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Llama 3.2 1B Instruct</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">LlamA 3.1 8B Instruct</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Llama 3.1 8B</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">DeepSeek R1 Distilled Llama 3.1 8B</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Qwen3 0.6B, Qwen3 4B</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Phi-4-Mini-Reasoning 3.8B</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllm",
                    "06b",
                    "foundation",
                    "model",
                    "qwen3"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This diverse selection of text LLMs spans a range of architectural scales and training specializations, including a base model, instruction-following variants, reasoning models, and hybrid configurations designed to balance instruction-following with reasoning. Our selection covers models of varying size classes (based on our size categorization), ranging from tiny (0.6-1B) to small (3&#8211;4B) and medium (8B) avoiding large and very-large LLMs for the efficiency of our experiments under limited compute resources. By choosing models from different families and training regimes, we aim to systematically investigate how model scale and capabilities influence the downstream slot-filling performance for regular (non-reasoning) and reasoning speechLLM setups. Each model was first used as the language backbone in a regular speechLLM and then incorporated into a reasoning speechLLM through supervised COT fine-tuning. This comparative approach allows us to isolate and interpret the contributions of instruction-following, reasoning ability, and model capacity to SLU performance, yielding insights into when and how reasoning capabilities translate to notable gains in SLU tasks.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllm",
                    "performance",
                    "regular",
                    "models",
                    "model",
                    "scale",
                    "hybrid",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">All text-based LLMs described above are integrated into speechLLMs as their text foundation models. They are fine-tuned using LoRA. The modality adapter is fully fine-tuned while keeping the speech encoder, from the Whisper-base model, frozen. Here, the fine-tuning is performed using the regular (non-reasoning) slot-filling dataset with speech-prompt-response triplets as described in Section&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S2.SS2\" style=\"font-size:90%;\" title=\"2.2 Instruction-based Dataset &#8227; 2 Data Preparation &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">2.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The response is a structured JSON object containing slot types and their corresponding values without any explicit multi-step reasoning traces. These results serve as our baseline prior to introducing COT supervision in the reasoning setup which we cover in the following section. Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S3.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 3.2 Text Foundation LLMs &#8227; 3 Experiments &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, &#8221;Regular SpeechLLM&#8221; column, summarizes performance of each regular speechLLM configuration determined by its text foundation LLM. We present results using partial-match precision, recall, and F1 scores. We adopt partial matching over exact match to better reflect the generative nature of the models, which may produce correct slot values with minor surface-level variations.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllm",
                    "performance",
                    "regular",
                    "models",
                    "speechllms",
                    "here",
                    "supervision",
                    "results",
                    "foundation",
                    "model",
                    "reasoning",
                    "finetuned"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our results in this regular (non-reasoning) slot-filling setup reveal several important trends concerning model scale, specialization, training strategy and its family-specific characteristics. First, within the Llama family, we observe a clear performance change with respect to model size and instruction following abilities. The medium sized instruction-following Llama 3.1 8B-Instruct model performs the best in the family. Its base variant, Llama 3.1 8B, while not as competitive, performs surprisingly close suggesting that capacity alone, without instruction tuning, contributes reasonably to the performance. On the other hand, the tiny instruction-tuned model, Llama 3.2 1B-Instruct, despite being a distilled version of the medium model, Llama 3.1 8B-Instruct, performs the worst in the Llama family. This suggests that distillation, while preserving some general capabilities, may lose general language knowledge for language understanding crucial for slot filling, especially with a smaller model size. Interestingly, the reasoning variant of Llama 3.1 8B (base), distilled from a high-performing large reasoning model (Deepseek R1), Deepseek R1 Distill Llama 3.1 8B, performs worse than all other family members, with a notable performance drop. This subpar performance is likely due to the model being over-specialized for abstract reasoning tasks such as math, logic and code, which may cause it to distort linguistic knowledge and language understanding capabilities required for SLU. This observation reinforces the idea that reasoning-optimized LLMs do not guarantee performance benefits in tasks that demand general language comprehension rather than symbolic manipulation. Similarly, in a recently published study </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> it is shown that instruction-following abilities are significantly deteriorated when the models are fine-tuned for reasoning.</span>\n</p>\n\n",
                "matched_terms": [
                    "smaller",
                    "performance",
                    "regular",
                    "models",
                    "results",
                    "scale",
                    "model",
                    "reasoning",
                    "finetuned"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In contrast, we find that the tiny hybrid model, Qwen3 0.6B, and small hybrid model, Qwen3 4B, which are trained for both reasoning and instruction-following across diverse domains, perform surprisingly well despite their relatively smaller size when compared to 8B models from the Llama series. Qwen3 4B achieved the best performance in regular speechLLMs. Their ability to balance both specializations (instruction-following and reasoning) likely lead to better generalization for the regular slot-filling task that demands some degree of implicit semantic interpretation for the direct generation of structured outputs from spoken language inputs. Notably, these hybrid models outperform the much larger reasoning-specialized model from the Llama family, Deepseek R1 Distill Llama 3.1 8B, indicating that balanced instruction-following and reasoning specialization can be more beneficial than the model size.\nWe also evaluated a small-size reasoning model, Phi4-mini reasoning 3.68B, from a different LLM family, Phi4, that is open-sourced by Microsoft and optimized for a math domain, but not heavily tuned for logic and coding domains. This model performs slightly better than the tiny hybrid model, Qwen3 0.6B, likely due to its larger size, despite being primarily specialized for reasoning tasks. It also outperforms the much larger reasoning-specialized model, Deepseek R1 Distill Llama 3.1 8B, which appears to suffer from domain overfitting since it has been fine-tuned on a broader range of domains including code and logic, compared to Phi4 model&#8217;s narrower focus on math. However, a similarly sized hybrid model, Qwen3 4B, significantly outperforms it, likely because it retains stronger instruction-following capabilities due to its hybrid training strategy.</span>\n</p>\n\n",
                "matched_terms": [
                    "smaller",
                    "performance",
                    "regular",
                    "models",
                    "model",
                    "speechllms",
                    "achieved",
                    "compared",
                    "06b",
                    "hybrid",
                    "reasoning",
                    "finetuned",
                    "qwen3"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Overall, these results indicate that text foundation LLMs which are specialized solely for reasoning do not offer advantages in regular speechLLMs for slot-filling tasks that do not explicitly employ multi-step reasoning. These results also indicate the importance of model scale, balanced training objectives, and domain relevance when adapting LLMs to speech-based language understanding tasks. Notably, hybrid models trained on both reasoning and instruction data, even at smaller scales, appear to strike an effective balance between capability and generalization, making them particularly well-suited for regular SLU applications.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "smaller",
                    "regular",
                    "models",
                    "model",
                    "speechllms",
                    "results",
                    "foundation",
                    "scale",
                    "hybrid",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this section we consider reasoning speechLLMs, where the models are fine-tuned using multi-step, COT style supervision for the slot-filling task. This setup enables us to assess how various text foundation LLMs differing in scale, instruction-following ability, and reasoning specialization respond to the reasoning supervision of speechLLMs. Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.19326v1#S3.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 3.2 Text Foundation LLMs &#8227; 3 Experiments &#8227; Slot Filling as a Reasoning Task for SpeechLLMs\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, &#8221;Reasoning SpeechLLM&#8221; column, presents the results.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "models",
                    "speechllms",
                    "supervision",
                    "results",
                    "foundation",
                    "scale",
                    "reasoning",
                    "finetuned"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We observe that the base, instruction-tuned, and 8B-parameters text foundation LLMs in reasoning speechLLMs demonstrate improvements over non-reasoning speechLLMs. However, the degree of improvement varies. Instruction-tuned foundation models show only moderate gains, suggesting that their existing alignment with instruction prompting and direct non-reasoning response generation may introduce some resistance to integrating high performant explicit multi-step reasoning traces. In contrast, the base model, which lacks prior specialization, exhibits notable improvements, and performs the best, indicating that models without post training may serve as more flexible candidates for incorporating reasoning capabilities in speechLLMs.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "models",
                    "speechllms",
                    "foundation",
                    "model",
                    "improvements",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The most striking observation comes from the reasoning-specialized text foundation LLM, Deepseek R1 Distill Llama 3.1 8B, which has previously shown the worst performance in the regular slot-filling setup. When its corresponding speechLLM is trained with reasoning supervision, it exhibits the largest relative performance gain of 22.72</span>\n  <math alttext=\"\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">%</mo>\n      <annotation encoding=\"application/x-tex\">\\%</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> among all other configurations. This suggests that its reasoning-focused distillation is effective when reasoning supervison becomes explicitly part of speechLLM fine-tuning. Nevertheless, this model still lags behind other models of comparable size in absolute performance, particularly when it is compared to the base model that it was distilled from. This demonstrates the cost of overfitting to a few domains (math, logic, code) and potential degradation of general linguistic knowledge and understanding during reasoning specialization.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllm",
                    "performance",
                    "relative",
                    "regular",
                    "gain",
                    "models",
                    "supervision",
                    "compared",
                    "foundation",
                    "model",
                    "reasoning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Interestingly, smaller-scale reasoning text foundation LLMs (tiny and small) not only fail to provide benefits to the reasoning supervision of speechLLMs, but in fact cause performance degradation compared to regular speechLLMs. Despite being the top-performing model in the regular slot-filling setup, the hybrid model Qwen3 4B shows the most significant relative performance drop, approximately 16%, when adapted to the reasoning speechLLM. This suggests that while hybrid LLMs are effective for the regular task, benefiting from implicit semantic interpretation that is likely improved due to the reasoning training of LLMs, the introduction of explicit reasoning overwhelms speechLLMs with these smaller-scale LLMs. This could be due not only to limited capacity but also to potential overfitting to the reasoning traces or a lack of regularization. In the next section, we demonstrate how hybrid training of speechLLMs helps mitigate this issue and improves overall performance.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speechllm",
                    "performance",
                    "relative",
                    "regular",
                    "model",
                    "speechllms",
                    "supervision",
                    "compared",
                    "foundation",
                    "hybrid",
                    "reasoning",
                    "qwen3"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this paper, we have introduced a novel formulation of slot filling as a reasoning task and automatically created datasets supporting both regular and reasoning-style supervision. We fine-tuned speechLLMs using direct, reasoning-style, or hybrid supervision, enabling analyses across a diverse set of text foundation LLMs with varying types, sizes and prior abilities. Our findings highlight that speechLLMs with medium-scale text foundation LLMs can benefit most from reasoning supervision, while they struggle with smaller and tiny models due to lack of sufficient capacity. In general, we observed that reasoning-optimized text foundation models, focused on a single or few domains (math, logic, code), may have some loss of general language knowledge and comprehension. This degradation limits the performance of speechLLMs for slot filling, where general linguistic understanding is essential. However, we further demonstrated that hybrid fine-tuning by hybrid supervision has consistently improved the performance when using hybrid text foundation LLMs, suggesting that the hybrid training provides an effective alternative strategy for balanced fine-tuning that improves the generalization and flexibility of the models.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "smaller",
                    "performance",
                    "regular",
                    "models",
                    "speechllms",
                    "supervision",
                    "foundation",
                    "hybrid",
                    "reasoning",
                    "finetuned"
                ]
            }
        ]
    }
}