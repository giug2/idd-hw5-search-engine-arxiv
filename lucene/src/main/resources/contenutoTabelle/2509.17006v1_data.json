{
    "S2.T1": {
        "caption": "Table 1: Objective evaluation metrics for comparison with baseline codecs.",
        "body": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\">Tokenizer</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">N</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">FR</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">BPS</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">PESQ <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m1\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">SI-SDR <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m2\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">STFT <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">Mel <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m4\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">MUSHRA<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">WER <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m6\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">SIM <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m7\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">Ground Truth</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">1</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">24khz</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">384k</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">4.64</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">10.56</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">90.7</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">3.01</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.96</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">MBCodec</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">25Hz</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">2.2k</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">2.98</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">7.70</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.17</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">3.62</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">82.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">4.25</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.90</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td\"/>\n<td class=\"ltx_td ltx_align_center\">8</td>\n<td class=\"ltx_td ltx_align_center\">50Hz</td>\n<td class=\"ltx_td ltx_align_center\">4.4k</td>\n<td class=\"ltx_td ltx_align_center\">3.07</td>\n<td class=\"ltx_td ltx_align_center\">7.72</td>\n<td class=\"ltx_td ltx_align_center\">0.12</td>\n<td class=\"ltx_td ltx_align_center\">3.36</td>\n<td class=\"ltx_td ltx_align_center\">83.2</td>\n<td class=\"ltx_td ltx_align_center\">3.38</td>\n<td class=\"ltx_td ltx_align_center\">0.91</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td\"/>\n<td class=\"ltx_td ltx_align_center\">16</td>\n<td class=\"ltx_td ltx_align_center\">25Hz</td>\n<td class=\"ltx_td ltx_align_center\">4.4k</td>\n<td class=\"ltx_td ltx_align_center\">3.64</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">7.98</span></td>\n<td class=\"ltx_td ltx_align_center\">0.11</td>\n<td class=\"ltx_td ltx_align_center\">3.21</td>\n<td class=\"ltx_td ltx_align_center\">85.3</td>\n<td class=\"ltx_td ltx_align_center\">3.32</td>\n<td class=\"ltx_td ltx_align_center\">0.93</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td\"/>\n<td class=\"ltx_td ltx_align_center\">16</td>\n<td class=\"ltx_td ltx_align_center\">50Hz</td>\n<td class=\"ltx_td ltx_align_center\">8.8k</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">3.83</span></td>\n<td class=\"ltx_td ltx_align_center\">7.94</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.08</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">2.34</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">85.9</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">3.24</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.97</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">DAC</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">25Hz</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">2.0k</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">3.18</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">7.95</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.14</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">5.02</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">82.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">4.39</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.83</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">SpeechTokenizer</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">50Hz</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">4.4k</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">1.26</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">6.66</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.58</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">7.02</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">79.0</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">5.26</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.82</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">Encodec</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">16</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">50Hz</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">8.8k</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">2.78</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">6.48</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.36</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">2.96</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">85.3</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">4.22</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.79</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "codecs",
            "pesq",
            "wer",
            "mbcodec",
            "tokenizer",
            "evaluation",
            "88k",
            "↓downarrow",
            "comparison",
            "dac",
            "objective",
            "20k",
            "25hz",
            "bps",
            "encodec",
            "truth",
            "stft",
            "metrics",
            "24khz",
            "22k",
            "mushra↑uparrow",
            "↑uparrow",
            "384k",
            "mel",
            "44k",
            "speechtokenizer",
            "sisdr",
            "sim",
            "50hz",
            "baseline",
            "ground"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">As presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#S2.T1\" title=\"Table 1 &#8227; 2 MBCodec &#8227; MBCodec: Thorough Disentanglement for High-Fidelity Audio Compression\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, our proposed MBCodec is comprehensively compared against the baseline codecs DAC <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib17\" title=\"\">17</a>]</cite>, Encodec <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib11\" title=\"\">11</a>]</cite> and SpeechTokenizer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib14\" title=\"\">14</a>]</cite>. Notably, our approach achieves its best performance in its 16-codebook, 50 Hz frame rate (FR) configuration, outperforming all competing baseline methods.\nFurthermore, our model achieves a high compression ratio of 170x on 24 kHz audio when configured with 8 codebooks at a 25 Hz frame rate.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">High-fidelity neural audio codecs in Text-to-speech (TTS) aim to compress speech signals into discrete representations for faithful reconstruction. However, prior approaches faced challenges in effectively disentangling acoustic and semantic information within tokens, leading to a lack of fine-grained details in synthesized speech. In this study, we propose MBCodec, a novel multi-codebook audio codec based on Residual Vector Quantization (RVQ) that learns a hierarchically structured representation. MBCodec leverages self-supervised semantic tokenization and audio subband features from the raw signals to construct a functionally-disentangled latent space. In order to encourage comprehensive learning across various layers of the codec embedding space, we introduce adaptive dropout depths to differentially train codebooks across layers, and employ a multi-channel pseudo-quadrature mirror filter (PQMF) during training. By thoroughly decoupling semantic and acoustic features, our method not only achieves near-lossless speech reconstruction but also enables a remarkable 170x compression of 24 kHz audio, resulting in a low bit rate of just 2.2 kbps. Experimental evaluations confirm its consistent and substantial outperformance of baselines across all evaluations.</p>\n\n",
                "matched_terms": [
                    "codecs",
                    "mbcodec"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Furthermore, MBCodec is trained with an adaptive dropout depths mechanism that dynamically adjusts the number of chosen codebooks, thereby enabling flexible bitrate selection and improving training efficiency. Experimental results demonstrate that MBCodec can reconstruct high fidelity audio at various frame rates with an ultra-high compression ratio that allows it to compress 24KHz audio to an ultra-low bitrate of 2.2kbps. And it also achieves superior performance over baselines in evaluations.</p>\n\n",
                "matched_terms": [
                    "24khz",
                    "mbcodec"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"\\mathbf{A}_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p4.m1\" intent=\":literal\"><semantics><msub><mi>&#119808;</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">\\mathbf{A}_{1}</annotation></semantics></math> and <math alttext=\"\\mathbf{A}_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p4.m2\" intent=\":literal\"><semantics><msub><mi>&#119808;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\mathbf{A}_{2}</annotation></semantics></math> denote the projection matrices that map the subbands and codebook representations to a common dimension. The superscript <math alttext=\"(:,d)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p4.m3\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><mo rspace=\"0em\">:</mo><mo>,</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(:,d)</annotation></semantics></math> denotes the vector for the <math alttext=\"d\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p4.m4\" intent=\":literal\"><semantics><mi>d</mi><annotation encoding=\"application/x-tex\">d</annotation></semantics></math>-th dimension across all time steps. In this context, <math alttext=\"\\mathbf{Q}_{\\text{acous}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p4.m5\" intent=\":literal\"><semantics><msub><mi>&#119824;</mi><mtext>acous</mtext></msub><annotation encoding=\"application/x-tex\">\\mathbf{Q}_{\\text{acous}}</annotation></semantics></math> denotes the acoustic embedding yielded by the <math alttext=\"{n_{q}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p4.m6\" intent=\":literal\"><semantics><msub><mi>n</mi><mi>q</mi></msub><annotation encoding=\"application/x-tex\">{n_{q}}</annotation></semantics></math> quantizer, while <math alttext=\"\\mathbf{H}_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p4.m7\" intent=\":literal\"><semantics><msub><mi>&#119815;</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">\\mathbf{H}_{i}</annotation></semantics></math> represents its corresponding target, the <math alttext=\"i_{th}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p4.m8\" intent=\":literal\"><semantics><msub><mi>i</mi><mrow><mi>t</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>h</mi></mrow></msub><annotation encoding=\"application/x-tex\">i_{th}</annotation></semantics></math> frequency subband. The training objective of MBCodec is shown in Equation&#160;(<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#S2.E5\" title=\"In 2.3 Training object &#8227; 2 MBCodec &#8227; MBCodec: Thorough Disentanglement for High-Fidelity Audio Compression\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>):</p>\n\n",
                "matched_terms": [
                    "objective",
                    "mbcodec"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We benchmark MBCodec against a Descript Audio Codec (DAC)-style baseline <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib17\" title=\"\">17</a>]</cite>.\nWe implement and evaluate two variants of MBCodec with 8 and 16 codebooks respectively, and test each variant at frame rates of both 25 Hz and 50 Hz. Each codebook contains 2048 entries.\nOur base models are trained on approximately 95k hours of audio from the Emilia<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib18\" title=\"\">18</a>]</cite> multilingual speech dataset, which is uniformly resampled to 24 kHz. We evaluate the speech reconstruction performance of our models on the test set of AudioSet&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib19\" title=\"\">19</a>]</cite>, following the experimental protocol of DAC.</p>\n\n",
                "matched_terms": [
                    "baseline",
                    "dac",
                    "mbcodec"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our model implementation is detailed as follows. Our model, featuring a 64-dim encoder and a 1536-dim decoder, is trained for two days on a single NVIDIA H20 GPU. During training, we use the snake activation function and a constant learning rate of <math alttext=\"1\\times 10^{-4}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><mn>1</mn><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>4</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">1\\times 10^{-4}</annotation></semantics></math>. All loss components are equally weighted, and other hyperparameters follow the DAC baseline. For the non-uniform sampling distributions, we use empirically validated parameters, which are detailed in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#S3.T2\" title=\"Table 2 &#8227; 3.2 Evaluation on reconstruction signal &#8227; 3 experiment &#8227; MBCodec: Thorough Disentanglement for High-Fidelity Audio Compression\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. These include the base for exponential decay, sigma for the half-Gaussian, and the degrees of freedom for Chi-squared.</p>\n\n",
                "matched_terms": [
                    "baseline",
                    "dac"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Within our MBCodec variants, models with fewer codebooks (N) consistently yield poorer performance metrics. However, at comparable bitrates, increasing N from 8 to 16 substantially boosts key metrics like PESQ and STFT, demonstrating that a larger codebook size is beneficial for improving audio reconstruction.\nUnder the same training and experimental settings, we evaluate various adaptive dropout strategies, as shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#S3.T2\" title=\"Table 2 &#8227; 3.2 Evaluation on reconstruction signal &#8227; 3 experiment &#8227; MBCodec: Thorough Disentanglement for High-Fidelity Audio Compression\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. The Half-Gaussian distribution proved to be the most effective, enabling the model to achieve superior reconstruction.</p>\n\n",
                "matched_terms": [
                    "stft",
                    "metrics",
                    "pesq",
                    "mbcodec"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">A common bottleneck for neural audio codecs is the challenge of high-frequency reconstruction. As illustrated in Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#S3.F2\" title=\"Figure 2 &#8227; 3.3 Visual analysis &#8227; 3 experiment &#8227; MBCodec: Thorough Disentanglement for High-Fidelity Audio Compression\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, DAC&#8217;s reconstruction in the mid-high band (2-6 kHz) is noticeably diffuse and lacks spectral definition. This degradation intensifies in the high-frequency region (6-9 kHz), where the output collapses into unstructured noise.\nIn sharp contrast, MBCodec maintains high fidelity across the spectrum, faithfully restoring the original signal&#8217;s spectral structure. This confirms MBCodec&#8217;s ability to preserve essential harmonics while avoiding the high-frequency artifacts that cause audible distortion.</p>\n\n",
                "matched_terms": [
                    "codecs",
                    "mbcodec"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We conduct an ablation study to investigate the contribution of each key component to the final performance. As shown in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#S3.T3\" title=\"Table 3 &#8227; 3.4 Ablation study &#8227; 3 experiment &#8227; MBCodec: Thorough Disentanglement for High-Fidelity Audio Compression\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, removing the PQMF supervision module leads to a significant degradation in PESQ and Mel-spectrogram distance, which measure subjective audio quality and spectral feature similarity. Furthermore, excluding the adaptive dropout function impacts the SI-SDR and STFT metrics, which measure fine-grained frequency changes and high-frequency information. Therefore, both components are indispensable for achieving high-fidelity speech reconstruction.</p>\n\n",
                "matched_terms": [
                    "sisdr",
                    "metrics",
                    "pesq",
                    "stft"
                ]
            }
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Reconstruction quality under different adaptive dropout distributions.",
        "body": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\">Chi-squared</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\">(df=4)</td>\n</tr>\n</table>\n",
        "informative_terms_identified": [
            "distributions",
            "reconstruction",
            "chisquared",
            "under",
            "df4",
            "dropout",
            "different",
            "adaptive",
            "quality"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Our model implementation is detailed as follows. Our model, featuring a 64-dim encoder and a 1536-dim decoder, is trained for two days on a single NVIDIA H20 GPU. During training, we use the snake activation function and a constant learning rate of <math alttext=\"1\\times 10^{-4}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><mn>1</mn><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>4</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">1\\times 10^{-4}</annotation></semantics></math>. All loss components are equally weighted, and other hyperparameters follow the DAC baseline. For the non-uniform sampling distributions, we use empirically validated parameters, which are detailed in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#S3.T2\" title=\"Table 2 &#8227; 3.2 Evaluation on reconstruction signal &#8227; 3 experiment &#8227; MBCodec: Thorough Disentanglement for High-Fidelity Audio Compression\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. These include the base for exponential decay, sigma for the half-Gaussian, and the degrees of freedom for Chi-squared.</p>\n\n",
            "<p class=\"ltx_p\">Within our MBCodec variants, models with fewer codebooks (N) consistently yield poorer performance metrics. However, at comparable bitrates, increasing N from 8 to 16 substantially boosts key metrics like PESQ and STFT, demonstrating that a larger codebook size is beneficial for improving audio reconstruction.\nUnder the same training and experimental settings, we evaluate various adaptive dropout strategies, as shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#S3.T2\" title=\"Table 2 &#8227; 3.2 Evaluation on reconstruction signal &#8227; 3 experiment &#8227; MBCodec: Thorough Disentanglement for High-Fidelity Audio Compression\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. The Half-Gaussian distribution proved to be the most effective, enabling the model to achieve superior reconstruction.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">High-fidelity neural audio codecs in Text-to-speech (TTS) aim to compress speech signals into discrete representations for faithful reconstruction. However, prior approaches faced challenges in effectively disentangling acoustic and semantic information within tokens, leading to a lack of fine-grained details in synthesized speech. In this study, we propose MBCodec, a novel multi-codebook audio codec based on Residual Vector Quantization (RVQ) that learns a hierarchically structured representation. MBCodec leverages self-supervised semantic tokenization and audio subband features from the raw signals to construct a functionally-disentangled latent space. In order to encourage comprehensive learning across various layers of the codec embedding space, we introduce adaptive dropout depths to differentially train codebooks across layers, and employ a multi-channel pseudo-quadrature mirror filter (PQMF) during training. By thoroughly decoupling semantic and acoustic features, our method not only achieves near-lossless speech reconstruction but also enables a remarkable 170x compression of 24 kHz audio, resulting in a low bit rate of just 2.2 kbps. Experimental evaluations confirm its consistent and substantial outperformance of baselines across all evaluations.</p>\n\n",
                "matched_terms": [
                    "dropout",
                    "reconstruction",
                    "adaptive"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Neural audio codecs have consistently attracted significant research attention, universally featuring an encoder-quantizer-decoder framework. High-quality discrete audio codecs are crucial for effectively decomposing speech into distinct subspaces like content, timbre, and prosody<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib2\" title=\"\">2</a>]</cite>. As the quantizer represents the most critical part of improving codec performance, recent studies have introduced various quantizers, including RVQ<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib3\" title=\"\">3</a>]</cite>, GVQ<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib4\" title=\"\">4</a>]</cite>, and GRVQ<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib5\" title=\"\">5</a>]</cite>. However, a key limitation is the lack of effective disentanglement<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib6\" title=\"\">6</a>]</cite> of different speech attributes into distinct representations, which can degrade the overall audio signal quality.</p>\n\n",
                "matched_terms": [
                    "different",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">However, prior work<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib12\" title=\"\">12</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib13\" title=\"\">13</a>]</cite> on multiple codebook architectures has not adequately addressed a key challenge: the effective disentanglement of semantic and acoustic information from the input signals. This is a critical area of research for enhancing the codec&#8217;s compression efficiency and reconstruction quality. Secondly, codec training efficiency is constrained by codebook quantity and size, underscoring the need for advancements in training paradigms. Most importantly, the poor interpretability of the individual codebooks in previous codec work led to inefficient model iteration.</p>\n\n",
                "matched_terms": [
                    "reconstruction",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Furthermore, MBCodec is trained with an adaptive dropout depths mechanism that dynamically adjusts the number of chosen codebooks, thereby enabling flexible bitrate selection and improving training efficiency. Experimental results demonstrate that MBCodec can reconstruct high fidelity audio at various frame rates with an ultra-high compression ratio that allows it to compress 24KHz audio to an ultra-low bitrate of 2.2kbps. And it also achieves superior performance over baselines in evaluations.</p>\n\n",
                "matched_terms": [
                    "dropout",
                    "adaptive"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The fidelity of speech reconstruction hinges on the successful recovery of both semantic and acoustic information from the original waveform. This requirement is particularly challenging given that acoustic information is not spectrally uniform, but is heterogeneously distributed across different frequency bands. The low-to-mid frequencies contain the bulk of energy and core intelligibility cues (e.g., fundamental frequency, vocalic formants), while high frequencies encode finer phonetic details like fricatives and sibilants.</p>\n\n",
                "matched_terms": [
                    "different",
                    "reconstruction"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To simultaneously boost computational efficiency and encourage robust information disentanglement, MBCodec employs an adaptive dropout strategy. Unlike prior work&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib10\" title=\"\">10</a>]</cite>, which employs a uniform quantizer dropout strategy by randomly sampling the number of active layers <math alttext=\"n_{q}\\in[1,N_{q}]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m1\" intent=\":literal\"><semantics><mrow><msub><mi>n</mi><mi>q</mi></msub><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mn>1</mn><mo>,</mo><msub><mi>N</mi><mi>q</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">n_{q}\\in[1,N_{q}]</annotation></semantics></math>, our approach recognizes a mismatch in this design. The nature of RVQ dictates that residual information diminishes with each successive layer. Consequently, later RVQ stages contribute only minor additional information, making this uniform sampling approach suboptimal.</p>\n\n",
                "matched_terms": [
                    "dropout",
                    "adaptive"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address this mismatch, we propose a non-uniform sampling mechanism that better aligns with the hierarchical nature of RVQ. Specifically, we evaluated three candidate distributions: an exponential decay, which strongly prefers leading layers to focus on the most critical information; a half-Gaussian distribution, providing a gentler initial decay rate that balances information from all layers; and a Chi-squared (<math alttext=\"\\chi^{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p2.m1\" intent=\":literal\"><semantics><msup><mi>&#967;</mi><mn>2</mn></msup><annotation encoding=\"application/x-tex\">\\chi^{2}</annotation></semantics></math>), a non-monotonic sampling strategy that avoids over-relying on the leading VQ layers.\nThis systematic approach is crucial for understanding the impact of various sampling policies on model training and performance.</p>\n\n",
                "matched_terms": [
                    "distributions",
                    "chisquared"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We conduct an ablation study to investigate the contribution of each key component to the final performance. As shown in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#S3.T3\" title=\"Table 3 &#8227; 3.4 Ablation study &#8227; 3 experiment &#8227; MBCodec: Thorough Disentanglement for High-Fidelity Audio Compression\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, removing the PQMF supervision module leads to a significant degradation in PESQ and Mel-spectrogram distance, which measure subjective audio quality and spectral feature similarity. Furthermore, excluding the adaptive dropout function impacts the SI-SDR and STFT metrics, which measure fine-grained frequency changes and high-frequency information. Therefore, both components are indispensable for achieving high-fidelity speech reconstruction.</p>\n\n",
                "matched_terms": [
                    "dropout",
                    "reconstruction",
                    "adaptive",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We introduce MBCodec, a novel audio codec employing multiple codebooks to explicitly disentangle semantic and acoustic information. This disentangled latent space simultaneously improves compression efficiency for higher-fidelity reconstruction at the same bitrate and enhances model interpretability. To further enhance performance, MBCodec introduces an adaptive dropout mechanism specifically designed to improve reconstruction quality in low bitrate scenarios.\nAs evidenced by our experimental results, MBCodec not only faithfully preserves the foundational harmonics but also maintains the resolution of high-frequency details essential for perceptual richness. This robust performance ensures nearly lossless reconstruction quality at extremely low bitrates. Additionally, this thorough disentanglement of semantic and acoustic information paves the way for flexible downstream applications like speech synthesis.\n</p>\n\n",
                "matched_terms": [
                    "dropout",
                    "reconstruction",
                    "adaptive",
                    "quality"
                ]
            }
        ]
    },
    "S3.T3": {
        "caption": "Table 3: Results of ablation study.",
        "body": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\">w/o adaptive</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_left\">dropout</td>\n</tr>\n</table>\n",
        "informative_terms_identified": [
            "study",
            "ablation",
            "results",
            "dropout",
            "adaptive"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">We conduct an ablation study to investigate the contribution of each key component to the final performance. As shown in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#S3.T3\" title=\"Table 3 &#8227; 3.4 Ablation study &#8227; 3 experiment &#8227; MBCodec: Thorough Disentanglement for High-Fidelity Audio Compression\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, removing the PQMF supervision module leads to a significant degradation in PESQ and Mel-spectrogram distance, which measure subjective audio quality and spectral feature similarity. Furthermore, excluding the adaptive dropout function impacts the SI-SDR and STFT metrics, which measure fine-grained frequency changes and high-frequency information. Therefore, both components are indispensable for achieving high-fidelity speech reconstruction.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">High-fidelity neural audio codecs in Text-to-speech (TTS) aim to compress speech signals into discrete representations for faithful reconstruction. However, prior approaches faced challenges in effectively disentangling acoustic and semantic information within tokens, leading to a lack of fine-grained details in synthesized speech. In this study, we propose MBCodec, a novel multi-codebook audio codec based on Residual Vector Quantization (RVQ) that learns a hierarchically structured representation. MBCodec leverages self-supervised semantic tokenization and audio subband features from the raw signals to construct a functionally-disentangled latent space. In order to encourage comprehensive learning across various layers of the codec embedding space, we introduce adaptive dropout depths to differentially train codebooks across layers, and employ a multi-channel pseudo-quadrature mirror filter (PQMF) during training. By thoroughly decoupling semantic and acoustic features, our method not only achieves near-lossless speech reconstruction but also enables a remarkable 170x compression of 24 kHz audio, resulting in a low bit rate of just 2.2 kbps. Experimental evaluations confirm its consistent and substantial outperformance of baselines across all evaluations.</p>\n\n",
                "matched_terms": [
                    "study",
                    "dropout",
                    "adaptive"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Furthermore, MBCodec is trained with an adaptive dropout depths mechanism that dynamically adjusts the number of chosen codebooks, thereby enabling flexible bitrate selection and improving training efficiency. Experimental results demonstrate that MBCodec can reconstruct high fidelity audio at various frame rates with an ultra-high compression ratio that allows it to compress 24KHz audio to an ultra-low bitrate of 2.2kbps. And it also achieves superior performance over baselines in evaluations.</p>\n\n",
                "matched_terms": [
                    "dropout",
                    "results",
                    "adaptive"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To simultaneously boost computational efficiency and encourage robust information disentanglement, MBCodec employs an adaptive dropout strategy. Unlike prior work&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#bib.bib10\" title=\"\">10</a>]</cite>, which employs a uniform quantizer dropout strategy by randomly sampling the number of active layers <math alttext=\"n_{q}\\in[1,N_{q}]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m1\" intent=\":literal\"><semantics><mrow><msub><mi>n</mi><mi>q</mi></msub><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mn>1</mn><mo>,</mo><msub><mi>N</mi><mi>q</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">n_{q}\\in[1,N_{q}]</annotation></semantics></math>, our approach recognizes a mismatch in this design. The nature of RVQ dictates that residual information diminishes with each successive layer. Consequently, later RVQ stages contribute only minor additional information, making this uniform sampling approach suboptimal.</p>\n\n",
                "matched_terms": [
                    "dropout",
                    "adaptive"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Within our MBCodec variants, models with fewer codebooks (N) consistently yield poorer performance metrics. However, at comparable bitrates, increasing N from 8 to 16 substantially boosts key metrics like PESQ and STFT, demonstrating that a larger codebook size is beneficial for improving audio reconstruction.\nUnder the same training and experimental settings, we evaluate various adaptive dropout strategies, as shown in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17006v1#S3.T2\" title=\"Table 2 &#8227; 3.2 Evaluation on reconstruction signal &#8227; 3 experiment &#8227; MBCodec: Thorough Disentanglement for High-Fidelity Audio Compression\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. The Half-Gaussian distribution proved to be the most effective, enabling the model to achieve superior reconstruction.</p>\n\n",
                "matched_terms": [
                    "dropout",
                    "adaptive"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We introduce MBCodec, a novel audio codec employing multiple codebooks to explicitly disentangle semantic and acoustic information. This disentangled latent space simultaneously improves compression efficiency for higher-fidelity reconstruction at the same bitrate and enhances model interpretability. To further enhance performance, MBCodec introduces an adaptive dropout mechanism specifically designed to improve reconstruction quality in low bitrate scenarios.\nAs evidenced by our experimental results, MBCodec not only faithfully preserves the foundational harmonics but also maintains the resolution of high-frequency details essential for perceptual richness. This robust performance ensures nearly lossless reconstruction quality at extremely low bitrates. Additionally, this thorough disentanglement of semantic and acoustic information paves the way for flexible downstream applications like speech synthesis.\n</p>\n\n",
                "matched_terms": [
                    "dropout",
                    "results",
                    "adaptive"
                ]
            }
        ]
    }
}