{
    "S3.T1": {
        "caption": "Table 1: Statistics of datasets used in our study, including the number of heterogeneous styles, speakers, and the train/val/test splits for both neutral and expressive subsets.",
        "body": "<table class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Styles</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Speakers</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Data Type</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Train</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Val</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Test</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">ESD</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">20</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Neutral</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">5,600</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">700</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">700</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Expressive</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">22,400</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2,800</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2,800</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">EmoV-DB</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">4</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Neutral</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1,254</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">156</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">158</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Expressive</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">4,260</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">532</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">533</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">RAVDESS</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">24</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Neutral</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">230</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">28</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">30</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Expressive</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">921</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">115</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">116</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">CREMA-D</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">12</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Neutral</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">869</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">108</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">110</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Expressive</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">4,355</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">544</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">545</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "type",
            "subsets",
            "cremad",
            "our",
            "study",
            "heterogeneous",
            "statistics",
            "val",
            "splits",
            "speakers",
            "test",
            "used",
            "emovdb",
            "ravdess",
            "styles",
            "expressive",
            "esd",
            "trainvaltest",
            "both",
            "number",
            "datasets",
            "train",
            "including",
            "neutral",
            "data",
            "dataset"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We used four publicly available datasets with emotion annotations.\nTo ensure style consistency across these diverse corpora, we first pooled all datasets and then employed the emotion2vec&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib18\" title=\"\">18</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> framework to map the various emotion labels into a unified, discrete style space. This unification process resulted in a total of 10 distinct style categories for the entire experimental setup.\nBased on the original annotations, the data were also grouped into two broader categories: neutral and expressive, with details of the source datasets shown in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#S3.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 3.1.1 Datasets &#8227; 3.1 Setup &#8227; 3 Experiments &#8227; Fed-PISA: Federated Voice Cloning via Personalized Identity-Style Adaptation\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThe ground truth text data of the dataset is annotated by Whisper-large-v3 Turbo&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and has been manually corrected.</span>\n</p>\n\n",
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Evaluation is conducted on the test split of each dataset (see Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#S3.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 3.1.1 Datasets &#8227; 3.1 Setup &#8227; 3 Experiments &#8227; Fed-PISA: Federated Voice Cloning via Personalized Identity-Style Adaptation\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">), comprising both neutral and expressive samples. Reported scores reflect the mean performance across all datasets.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Voice cloning for Text-to-Speech (TTS) aims to generate expressive and personalized speech from text using limited data from a target speaker. Federated Learning (FL) offers a collaborative and privacy-preserving framework for this task, but existing approaches suffer from high communication costs and tend to suppress <em class=\"ltx_emph ltx_font_italic\">stylistic heterogeneity</em>, resulting in insufficient personalization. To address these issues, we propose Fed-PISA, which stands for <span class=\"ltx_text ltx_font_bold\">Fed</span>erated <span class=\"ltx_text ltx_font_bold\">P</span>ersonalized <span class=\"ltx_text ltx_font_bold\">I</span>dentity-<span class=\"ltx_text ltx_font_bold\">S</span>tyle <span class=\"ltx_text ltx_font_bold\">A</span>daptation. To minimize communication costs, Fed-PISA introduces a disentangled Low-Rank Adaptation (LoRA) mechanism: the speaker&#8217;s timbre is retained locally through a private ID-LoRA, while only a lightweight style-LoRA is transmitted to the server, thereby minimizing parameter exchange. To harness heterogeneity, our aggregation method, inspired by collaborative filtering, is introduced to create custom models for each client by learning from stylistically similar peers. Experiments show that Fed-PISA improves style expressivity, naturalness, and speaker similarity, outperforming standard federated baselines with minimal communication costs.</span>\n</p>\n\n",
                "matched_terms": [
                    "data",
                    "expressive",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Under such circumstances, Federated Learning (FL)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib11\" title=\"\">11</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> offers a privacy-preserving approach that allows multiple clients to collaboratively train a model while keeping their private data on local devices. Existing FL-based TTS frameworks, such as FedSpeech&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Federated Dynamic Transformer&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib13\" title=\"\">13</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, primarily focus on backbone modification or partitioning to balance speaker-specific personalization with shared global knowledge. Nevertheless, training personalized TTS systems in this manner faces two key challenges. First, these methods often incur substantial computational and communication costs due to complex backbone modifications or large-scale parameter exchanges, hindering their deployment on resource-constrained edge devices. Second, they suppress the severe </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">stylistic heterogeneity</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> exhibited in speech data distribution (e.g., variations in emotion, prosody) to preserve individual speaker timbre. FedSpeech isolates style features locally by parameter masking, while Federated Dynamic Transformer retains personalized layers that capture styles locally, aggregating only the general model. Such suppression limits the model from effectively learn diverse and expressive styles across heterogeneous client data, leading to insufficient model personalization capabilities. This motivates the exploration:\n</span>\n  <em class=\"ltx_emph ltx_font_bold ltx_font_italic\" style=\"font-size:90%;\">Can a federated TTS system effectively learn and utilize heterogeneous styles across clients while maintaining low communication costs?</em>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"/>\n</p>\n\n",
                "matched_terms": [
                    "train",
                    "heterogeneous",
                    "expressive",
                    "styles",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Stylization.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> Given expressive speech samples </span>\n  <math alttext=\"(x,y)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n        <mi mathsize=\"0.900em\">x</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">y</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">(x,y)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> from a client&#8217;s dataset, we perform teacher-forced decoding using the backbone and optimize only the style adapter </span>\n  <math alttext=\"W_{\\mathrm{style}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p3.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">style</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{style}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> via a token-level cross-entropy loss. To ensure modularity, gradients to the ID-LoRA </span>\n  <math alttext=\"W_{\\mathrm{ID}}^{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p3.m3\" intent=\":literal\">\n    <semantics>\n      <msubsup>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">ID</mi>\n        <mi mathsize=\"0.900em\">i</mi>\n      </msubsup>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{ID}}^{i}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> are blocked, isolating style learning from speaker timbre. During training, we enforce a consistent emotional style within each batch of expressive data from the same client.</span>\n</p>\n\n",
                "matched_terms": [
                    "dataset",
                    "data",
                    "expressive"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">As a non-federated reference, we first include a zero-shot in-context learning (ICL) baseline using </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">CosyVoice2</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib1\" title=\"\">1</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">GPT-SoVITS-v4</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We also consider a fully local finetuning baseline (Local FT), where each client independently trains both ID-LoRA and Style-LoRA using private neutral and expressive data without federated sharing. To compare with existing federated learning paradigms, we include three additional baselines. FedSpeech&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> applies selective masking to retain client-specific prosodic features, while Federated Dynamic Transformer (Fed Dy. Trans.)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib13\" title=\"\">13</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> incrementally expands encoder and decoder layers.\nIt is important to note that these established federated methods are </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">intrinsically coupled with their specific backbone architectures</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (i.e., FastSpeech2&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib20\" title=\"\">20</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Transformer-TTS&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib21\" title=\"\">21</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, respectively) and are </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">not directly compatible with LoRA techniques</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Therefore, for a fair evaluation of these methods, we adopted their original, published configurations.</span>\n</p>\n\n",
                "matched_terms": [
                    "neutral",
                    "data",
                    "both",
                    "expressive"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The federated simulation comprises 60 clients, where each speaker from the datasets is treated as an independent client.\nThe entire training process spans 50 communication rounds, with a client participation rate of 20% per round.\nFor both the private ID-LoRA and the federated Style-LoRA, we set the rank to 8 and the scaling factor to </span>\n  <math alttext=\"16\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">16</mn>\n      <annotation encoding=\"application/x-tex\">16</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nLocal adaptation is performed using the AdamW optimizer with a batch size of </span>\n  <math alttext=\"16\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">16</mn>\n      <annotation encoding=\"application/x-tex\">16</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We employ a learning rate of </span>\n  <math alttext=\"2\\times 10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">2</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">5</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">2\\times 10^{-5}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with a cosine decay schedule and a warmup ratio of </span>\n  <math alttext=\"0.1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">0.1</mn>\n      <annotation encoding=\"application/x-tex\">0.1</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. For main experiments on each client, the timbre cloning phase runs for </span>\n  <math alttext=\"80\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">80</mn>\n      <annotation encoding=\"application/x-tex\">80</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> steps, followed by the stylization phase, which runs for </span>\n  <math alttext=\"20\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m6\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">20</mn>\n      <annotation encoding=\"application/x-tex\">20</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> steps. Experiments were conducted on four NVIDIA V100 GPUs.</span>\n</p>\n\n",
                "matched_terms": [
                    "datasets",
                    "both"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Comparison with Foundation and Local Baselines.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nAs presented in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3.2 Main Results &#8227; 3 Experiments &#8227; Fed-PISA: Federated Voice Cloning via Personalized Identity-Style Adaptation\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, compared to zero-shot voice cloning, </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> shows a dramatic improvement. This highlights the necessity of fine-tuning for high-fidelity personalization. More critically, </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> surpasses the Local FT (LoRA) baseline, where each client trains independently. Our collaborative approach achieves a higher SS score, which proves that </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#8217;s collaborative learning paradigm allows clients to learn richer stylistic variations from their peers, overcoming the data scarcity limitations of purely local fine-tuning.</span>\n</p>\n\n",
                "matched_terms": [
                    "data",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Identity-Style Disentanglement:</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> The ablation results confirm the necessity of our identity-style disentanglement, as removing either the private ID-LoRA or the collaborative Style-LoRA leads to a significant degradation in speaker similarity and naturalness. This is because a single adapter struggles to reconcile the competing objectives of preserving a private, static identity and learning from diverse, shared styles, whereas our disentangled design allows both goals to be optimized without mutual interference.</span>\n</p>\n\n",
                "matched_terms": [
                    "both",
                    "styles",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Personalized Aggregation:</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> The comparison with FedAvg&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib17\" title=\"\">17</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is most telling, as it is conducted under an identical backbone and LoRA setup, providing a perfectly controlled ablation of our aggregation strategy. It demonstrates that a naive aggregation of style updates leads to a &#8220;style-averaging&#8221; effect that harms both speaker identity and expressive quality. In contrast, our attention-based personalized aggregation successfully leverages stylistic similarities between clients with </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">heterogeneous styles</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "heterogeneous",
                    "expressive",
                    "styles",
                    "both",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We analyzed the trade-off between timbre cloning (</span>\n  <math alttext=\"n\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">n</mi>\n      <annotation encoding=\"application/x-tex\">n</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> steps) and stylization (</span>\n  <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">m</mi>\n      <annotation encoding=\"application/x-tex\">m</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> steps) on the held-out validation by varying their allocation while keeping the total steps constant at 100. We found that speaker similarity (SS) monotonically decreased with increasing stylization, while naturalness peaked at a 20% allocation (</span>\n  <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">m</mi>\n      <annotation encoding=\"application/x-tex\">m</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> = 20). Excessive stylization corrupted speaker identity and degraded naturalness. This validates our choice of </span>\n  <math alttext=\"n=80\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">n</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">80</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">n=80</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"m=20\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">m</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">20</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">m=20</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which strikes an optimal balance without consulting the test set.</span>\n</p>\n\n",
                "matched_terms": [
                    "test",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Compliance with Ethical Standards. This study was performed in line with the principles of the Declaration of Helsinki. Approval was granted by the Ethics Committee of the Institute of Computing Technology, Chinese Academy of Sciences (ICT, CAS). All participants in the blind listening tests (n = 22) provided informed consent; only anonymized ratings were collected. We additionally used open-access human-speech datasets (ESD, EmoV-DB, RAVDESS, CREMA-D) strictly in accordance with their licenses; no new recordings were collected from these corpora.</span>\n</p>\n\n",
                "matched_terms": [
                    "study",
                    "ravdess",
                    "emovdb",
                    "esd",
                    "used",
                    "cremad",
                    "datasets"
                ]
            }
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Main experimental results comparing Fed-PISA with baseline methods and ablation studies. The best and second-best results are bolded and underlined. Results are reported over 3 runs with different random seeds.",
        "body": "<table class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Backbone</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Efficiency</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Correctness</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Similarity</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Naturalness</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td\"/>\n<td class=\"ltx_td\"/>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Tuned/Total (B)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Round</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\">\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Cost (GiB)</span><span class=\"ltx_text\" style=\"font-size:90%;\"> </span><math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.m1\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SE</span><span class=\"ltx_text\" style=\"font-size:90%;\"> </span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.m2\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">WER</span><span class=\"ltx_text\" style=\"font-size:90%;\"> (%) </span><math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.m3\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SS</span><span class=\"ltx_text\" style=\"font-size:90%;\"> </span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.m4\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">\n<span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">nMOS</span><span class=\"ltx_text\" style=\"font-size:90%;\"> </span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.m5\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"9\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Zero-Shot</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Foundation (ICL)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">CosyVoice2</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0/0.50</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.659</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">7.20</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.619</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.84</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Foundation</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">GPT-SoVITS-v4</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0/0.41</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.605</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.18</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.464</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.39</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"9\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Local Personalization Baseline</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Local FT (Full)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">GPT-SoVITS-v4</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.41/0.41</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.618</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.12</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.554</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.40</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Local FT (LoRA)</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">GPT-SoVITS-v4</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.06/0.41</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.626</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.35</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.529</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.36</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"9\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Federated Baselines and Our Method</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">FedSpeech</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">FastSpeech2-XL</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.52/0.52</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">50</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">145.28</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.416</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">6.82</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.556</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.77</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Fed Dy. Trans.</span></td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Transformer-TTS</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.22/0.35</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">50</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">456.35</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.463</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">8.75</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.602</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.72</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">\n<span class=\"ltx_ERROR undefined\">\\rowcolor</span><span class=\"ltx_text\" style=\"font-size:90%;\">gray!20</span><span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA<span class=\"ltx_text ltx_font_upright\"> (Ours)</span></span>\n</td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">GPT-SoVITS-v4</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.04/0.41</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">50</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">45.8</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.704</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">2.70</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.645</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">4.08</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"9\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Ablation Studies</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">\n<span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span><span class=\"ltx_text\" style=\"font-size:90%;\"> w/o ID-LoRA</span>\n</td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">GPT-SoVITS-v4</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.02/0.41</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">50</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">45.8</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.624</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.02</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.507</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.68</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">\n<span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span><span class=\"ltx_text\" style=\"font-size:90%;\"> w/o Style-LoRA</span>\n</td>\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">GPT-SoVITS-v4</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.02/0.41</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">50</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">45.8</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.588</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.77</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.610</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.55</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">FedAvg</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">GPT-SoVITS-v4</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.04/0.41</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">50</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">45.8</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.476</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.60</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.523</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.80</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "full",
            "wer",
            "foundation",
            "baselines",
            "naturalness",
            "fastspeech2xl",
            "fedavg",
            "seeds",
            "stylelora",
            "idlora",
            "fedpisa",
            "↓downarrow",
            "fed",
            "experimental",
            "our",
            "similarity",
            "zeroshot",
            "round",
            "studies",
            "personalization",
            "rowcolorgray20fedpisa",
            "ablation",
            "reported",
            "runs",
            "efficiency",
            "methods",
            "icl",
            "cost",
            "gib",
            "lora",
            "transformertts",
            "over",
            "comparing",
            "backbone",
            "main",
            "cosyvoice2",
            "results",
            "underlined",
            "gptsovitsv4",
            "bolded",
            "nmos",
            "ours",
            "random",
            "↑uparrow",
            "secondbest",
            "local",
            "tunedtotal",
            "fedspeech",
            "best",
            "correctness",
            "trans",
            "method",
            "federated",
            "baseline",
            "different"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Comparison with Foundation and Local Baselines.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nAs presented in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3.2 Main Results &#8227; 3 Experiments &#8227; Fed-PISA: Federated Voice Cloning via Personalized Identity-Style Adaptation\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, compared to zero-shot voice cloning, </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> shows a dramatic improvement. This highlights the necessity of fine-tuning for high-fidelity personalization. More critically, </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> surpasses the Local FT (LoRA) baseline, where each client trains independently. Our collaborative approach achieves a higher SS score, which proves that </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#8217;s collaborative learning paradigm allows clients to learn richer stylistic variations from their peers, overcoming the data scarcity limitations of purely local fine-tuning.</span>\n</p>\n\n",
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Comparison with Federated Baselines.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\nExisting federated baselines exhibit even lower style expressivity than zero-shot voice cloning methods, suggesting that prior FL approaches tend to suppress the stylistic heterogeneity that </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> effectively preserves and leverages. In addition, </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> achieves substantially better performance in terms of WER, SS, and SpeechMOS. This highlights a key advantage of our paradigm: its flexibility and applicability to modern, more powerful foundation models. The results in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3.2 Main Results &#8227; 3 Experiments &#8227; Fed-PISA: Federated Voice Cloning via Personalized Identity-Style Adaptation\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrate that the Fed-PISA framework, by effectively leveraging such models via PEFT&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib8\" title=\"\">8</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib9\" title=\"\">9</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib10\" title=\"\">10</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, significantly outperforms these legacy federated systems.</span>\n</p>\n\n",
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Ablation studies (Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3.2 Main Results &#8227; 3 Experiments &#8227; Fed-PISA: Federated Voice Cloning via Personalized Identity-Style Adaptation\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) validate our key design choices.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Voice cloning for Text-to-Speech (TTS) aims to generate expressive and personalized speech from text using limited data from a target speaker. Federated Learning (FL) offers a collaborative and privacy-preserving framework for this task, but existing approaches suffer from high communication costs and tend to suppress <em class=\"ltx_emph ltx_font_italic\">stylistic heterogeneity</em>, resulting in insufficient personalization. To address these issues, we propose Fed-PISA, which stands for <span class=\"ltx_text ltx_font_bold\">Fed</span>erated <span class=\"ltx_text ltx_font_bold\">P</span>ersonalized <span class=\"ltx_text ltx_font_bold\">I</span>dentity-<span class=\"ltx_text ltx_font_bold\">S</span>tyle <span class=\"ltx_text ltx_font_bold\">A</span>daptation. To minimize communication costs, Fed-PISA introduces a disentangled Low-Rank Adaptation (LoRA) mechanism: the speaker&#8217;s timbre is retained locally through a private ID-LoRA, while only a lightweight style-LoRA is transmitted to the server, thereby minimizing parameter exchange. To harness heterogeneity, our aggregation method, inspired by collaborative filtering, is introduced to create custom models for each client by learning from stylistically similar peers. Experiments show that Fed-PISA improves style expressivity, naturalness, and speaker similarity, outperforming standard federated baselines with minimal communication costs.</span>\n</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "personalization",
                    "baselines",
                    "naturalness",
                    "stylelora",
                    "method",
                    "idlora",
                    "fedpisa",
                    "federated",
                    "lora",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Among these, two main directions have emerged: high-fidelity zero-shot personalization based on style vectors or large-scale corpus&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib4\" title=\"\">4</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib5\" title=\"\">5</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, along with lightweight on-device deployment via model pruning and Parameter-Efficient Fine-Tuning (PEFT)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib6\" title=\"\">6</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib7\" title=\"\">7</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib8\" title=\"\">8</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib9\" title=\"\">9</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib10\" title=\"\">10</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nDespite improvements in speaker similarity and efficiency, these methods share a fundamental limitation: the personalization process is isolated.\nThis isolation creates &#8220;style silos&#8221;, where a client&#8217;s model is constrained by their own limited data, unable to leverage the rich stylistic heterogeneity present across a wider community of peers.\nConsequently, there is an increasing need for collaborative style learning across different clients under strict preservation of the local data privacy.</span>\n</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "zeroshot",
                    "personalization",
                    "local",
                    "main",
                    "efficiency",
                    "methods",
                    "different"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Under such circumstances, Federated Learning (FL)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib11\" title=\"\">11</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> offers a privacy-preserving approach that allows multiple clients to collaboratively train a model while keeping their private data on local devices. Existing FL-based TTS frameworks, such as FedSpeech&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Federated Dynamic Transformer&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib13\" title=\"\">13</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, primarily focus on backbone modification or partitioning to balance speaker-specific personalization with shared global knowledge. Nevertheless, training personalized TTS systems in this manner faces two key challenges. First, these methods often incur substantial computational and communication costs due to complex backbone modifications or large-scale parameter exchanges, hindering their deployment on resource-constrained edge devices. Second, they suppress the severe </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">stylistic heterogeneity</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> exhibited in speech data distribution (e.g., variations in emotion, prosody) to preserve individual speaker timbre. FedSpeech isolates style features locally by parameter masking, while Federated Dynamic Transformer retains personalized layers that capture styles locally, aggregating only the general model. Such suppression limits the model from effectively learn diverse and expressive styles across heterogeneous client data, leading to insufficient model personalization capabilities. This motivates the exploration:\n</span>\n  <em class=\"ltx_emph ltx_font_bold ltx_font_italic\" style=\"font-size:90%;\">Can a federated TTS system effectively learn and utilize heterogeneous styles across clients while maintaining low communication costs?</em>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"/>\n</p>\n\n",
                "matched_terms": [
                    "personalization",
                    "backbone",
                    "local",
                    "fedspeech",
                    "methods",
                    "federated"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To tackle the aforementioned issues, we propose an efficient and personalized federated TTS framework, namely </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Fed</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">erated </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">P</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">ersonalized </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">I</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">dentity-</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">S</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">tyle </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">A</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">daptation&#160;(</span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">).\n</span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> builds upon the PEFT techniques, specifically inspired by recent studies that utilize Low-Rank Adaptation (LoRA) for single-client TTS personalization&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib8\" title=\"\">8</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib9\" title=\"\">9</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib10\" title=\"\">10</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib14\" title=\"\">14</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nIt adapts the LoRA to a more complex federated setting and consists of two key components:\n(i) To improve efficiency and preserve speaker timbre, a decoupled LoRA mechanism is introduced. A private ID-LoRA is trained for each client and locally frozen to capture their unique speaker timbre robustly. A lightweight Style-LoRA is used for communication on the server, effectively reducing costs. (ii) To leverage stylistic heterogeneity, we introduce a personalized aggregation strategy. Inspired by collaborative filtering in recommendation systems&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib15\" title=\"\">15</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, this strategy creates a custom-aggregated style model for each client by prioritizing updates from stylistically similar peers.</span>\n</p>\n\n",
                "matched_terms": [
                    "personalization",
                    "studies",
                    "efficiency",
                    "stylelora",
                    "idlora",
                    "fedpisa",
                    "federated",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our main contributions are threefold</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\">\n    <sup class=\"ltx_note_mark\">1</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>Codes and Audio samples are available at <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/spaces/sDuoluoluos/FedPISA-Demo\" title=\"\">https://huggingface.co/spaces/sDuoluoluos/FedPISA-Demo</a></span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\n:</span>\n</p>\n\n",
                "matched_terms": [
                    "main",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our work addresses a key challenge overlooked by prior federated TTS frameworks: tackling high communication costs and overcoming the suppression of </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">stylistic heterogeneity</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "federated",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We propose </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, an efficient framework that disentangles speaker timbre from collaborative style learning using LoRA and a novel personalized aggregation mechanism.</span>\n</p>\n\n",
                "matched_terms": [
                    "fedpisa",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Experiments on four public datasets demonstrate that </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> consistently improves style expressivity, speaker similarity, naturalness, and communication efficiency over federated and nonfederated baselines.</span>\n</p>\n\n",
                "matched_terms": [
                    "over",
                    "similarity",
                    "baselines",
                    "naturalness",
                    "efficiency",
                    "fedpisa",
                    "federated"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">LoRA Placement.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\n</span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">ID-LoRA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (</span>\n  <math alttext=\"W_{\\mathrm{ID}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p3.m1\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">ID</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{ID}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) is a private, client-specific . It captures speaker timbre and channel coloration, is fine-tuned locally once, and remains </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">permanently frozen&#8212;never uploaded or aggregated</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> to the server.\nIn contrast, </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Style-LoRA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (</span>\n  <math alttext=\"W_{\\mathrm{style}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p3.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">style</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{style}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) is a </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">federated, globally shared adapter</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> that modulates expressive variation and is updated collaboratively across clients.</span>\n</p>\n\n",
                "matched_terms": [
                    "idlora",
                    "federated",
                    "lora",
                    "stylelora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In the </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">GPT-SoVITS-v4</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> backbone, the Style-LoRA </span>\n  <math alttext=\"W_{\\mathrm{style}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p4.m1\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">style</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{style}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and the speaker-specific ID-LoRA </span>\n  <math alttext=\"W_{\\mathrm{ID}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p4.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">ID</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{ID}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> are injected into linear projection layers. Within the GPT component, LoRA adapters are applied to all self-attention projections (</span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">q</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">k</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">v</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">out</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) as well as the two feed-forward layers (i.e., the up- and down-projection in the MLP block). For the SoVITS component, LoRA is inserted into the attention projections (</span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">q</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">k</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">v</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, </span>\n  <span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">out</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) within each CFM block.</span>\n</p>\n\n",
                "matched_terms": [
                    "backbone",
                    "stylelora",
                    "idlora",
                    "gptsovitsv4",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Each selected client </span>\n  <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">i</mi>\n      <annotation encoding=\"application/x-tex\">i</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> loads the frozen backbone, its private ID-LoRA </span>\n  <math alttext=\"W_{\\mathrm{ID}}^{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <msubsup>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">ID</mi>\n        <mi mathsize=\"0.900em\">i</mi>\n      </msubsup>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{ID}}^{i}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and the current personalized Style-LoRA from the previous round, </span>\n  <math alttext=\"W_{\\mathrm{sty}}^{\\prime i,t-1}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <msubsup>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">sty</mi>\n        <mrow>\n          <mo mathsize=\"1.420em\">&#8242;</mo>\n          <mo lspace=\"0em\">&#8291;</mo>\n          <mrow>\n            <mi mathsize=\"0.900em\">i</mi>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mrow>\n              <mi mathsize=\"0.900em\">t</mi>\n              <mo mathsize=\"0.900em\">&#8722;</mo>\n              <mn mathsize=\"0.900em\">1</mn>\n            </mrow>\n          </mrow>\n        </mrow>\n      </msubsup>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{sty}}^{\\prime i,t-1}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (or a global model for the first round). Given a local batch </span>\n  <math alttext=\"(x,y)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n        <mi mathsize=\"0.900em\">x</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">y</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">(x,y)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we compute acoustic/semantic units </span>\n  <math alttext=\"u=E(y)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">u</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mrow>\n          <mi mathsize=\"0.900em\">E</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mrow>\n            <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n            <mi mathsize=\"0.900em\">y</mi>\n            <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n          </mrow>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">u=E(y)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "round",
                    "backbone",
                    "local",
                    "stylelora",
                    "idlora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Timbre Cloning.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> Using neutral speech samples </span>\n  <math alttext=\"(x,y)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p2.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n        <mi mathsize=\"0.900em\">x</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">y</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">(x,y)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> from the client, and with a frozen speaker encoder, we update only </span>\n  <math alttext=\"W_{\\mathrm{ID}}^{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p2.m2\" intent=\":literal\">\n    <semantics>\n      <msubsup>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">ID</mi>\n        <mi mathsize=\"0.900em\">i</mi>\n      </msubsup>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{ID}}^{i}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> to maximize the cosine similarity between speaker embeddings of the predicted and target waveforms. Gradients to the backbone and </span>\n  <math alttext=\"W_{\\mathrm{style}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p2.m3\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">style</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{style}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> are blocked to focus on timbre fidelity.</span>\n</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "backbone"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Stylization.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> Given expressive speech samples </span>\n  <math alttext=\"(x,y)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n        <mi mathsize=\"0.900em\">x</mi>\n        <mo mathsize=\"0.900em\">,</mo>\n        <mi mathsize=\"0.900em\">y</mi>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">(x,y)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> from a client&#8217;s dataset, we perform teacher-forced decoding using the backbone and optimize only the style adapter </span>\n  <math alttext=\"W_{\\mathrm{style}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p3.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">style</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{style}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> via a token-level cross-entropy loss. To ensure modularity, gradients to the ID-LoRA </span>\n  <math alttext=\"W_{\\mathrm{ID}}^{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p3.m3\" intent=\":literal\">\n    <semantics>\n      <msubsup>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">ID</mi>\n        <mi mathsize=\"0.900em\">i</mi>\n      </msubsup>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{ID}}^{i}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> are blocked, isolating style learning from speaker timbre. During training, we enforce a consistent emotional style within each batch of expressive data from the same client.</span>\n</p>\n\n",
                "matched_terms": [
                    "idlora",
                    "backbone"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Each client&#8217;s model is first trained locally for </span>\n  <math alttext=\"n\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p4.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">n</mi>\n      <annotation encoding=\"application/x-tex\">n</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> steps to perform timbre cloning, followed by </span>\n  <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p4.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">m</mi>\n      <annotation encoding=\"application/x-tex\">m</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> steps of stylization. After local adaptation, the client obtains an updated Style-LoRA </span>\n  <math alttext=\"W_{\\mathrm{sty}}^{i,t}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p4.m3\" intent=\":literal\">\n    <semantics>\n      <msubsup>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">sty</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n        </mrow>\n      </msubsup>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{sty}}^{i,t}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, composed of the LoRA matrices </span>\n  <math alttext=\"(A_{\\mathrm{style}}^{i,t},B_{\\mathrm{style}}^{i,t})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p4.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n        <msubsup>\n          <mi mathsize=\"0.900em\">A</mi>\n          <mi mathsize=\"0.900em\">style</mi>\n          <mrow>\n            <mi mathsize=\"0.900em\">i</mi>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mi mathsize=\"0.900em\">t</mi>\n          </mrow>\n        </msubsup>\n        <mo mathsize=\"0.900em\">,</mo>\n        <msubsup>\n          <mi mathsize=\"0.900em\">B</mi>\n          <mi mathsize=\"0.900em\">style</mi>\n          <mrow>\n            <mi mathsize=\"0.900em\">i</mi>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mi mathsize=\"0.900em\">t</mi>\n          </mrow>\n        </msubsup>\n        <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">(A_{\\mathrm{style}}^{i,t},B_{\\mathrm{style}}^{i,t})</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nOnly these style-specific parameters </span>\n  <math alttext=\"W_{\\mathrm{style}}^{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p4.m5\" intent=\":literal\">\n    <semantics>\n      <msubsup>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">style</mi>\n        <mi mathsize=\"0.900em\">i</mi>\n      </msubsup>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{style}}^{i}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in Figure&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Fed-PISA: Federated Voice Cloning via Personalized Identity-Style Adaptation\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> are transmitted to the server, while the ID-LoRA </span>\n  <math alttext=\"W_{\\mathrm{ID}}^{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p4.m6\" intent=\":literal\">\n    <semantics>\n      <msubsup>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mi mathsize=\"0.900em\">ID</mi>\n        <mi mathsize=\"0.900em\">i</mi>\n      </msubsup>\n      <annotation encoding=\"application/x-tex\">W_{\\mathrm{ID}}^{i}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> remains private and stored on-device.</span>\n</p>\n\n",
                "matched_terms": [
                    "idlora",
                    "lora",
                    "stylelora",
                    "local"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">At round </span>\n  <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">t</mi>\n      <annotation encoding=\"application/x-tex\">t</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, after receiving Style-LoRA updates (</span>\n  <math alttext=\"A_{\\mathrm{style}}^{j,t},B_{\\mathrm{style}}^{j,t}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <msubsup>\n          <mi mathsize=\"0.900em\">A</mi>\n          <mi mathsize=\"0.900em\">style</mi>\n          <mrow>\n            <mi mathsize=\"0.900em\">j</mi>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mi mathsize=\"0.900em\">t</mi>\n          </mrow>\n        </msubsup>\n        <mo mathsize=\"0.900em\">,</mo>\n        <msubsup>\n          <mi mathsize=\"0.900em\">B</mi>\n          <mi mathsize=\"0.900em\">style</mi>\n          <mrow>\n            <mi mathsize=\"0.900em\">j</mi>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mi mathsize=\"0.900em\">t</mi>\n          </mrow>\n        </msubsup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">A_{\\mathrm{style}}^{j,t},B_{\\mathrm{style}}^{j,t}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) from </span>\n  <math alttext=\"C\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">C</mi>\n      <annotation encoding=\"application/x-tex\">C</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> clients, the server builds a personalized model </span>\n  <math alttext=\"W_{style}^{\\prime i,t}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m4\" intent=\":literal\">\n    <semantics>\n      <msubsup>\n        <mi mathsize=\"0.900em\">W</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">s</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">t</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">y</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">l</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">e</mi>\n        </mrow>\n        <mrow>\n          <mo mathsize=\"1.420em\">&#8242;</mo>\n          <mo lspace=\"0em\">&#8291;</mo>\n          <mrow>\n            <mi mathsize=\"0.900em\">i</mi>\n            <mo mathsize=\"0.900em\">,</mo>\n            <mi mathsize=\"0.900em\">t</mi>\n          </mrow>\n        </mrow>\n      </msubsup>\n      <annotation encoding=\"application/x-tex\">W_{style}^{\\prime i,t}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> for each client </span>\n  <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m5\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">i</mi>\n      <annotation encoding=\"application/x-tex\">i</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. It computes attention scores by applying a softmax to the pairwise cosine similarity of the </span>\n  <math alttext=\"A\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m6\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">A</mi>\n      <annotation encoding=\"application/x-tex\">A</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"B\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m7\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">B</mi>\n      <annotation encoding=\"application/x-tex\">B</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> matrices scaled by temperature </span>\n  <math alttext=\"\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m8\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#964;</mi>\n      <annotation encoding=\"application/x-tex\">\\tau</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. For client </span>\n  <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m9\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">i</mi>\n      <annotation encoding=\"application/x-tex\">i</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, the scores </span>\n  <math alttext=\"\\alpha_{ij}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m10\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#945;</mi>\n        <mrow>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n          <mi mathsize=\"0.900em\">j</mi>\n        </mrow>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\alpha_{ij}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> are:</span>\n</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "round",
                    "stylelora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Inspired by prior work&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib16\" title=\"\">16</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> on temperature-scaled aggregation in federated learning, we set </span>\n  <math alttext=\"\\tau\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m11\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#964;</mi>\n      <annotation encoding=\"application/x-tex\">\\tau</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> to 0.5 to control the sharpness of the attention distribution over clients.</span>\n</p>\n\n",
                "matched_terms": [
                    "over",
                    "federated"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">As a non-federated reference, we first include a zero-shot in-context learning (ICL) baseline using </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">CosyVoice2</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib1\" title=\"\">1</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">GPT-SoVITS-v4</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We also consider a fully local finetuning baseline (Local FT), where each client independently trains both ID-LoRA and Style-LoRA using private neutral and expressive data without federated sharing. To compare with existing federated learning paradigms, we include three additional baselines. FedSpeech&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> applies selective masking to retain client-specific prosodic features, while Federated Dynamic Transformer (Fed Dy. Trans.)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib13\" title=\"\">13</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> incrementally expands encoder and decoder layers.\nIt is important to note that these established federated methods are </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">intrinsically coupled with their specific backbone architectures</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (i.e., FastSpeech2&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib20\" title=\"\">20</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Transformer-TTS&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib21\" title=\"\">21</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, respectively) and are </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">not directly compatible with LoRA techniques</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Therefore, for a fair evaluation of these methods, we adopted their original, published configurations.</span>\n</p>\n\n",
                "matched_terms": [
                    "zeroshot",
                    "backbone",
                    "local",
                    "icl",
                    "fedspeech",
                    "federated",
                    "baselines",
                    "cosyvoice2",
                    "trans",
                    "stylelora",
                    "methods",
                    "idlora",
                    "gptsovitsv4",
                    "fed",
                    "baseline",
                    "lora",
                    "transformertts"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The federated simulation comprises 60 clients, where each speaker from the datasets is treated as an independent client.\nThe entire training process spans 50 communication rounds, with a client participation rate of 20% per round.\nFor both the private ID-LoRA and the federated Style-LoRA, we set the rank to 8 and the scaling factor to </span>\n  <math alttext=\"16\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">16</mn>\n      <annotation encoding=\"application/x-tex\">16</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nLocal adaptation is performed using the AdamW optimizer with a batch size of </span>\n  <math alttext=\"16\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">16</mn>\n      <annotation encoding=\"application/x-tex\">16</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We employ a learning rate of </span>\n  <math alttext=\"2\\times 10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">2</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">5</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">2\\times 10^{-5}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with a cosine decay schedule and a warmup ratio of </span>\n  <math alttext=\"0.1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">0.1</mn>\n      <annotation encoding=\"application/x-tex\">0.1</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. For main experiments on each client, the timbre cloning phase runs for </span>\n  <math alttext=\"80\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">80</mn>\n      <annotation encoding=\"application/x-tex\">80</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> steps, followed by the stylization phase, which runs for </span>\n  <math alttext=\"20\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS3.p1.m6\" intent=\":literal\">\n    <semantics>\n      <mn mathsize=\"0.900em\">20</mn>\n      <annotation encoding=\"application/x-tex\">20</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> steps. Experiments were conducted on four NVIDIA V100 GPUs.</span>\n</p>\n\n",
                "matched_terms": [
                    "round",
                    "local",
                    "main",
                    "runs",
                    "stylelora",
                    "idlora",
                    "federated"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We evaluate the generated speech from three perspectives: correctness, speaker similarity, and naturalness. For correctness, we report Word Error Rate (WER) and Character Error Rate (CER), calculated by comparing the Whisper-large-v3 Turbo&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> transcription of the generated speech against the ground-truth text. Lower values indicate a more accurate and understandable synthesis.\nWe evaluate Style Expressivity (SE) by applying the emotion2vec&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib18\" title=\"\">18</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> classifier that is finetuned on the trainset to synthesized audio and use the predicted probability of the ground-truth emotion as the score, averaged over the test set. To assess speaker similarity (SS), we extract speaker embeddings using ECAPA-TDNN model &#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and compute the cosine similarity between synthesized and reference audio samples; higher similarity scores reflect better voice cloning fidelity. Finally, to estimate perceptual naturalness, we use the nMOS metric, with blind listening evaluations conducted by 22 researchers in the laboratory, and the final evaluation results are averaged. We report cost as the cumulative upload and download bandwidth over all rounds and participating clients, counting only the trainable parameters actually transmitted. Values assume FP16 (2 bytes per parameter) and are reported in GiB.</span>\n</p>\n\n",
                "matched_terms": [
                    "over",
                    "similarity",
                    "comparing",
                    "wer",
                    "naturalness",
                    "reported",
                    "correctness",
                    "results",
                    "cost",
                    "gib",
                    "nmos"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Efficiency Analysis.</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">\n</span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrates strong efficiency advantages. Owing to the use of LoRA, its trainable parameter count is approximately 1/5 that of Fed Dy. Trans. under comparable backbone sizes. In terms of communication cost, </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">Fed-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> incurs only 1/10 the costs of Fed Dy. Trans., and about 1/3 that of FedSpeech, despite the latter employing a masking mechanism to reduce transmission load.</span>\n</p>\n\n",
                "matched_terms": [
                    "backbone",
                    "fedspeech",
                    "cost",
                    "trans",
                    "efficiency",
                    "fedpisa",
                    "fed",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Identity-Style Disentanglement:</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> The ablation results confirm the necessity of our identity-style disentanglement, as removing either the private ID-LoRA or the collaborative Style-LoRA leads to a significant degradation in speaker similarity and naturalness. This is because a single adapter struggles to reconcile the competing objectives of preserving a private, static identity and learning from diverse, shared styles, whereas our disentangled design allows both goals to be optimized without mutual interference.</span>\n</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "ablation",
                    "naturalness",
                    "stylelora",
                    "results",
                    "idlora",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Personalized Aggregation:</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> The comparison with FedAvg&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.16010v1#bib.bib17\" title=\"\">17</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is most telling, as it is conducted under an identical backbone and LoRA setup, providing a perfectly controlled ablation of our aggregation strategy. It demonstrates that a naive aggregation of style updates leads to a &#8220;style-averaging&#8221; effect that harms both speaker identity and expressive quality. In contrast, our attention-based personalized aggregation successfully leverages stylistic similarities between clients with </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">heterogeneous styles</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "backbone",
                    "ablation",
                    "fedavg",
                    "lora",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We analyzed the trade-off between timbre cloning (</span>\n  <math alttext=\"n\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">n</mi>\n      <annotation encoding=\"application/x-tex\">n</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> steps) and stylization (</span>\n  <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">m</mi>\n      <annotation encoding=\"application/x-tex\">m</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> steps) on the held-out validation by varying their allocation while keeping the total steps constant at 100. We found that speaker similarity (SS) monotonically decreased with increasing stylization, while naturalness peaked at a 20% allocation (</span>\n  <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">m</mi>\n      <annotation encoding=\"application/x-tex\">m</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> = 20). Excessive stylization corrupted speaker identity and degraded naturalness. This validates our choice of </span>\n  <math alttext=\"n=80\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">n</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">80</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">n=80</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"m=20\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">m</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">20</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">m=20</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which strikes an optimal balance without consulting the test set.</span>\n</p>\n\n",
                "matched_terms": [
                    "naturalness",
                    "similarity",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We introduced </span>\n  <span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">FED-PISA</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> to address the central challenge in federated voice cloning: leveraging stylistic heterogeneity across clients without incurring high communication costs or degrading speaker identity. Our framework resolves this by disentangling a private ID-LoRA from a collaborative Style-LoRA and employing a personalized aggregation strategy. Experiments show significant improvements in style expressivity and speaker similarity over federated baselines.</span>\n</p>\n\n",
                "matched_terms": [
                    "over",
                    "similarity",
                    "baselines",
                    "stylelora",
                    "idlora",
                    "fedpisa",
                    "federated",
                    "our"
                ]
            }
        ]
    }
}