{
    "S3.T1": {
        "caption": "Table 1: Our adapted datasets, covering social-bias taxonomy and contents: stereotypes (Stereo), gender-occupation bias (Occup), and hate-toxicity (Hate/Tox). Empty cells: not covered; ✓: demographic target covered; ✥: involved in multi-axis targeted biases; gray cells: coverage after adaptations (Section 3.2).",
        "body": "<table class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_bold\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"10\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_bold\">Data Bias Taxonomy Coverage</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_bold\">Content</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_bold\">Samples</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_typewriter\">GEN</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_typewriter\">SO</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_typewriter\">DIS</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_typewriter\">AGE</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_typewriter\">RAC</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_typewriter\">NAT</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_typewriter\">REL</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_typewriter\">SES</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_typewriter\">PHY</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text ltx_font_typewriter\">UNB</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">BBQ&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Stereo</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">7843</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">BEC-Pro&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Bartl et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib2\" title=\"\">2020</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_rr ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Occup</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">2580</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">CrowS-pairs&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Nangia et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib39\" title=\"\">2020</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Stereo</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">1278</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">HateXplain&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_border_rr ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Hate/Tox</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">5437</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">ImplicitHate&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(ElSherief et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib11\" title=\"\">2021</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10003;</span></td>\n<td class=\"ltx_td ltx_border_rr ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Hate/Tox</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">2876</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">RedditBias&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Barikeri et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib1\" title=\"\">2021</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Stereo</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">9087</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">SBIC&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sap et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib47\" title=\"\">2020</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_rr ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Hate/Tox</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">5243</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">StereoSet&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Nadeem et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib38\" title=\"\">2021</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10003;</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_rr ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Stereo</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">1417</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">ToxiGen&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Hartvigsen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib20\" title=\"\">2022</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10021;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10021;</span></td>\n<td class=\"ltx_td ltx_border_rr ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Hate/Tox</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">2096</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">WinoBias&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Zhao et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib63\" title=\"\">2018</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_rr ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Occup</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">3168</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Winogender&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Rudinger et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib46\" title=\"\">2018</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_rr ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Occup</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">240</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Winoqueer&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Felkner et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib15\" title=\"\">2023</a>)</cite>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" style=\"--ltx-bg-color:#D9D9D9;padding-top:0.75pt;padding-bottom:0.75pt;\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#D9D9D9;\">&#10003;</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_border_b ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_b ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_b ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_b ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_b ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_b ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_border_b ltx_border_rr ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">&#10003;</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">Stereo</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.75pt;padding-bottom:0.75pt;\">5516</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "socialbias",
            "hatetox",
            "nadeem",
            "content",
            "winoqueer",
            "hatexplain",
            "rac",
            "sbic",
            "covered",
            "hartvigsen",
            "zhao",
            "not",
            "biases",
            "our",
            "hatetoxicity",
            "genderoccupation",
            "winogender",
            "empty",
            "toxigen",
            "gray",
            "sap",
            "after",
            "multiaxis",
            "age",
            "ses",
            "target",
            "cells",
            "demographic",
            "dis",
            "adapted",
            "contents",
            "nat",
            "rudinger",
            "covering",
            "bartl",
            "mathew",
            "bbq",
            "rel",
            "samples",
            "crowspairs",
            "stereotypes",
            "nangia",
            "elsherief",
            "felkner",
            "occup",
            "stereo",
            "implicithate",
            "involved",
            "datasets",
            "becpro",
            "taxonomy",
            "phy",
            "redditbias",
            "winobias",
            "gen",
            "barikeri",
            "parrish",
            "data",
            "stereoset",
            "unb",
            "dataset",
            "targeted",
            "coverage",
            "adaptations",
            "bias"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">To enable comprehensive empirical evaluation in realistic settings, we adapt existing English datasets to align with our demographic-targeted social bias taxonomy. We surveyed widely used NLP datasets&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite>, prioritizing diversity across demographic axes and harm types. Unlike prior benchmarks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, which often rely on fully GPT-generated categories (e.g., toxic text), we minimize synthetic data to reduce evaluation artifacts&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Koo et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib28\" title=\"\">2024</a>; Maheshwari et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib35\" title=\"\">2024</a>)</cite>.<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>The only exception is ToxiGen, although it has human-annotated GPT text, unlike&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>.</span></span></span> Based on this review, we curated samples from <span class=\"ltx_text ltx_font_bold\">twelve</span> distinct datasets (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T1\" title=\"Table 1 &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora used to train general-purpose AI (GPAI) models often contain harmful demographic-targeted social biases, creating a regulatory need for data auditing and developing scalable bias-detection methods. Although prior work has investigated biases in text datasets and related detection methods, these studies remain narrow in scope. They typically focus on a single content type (e.g., hate speech), cover limited demographic axes, overlook biases affecting multiple demographics simultaneously, and analyze limited techniques. Consequently, practitioners lack a holistic understanding of the strengths and limitations of recent large language models (LLMs) for automated and scalable bias detection in datasets. In this study, we present a comprehensive evaluation framework aimed at English texts to assess the ability of LLMs in detecting demographic-targeted social biases. To align with regulatory requirements, we frame bias detection as a multi-label task using a demographic-focused taxonomy. We then conduct a systematic evaluation with models across scales and techniques, including prompting, in-context learning, and fine-tuning. Using twelve datasets spanning diverse content types and demographics, our study demonstrates the promise of fine-tuned smaller models for scalable detection. However, our analyses also expose persistent gaps across demographic axes and multi-demographic targeted biases, underscoring the need for more effective and scalable auditing frameworks.</p>\n\n",
                "matched_terms": [
                    "taxonomy",
                    "biases",
                    "content",
                    "data",
                    "demographic",
                    "targeted",
                    "datasets",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora have significantly driven recent advances in general-purpose AI (GPAI) models. These corpora, however, are often minimally curated and can contain harmful social biases, e.g., hateful, toxic, or stereotypical content <span class=\"ltx_text ltx_font_italic\">targeting various demographic axes</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Navigli et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib40\" title=\"\">2023</a>)</cite>. Consequently, training on such content can lead to unsafe model outputs and real-world harms&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Dodge et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>; Vashney, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib52\" title=\"\">2022</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "content",
                    "biases",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Detecting demographic-targeted social biases in data has become both a regulatory and technical requirement&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Tabassi, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib51\" title=\"\">2023</a>; European Union, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib14\" title=\"\">2024</a>)</cite>. For example, the EU&#8217;s GPAI Code of Practice highlights the importance of documenting demographic-centric harms in training corpora. Effective data-level mitigation strategies&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite> also depend on reliably identifying biased instances. While prior studies have examined biases in text corpora&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kreutzer et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib29\" title=\"\">2022</a>; Luccioni and Viviano, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib34\" title=\"\">2021</a>; Dodge et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>)</cite>, they typically rely either on small-scale human annotations or on simplistic automated techniques. Manual inspection, however, poses psychological risks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Steiger et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib49\" title=\"\">2021</a>)</cite>, and despite advances in LLMs, few works offer a comprehensive analysis of the state of the art in social bias detection.</p>\n\n",
                "matched_terms": [
                    "data",
                    "biases",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Compared to systematic benchmarks that examine LLMs for biased generation&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>; Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>)</cite>, detailed studies of their potential as tools for detecting social biases in text remain underexplored. Existing work is often limited across one or more dimensions: focusing on narrow demographics&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, restricting attention to a single type of content such as hate&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>)</cite>, analyzing only specific contexts like certain subreddits&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kumar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib30\" title=\"\">2024</a>)</cite>, or analyzing only few methods such as zero-shot prompting&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>)</cite>. Moreover, most studies overlook biases that target <em class=\"ltx_emph ltx_font_italic\">multiple demographic axes simultaneously</em>, e.g., intersectionality. These gaps motivate a structured and comprehensive study of the current capabilities of recent LLMs in detecting demographic-targeted social biases.</p>\n\n",
                "matched_terms": [
                    "mathew",
                    "content",
                    "parrish",
                    "target",
                    "demographic",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address these gaps, we propose an evaluation framework for systematically assessing recent LLMs in detecting demographic-targeted social biases in English text. Our findings reveal both the potential of fine-tuned smaller LLMs and existing performance disparities across demographics and multi-targeted cases. By establishing a structured foundation, this work provides practical guidance for regulatory compliance and safer AI deployment. Our main contributions are as follows.</p>\n\n",
                "matched_terms": [
                    "biases",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We develop a <em class=\"ltx_emph ltx_font_italic\">demographic-focused</em> taxonomy for social bias detection for better alignment with anti-discrimination principles and multi-axis targeted bias detection.</p>\n\n",
                "matched_terms": [
                    "taxonomy",
                    "targeted",
                    "bias",
                    "multiaxis"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We adapt twelve widely used English datasets covering diverse content types and demographics targeted by social biases.</p>\n\n",
                "matched_terms": [
                    "covering",
                    "datasets",
                    "content",
                    "targeted",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_inline-block\" style=\"width:14.0pt;--ltx-fg-color:#FF0000;\">\n    <span class=\"ltx_text ltx_inline-block\" style=\"width:0.0pt;position:relative; bottom:1.0pt;\">!</span>\n    <span class=\"ltx_text ltx_inline-block\" style=\"width:0.0pt;\">\n      <math alttext=\"\\bigtriangleup\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m1\" intent=\":literal\">\n        <semantics>\n          <mo mathcolor=\"#FF0000\" style=\"--ltx-fg-color:#FF0000;\">&#9651;</mo>\n          <annotation encoding=\"application/x-tex\">\\bigtriangleup</annotation>\n        </semantics>\n      </math>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"--ltx-fg-color:#FF0000;\">This paper may contain potentially <span class=\"ltx_text ltx_font_bold\">harmful and biased</span> <span class=\"ltx_text ltx_font_bold\">text samples</span>. The authors <span class=\"ltx_text ltx_font_bold\">do not endorse</span> these views.</span>\n</p>\n\n",
                "matched_terms": [
                    "samples",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias in LLMs.</span>\nSeveral works have evaluated biases in LLMs, independently analyzing content types like stereotypes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Nadeem et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib38\" title=\"\">2021</a>; Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>)</cite> and hate/toxic content&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gehman et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib17\" title=\"\">2020</a>)</cite>. Recently, <cite class=\"ltx_cite ltx_citemacro_citet\">Li et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib31\" title=\"\">2023</a>)</cite> also studied the fairness of ChatGPT in binary decision-making. Several benchmarks also analyzed stereotype and toxic characteristics in generations of recently developed LLMs&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib54\" title=\"\">2023</a>; Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "nadeem",
                    "content",
                    "stereotypes",
                    "parrish",
                    "biases",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias detection with LLMs.</span>\nPrior work explored using LLMs in hate-speech moderation&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Barikeri et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib1\" title=\"\">2021</a>; Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>; Kumar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib30\" title=\"\">2024</a>; Zhan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib62\" title=\"\">2025</a>)</cite> or domain-specific bias detection&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Raza et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib45\" title=\"\">2024</a>)</cite>. Recent work&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite> also benchmarked prompt-based bias detection. However, they are restricted to zero-shot settings, cover limited demographics and data. In contrast, we systematically evaluate across multiple LLM-based methods, a broader range of demographics, and holistically analyze across different content types.</p>\n\n",
                "matched_terms": [
                    "mathew",
                    "content",
                    "barikeri",
                    "data",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias analysis of corpora.</span>\nOther work has directly analyzed large text corpora. <cite class=\"ltx_cite ltx_citemacro_citet\">Kreutzer et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib29\" title=\"\">2022</a>)</cite> employed human surveys on a small web-crawled subset to assess multilingual quality and offensive content. Lexicon-based approaches have been used to detect opinion biases in Wikipedia&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Hube and Fetahu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib23\" title=\"\">2018</a>)</cite>. <cite class=\"ltx_cite ltx_citemacro_citet\">Luccioni and Viviano (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib34\" title=\"\">2021</a>)</cite> subsampled Common Crawl to study sexual and hateful content using n-grams, BERT, and logistic regression, while <cite class=\"ltx_cite ltx_citemacro_citet\">Dodge et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>)</cite> analyzed C4, linking sentiment toward racial groups to biased QA outcomes. Although these studies provide valuable insights, they rely on relatively simplistic detection methods. In contrast, our work offers a systematic evaluation of state-of-the-art LLMs for social bias detection, providing deeper insights that can complement and extend prior analyses of large-scale corpora.</p>\n\n",
                "matched_terms": [
                    "content",
                    "biases",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">LLM guardrails.</span>\nLLMs have also been explored as guardrails for GPAI systems&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Markov et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib36\" title=\"\">2023</a>; Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>; Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib5\" title=\"\">2024a</a>; Zeng et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib61\" title=\"\">2024</a>)</cite>, primarily to mitigate harmful user prompts and model-generated outputs. While effective for moderating AI systems, these models are not designed for systematically identifying biases in raw text. As we later show, they fail to capture subtle social biases in texts, highlighting the need for dedicated evaluations and methods.</p>\n\n",
                "matched_terms": [
                    "not",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section outlines the practical setup of our evaluation framework for analyzing the ability of LLMs to detect social biases in texts targeting different demographic groups. We first present the demographic-targeted taxonomy that underpins our framework, then describe how we adapt and integrate existing datasets for a holistic evaluation of bias detection. Finally, we detail the testbed we constructed to ensure comprehensive coverage of LLMs and detection methods.</p>\n\n",
                "matched_terms": [
                    "taxonomy",
                    "biases",
                    "demographic",
                    "coverage",
                    "datasets",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Prior evaluation studies are limited in scope: (i) they narrowly focus on specific content types (e.g., hate&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>)</cite>), (ii) adopt narrow context-specific taxonomies (e.g., subreddits&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kumar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib30\" title=\"\">2024</a>)</cite>), or (iii) consider only a small set of demographic axes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>. Hence, we lack a <em class=\"ltx_emph ltx_font_italic\">holistic view</em> of the current capabilities for detecting <em class=\"ltx_emph ltx_font_italic\">social biases</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Navigli et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib40\" title=\"\">2023</a>)</cite>, i.e., &#8220;prejudices, stereotypes, and discriminatory attitudes against certain groups&#8221; embedded in texts.</p>\n\n",
                "matched_terms": [
                    "mathew",
                    "content",
                    "stereotypes",
                    "demographic",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address the limitations, our framework employs a <em class=\"ltx_emph ltx_font_italic\">demographic-centered taxonomy</em> that identifies the demographic axes targeted by biased texts. This approach aligns directly with anti-discrimination regulations and governance measures&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(European Commission, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib13\" title=\"\">2025</a>)</cite>, while also enabling the study of <em class=\"ltx_emph ltx_font_italic\">multi-axis</em> biases: cases where texts simultaneously target multiple groups, an aspect often overlooked. Concretely, our taxonomy spans nine axes with differing legal recognition:</p>\n\n",
                "matched_terms": [
                    "taxonomy",
                    "multiaxis",
                    "target",
                    "demographic",
                    "targeted",
                    "biases",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Broad recognition</span>: <em class=\"ltx_emph ltx_font_italic\">Gender identity</em> (<span class=\"ltx_text ltx_font_typewriter\">GEN</span>), <em class=\"ltx_emph ltx_font_italic\">Sexual orientation</em> (<span class=\"ltx_text ltx_font_typewriter\">SO</span>), <em class=\"ltx_emph ltx_font_italic\">Disability</em> (<span class=\"ltx_text ltx_font_typewriter\">DIS</span>), <em class=\"ltx_emph ltx_font_italic\">Age</em> (<span class=\"ltx_text ltx_font_typewriter\">AGE</span>), <em class=\"ltx_emph ltx_font_italic\">Race/ethnicity</em> (<span class=\"ltx_text ltx_font_typewriter\">RAC</span>), <em class=\"ltx_emph ltx_font_italic\">Nationality</em> (<span class=\"ltx_text ltx_font_typewriter\">NAT</span>), and <em class=\"ltx_emph ltx_font_italic\">Religion</em> (<span class=\"ltx_text ltx_font_typewriter\">REL</span>), all widely protected&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Congress, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib7\" title=\"\">1964</a>; EU FRA, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib12\" title=\"\">2018</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "gen",
                    "rel",
                    "rac",
                    "age",
                    "dis",
                    "nat"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Narrow recognition</span>: <em class=\"ltx_emph ltx_font_italic\">Socioeconomic status</em> (<span class=\"ltx_text ltx_font_typewriter\">SES</span>) and <em class=\"ltx_emph ltx_font_italic\">Physical appearance</em> (<span class=\"ltx_text ltx_font_typewriter\">PHY</span>), protected in certain regional frameworks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Viprey, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib53\" title=\"\">2002</a>; Klose et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib27\" title=\"\">2025</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "phy",
                    "ses"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Any text not targeting one or more of these axes is considered &#8220;unbiased&#8221; (<span class=\"ltx_text ltx_font_typewriter\">UNB</span>) <em class=\"ltx_emph ltx_font_italic\">within our taxonomy</em>. Each demographic axis serves as a prediction category, making the detection task twofold: (i) identify whether a text expresses demographic-targeted bias, and (ii) determine which demographics are targeted. Unlike prior benchmarks that treat bias detection as single-label or multi-class classification&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, our formulation supports <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em>, capturing both <span class=\"ltx_text ltx_font_italic\">single-axis</span> (e.g., race only) and <span class=\"ltx_text ltx_font_italic\">multi-axis</span> (e.g., gender+race) biases (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T2\" title=\"Table 2 &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>).</p>\n\n",
                "matched_terms": [
                    "taxonomy",
                    "mathew",
                    "multiaxis",
                    "demographic",
                    "unb",
                    "targeted",
                    "not",
                    "biases",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our taxonomy also considers a <em class=\"ltx_emph ltx_font_italic\">broad range of content types</em> encoding social biases through <em class=\"ltx_emph ltx_font_italic\">implicit harms</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Blodgett et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib3\" title=\"\">2020</a>)</cite>, including:\ni) <span class=\"ltx_text ltx_font_italic\">Stereotype descriptions</span> that stereotype, misrepresent, or disparage identities, ii) <span class=\"ltx_text ltx_font_italic\">Occupation&#8211;gender associations</span> that stereotype, erase, or exclude gender identities, and <span class=\"ltx_text ltx_font_italic\">Hate or toxic content</span> targeting demographics through toxicity, derogation, or dehumanization. However, by centering on <em class=\"ltx_emph ltx_font_italic\">demographic axes</em> rather than surface content types, we enable systematic characterization of which demographics are harmed, allow for analysis of multi-axis cases, and align directly with anti-discrimination and AI governance frameworks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(European Union, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib14\" title=\"\">2024</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "taxonomy",
                    "content",
                    "multiaxis",
                    "demographic",
                    "biases",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Since some datasets were originally designed for evaluating generative biases, we applied minor adaptations similar to&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>. For StereoSet, we concatenate the context with the stereotype options. For BBQ, we construct text instances by pairing disambiguated contexts with answers. For CrowS-Pairs, we retain only the &#8220;more biased&#8221; sentences. For SBIC, we derive a single label using the majority vote across annotators. For ToxiGen, we label texts as biased only when human annotator scores indicate bias.</p>\n\n",
                "matched_terms": [
                    "biases",
                    "bbq",
                    "toxigen",
                    "crowspairs",
                    "stereoset",
                    "adaptations",
                    "sbic",
                    "datasets",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We also observed inconsistencies in how demographic groups are labeled across datasets, so we standardized labels for consistency. For instance, bias against &#8220;Arabs&#8221; or &#8220;Middle Eastern&#8221; identities, labeled inconsistently as <span class=\"ltx_text ltx_font_typewriter\">RAC</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Nadeem et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib38\" title=\"\">2021</a>)</cite> or <span class=\"ltx_text ltx_font_typewriter\">REL</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Barikeri et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib1\" title=\"\">2021</a>)</cite>, is mapped to <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, reserving <span class=\"ltx_text ltx_font_typewriter\">REL</span> for explicit religious references. Biases against national identities such as &#8220;Chinese&#8221; or &#8220;Mexican&#8221; are assigned to <span class=\"ltx_text ltx_font_typewriter\">NAT</span>. Bias against &#8220;Jewish&#8221; identity is annotated as both <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">REL</span> to reflect its ethnoreligious nature&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Litt, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib32\" title=\"\">1961</a>)</cite>. We also improve regulatory alignment by disambiguating <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">SO</span> (e.g., transgender bias labeled as <span class=\"ltx_text ltx_font_typewriter\">GEN</span>) and denoting pregnancy-targeted bias under <span class=\"ltx_text ltx_font_typewriter\">GEN</span> rather than <span class=\"ltx_text ltx_font_typewriter\">PHY</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>)</cite>. Labels outside our taxonomy (e.g., <em class=\"ltx_emph ltx_font_italic\">victim</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sap et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib47\" title=\"\">2020</a>)</cite>) are excluded.</p>\n\n",
                "matched_terms": [
                    "phy",
                    "taxonomy",
                    "nadeem",
                    "datasets",
                    "nat",
                    "gen",
                    "rel",
                    "sap",
                    "barikeri",
                    "rac",
                    "parrish",
                    "demographic",
                    "biases",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The resulting dataset contains <span class=\"ltx_text ltx_font_bold\">46,781</span> entries, substantially larger than comparable benchmarks (e.g., 11,004 samples in&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>). Biased instances are more prevalent (around 70%), with most targeting a single demographic axis and roughly 12% of biased instances targeting multiple axes simultaneously. Among demographic targets, <span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, <span class=\"ltx_text ltx_font_typewriter\">SO</span>, and <span class=\"ltx_text ltx_font_typewriter\">REL</span> are most common, while <span class=\"ltx_text ltx_font_typewriter\">PHY</span> is least prevalent. Multi-axis biases most frequently combine {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">SO</span>} or {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>}.</p>\n\n",
                "matched_terms": [
                    "phy",
                    "gen",
                    "rel",
                    "samples",
                    "multiaxis",
                    "rac",
                    "demographic",
                    "dataset",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_citet\">Brown et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib4\" title=\"\">2020</a>)</cite> demonstrated that <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> LLMs can effectively perform a variety of tasks through textual prompting in <em class=\"ltx_emph ltx_font_italic\">zero-shot</em> scenarios. Following&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>; Palla et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib42\" title=\"\">2025</a>)</cite>, our evaluation framework employs <em class=\"ltx_emph ltx_font_italic\">policy-based</em> prompting for bias detection. Specifically, the prompt includes a policy detailing the bias detection task and our demographic-based social bias taxonomy. To enhance the bias detection capabilities within this prompting framework, we also assess the benefits of incorporating <em class=\"ltx_emph ltx_font_italic\">few-shot</em> examples for <em class=\"ltx_emph ltx_font_italic\">in-context learning</em>. Specifically, we utilize the retrieval-augmented (RAG) framework&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib5\" title=\"\">2024a</a>)</cite>, where an embedding model identifies the most <em class=\"ltx_emph ltx_font_italic\">relevant</em> in-context examples for each input instance from the training/development set.</p>\n\n",
                "matched_terms": [
                    "taxonomy",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We also evaluate the effectiveness of aligning LLMs to the bias detection task through <em class=\"ltx_emph ltx_font_italic\">fine-tuning</em>. The task is framed as <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em> over the nine demographic axes. We solve it through sequence classification by attaching nine classifier nodes to a pre-trained LLM: to the [CLS] token for encoder-only models and to the final output token for decoder-only models.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Because detection must perform reliably <em class=\"ltx_emph ltx_font_italic\">across all demographic axes</em>, our evaluation framework also explores the effectiveness of <em class=\"ltx_emph ltx_font_italic\">data reweighting</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kamiran and Calders, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib25\" title=\"\">2012</a>)</cite> to address imbalances. Let <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> denote the number of samples and <math alttext=\"\\mathcal{M}_{\\phi}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m2\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8499;</mi><mi>&#981;</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{M}_{\\phi}</annotation></semantics></math> the model. For a given instance <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m3\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>, its labels <math alttext=\"Y_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m4\" intent=\":literal\"><semantics><msub><mi>Y</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">Y_{i}</annotation></semantics></math> form a binary vector of length nine, where <math alttext=\"Y_{i}^{m}=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m5\" intent=\":literal\"><semantics><mrow><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">Y_{i}^{m}=1</annotation></semantics></math> if the demographic axis <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m6\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> is targeted and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m7\" intent=\":literal\"><mn>0</mn></math> otherwise. The weighted loss is defined as:</p>\n\n",
                "matched_terms": [
                    "samples",
                    "data",
                    "demographic",
                    "targeted",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"\\alpha_{m}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m8\" intent=\":literal\"><semantics><msub><mi>&#945;</mi><mi>m</mi></msub><annotation encoding=\"application/x-tex\">\\alpha_{m}</annotation></semantics></math> balances across demographic axes, and <math alttext=\"w_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m9\" intent=\":literal\"><semantics><msub><mi>w</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">w_{i}</annotation></semantics></math> compensates for binary imbalances regarding biased and unbiased instances. All weights are derived from training data statistics.</p>\n\n",
                "matched_terms": [
                    "data",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our comprehensive framework uses metrics capturing three dimensions: (i) distinguishing <em class=\"ltx_emph ltx_font_italic\">biased vs. unbiased</em> text, (ii) accurate <em class=\"ltx_emph ltx_font_italic\">multi-label classification</em> of bias types, and (iii) ensuring <em class=\"ltx_emph ltx_font_italic\">parity</em> in detection performance across demographic axes and for multi-targeted texts compared to single-targeted texts.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "demographic",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Let <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> be the number of evaluation instances. For each instance <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m2\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>, annotated labels are represented as <math alttext=\"Y_{i}=\\begin{pmatrix}Y_{i}^{m}\\end{pmatrix}_{m=1}^{9}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m3\" intent=\":literal\"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><msubsup><mrow><mo>(</mo><mtable><mtr><mtd><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup></mtd></mtr></mtable><mo>)</mo></mrow><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mn>9</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">Y_{i}=\\begin{pmatrix}Y_{i}^{m}\\end{pmatrix}_{m=1}^{9}</annotation></semantics></math> and model predictions as <math alttext=\"\\hat{Y}_{i}=\\begin{pmatrix}\\hat{Y}_{i}^{m}\\end{pmatrix}_{m=1}^{9}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m4\" intent=\":literal\"><semantics><mrow><msub><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><mi>i</mi></msub><mo>=</mo><msubsup><mrow><mo>(</mo><mtable><mtr><mtd><msubsup><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><mi>i</mi><mi>m</mi></msubsup></mtd></mtr></mtable><mo>)</mo></mrow><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mn>9</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">\\hat{Y}_{i}=\\begin{pmatrix}\\hat{Y}_{i}^{m}\\end{pmatrix}_{m=1}^{9}</annotation></semantics></math>, where <math alttext=\"Y_{i}^{m},\\hat{Y}_{i}^{m}\\in\\{0,1\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m5\" intent=\":literal\"><semantics><mrow><mrow><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>,</mo><msubsup><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><mi>i</mi><mi>m</mi></msubsup></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">Y_{i}^{m},\\hat{Y}_{i}^{m}\\in\\{0,1\\}</annotation></semantics></math> denote whether axis <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m6\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> is targeted (1) or not (0).</p>\n\n",
                "matched_terms": [
                    "targeted",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Detection disparities.</span>\nOur evaluation also examines whether LLMs not only detect social biases accurately but also exhibit systematic performance gaps across different demographic targets. Given <math alttext=\"\\mathcal{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p5.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><annotation encoding=\"application/x-tex\">\\mathcal{P}</annotation></semantics></math> denotes FPR or FNR, we analyze disparities in the following scenarios:</p>\n\n",
                "matched_terms": [
                    "not",
                    "biases",
                    "demographic",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-demographic.</span> Inspired by&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite>, we measure if the models make systematically more errors in detecting biases that <em class=\"ltx_emph ltx_font_italic\">specifically</em> target <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em> (e.g., {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}) relative to biases that target <span class=\"ltx_text ltx_font_italic\">each constituent axis</span> (e.g., only <span class=\"ltx_text ltx_font_typewriter\">GEN</span> or <span class=\"ltx_text ltx_font_typewriter\">RAC</span>).\n<math alttext=\"\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.I3.i2.p1.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>=</mo><mrow><munder accentunder=\"true\"><mi>max</mi><mrow><mi>x</mi><mo>&#8712;</mo><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></mrow></munder><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msub><mo>&#8722;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mi>x</mi></msub></mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|</annotation></semantics></math>. This measure helps us understand if the FPR or FNR of multi-axis targeted biased instances is markedly higher, indicating potential blind spots for automated bias detection methods.</p>\n\n",
                "matched_terms": [
                    "gen",
                    "multiaxis",
                    "rac",
                    "target",
                    "targeted",
                    "biases",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section illustrates how our comprehensive evaluation study enables the practical assessment of LLM-based methods for detecting demographic-targeted social biases in text. Our analysis reveals both the strengths and current limitations of these approaches. For rigorous assessment of the overall results, we perform 1,000 bootstrap samples with replacement on the combined test set to compute 95% confidence intervals. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> presents a detailed comparison of prompting and fine-tuning, reporting both binary performance (biased vs. unbiased) and multi-label categorization. We also report median inference time (in milliseconds) for each text instance. Moreover, for more fine-grained analysis, Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> reports bias detection performance of select prompted and fine-tuned LLMs for the twelve constituent datasets.</p>\n\n",
                "matched_terms": [
                    "biases",
                    "samples",
                    "datasets",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our detailed results in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> show how bias detection with prompting is <em class=\"ltx_emph ltx_font_italic\">highly sensitive to both in-context learning and model capacity</em>.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Guardrail models transfer poorly.</span> Llama Guard, fine-tuned for moderation, consistently underperforms instruction-tuned models of similar size (e.g., Llama-3.1-8B), achieving the lowest binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> and highest FNR. While effective at detecting overt hate speech, it fails to capture subtler biases like stereotypes.</p>\n\n",
                "matched_terms": [
                    "stereotypes",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nFrom Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we see the role of scale from the binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. The 70B Llama model outperforms smaller variants across most datasets. Llama-Guard shows lower overall binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, but performs relatively well on hate/toxic content. It specifically achieves the highest score across all models on Toxigen, which is GPT-generated. This finding is consistent with its design as a GPAI guardrail. Multi-label metrics show that even larger models struggle to correctly identify bias types, especially for stereotyped contents, e.g., StereoSet and RedditBias.</p>\n\n",
                "matched_terms": [
                    "redditbias",
                    "content",
                    "toxigen",
                    "stereoset",
                    "contents",
                    "datasets",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our results in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> show how the performance of fine-tuned LLM-based bias detectors is <em class=\"ltx_emph ltx_font_italic\">shaped by model size, architecture, and optimization strategy</em>.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> shows how fine-tuned models achieve stronger binary detection across most datasets compared to prompting-based LLMs. Encoder models (DeBERTa) generally outperform decoder-only GPT-2, which remains competitive on many datasets but struggles with subtle stereotype cases, e.g, RedditBias and Winogender. For multi-label detection, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> shows consistently lower HL, indicating more accurate detection of demographic axes targeted.</p>\n\n",
                "matched_terms": [
                    "redditbias",
                    "winogender",
                    "demographic",
                    "targeted",
                    "datasets"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nFine-tuned encoder models provide the most effective bias detection, outperforming prompting much larger models in both binary detection and identification of the correct bias types. Decoder-based models can perform well but show weaknesses on subtle stereotype datasets. Fine-tuning with reweighted loss improves recall, but may increase false positives, highlighting important tradeoffs that require consideration.</p>\n\n",
                "matched_terms": [
                    "datasets",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use our evaluation framework to examine <em class=\"ltx_emph ltx_font_italic\">potential disparities</em> in social bias detection across models and setups with respect to targeted demographic axes. While the previous analysis provided a global view of model performance, this section focuses on <em class=\"ltx_emph ltx_font_italic\">systematic differences</em> in how effectively models detect biases. We first analyze disparities for individual demographic axes. Next, owing to our multi-label setup, we evaluate model performances on instances targeting <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em>, highlighting current capabilities in detecting multi-targeted biases. We provide the comprehensive disparity analysis in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S5.T5\" title=\"Table 5 &#8227; 5 Evaluating detection disparities &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>.</p>\n\n",
                "matched_terms": [
                    "demographic",
                    "targeted",
                    "biases",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We assess systemic performance disparities using <math alttext=\"\\Delta_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p1.m1\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}</annotation></semantics></math> and <math alttext=\"\\Delta_{\\text{FPR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p1.m2\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}</annotation></semantics></math>, which measure the maximum performance gaps across the nine social bias demographic target axes in our taxonomy.</p>\n\n",
                "matched_terms": [
                    "taxonomy",
                    "target",
                    "demographic",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nPrompting, even with larger models and few-shot examples, shows substantial per-axis disparities. Fine-tuned models, particularly with reweighted loss, achieve more balanced performance, although notable gaps remain. In additional analyses (in the appendix), we examined <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across the nine demographic axes. We found that certain targets, such as <span class=\"ltx_text ltx_font_typewriter\">NAT</span> and <span class=\"ltx_text ltx_font_typewriter\">PHY</span>, consistently have lower detection accuracy, which contributes to the observed disparities.</p>\n\n",
                "matched_terms": [
                    "phy",
                    "nat",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We now analyze texts targeting <span class=\"ltx_text ltx_font_italic\">multiple axes simultaneously</span>, focusing on {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>} and {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}. We compare performance on these multi-axis instances to that on the instances that target only constituent single axes (e.g., only <span class=\"ltx_text ltx_font_typewriter\">GEN</span> or <span class=\"ltx_text ltx_font_typewriter\">SO</span> for {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>}).</p>\n\n",
                "matched_terms": [
                    "target",
                    "gen",
                    "multiaxis"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our study provides a practical assessment of how LLMs can scale the detection of demographic-targeted social biases in text, supporting compliance with governance and regulatory standards. In this section, we discuss broader implications, key limitations, and directions for future work.</p>\n\n",
                "matched_terms": [
                    "biases",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Inclusive stakeholder input.</span>\nAutomation enables large-scale auditing while minimizing human exposure to harmful content&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Steiger et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib49\" title=\"\">2021</a>)</cite>. However, bias detection remains a <em class=\"ltx_emph ltx_font_italic\">socio-technical challenge</em>: social biases are culturally situated, and the detection pipeline must be guided by participatory processes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Markov et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib36\" title=\"\">2023</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "content",
                    "biases",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Data coverage.</span>\nOur evaluation relies mainly on English datasets reflecting global North contexts, which limits generalizability to other languages and regions. Progress will require multilingual and cross-lingual benchmarks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Corazza et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib8\" title=\"\">2020</a>; Huang and Xiong, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib22\" title=\"\">2023</a>; Neplenbroek et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib41\" title=\"\">2024</a>)</cite>, methods adapted for low-resource settings, and attention to language-specific biases that may not align with English-centric taxonomies. Dataset diversity should also ensure sufficient coverage of social biases that may exist in different cultural contexts. Coverage should also extend to more categories, e.g., political beliefs and biases encoded across multiple data modalities.</p>\n\n",
                "matched_terms": [
                    "datasets",
                    "dataset",
                    "data",
                    "adapted",
                    "coverage",
                    "not",
                    "biases",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methodological opportunities.</span>\nOur findings highlight both promises and existing limitations of scalable automated bias detection. Future work should further explore advanced prompting (e.g., <span class=\"ltx_text ltx_font_italic\">chain-of-thought</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wei et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib56\" title=\"\">2022</a>)</cite>) and efficient fine-tuning (e.g., using adapters). To handle multimodal data, exploring effective and scalable solutions remains an interesting open challenge. Moreover, while our results offer initial guidance, balancing the potential gains from training and deploying larger models and the scalability required for auditing massive corpora warrants deeper exploration. Finally, our study shows that detecting infrequent, subtle, and multi-axis biases remains a crucial underexplored direction for future research.</p>\n\n",
                "matched_terms": [
                    "multiaxis",
                    "data",
                    "biases",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Mitigation through data bias detection.</span>\nBias detection enables more than regulatory reporting; it allows for leveraging the flagged data instances for more responsible model development through targeted data augmentation, filtering, or fine-tuning&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite>. However, any remedial action <span class=\"ltx_text ltx_font_italic\">must be</span> guided by rigorous ethical considerations and incorporate human oversight.</p>\n\n",
                "matched_terms": [
                    "targeted",
                    "data",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Text statistics.</span>\nIn Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F1.sf1\" title=\"In Figure 1 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1(a)</span></a>, we show the token count distribution for all the bias categories, including the <em class=\"ltx_emph ltx_font_italic\">unbiased</em> texts. To obtain tokens, we use the RoBERTa tokenizer. We see that the token counts for each text instance are generally low, indicating our dataset mainly contains short text instances. However, there are some outliers, e.g., in <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">SO</span>, where we see around 400 token length texts. Upon inspection, we observed that such instances primarily come from the BBQ dataset, that have very long context texts.</p>\n\n",
                "matched_terms": [
                    "gen",
                    "bbq",
                    "dataset",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Label statistics.</span>\nIn Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F2\" title=\"Figure 2 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, we visualize the label statistics in the final curated dataset. The visualizations show label imbalances in the data, highlighting the need for weighted loss for optimization and motivating future work to explore further fairness interventions to ensure equitable bias detection performance. The statistics show that our data contains more biased instances than unbiased ones. Furthermore, we see that most instances target a single demographic axis. However, many instances target two axes. Instances targeting more than two demographic axes are significantly fewer in our dataset. We provide more detailed label co-occurrence statistics in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F1.sf2\" title=\"In Figure 1 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1(b)</span></a>. The figure shows that text instances target specific demographics more often. For instance, texts target <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">GEN</span> more often. Similarly, texts target <span class=\"ltx_text ltx_font_typewriter\">DIS</span>,<span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">PHY</span> relatively less often. Furthermore, we see that <span class=\"ltx_text ltx_font_typewriter\">GEN</span> co-occurs with many other demographic axes, e.g., <span class=\"ltx_text ltx_font_typewriter\">SO</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, and <span class=\"ltx_text ltx_font_typewriter\">DIS</span>. Note that while <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">REL</span> appear together frequently, many of these instances simply target &#8220;Jewish identities.&#8221;</p>\n\n",
                "matched_terms": [
                    "phy",
                    "gen",
                    "rel",
                    "rac",
                    "target",
                    "data",
                    "demographic",
                    "dis",
                    "dataset",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All LLMs are accessed via API through an MLOps platform. We fix <span class=\"ltx_text ltx_font_typewriter\">temperature</span> to 0 and <span class=\"ltx_text ltx_font_typewriter\">top_p</span> to 1, ensuring deterministic outputs by selecting the model&#8217;s most likely generation while still allowing consideration of the full token space. For in-context learning, we embed the training and development sets using BGE-M3 or BCEmbedding models. At inference time, we compute cosine similarity between the query and development set vectors to retrieve the top-<math alttext=\"K\" class=\"ltx_Math\" display=\"inline\" id=\"A2.SS1.p1.m1\" intent=\":literal\"><semantics><mi>K</mi><annotation encoding=\"application/x-tex\">K</annotation></semantics></math> few-shot examples. As a baseline, we also apply a random few-shot selection from the training set, with balanced sampling between biased and unbiased texts. Model predictions are extracted via pattern matching. Responses that cannot be parsed through pattern matching to assign to one of the multiple demographic axes are marked as &#8220;invalid.&#8221; The <span class=\"ltx_text ltx_font_italic\">social bias policy</span> used in the text prompt is shown here.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">BGE-M3 exhibits a slight but consistent advantage in binary bias detection, producing marginally higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across multiple LLMs. However, the overall differences are minimal. In contrast, for multi-label prediction, BCEmbedding performs slightly better on metrics such as MR for many models. This finding suggests that while both embedding models select examples that yield similar overall outcomes, subtle differences exist. Specifically, BGE-M3-selected examples tend to improve binary bias detection by helping models better distinguish biased from unbiased samples, whereas BCEmbedding-selected examples slightly enhance the detection of specific bias types within biased instances.</p>\n\n",
                "matched_terms": [
                    "samples",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We now analyze model performance across different demographic targets. Specifically, we examine the <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p1.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores for all demographic axes in our taxonomy that may be subject to bias. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F5\" title=\"Figure 5 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents results for various prompted models using <em class=\"ltx_emph ltx_font_italic\">10-shot RAG-based in-context learning</em> with BGE-M3, while Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F6\" title=\"Figure 6 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> compares fine-tuned models and explores the impact of reweighted loss (&#8220;bal&#8221; in the figure) across demographics.</p>\n\n",
                "matched_terms": [
                    "taxonomy",
                    "bias",
                    "demographic",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our analysis shows that fine-tuned models consistently outperform prompting and transfer learning across all bias classes. The most notable <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> score gains appear in the AGE and SES categories, which are less frequent in the dataset.</p>\n\n",
                "matched_terms": [
                    "ses",
                    "age",
                    "dataset",
                    "bias",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Among the prompted LLMs, Llama-3.1-70B achieves the highest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p3.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across nearly all bias categories, except for <span class=\"ltx_text ltx_font_typewriter\">GEN</span>, where GLM-9B&#8212;despite being much smaller&#8212;slightly outperforms it. Interestingly, Qwen-2.5-72B, though the largest LLM, performs worse in many low-frequency categories such as <span class=\"ltx_text ltx_font_typewriter\">DIS</span>, <span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">SES</span>. It performs comparably to the best prompting models only for <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, which are the most common categories in the benchmark.</p>\n\n",
                "matched_terms": [
                    "gen",
                    "ses",
                    "rac",
                    "age",
                    "dis",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For fine-tuned models, encoder-only architectures (e.g., RoBERTa and DeBERTa) generally outperform decoder-only language models, i.e., GPT-2, across most demographic axes. The trends mirror those observed in the prompting setup: models achieve their best performance for <span class=\"ltx_text ltx_font_typewriter\">SES</span>, while <span class=\"ltx_text ltx_font_typewriter\">NAT</span> consistently shows the lowest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. Reweighted loss often improves detection performance or yields similar results to the default loss. For example, in <span class=\"ltx_text ltx_font_typewriter\">NAT</span>, the axis that suffered from the weakest detection performance, reweighted loss improves performance across all models. However, improvements are not universal. For instance, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">large</span> experiences slight declines in <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> for some demographics such as <span class=\"ltx_text ltx_font_typewriter\">AGE</span> and <span class=\"ltx_text ltx_font_typewriter\">SES</span> when reweighted loss is applied.</p>\n\n",
                "matched_terms": [
                    "ses",
                    "age",
                    "demographic",
                    "not",
                    "nat"
                ]
            }
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Representative examples showing biases targeting single and multiple demographic axes.",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Bias Type</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Labels</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:310.5pt;\"><span class=\"ltx_text ltx_font_bold\">Example</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Unbiased</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">UNB</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:310.5pt;\">&#8220;<span class=\"ltx_text ltx_font_italic\">its always a mistaken identity because they think every black person is a criminal.</span>&#8221; <cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text ltx_font_bold\">(</span>Barikeri et&#160;al.<span class=\"ltx_text ltx_font_bold\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib1\" title=\"\">2021</a><span class=\"ltx_text ltx_font_bold\">)</span></cite></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Single-axis</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">RAC</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:310.5pt;\">&#8220;<span class=\"ltx_text ltx_font_italic\">what are you talking about arabs are rich af. they got arab money</span>&#8221; <cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text ltx_font_bold\">(</span>Barikeri et&#160;al.<span class=\"ltx_text ltx_font_bold\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib1\" title=\"\">2021</a><span class=\"ltx_text ltx_font_bold\">)</span></cite></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Multi-axis</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">GEN,RAC</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:310.5pt;\">&#8220;<span class=\"ltx_text ltx_font_italic\">I like my women like I like my black people Dead</span>&#8221; <cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text ltx_font_bold\">(</span>Sap et&#160;al.<span class=\"ltx_text ltx_font_bold\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib47\" title=\"\">2020</a><span class=\"ltx_text ltx_font_bold\">)</span></cite></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_border_b ltx_border_l ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"/>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">GEN,RAC</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:310.5pt;\">&#8220;<span class=\"ltx_text ltx_font_italic\">interracism is a form of race war. it is black males waging sexual war of conquest and colonizing white wombs to make brown babies</span>&#8221; <cite class=\"ltx_cite ltx_citemacro_citep\"><span class=\"ltx_text ltx_font_bold\">(</span>ElSherief et&#160;al.<span class=\"ltx_text ltx_font_bold\">, </span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib11\" title=\"\">2021</a><span class=\"ltx_text ltx_font_bold\">)</span></cite></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "representative",
            "type",
            "you",
            "“interracism",
            "identity",
            "targeting",
            "example",
            "conquest",
            "they",
            "rac",
            "wombs",
            "make",
            "axes",
            "colonizing",
            "rich",
            "single",
            "biases",
            "examples",
            "males",
            "brown",
            "genrac",
            "“its",
            "babies”",
            "unbiased",
            "black",
            "showing",
            "sap",
            "multiaxis",
            "mistaken",
            "think",
            "demographic",
            "war",
            "like",
            "about",
            "sexual",
            "criminal”",
            "arabs",
            "“what",
            "labels",
            "elsherief",
            "arab",
            "multiple",
            "money”",
            "singleaxis",
            "dead”",
            "talking",
            "women",
            "waging",
            "white",
            "race",
            "form",
            "people",
            "got",
            "person",
            "barikeri",
            "because",
            "unb",
            "every",
            "bias",
            "always"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Any text not targeting one or more of these axes is considered &#8220;unbiased&#8221; (<span class=\"ltx_text ltx_font_typewriter\">UNB</span>) <em class=\"ltx_emph ltx_font_italic\">within our taxonomy</em>. Each demographic axis serves as a prediction category, making the detection task twofold: (i) identify whether a text expresses demographic-targeted bias, and (ii) determine which demographics are targeted. Unlike prior benchmarks that treat bias detection as single-label or multi-class classification&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, our formulation supports <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em>, capturing both <span class=\"ltx_text ltx_font_italic\">single-axis</span> (e.g., race only) and <span class=\"ltx_text ltx_font_italic\">multi-axis</span> (e.g., gender+race) biases (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T2\" title=\"Table 2 &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>).</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora used to train general-purpose AI (GPAI) models often contain harmful demographic-targeted social biases, creating a regulatory need for data auditing and developing scalable bias-detection methods. Although prior work has investigated biases in text datasets and related detection methods, these studies remain narrow in scope. They typically focus on a single content type (e.g., hate speech), cover limited demographic axes, overlook biases affecting multiple demographics simultaneously, and analyze limited techniques. Consequently, practitioners lack a holistic understanding of the strengths and limitations of recent large language models (LLMs) for automated and scalable bias detection in datasets. In this study, we present a comprehensive evaluation framework aimed at English texts to assess the ability of LLMs in detecting demographic-targeted social biases. To align with regulatory requirements, we frame bias detection as a multi-label task using a demographic-focused taxonomy. We then conduct a systematic evaluation with models across scales and techniques, including prompting, in-context learning, and fine-tuning. Using twelve datasets spanning diverse content types and demographics, our study demonstrates the promise of fine-tuned smaller models for scalable detection. However, our analyses also expose persistent gaps across demographic axes and multi-demographic targeted biases, underscoring the need for more effective and scalable auditing frameworks.</p>\n\n",
                "matched_terms": [
                    "type",
                    "multiple",
                    "axes",
                    "demographic",
                    "single",
                    "biases",
                    "bias",
                    "they"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora have significantly driven recent advances in general-purpose AI (GPAI) models. These corpora, however, are often minimally curated and can contain harmful social biases, e.g., hateful, toxic, or stereotypical content <span class=\"ltx_text ltx_font_italic\">targeting various demographic axes</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Navigli et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib40\" title=\"\">2023</a>)</cite>. Consequently, training on such content can lead to unsafe model outputs and real-world harms&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Dodge et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>; Vashney, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib52\" title=\"\">2022</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "demographic",
                    "targeting",
                    "axes",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Detecting demographic-targeted social biases in data has become both a regulatory and technical requirement&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Tabassi, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib51\" title=\"\">2023</a>; European Union, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib14\" title=\"\">2024</a>)</cite>. For example, the EU&#8217;s GPAI Code of Practice highlights the importance of documenting demographic-centric harms in training corpora. Effective data-level mitigation strategies&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite> also depend on reliably identifying biased instances. While prior studies have examined biases in text corpora&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kreutzer et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib29\" title=\"\">2022</a>; Luccioni and Viviano, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib34\" title=\"\">2021</a>; Dodge et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>)</cite>, they typically rely either on small-scale human annotations or on simplistic automated techniques. Manual inspection, however, poses psychological risks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Steiger et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib49\" title=\"\">2021</a>)</cite>, and despite advances in LLMs, few works offer a comprehensive analysis of the state of the art in social bias detection.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "example",
                    "biases",
                    "they"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Compared to systematic benchmarks that examine LLMs for biased generation&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>; Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>)</cite>, detailed studies of their potential as tools for detecting social biases in text remain underexplored. Existing work is often limited across one or more dimensions: focusing on narrow demographics&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, restricting attention to a single type of content such as hate&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>)</cite>, analyzing only specific contexts like certain subreddits&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kumar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib30\" title=\"\">2024</a>)</cite>, or analyzing only few methods such as zero-shot prompting&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>)</cite>. Moreover, most studies overlook biases that target <em class=\"ltx_emph ltx_font_italic\">multiple demographic axes simultaneously</em>, e.g., intersectionality. These gaps motivate a structured and comprehensive study of the current capabilities of recent LLMs in detecting demographic-targeted social biases.</p>\n\n",
                "matched_terms": [
                    "type",
                    "multiple",
                    "axes",
                    "demographic",
                    "like",
                    "single",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We develop a <em class=\"ltx_emph ltx_font_italic\">demographic-focused</em> taxonomy for social bias detection for better alignment with anti-discrimination principles and multi-axis targeted bias detection.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "multiaxis"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We conduct an extensive empirical evaluation assessing both detection accuracy and performance disparities across demographic axes.</p>\n\n",
                "matched_terms": [
                    "axes",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias in LLMs.</span>\nSeveral works have evaluated biases in LLMs, independently analyzing content types like stereotypes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Nadeem et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib38\" title=\"\">2021</a>; Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>)</cite> and hate/toxic content&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gehman et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib17\" title=\"\">2020</a>)</cite>. Recently, <cite class=\"ltx_cite ltx_citemacro_citet\">Li et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib31\" title=\"\">2023</a>)</cite> also studied the fairness of ChatGPT in binary decision-making. Several benchmarks also analyzed stereotype and toxic characteristics in generations of recently developed LLMs&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib54\" title=\"\">2023</a>; Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "like",
                    "biases",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias detection with LLMs.</span>\nPrior work explored using LLMs in hate-speech moderation&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Barikeri et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib1\" title=\"\">2021</a>; Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>; Kumar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib30\" title=\"\">2024</a>; Zhan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib62\" title=\"\">2025</a>)</cite> or domain-specific bias detection&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Raza et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib45\" title=\"\">2024</a>)</cite>. Recent work&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite> also benchmarked prompt-based bias detection. However, they are restricted to zero-shot settings, cover limited demographics and data. In contrast, we systematically evaluate across multiple LLM-based methods, a broader range of demographics, and holistically analyze across different content types.</p>\n\n",
                "matched_terms": [
                    "multiple",
                    "they",
                    "bias",
                    "barikeri"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias analysis of corpora.</span>\nOther work has directly analyzed large text corpora. <cite class=\"ltx_cite ltx_citemacro_citet\">Kreutzer et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib29\" title=\"\">2022</a>)</cite> employed human surveys on a small web-crawled subset to assess multilingual quality and offensive content. Lexicon-based approaches have been used to detect opinion biases in Wikipedia&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Hube and Fetahu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib23\" title=\"\">2018</a>)</cite>. <cite class=\"ltx_cite ltx_citemacro_citet\">Luccioni and Viviano (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib34\" title=\"\">2021</a>)</cite> subsampled Common Crawl to study sexual and hateful content using n-grams, BERT, and logistic regression, while <cite class=\"ltx_cite ltx_citemacro_citet\">Dodge et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>)</cite> analyzed C4, linking sentiment toward racial groups to biased QA outcomes. Although these studies provide valuable insights, they rely on relatively simplistic detection methods. In contrast, our work offers a systematic evaluation of state-of-the-art LLMs for social bias detection, providing deeper insights that can complement and extend prior analyses of large-scale corpora.</p>\n\n",
                "matched_terms": [
                    "sexual",
                    "biases",
                    "bias",
                    "they"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">LLM guardrails.</span>\nLLMs have also been explored as guardrails for GPAI systems&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Markov et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib36\" title=\"\">2023</a>; Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>; Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib5\" title=\"\">2024a</a>; Zeng et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib61\" title=\"\">2024</a>)</cite>, primarily to mitigate harmful user prompts and model-generated outputs. While effective for moderating AI systems, these models are not designed for systematically identifying biases in raw text. As we later show, they fail to capture subtle social biases in texts, highlighting the need for dedicated evaluations and methods.</p>\n\n",
                "matched_terms": [
                    "biases",
                    "they"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section outlines the practical setup of our evaluation framework for analyzing the ability of LLMs to detect social biases in texts targeting different demographic groups. We first present the demographic-targeted taxonomy that underpins our framework, then describe how we adapt and integrate existing datasets for a holistic evaluation of bias detection. Finally, we detail the testbed we constructed to ensure comprehensive coverage of LLMs and detection methods.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "targeting",
                    "biases",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Prior evaluation studies are limited in scope: (i) they narrowly focus on specific content types (e.g., hate&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>)</cite>), (ii) adopt narrow context-specific taxonomies (e.g., subreddits&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kumar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib30\" title=\"\">2024</a>)</cite>), or (iii) consider only a small set of demographic axes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>. Hence, we lack a <em class=\"ltx_emph ltx_font_italic\">holistic view</em> of the current capabilities for detecting <em class=\"ltx_emph ltx_font_italic\">social biases</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Navigli et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib40\" title=\"\">2023</a>)</cite>, i.e., &#8220;prejudices, stereotypes, and discriminatory attitudes against certain groups&#8221; embedded in texts.</p>\n\n",
                "matched_terms": [
                    "demographic",
                    "axes",
                    "biases",
                    "they"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address the limitations, our framework employs a <em class=\"ltx_emph ltx_font_italic\">demographic-centered taxonomy</em> that identifies the demographic axes targeted by biased texts. This approach aligns directly with anti-discrimination regulations and governance measures&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(European Commission, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib13\" title=\"\">2025</a>)</cite>, while also enabling the study of <em class=\"ltx_emph ltx_font_italic\">multi-axis</em> biases: cases where texts simultaneously target multiple groups, an aspect often overlooked. Concretely, our taxonomy spans nine axes with differing legal recognition:</p>\n\n",
                "matched_terms": [
                    "multiaxis",
                    "multiple",
                    "axes",
                    "demographic",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Broad recognition</span>: <em class=\"ltx_emph ltx_font_italic\">Gender identity</em> (<span class=\"ltx_text ltx_font_typewriter\">GEN</span>), <em class=\"ltx_emph ltx_font_italic\">Sexual orientation</em> (<span class=\"ltx_text ltx_font_typewriter\">SO</span>), <em class=\"ltx_emph ltx_font_italic\">Disability</em> (<span class=\"ltx_text ltx_font_typewriter\">DIS</span>), <em class=\"ltx_emph ltx_font_italic\">Age</em> (<span class=\"ltx_text ltx_font_typewriter\">AGE</span>), <em class=\"ltx_emph ltx_font_italic\">Race/ethnicity</em> (<span class=\"ltx_text ltx_font_typewriter\">RAC</span>), <em class=\"ltx_emph ltx_font_italic\">Nationality</em> (<span class=\"ltx_text ltx_font_typewriter\">NAT</span>), and <em class=\"ltx_emph ltx_font_italic\">Religion</em> (<span class=\"ltx_text ltx_font_typewriter\">REL</span>), all widely protected&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Congress, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib7\" title=\"\">1964</a>; EU FRA, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib12\" title=\"\">2018</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "identity",
                    "rac",
                    "sexual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our taxonomy also considers a <em class=\"ltx_emph ltx_font_italic\">broad range of content types</em> encoding social biases through <em class=\"ltx_emph ltx_font_italic\">implicit harms</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Blodgett et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib3\" title=\"\">2020</a>)</cite>, including:\ni) <span class=\"ltx_text ltx_font_italic\">Stereotype descriptions</span> that stereotype, misrepresent, or disparage identities, ii) <span class=\"ltx_text ltx_font_italic\">Occupation&#8211;gender associations</span> that stereotype, erase, or exclude gender identities, and <span class=\"ltx_text ltx_font_italic\">Hate or toxic content</span> targeting demographics through toxicity, derogation, or dehumanization. However, by centering on <em class=\"ltx_emph ltx_font_italic\">demographic axes</em> rather than surface content types, we enable systematic characterization of which demographics are harmed, allow for analysis of multi-axis cases, and align directly with anti-discrimination and AI governance frameworks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(European Union, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib14\" title=\"\">2024</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "targeting",
                    "multiaxis",
                    "axes",
                    "demographic",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To enable comprehensive empirical evaluation in realistic settings, we adapt existing English datasets to align with our demographic-targeted social bias taxonomy. We surveyed widely used NLP datasets&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite>, prioritizing diversity across demographic axes and harm types. Unlike prior benchmarks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, which often rely on fully GPT-generated categories (e.g., toxic text), we minimize synthetic data to reduce evaluation artifacts&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Koo et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib28\" title=\"\">2024</a>; Maheshwari et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib35\" title=\"\">2024</a>)</cite>.<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>The only exception is ToxiGen, although it has human-annotated GPT text, unlike&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>.</span></span></span> Based on this review, we curated samples from <span class=\"ltx_text ltx_font_bold\">twelve</span> distinct datasets (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T1\" title=\"Table 1 &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).</p>\n\n",
                "matched_terms": [
                    "bias",
                    "axes",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Since some datasets were originally designed for evaluating generative biases, we applied minor adaptations similar to&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>. For StereoSet, we concatenate the context with the stereotype options. For BBQ, we construct text instances by pairing disambiguated contexts with answers. For CrowS-Pairs, we retain only the &#8220;more biased&#8221; sentences. For SBIC, we derive a single label using the majority vote across annotators. For ToxiGen, we label texts as biased only when human annotator scores indicate bias.</p>\n\n",
                "matched_terms": [
                    "single",
                    "biases",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We also observed inconsistencies in how demographic groups are labeled across datasets, so we standardized labels for consistency. For instance, bias against &#8220;Arabs&#8221; or &#8220;Middle Eastern&#8221; identities, labeled inconsistently as <span class=\"ltx_text ltx_font_typewriter\">RAC</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Nadeem et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib38\" title=\"\">2021</a>)</cite> or <span class=\"ltx_text ltx_font_typewriter\">REL</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Barikeri et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib1\" title=\"\">2021</a>)</cite>, is mapped to <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, reserving <span class=\"ltx_text ltx_font_typewriter\">REL</span> for explicit religious references. Biases against national identities such as &#8220;Chinese&#8221; or &#8220;Mexican&#8221; are assigned to <span class=\"ltx_text ltx_font_typewriter\">NAT</span>. Bias against &#8220;Jewish&#8221; identity is annotated as both <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">REL</span> to reflect its ethnoreligious nature&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Litt, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib32\" title=\"\">1961</a>)</cite>. We also improve regulatory alignment by disambiguating <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">SO</span> (e.g., transgender bias labeled as <span class=\"ltx_text ltx_font_typewriter\">GEN</span>) and denoting pregnancy-targeted bias under <span class=\"ltx_text ltx_font_typewriter\">GEN</span> rather than <span class=\"ltx_text ltx_font_typewriter\">PHY</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>)</cite>. Labels outside our taxonomy (e.g., <em class=\"ltx_emph ltx_font_italic\">victim</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sap et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib47\" title=\"\">2020</a>)</cite>) are excluded.</p>\n\n",
                "matched_terms": [
                    "labels",
                    "identity",
                    "sap",
                    "barikeri",
                    "rac",
                    "demographic",
                    "biases",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The resulting dataset contains <span class=\"ltx_text ltx_font_bold\">46,781</span> entries, substantially larger than comparable benchmarks (e.g., 11,004 samples in&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>). Biased instances are more prevalent (around 70%), with most targeting a single demographic axis and roughly 12% of biased instances targeting multiple axes simultaneously. Among demographic targets, <span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, <span class=\"ltx_text ltx_font_typewriter\">SO</span>, and <span class=\"ltx_text ltx_font_typewriter\">REL</span> are most common, while <span class=\"ltx_text ltx_font_typewriter\">PHY</span> is least prevalent. Multi-axis biases most frequently combine {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">SO</span>} or {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>}.</p>\n\n",
                "matched_terms": [
                    "targeting",
                    "multiaxis",
                    "rac",
                    "multiple",
                    "axes",
                    "demographic",
                    "single",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_citet\">Brown et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib4\" title=\"\">2020</a>)</cite> demonstrated that <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> LLMs can effectively perform a variety of tasks through textual prompting in <em class=\"ltx_emph ltx_font_italic\">zero-shot</em> scenarios. Following&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>; Palla et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib42\" title=\"\">2025</a>)</cite>, our evaluation framework employs <em class=\"ltx_emph ltx_font_italic\">policy-based</em> prompting for bias detection. Specifically, the prompt includes a policy detailing the bias detection task and our demographic-based social bias taxonomy. To enhance the bias detection capabilities within this prompting framework, we also assess the benefits of incorporating <em class=\"ltx_emph ltx_font_italic\">few-shot</em> examples for <em class=\"ltx_emph ltx_font_italic\">in-context learning</em>. Specifically, we utilize the retrieval-augmented (RAG) framework&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib5\" title=\"\">2024a</a>)</cite>, where an embedding model identifies the most <em class=\"ltx_emph ltx_font_italic\">relevant</em> in-context examples for each input instance from the training/development set.</p>\n\n",
                "matched_terms": [
                    "brown",
                    "bias",
                    "examples"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We also evaluate the effectiveness of aligning LLMs to the bias detection task through <em class=\"ltx_emph ltx_font_italic\">fine-tuning</em>. The task is framed as <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em> over the nine demographic axes. We solve it through sequence classification by attaching nine classifier nodes to a pre-trained LLM: to the [CLS] token for encoder-only models and to the final output token for decoder-only models.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "axes",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Because detection must perform reliably <em class=\"ltx_emph ltx_font_italic\">across all demographic axes</em>, our evaluation framework also explores the effectiveness of <em class=\"ltx_emph ltx_font_italic\">data reweighting</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kamiran and Calders, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib25\" title=\"\">2012</a>)</cite> to address imbalances. Let <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> denote the number of samples and <math alttext=\"\\mathcal{M}_{\\phi}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m2\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8499;</mi><mi>&#981;</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{M}_{\\phi}</annotation></semantics></math> the model. For a given instance <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m3\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>, its labels <math alttext=\"Y_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m4\" intent=\":literal\"><semantics><msub><mi>Y</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">Y_{i}</annotation></semantics></math> form a binary vector of length nine, where <math alttext=\"Y_{i}^{m}=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m5\" intent=\":literal\"><semantics><mrow><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">Y_{i}^{m}=1</annotation></semantics></math> if the demographic axis <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m6\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> is targeted and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m7\" intent=\":literal\"><mn>0</mn></math> otherwise. The weighted loss is defined as:</p>\n\n",
                "matched_terms": [
                    "labels",
                    "form",
                    "because",
                    "axes",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"\\alpha_{m}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m8\" intent=\":literal\"><semantics><msub><mi>&#945;</mi><mi>m</mi></msub><annotation encoding=\"application/x-tex\">\\alpha_{m}</annotation></semantics></math> balances across demographic axes, and <math alttext=\"w_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m9\" intent=\":literal\"><semantics><msub><mi>w</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">w_{i}</annotation></semantics></math> compensates for binary imbalances regarding biased and unbiased instances. All weights are derived from training data statistics.</p>\n\n",
                "matched_terms": [
                    "unbiased",
                    "axes",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our comprehensive framework uses metrics capturing three dimensions: (i) distinguishing <em class=\"ltx_emph ltx_font_italic\">biased vs. unbiased</em> text, (ii) accurate <em class=\"ltx_emph ltx_font_italic\">multi-label classification</em> of bias types, and (iii) ensuring <em class=\"ltx_emph ltx_font_italic\">parity</em> in detection performance across demographic axes and for multi-targeted texts compared to single-targeted texts.</p>\n\n",
                "matched_terms": [
                    "unbiased",
                    "bias",
                    "axes",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Binary bias detection.</span>\nWe reduce the multi-label task to a binary one by defining\nground-truth labels <math alttext=\"Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.SS4.p3.m1\" intent=\":literal\"><semantics><mrow><msub><mi>Y</mi><msub><mi>B</mi><mi>i</mi></msub></msub><mo>=</mo><mn>1</mn><mo>&#8722;</mo><mi>&#120128;</mi><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>0</mn><mo>,</mo><mo>,</mo><mo rspace=\"0.167em\">&#8704;</mo><mi>m</mi><mo>&#8712;</mo><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><mn>9</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]</annotation></semantics></math>, with predictions <math alttext=\"\\hat{Y}_{B_{i}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m2\" intent=\":literal\"><semantics><msub><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><msub><mi>B</mi><mi>i</mi></msub></msub><annotation encoding=\"application/x-tex\">\\hat{Y}_{B_{i}}</annotation></semantics></math> defined analogously. A value of <math alttext=\"1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m3\" intent=\":literal\"><semantics><mn>1</mn><annotation encoding=\"application/x-tex\">1</annotation></semantics></math> indicates the presence of any bias, and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m4\" intent=\":literal\"><mn>0</mn></math> indicates none. On these binary labels, we report <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m5\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, false positive rate (FPR), and false negative rate (FNR).</p>\n\n",
                "matched_terms": [
                    "labels",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Detection disparities.</span>\nOur evaluation also examines whether LLMs not only detect social biases accurately but also exhibit systematic performance gaps across different demographic targets. Given <math alttext=\"\\mathcal{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p5.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><annotation encoding=\"application/x-tex\">\\mathcal{P}</annotation></semantics></math> denotes FPR or FNR, we analyze disparities in the following scenarios:</p>\n\n",
                "matched_terms": [
                    "biases",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-demographic.</span> Following predictive fairness&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Hardt et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib19\" title=\"\">2016</a>; Zafar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib60\" title=\"\">2017</a>)</cite>, we compute the <em class=\"ltx_emph ltx_font_italic\">maximum absolute error gap</em>, i.e., <span class=\"ltx_text ltx_font_italic\">overall detection disparity</span> across <span class=\"ltx_text ltx_font_italic\">individual</span> demographic axes:\n<math alttext=\"\\Delta_{\\mathcal{P}}=\\underset{m,m^{\\prime}}{\\text{max}}\\big|\\mathcal{P}_{m}-\\mathcal{P}_{m^{\\prime}}\\big|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.I3.i1.p1.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi></msub><mo>=</mo><mrow><munder accentunder=\"true\"><mtext>max</mtext><mrow><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup></mrow></munder><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mi>m</mi></msub><mo>&#8722;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><msup><mi>m</mi><mo>&#8242;</mo></msup></msub></mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\mathcal{P}}=\\underset{m,m^{\\prime}}{\\text{max}}\\big|\\mathcal{P}_{m}-\\mathcal{P}_{m^{\\prime}}\\big|</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "axes",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-demographic.</span> Inspired by&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite>, we measure if the models make systematically more errors in detecting biases that <em class=\"ltx_emph ltx_font_italic\">specifically</em> target <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em> (e.g., {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}) relative to biases that target <span class=\"ltx_text ltx_font_italic\">each constituent axis</span> (e.g., only <span class=\"ltx_text ltx_font_typewriter\">GEN</span> or <span class=\"ltx_text ltx_font_typewriter\">RAC</span>).\n<math alttext=\"\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.I3.i2.p1.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>=</mo><mrow><munder accentunder=\"true\"><mi>max</mi><mrow><mi>x</mi><mo>&#8712;</mo><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></mrow></munder><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msub><mo>&#8722;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mi>x</mi></msub></mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|</annotation></semantics></math>. This measure helps us understand if the FPR or FNR of multi-axis targeted biased instances is markedly higher, indicating potential blind spots for automated bias detection methods.</p>\n\n",
                "matched_terms": [
                    "genrac",
                    "multiaxis",
                    "rac",
                    "multiple",
                    "make",
                    "axes",
                    "biases",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section illustrates how our comprehensive evaluation study enables the practical assessment of LLM-based methods for detecting demographic-targeted social biases in text. Our analysis reveals both the strengths and current limitations of these approaches. For rigorous assessment of the overall results, we perform 1,000 bootstrap samples with replacement on the combined test set to compute 95% confidence intervals. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> presents a detailed comparison of prompting and fine-tuning, reporting both binary performance (biased vs. unbiased) and multi-label categorization. We also report median inference time (in milliseconds) for each text instance. Moreover, for more fine-grained analysis, Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> reports bias detection performance of select prompted and fine-tuned LLMs for the twelve constituent datasets.</p>\n\n",
                "matched_terms": [
                    "unbiased",
                    "biases",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">In-context learning substantially improves detection.</span> Across all models, providing few-shot examples consistently boosts binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, lowers FNR, and increases multi-label metrics (MR, HL, <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>). Gains are significant with as few as five examples, while moving from five to ten shots yields only marginal improvements. However, inference time grows with the number of examples, highlighting the accuracy&#8211;efficiency tradeoff in prompting. Beyond the reported results, we also analyzed alternative in-context setups (in the appendix). We found that (i) RAG-based example selection outperforms random sampling, and (ii) alternative embeddings&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Youdao, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib59\" title=\"\">2023</a>)</cite> yield comparable results.</p>\n\n",
                "matched_terms": [
                    "example",
                    "examples"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Guardrail models transfer poorly.</span> Llama Guard, fine-tuned for moderation, consistently underperforms instruction-tuned models of similar size (e.g., Llama-3.1-8B), achieving the lowest binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> and highest FNR. While effective at detecting overt hate speech, it fails to capture subtler biases like stereotypes.</p>\n\n",
                "matched_terms": [
                    "like",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> shows how fine-tuned models achieve stronger binary detection across most datasets compared to prompting-based LLMs. Encoder models (DeBERTa) generally outperform decoder-only GPT-2, which remains competitive on many datasets but struggles with subtle stereotype cases, e.g, RedditBias and Winogender. For multi-label detection, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> shows consistently lower HL, indicating more accurate detection of demographic axes targeted.</p>\n\n",
                "matched_terms": [
                    "axes",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use our evaluation framework to examine <em class=\"ltx_emph ltx_font_italic\">potential disparities</em> in social bias detection across models and setups with respect to targeted demographic axes. While the previous analysis provided a global view of model performance, this section focuses on <em class=\"ltx_emph ltx_font_italic\">systematic differences</em> in how effectively models detect biases. We first analyze disparities for individual demographic axes. Next, owing to our multi-label setup, we evaluate model performances on instances targeting <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em>, highlighting current capabilities in detecting multi-targeted biases. We provide the comprehensive disparity analysis in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S5.T5\" title=\"Table 5 &#8227; 5 Evaluating detection disparities &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>.</p>\n\n",
                "matched_terms": [
                    "targeting",
                    "multiple",
                    "axes",
                    "demographic",
                    "biases",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We assess systemic performance disparities using <math alttext=\"\\Delta_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p1.m1\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}</annotation></semantics></math> and <math alttext=\"\\Delta_{\\text{FPR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p1.m2\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}</annotation></semantics></math>, which measure the maximum performance gaps across the nine social bias demographic target axes in our taxonomy.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "axes",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nPrompting, even with larger models and few-shot examples, shows substantial per-axis disparities. Fine-tuned models, particularly with reweighted loss, achieve more balanced performance, although notable gaps remain. In additional analyses (in the appendix), we examined <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across the nine demographic axes. We found that certain targets, such as <span class=\"ltx_text ltx_font_typewriter\">NAT</span> and <span class=\"ltx_text ltx_font_typewriter\">PHY</span>, consistently have lower detection accuracy, which contributes to the observed disparities.</p>\n\n",
                "matched_terms": [
                    "demographic",
                    "axes",
                    "examples"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We now analyze texts targeting <span class=\"ltx_text ltx_font_italic\">multiple axes simultaneously</span>, focusing on {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>} and {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}. We compare performance on these multi-axis instances to that on the instances that target only constituent single axes (e.g., only <span class=\"ltx_text ltx_font_typewriter\">GEN</span> or <span class=\"ltx_text ltx_font_typewriter\">SO</span> for {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>}).</p>\n\n",
                "matched_terms": [
                    "genrac",
                    "targeting",
                    "multiaxis",
                    "multiple",
                    "axes",
                    "single"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Prompting improves with scale and few-shot examples.</span> Few-shot prompting substantially narrows multi-axis gaps. For Llama-3.1-70B, <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m1\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}</annotation></semantics></math> drops from 0.736 (zero-shot) to 0.164 (10-shot), and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m2\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}</annotation></semantics></math> from 0.262 to 0.088. Larger models benefit more from in-context learning: Llama-3.1-70B outperforms Llama-3.1-8B, and disparities are generally higher for {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>} than {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}.</p>\n\n",
                "matched_terms": [
                    "genrac",
                    "examples",
                    "multiaxis"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuned models show persistent gaps.</span> Despite strong per-axis parity, fine-tuned models underperform on multi-axis instances, reflecting <em class=\"ltx_emph ltx_font_italic\">gerrymandering</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite> in their detection performance. For example, RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> with reweighting achieves <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.436</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436</annotation></semantics></math> and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m2\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.373</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373</annotation></semantics></math>, higher than few-shot Llama-3.1-70B and Qwen-2.5-72B. Encoder models outperform GPT-2, and scaling improves parity (e.g., DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> at <math alttext=\"\\approx 0.28\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m3\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8776;</mo><mn>0.28</mn></mrow><annotation encoding=\"application/x-tex\">\\approx 0.28</annotation></semantics></math> vs. DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> at 0.39 for FNR regarding {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>}). As with per-axis results, reweighting reduces FNR gaps but can slightly raise FPR gaps.</p>\n\n",
                "matched_terms": [
                    "example",
                    "multiaxis"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nDetecting multi-demographic biases remains particularly difficult for LLM-based methods. Fine-tuned models achieve relatively low disparities regarding single axes but struggle with biases targeting multiple demographics. These results highlight intersectional disparities as an important direction for future research.</p>\n\n",
                "matched_terms": [
                    "targeting",
                    "multiple",
                    "axes",
                    "single",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Inclusive stakeholder input.</span>\nAutomation enables large-scale auditing while minimizing human exposure to harmful content&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Steiger et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib49\" title=\"\">2021</a>)</cite>. However, bias detection remains a <em class=\"ltx_emph ltx_font_italic\">socio-technical challenge</em>: social biases are culturally situated, and the detection pipeline must be guided by participatory processes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Markov et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib36\" title=\"\">2023</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "biases",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Data coverage.</span>\nOur evaluation relies mainly on English datasets reflecting global North contexts, which limits generalizability to other languages and regions. Progress will require multilingual and cross-lingual benchmarks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Corazza et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib8\" title=\"\">2020</a>; Huang and Xiong, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib22\" title=\"\">2023</a>; Neplenbroek et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib41\" title=\"\">2024</a>)</cite>, methods adapted for low-resource settings, and attention to language-specific biases that may not align with English-centric taxonomies. Dataset diversity should also ensure sufficient coverage of social biases that may exist in different cultural contexts. Coverage should also extend to more categories, e.g., political beliefs and biases encoded across multiple data modalities.</p>\n\n",
                "matched_terms": [
                    "multiple",
                    "biases"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methodological opportunities.</span>\nOur findings highlight both promises and existing limitations of scalable automated bias detection. Future work should further explore advanced prompting (e.g., <span class=\"ltx_text ltx_font_italic\">chain-of-thought</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wei et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib56\" title=\"\">2022</a>)</cite>) and efficient fine-tuning (e.g., using adapters). To handle multimodal data, exploring effective and scalable solutions remains an interesting open challenge. Moreover, while our results offer initial guidance, balancing the potential gains from training and deploying larger models and the scalability required for auditing massive corpora warrants deeper exploration. Finally, our study shows that detecting infrequent, subtle, and multi-axis biases remains a crucial underexplored direction for future research.</p>\n\n",
                "matched_terms": [
                    "biases",
                    "bias",
                    "multiaxis"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Text statistics.</span>\nIn Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F1.sf1\" title=\"In Figure 1 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1(a)</span></a>, we show the token count distribution for all the bias categories, including the <em class=\"ltx_emph ltx_font_italic\">unbiased</em> texts. To obtain tokens, we use the RoBERTa tokenizer. We see that the token counts for each text instance are generally low, indicating our dataset mainly contains short text instances. However, there are some outliers, e.g., in <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">SO</span>, where we see around 400 token length texts. Upon inspection, we observed that such instances primarily come from the BBQ dataset, that have very long context texts.</p>\n\n",
                "matched_terms": [
                    "unbiased",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Label statistics.</span>\nIn Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F2\" title=\"Figure 2 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, we visualize the label statistics in the final curated dataset. The visualizations show label imbalances in the data, highlighting the need for weighted loss for optimization and motivating future work to explore further fairness interventions to ensure equitable bias detection performance. The statistics show that our data contains more biased instances than unbiased ones. Furthermore, we see that most instances target a single demographic axis. However, many instances target two axes. Instances targeting more than two demographic axes are significantly fewer in our dataset. We provide more detailed label co-occurrence statistics in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F1.sf2\" title=\"In Figure 1 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1(b)</span></a>. The figure shows that text instances target specific demographics more often. For instance, texts target <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">GEN</span> more often. Similarly, texts target <span class=\"ltx_text ltx_font_typewriter\">DIS</span>,<span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">PHY</span> relatively less often. Furthermore, we see that <span class=\"ltx_text ltx_font_typewriter\">GEN</span> co-occurs with many other demographic axes, e.g., <span class=\"ltx_text ltx_font_typewriter\">SO</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, and <span class=\"ltx_text ltx_font_typewriter\">DIS</span>. Note that while <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">REL</span> appear together frequently, many of these instances simply target &#8220;Jewish identities.&#8221;</p>\n\n",
                "matched_terms": [
                    "unbiased",
                    "targeting",
                    "rac",
                    "axes",
                    "demographic",
                    "single",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All LLMs are accessed via API through an MLOps platform. We fix <span class=\"ltx_text ltx_font_typewriter\">temperature</span> to 0 and <span class=\"ltx_text ltx_font_typewriter\">top_p</span> to 1, ensuring deterministic outputs by selecting the model&#8217;s most likely generation while still allowing consideration of the full token space. For in-context learning, we embed the training and development sets using BGE-M3 or BCEmbedding models. At inference time, we compute cosine similarity between the query and development set vectors to retrieve the top-<math alttext=\"K\" class=\"ltx_Math\" display=\"inline\" id=\"A2.SS1.p1.m1\" intent=\":literal\"><semantics><mi>K</mi><annotation encoding=\"application/x-tex\">K</annotation></semantics></math> few-shot examples. As a baseline, we also apply a random few-shot selection from the training set, with balanced sampling between biased and unbiased texts. Model predictions are extracted via pattern matching. Responses that cannot be parsed through pattern matching to assign to one of the multiple demographic axes are marked as &#8220;invalid.&#8221; The <span class=\"ltx_text ltx_font_italic\">social bias policy</span> used in the text prompt is shown here.</p>\n\n",
                "matched_terms": [
                    "unbiased",
                    "bias",
                    "multiple",
                    "axes",
                    "demographic",
                    "examples"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate the impact of retrieval-augmented generation (RAG) on few-shot example selection compared to random sampling. Results are presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.T6\" title=\"Table 6 &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>. Overall, RAG consistently enhances bias detection performance.</p>\n\n",
                "matched_terms": [
                    "example",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">BGE-M3 exhibits a slight but consistent advantage in binary bias detection, producing marginally higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across multiple LLMs. However, the overall differences are minimal. In contrast, for multi-label prediction, BCEmbedding performs slightly better on metrics such as MR for many models. This finding suggests that while both embedding models select examples that yield similar overall outcomes, subtle differences exist. Specifically, BGE-M3-selected examples tend to improve binary bias detection by helping models better distinguish biased from unbiased samples, whereas BCEmbedding-selected examples slightly enhance the detection of specific bias types within biased instances.</p>\n\n",
                "matched_terms": [
                    "multiple",
                    "bias",
                    "unbiased",
                    "examples"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We now analyze model performance across different demographic targets. Specifically, we examine the <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p1.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores for all demographic axes in our taxonomy that may be subject to bias. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F5\" title=\"Figure 5 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents results for various prompted models using <em class=\"ltx_emph ltx_font_italic\">10-shot RAG-based in-context learning</em> with BGE-M3, while Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F6\" title=\"Figure 6 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> compares fine-tuned models and explores the impact of reweighted loss (&#8220;bal&#8221; in the figure) across demographics.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "axes",
                    "demographic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Among the prompted LLMs, Llama-3.1-70B achieves the highest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p3.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across nearly all bias categories, except for <span class=\"ltx_text ltx_font_typewriter\">GEN</span>, where GLM-9B&#8212;despite being much smaller&#8212;slightly outperforms it. Interestingly, Qwen-2.5-72B, though the largest LLM, performs worse in many low-frequency categories such as <span class=\"ltx_text ltx_font_typewriter\">DIS</span>, <span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">SES</span>. It performs comparably to the best prompting models only for <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, which are the most common categories in the benchmark.</p>\n\n",
                "matched_terms": [
                    "rac",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For fine-tuned models, encoder-only architectures (e.g., RoBERTa and DeBERTa) generally outperform decoder-only language models, i.e., GPT-2, across most demographic axes. The trends mirror those observed in the prompting setup: models achieve their best performance for <span class=\"ltx_text ltx_font_typewriter\">SES</span>, while <span class=\"ltx_text ltx_font_typewriter\">NAT</span> consistently shows the lowest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. Reweighted loss often improves detection performance or yields similar results to the default loss. For example, in <span class=\"ltx_text ltx_font_typewriter\">NAT</span>, the axis that suffered from the weakest detection performance, reweighted loss improves performance across all models. However, improvements are not universal. For instance, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">large</span> experiences slight declines in <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> for some demographics such as <span class=\"ltx_text ltx_font_typewriter\">AGE</span> and <span class=\"ltx_text ltx_font_typewriter\">SES</span> when reweighted loss is applied.</p>\n\n",
                "matched_terms": [
                    "demographic",
                    "example",
                    "axes"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">These findings provide additional insight into the <em class=\"ltx_emph ltx_font_italic\">disparity results</em> discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S5\" title=\"5 Evaluating detection disparities &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, which highlight performance gaps across demographic axes. This deeper analysis underscores the need to develop <em class=\"ltx_emph ltx_font_italic\">more nuanced methods</em> that can mitigate detection disparities without substantially compromising overall performance.</p>\n\n",
                "matched_terms": [
                    "axes",
                    "demographic"
                ]
            }
        ]
    },
    "S3.T3": {
        "caption": "Table 3: Bias detection using prompting (zero-shot or in-context) and fine-tuning (default unw. or reweighted rew. prediction loss). Binary indicates unbiased (negative) vs biased (positive) detection. Other measures are for multi-label bias prediction of bias targets. For MR and F1F_{1} scores, higher is better; for HL, FPR, and FNR, lower is better. Time: median inference time in milliseconds.",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Setup</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Binary prediction</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Multi-label prediction</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Time</span></th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m3\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">FPR</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">FNR</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">MR</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">HL</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m4\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m5\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"15\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">\n<span class=\"ltx_inline-block ltx_parbox ltx_align_top\" style=\"width:5.7pt;\">\n<span class=\"ltx_p\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:8.8pt;height:46.9pt;vertical-align:-21.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:46.8pt;transform:translate(-19.0pt,-19.0pt) rotate(-90deg) ;\">\n<span class=\"ltx_p\">Prompting</span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Llama Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">0-shot</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"68.94_{\\pm 0.71}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m6\" intent=\":literal\"><semantics><msub><mn>68.94</mn><mrow><mo>&#177;</mo><mn>0.71</mn></mrow></msub><annotation encoding=\"application/x-tex\">68.94_{\\pm 0.71}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.184_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m7\" intent=\":literal\"><semantics><msub><mn>0.184</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.184_{\\pm 0.011}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.440_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m8\" intent=\":literal\"><semantics><msub><mn>0.440</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.440_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.372_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m9\" intent=\":literal\"><semantics><msub><mn>0.372</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.372_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.085_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m10\" intent=\":literal\"><semantics><msub><mn>0.085</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.085_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"54.68_{\\pm 0.80}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m11\" intent=\":literal\"><semantics><msub><mn>54.68</mn><mrow><mo>&#177;</mo><mn>0.80</mn></mrow></msub><annotation encoding=\"application/x-tex\">54.68_{\\pm 0.80}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"38.69_{\\pm 1.62}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m12\" intent=\":literal\"><semantics><msub><mn>38.69</mn><mrow><mo>&#177;</mo><mn>1.62</mn></mrow></msub><annotation encoding=\"application/x-tex\">38.69_{\\pm 1.62}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">305</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5-shot</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.16_{\\pm 0.64}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m13\" intent=\":literal\"><semantics><msub><mn>75.16</mn><mrow><mo>&#177;</mo><mn>0.64</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.16_{\\pm 0.64}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.192_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m14\" intent=\":literal\"><semantics><msub><mn>0.192</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.192_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.358_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m15\" intent=\":literal\"><semantics><msub><mn>0.358</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.358_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.485_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m16\" intent=\":literal\"><semantics><msub><mn>0.485</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.485_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.067_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m17\" intent=\":literal\"><semantics><msub><mn>0.067</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.067_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"65.66_{\\pm 0.68}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m18\" intent=\":literal\"><semantics><msub><mn>65.66</mn><mrow><mo>&#177;</mo><mn>0.68</mn></mrow></msub><annotation encoding=\"application/x-tex\">65.66_{\\pm 0.68}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"46.24_{\\pm 1.87}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m19\" intent=\":literal\"><semantics><msub><mn>46.24</mn><mrow><mo>&#177;</mo><mn>1.87</mn></mrow></msub><annotation encoding=\"application/x-tex\">46.24_{\\pm 1.87}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">354</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10-shot</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.17_{\\pm 0.64}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m20\" intent=\":literal\"><semantics><msub><mn>75.17</mn><mrow><mo>&#177;</mo><mn>0.64</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.17_{\\pm 0.64}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.186_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m21\" intent=\":literal\"><semantics><msub><mn>0.186</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.186_{\\pm 0.011}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.359_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m22\" intent=\":literal\"><semantics><msub><mn>0.359</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.359_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.486_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m23\" intent=\":literal\"><semantics><msub><mn>0.486</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.486_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.067_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m24\" intent=\":literal\"><semantics><msub><mn>0.067</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.067_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"65.79_{\\pm 0.69}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m25\" intent=\":literal\"><semantics><msub><mn>65.79</mn><mrow><mo>&#177;</mo><mn>0.69</mn></mrow></msub><annotation encoding=\"application/x-tex\">65.79_{\\pm 0.69}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"44.68_{\\pm 1.82}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m26\" intent=\":literal\"><semantics><msub><mn>44.68</mn><mrow><mo>&#177;</mo><mn>1.82</mn></mrow></msub><annotation encoding=\"application/x-tex\">44.68_{\\pm 1.82}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">371</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Llama-3.1-8B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">0-shot</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.72_{\\pm 0.45}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m27\" intent=\":literal\"><semantics><msub><mn>83.72</mn><mrow><mo>&#177;</mo><mn>0.45</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.72_{\\pm 0.45}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.686_{\\pm 0.013}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m28\" intent=\":literal\"><semantics><msub><mn>0.686</mn><mrow><mo>&#177;</mo><mn>0.013</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.686_{\\pm 0.013}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.108_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m29\" intent=\":literal\"><semantics><msub><mn>0.108</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.108_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.046_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m30\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.202_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m31\" intent=\":literal\"><semantics><msub><mn>0.202</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.202_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"49.17_{\\pm 0.47}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m32\" intent=\":literal\"><semantics><msub><mn>49.17</mn><mrow><mo>&#177;</mo><mn>0.47</mn></mrow></msub><annotation encoding=\"application/x-tex\">49.17_{\\pm 0.47}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"36.01_{\\pm 0.60}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m33\" intent=\":literal\"><semantics><msub><mn>36.01</mn><mrow><mo>&#177;</mo><mn>0.60</mn></mrow></msub><annotation encoding=\"application/x-tex\">36.01_{\\pm 0.60}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">307</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5-shot</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.27_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m34\" intent=\":literal\"><semantics><msub><mn>87.27</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.27_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.752_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m35\" intent=\":literal\"><semantics><msub><mn>0.752</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.752_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.023_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m36\" intent=\":literal\"><semantics><msub><mn>0.023</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.023_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.411_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m37\" intent=\":literal\"><semantics><msub><mn>0.411</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.411_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.140_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m38\" intent=\":literal\"><semantics><msub><mn>0.140</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.140_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"62.19_{\\pm 0.68}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m39\" intent=\":literal\"><semantics><msub><mn>62.19</mn><mrow><mo>&#177;</mo><mn>0.68</mn></mrow></msub><annotation encoding=\"application/x-tex\">62.19_{\\pm 0.68}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"44.58_{\\pm 0.73}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m40\" intent=\":literal\"><semantics><msub><mn>44.58</mn><mrow><mo>&#177;</mo><mn>0.73</mn></mrow></msub><annotation encoding=\"application/x-tex\">44.58_{\\pm 0.73}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">359</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10-shot</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.47_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m41\" intent=\":literal\"><semantics><msub><mn>87.47</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.47_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.746_{\\pm 0.013}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m42\" intent=\":literal\"><semantics><msub><mn>0.746</mn><mrow><mo>&#177;</mo><mn>0.013</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.746_{\\pm 0.013}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.021_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m43\" intent=\":literal\"><semantics><msub><mn>0.021</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.021_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.501_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m44\" intent=\":literal\"><semantics><msub><mn>0.501</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.501_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.127_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m45\" intent=\":literal\"><semantics><msub><mn>0.127</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.127_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"64.69_{\\pm 0.70}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m46\" intent=\":literal\"><semantics><msub><mn>64.69</mn><mrow><mo>&#177;</mo><mn>0.70</mn></mrow></msub><annotation encoding=\"application/x-tex\">64.69_{\\pm 0.70}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"45.96_{\\pm 0.82}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m47\" intent=\":literal\"><semantics><msub><mn>45.96</mn><mrow><mo>&#177;</mo><mn>0.82</mn></mrow></msub><annotation encoding=\"application/x-tex\">45.96_{\\pm 0.82}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">378</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">GLM-4-9B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">0-shot</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.65_{\\pm 0.45}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m48\" intent=\":literal\"><semantics><msub><mn>83.65</mn><mrow><mo>&#177;</mo><mn>0.45</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.65_{\\pm 0.45}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.769_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m49\" intent=\":literal\"><semantics><msub><mn>0.769</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.769_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.089_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m50\" intent=\":literal\"><semantics><msub><mn>0.089</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.089_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.373_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m51\" intent=\":literal\"><semantics><msub><mn>0.373</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.373_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.104_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m52\" intent=\":literal\"><semantics><msub><mn>0.104</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.104_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"62.23_{\\pm 0.60}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m53\" intent=\":literal\"><semantics><msub><mn>62.23</mn><mrow><mo>&#177;</mo><mn>0.60</mn></mrow></msub><annotation encoding=\"application/x-tex\">62.23_{\\pm 0.60}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"49.96_{\\pm 1.60}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m54\" intent=\":literal\"><semantics><msub><mn>49.96</mn><mrow><mo>&#177;</mo><mn>1.60</mn></mrow></msub><annotation encoding=\"application/x-tex\">49.96_{\\pm 1.60}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">331</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5-shot</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.10_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m55\" intent=\":literal\"><semantics><msub><mn>87.10</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.10_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.774_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m56\" intent=\":literal\"><semantics><msub><mn>0.774</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.774_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.021_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m57\" intent=\":literal\"><semantics><msub><mn>0.021</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.021_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.773_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m58\" intent=\":literal\"><semantics><msub><mn>0.773</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.773_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.036_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m59\" intent=\":literal\"><semantics><msub><mn>0.036</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.036_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"85.95_{\\pm 0.50}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m60\" intent=\":literal\"><semantics><msub><mn>85.95</mn><mrow><mo>&#177;</mo><mn>0.50</mn></mrow></msub><annotation encoding=\"application/x-tex\">85.95_{\\pm 0.50}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"73.43_{\\pm 1.69}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m61\" intent=\":literal\"><semantics><msub><mn>73.43</mn><mrow><mo>&#177;</mo><mn>1.69</mn></mrow></msub><annotation encoding=\"application/x-tex\">73.43_{\\pm 1.69}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">351</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10-shot</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"86.98_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m62\" intent=\":literal\"><semantics><msub><mn>86.98</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">86.98_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.775_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m63\" intent=\":literal\"><semantics><msub><mn>0.775</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.775_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.023_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m64\" intent=\":literal\"><semantics><msub><mn>0.023</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.023_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.782_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m65\" intent=\":literal\"><semantics><msub><mn>0.782</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.782_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.034_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m66\" intent=\":literal\"><semantics><msub><mn>0.034</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.034_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"86.74_{\\pm 0.48}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m67\" intent=\":literal\"><semantics><msub><mn>86.74</mn><mrow><mo>&#177;</mo><mn>0.48</mn></mrow></msub><annotation encoding=\"application/x-tex\">86.74_{\\pm 0.48}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.46_{\\pm 1.68}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m68\" intent=\":literal\"><semantics><msub><mn>75.46</mn><mrow><mo>&#177;</mo><mn>1.68</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.46_{\\pm 1.68}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">385</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">0-shot</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.43_{\\pm 0.49}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m69\" intent=\":literal\"><semantics><msub><mn>83.43</mn><mrow><mo>&#177;</mo><mn>0.49</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.43_{\\pm 0.49}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.527_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m70\" intent=\":literal\"><semantics><msub><mn>0.527</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.527_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.153_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m71\" intent=\":literal\"><semantics><msub><mn>0.153</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.153_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.275_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m72\" intent=\":literal\"><semantics><msub><mn>0.275</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.275_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.098_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m73\" intent=\":literal\"><semantics><msub><mn>0.098</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.098_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"66.46_{\\pm 0.48}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m74\" intent=\":literal\"><semantics><msub><mn>66.46</mn><mrow><mo>&#177;</mo><mn>0.48</mn></mrow></msub><annotation encoding=\"application/x-tex\">66.46_{\\pm 0.48}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"55.66_{\\pm 1.34}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m75\" intent=\":literal\"><semantics><msub><mn>55.66</mn><mrow><mo>&#177;</mo><mn>1.34</mn></mrow></msub><annotation encoding=\"application/x-tex\">55.66_{\\pm 1.34}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">545</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5-shot</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"88.49_{\\pm 0.38}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m76\" intent=\":literal\"><semantics><msub><mn>88.49</mn><mrow><mo>&#177;</mo><mn>0.38</mn></mrow></msub><annotation encoding=\"application/x-tex\">88.49_{\\pm 0.38}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.581_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m77\" intent=\":literal\"><semantics><msub><mn>0.581</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.581_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.046_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m78\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.657_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m79\" intent=\":literal\"><semantics><msub><mn>0.657</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.657_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.046_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m80\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.28_{\\pm 0.42}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m81\" intent=\":literal\"><semantics><msub><mn>83.28</mn><mrow><mo>&#177;</mo><mn>0.42</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.28_{\\pm 0.42}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"73.16_{\\pm 1.36}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m82\" intent=\":literal\"><semantics><msub><mn>73.16</mn><mrow><mo>&#177;</mo><mn>1.36</mn></mrow></msub><annotation encoding=\"application/x-tex\">73.16_{\\pm 1.36}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">583</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10-shot</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"88.82_{\\pm 0.39}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m83\" intent=\":literal\"><semantics><msub><mn>88.82</mn><mrow><mo>&#177;</mo><mn>0.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">88.82_{\\pm 0.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.557_{\\pm 0.015}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m84\" intent=\":literal\"><semantics><msub><mn>0.557</mn><mrow><mo>&#177;</mo><mn>0.015</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.557_{\\pm 0.015}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.046_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m85\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.648_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m86\" intent=\":literal\"><semantics><msub><mn>0.648</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.648_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.047_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m87\" intent=\":literal\"><semantics><msub><mn>0.047</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.047_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.08_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m88\" intent=\":literal\"><semantics><msub><mn>83.08</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.08_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.07_{\\pm 1.39}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m89\" intent=\":literal\"><semantics><msub><mn>75.07</mn><mrow><mo>&#177;</mo><mn>1.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.07_{\\pm 1.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">591</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Qwen-2.5-72B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">0-shot</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"82.20_{\\pm 0.47}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m90\" intent=\":literal\"><semantics><msub><mn>82.20</mn><mrow><mo>&#177;</mo><mn>0.47</mn></mrow></msub><annotation encoding=\"application/x-tex\">82.20_{\\pm 0.47}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.687_{\\pm 0.013}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m91\" intent=\":literal\"><semantics><msub><mn>0.687</mn><mrow><mo>&#177;</mo><mn>0.013</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.687_{\\pm 0.013}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.136_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m92\" intent=\":literal\"><semantics><msub><mn>0.136</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.136_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.126_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m93\" intent=\":literal\"><semantics><msub><mn>0.126</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.126_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.208_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m94\" intent=\":literal\"><semantics><msub><mn>0.208</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.208_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"49.31_{\\pm 0.50}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m95\" intent=\":literal\"><semantics><msub><mn>49.31</mn><mrow><mo>&#177;</mo><mn>0.50</mn></mrow></msub><annotation encoding=\"application/x-tex\">49.31_{\\pm 0.50}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"37.87_{\\pm 0.55}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m96\" intent=\":literal\"><semantics><msub><mn>37.87</mn><mrow><mo>&#177;</mo><mn>0.55</mn></mrow></msub><annotation encoding=\"application/x-tex\">37.87_{\\pm 0.55}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">548</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5-shot</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.24_{\\pm 0.39}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m97\" intent=\":literal\"><semantics><msub><mn>87.24</mn><mrow><mo>&#177;</mo><mn>0.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.24_{\\pm 0.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.551_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m98\" intent=\":literal\"><semantics><msub><mn>0.551</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.551_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.078_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m99\" intent=\":literal\"><semantics><msub><mn>0.078</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.078_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.583_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m100\" intent=\":literal\"><semantics><msub><mn>0.583</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.583_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.065_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m101\" intent=\":literal\"><semantics><msub><mn>0.065</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.065_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"77.33_{\\pm 0.55}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m102\" intent=\":literal\"><semantics><msub><mn>77.33</mn><mrow><mo>&#177;</mo><mn>0.55</mn></mrow></msub><annotation encoding=\"application/x-tex\">77.33_{\\pm 0.55}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"60.44_{\\pm 1.15}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m103\" intent=\":literal\"><semantics><msub><mn>60.44</mn><mrow><mo>&#177;</mo><mn>1.15</mn></mrow></msub><annotation encoding=\"application/x-tex\">60.44_{\\pm 1.15}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">584</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10-shot</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.38_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m104\" intent=\":literal\"><semantics><msub><mn>87.38</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.38_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.552_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m105\" intent=\":literal\"><semantics><msub><mn>0.552</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.552_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.075_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m106\" intent=\":literal\"><semantics><msub><mn>0.075</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.075_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.600_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m107\" intent=\":literal\"><semantics><msub><mn>0.600</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.600_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.060_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m108\" intent=\":literal\"><semantics><msub><mn>0.060</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.060_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"78.94_{\\pm 0.52}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m109\" intent=\":literal\"><semantics><msub><mn>78.94</mn><mrow><mo>&#177;</mo><mn>0.52</mn></mrow></msub><annotation encoding=\"application/x-tex\">78.94_{\\pm 0.52}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"63.00_{\\pm 1.19}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m110\" intent=\":literal\"><semantics><msub><mn>63.00</mn><mrow><mo>&#177;</mo><mn>1.19</mn></mrow></msub><annotation encoding=\"application/x-tex\">63.00_{\\pm 1.19}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">630</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"12\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">\n<span class=\"ltx_inline-block ltx_parbox ltx_align_top\" style=\"width:5.7pt;\">\n<span class=\"ltx_p\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:8.8pt;height:50.9pt;vertical-align:-23.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:51.0pt;transform:translate(-21.1pt,-21.1pt) rotate(-90deg) ;\">\n<span class=\"ltx_p\">Fine-tuning</span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"90.80_{\\pm 0.33}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m111\" intent=\":literal\"><semantics><msub><mn>90.80</mn><mrow><mo>&#177;</mo><mn>0.33</mn></mrow></msub><annotation encoding=\"application/x-tex\">90.80_{\\pm 0.33}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.299_{\\pm 0.013}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m112\" intent=\":literal\"><semantics><msub><mn>0.299</mn><mrow><mo>&#177;</mo><mn>0.013</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.299_{\\pm 0.013}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.082_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m113\" intent=\":literal\"><semantics><msub><mn>0.082</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.082_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.823_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m114\" intent=\":literal\"><semantics><msub><mn>0.823</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.823_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.026_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m115\" intent=\":literal\"><semantics><msub><mn>0.026</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.026_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"89.15_{\\pm 0.44}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m116\" intent=\":literal\"><semantics><msub><mn>89.15</mn><mrow><mo>&#177;</mo><mn>0.44</mn></mrow></msub><annotation encoding=\"application/x-tex\">89.15_{\\pm 0.44}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"81.30_{\\pm 1.74}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m117\" intent=\":literal\"><semantics><msub><mn>81.30</mn><mrow><mo>&#177;</mo><mn>1.74</mn></mrow></msub><annotation encoding=\"application/x-tex\">81.30_{\\pm 1.74}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">13</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"92.04_{\\pm 0.33}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m118\" intent=\":literal\"><semantics><msub><mn>92.04</mn><mrow><mo>&#177;</mo><mn>0.33</mn></mrow></msub><annotation encoding=\"application/x-tex\">92.04_{\\pm 0.33}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.328_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m119\" intent=\":literal\"><semantics><msub><mn>0.328</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.328_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.050_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m120\" intent=\":literal\"><semantics><msub><mn>0.050</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.050_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.816_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m121\" intent=\":literal\"><semantics><msub><mn>0.816</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.816_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.027_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m122\" intent=\":literal\"><semantics><msub><mn>0.027</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.027_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"89.33_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m123\" intent=\":literal\"><semantics><msub><mn>89.33</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">89.33_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"82.14_{\\pm 1.45}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m124\" intent=\":literal\"><semantics><msub><mn>82.14</mn><mrow><mo>&#177;</mo><mn>1.45</mn></mrow></msub><annotation encoding=\"application/x-tex\">82.14_{\\pm 1.45}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">13</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"91.20_{\\pm 0.36}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m125\" intent=\":literal\"><semantics><msub><mn>91.20</mn><mrow><mo>&#177;</mo><mn>0.36</mn></mrow></msub><annotation encoding=\"application/x-tex\">91.20_{\\pm 0.36}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.221_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m126\" intent=\":literal\"><semantics><msub><mn>0.221</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.221_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.097_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m127\" intent=\":literal\"><semantics><msub><mn>0.097</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.097_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.809_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m128\" intent=\":literal\"><semantics><msub><mn>0.809</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.809_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.027_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m129\" intent=\":literal\"><semantics><msub><mn>0.027</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.027_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"88.43_{\\pm 0.46}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m130\" intent=\":literal\"><semantics><msub><mn>88.43</mn><mrow><mo>&#177;</mo><mn>0.46</mn></mrow></msub><annotation encoding=\"application/x-tex\">88.43_{\\pm 0.46}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"82.75_{\\pm 1.48}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m131\" intent=\":literal\"><semantics><msub><mn>82.75</mn><mrow><mo>&#177;</mo><mn>1.48</mn></mrow></msub><annotation encoding=\"application/x-tex\">82.75_{\\pm 1.48}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">36</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"92.98_{\\pm 0.31}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m132\" intent=\":literal\"><semantics><msub><mn>92.98</mn><mrow><mo>&#177;</mo><mn>0.31</mn></mrow></msub><annotation encoding=\"application/x-tex\">92.98_{\\pm 0.31}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.325_{\\pm 0.013}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m133\" intent=\":literal\"><semantics><msub><mn>0.325</mn><mrow><mo>&#177;</mo><mn>0.013</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.325_{\\pm 0.013}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.033_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m134\" intent=\":literal\"><semantics><msub><mn>0.033</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.033_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.839_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m135\" intent=\":literal\"><semantics><msub><mn>0.839</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.839_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.023_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m136\" intent=\":literal\"><semantics><msub><mn>0.023</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.023_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"90.84_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m137\" intent=\":literal\"><semantics><msub><mn>90.84</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">90.84_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"84.82_{\\pm 1.28}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m138\" intent=\":literal\"><semantics><msub><mn>84.82</mn><mrow><mo>&#177;</mo><mn>1.28</mn></mrow></msub><annotation encoding=\"application/x-tex\">84.82_{\\pm 1.28}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">36</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"92.70_{\\pm 0.32}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m139\" intent=\":literal\"><semantics><msub><mn>92.70</mn><mrow><mo>&#177;</mo><mn>0.32</mn></mrow></msub><annotation encoding=\"application/x-tex\">92.70_{\\pm 0.32}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.203_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m140\" intent=\":literal\"><semantics><msub><mn>0.203</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.203_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.075_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m141\" intent=\":literal\"><semantics><msub><mn>0.075</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.075_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.832_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m142\" intent=\":literal\"><semantics><msub><mn>0.832</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.832_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.024_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m143\" intent=\":literal\"><semantics><msub><mn>0.024</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.024_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"89.86_{\\pm 0.42}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m144\" intent=\":literal\"><semantics><msub><mn>89.86</mn><mrow><mo>&#177;</mo><mn>0.42</mn></mrow></msub><annotation encoding=\"application/x-tex\">89.86_{\\pm 0.42}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"82.94_{\\pm 1.44}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m145\" intent=\":literal\"><semantics><msub><mn>82.94</mn><mrow><mo>&#177;</mo><mn>1.44</mn></mrow></msub><annotation encoding=\"application/x-tex\">82.94_{\\pm 1.44}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">104</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"93.84_{\\pm 0.30}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m146\" intent=\":literal\"><semantics><msub><mn>93.84</mn><mrow><mo>&#177;</mo><mn>0.30</mn></mrow></msub><annotation encoding=\"application/x-tex\">93.84_{\\pm 0.30}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.225_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m147\" intent=\":literal\"><semantics><msub><mn>0.225</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.225_{\\pm 0.011}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.047_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m148\" intent=\":literal\"><semantics><msub><mn>0.047</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.047_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.834_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m149\" intent=\":literal\"><semantics><msub><mn>0.834</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.834_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.024_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m150\" intent=\":literal\"><semantics><msub><mn>0.024</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.024_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"90.35_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m151\" intent=\":literal\"><semantics><msub><mn>90.35</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">90.35_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.31_{\\pm 1.33}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m152\" intent=\":literal\"><semantics><msub><mn>83.31</mn><mrow><mo>&#177;</mo><mn>1.33</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.31_{\\pm 1.33}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">102</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"91.96_{\\pm 0.34}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m153\" intent=\":literal\"><semantics><msub><mn>91.96</mn><mrow><mo>&#177;</mo><mn>0.34</mn></mrow></msub><annotation encoding=\"application/x-tex\">91.96_{\\pm 0.34}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.223_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m154\" intent=\":literal\"><semantics><msub><mn>0.223</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.223_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.083_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m155\" intent=\":literal\"><semantics><msub><mn>0.083</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.083_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.825_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m156\" intent=\":literal\"><semantics><msub><mn>0.825</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.825_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.026_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m157\" intent=\":literal\"><semantics><msub><mn>0.026</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.026_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"89.21_{\\pm 0.44}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m158\" intent=\":literal\"><semantics><msub><mn>89.21</mn><mrow><mo>&#177;</mo><mn>0.44</mn></mrow></msub><annotation encoding=\"application/x-tex\">89.21_{\\pm 0.44}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"81.69_{\\pm 1.66}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m159\" intent=\":literal\"><semantics><msub><mn>81.69</mn><mrow><mo>&#177;</mo><mn>1.66</mn></mrow></msub><annotation encoding=\"application/x-tex\">81.69_{\\pm 1.66}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">56</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"93.52_{\\pm 0.30}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m160\" intent=\":literal\"><semantics><msub><mn>93.52</mn><mrow><mo>&#177;</mo><mn>0.30</mn></mrow></msub><annotation encoding=\"application/x-tex\">93.52_{\\pm 0.30}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.253_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m161\" intent=\":literal\"><semantics><msub><mn>0.253</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.253_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.044_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m162\" intent=\":literal\"><semantics><msub><mn>0.044</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.044_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.814_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m163\" intent=\":literal\"><semantics><msub><mn>0.814</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.814_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.028_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m164\" intent=\":literal\"><semantics><msub><mn>0.028</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.028_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"89.11_{\\pm 0.42}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m165\" intent=\":literal\"><semantics><msub><mn>89.11</mn><mrow><mo>&#177;</mo><mn>0.42</mn></mrow></msub><annotation encoding=\"application/x-tex\">89.11_{\\pm 0.42}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"77.59_{\\pm 1.29}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m166\" intent=\":literal\"><semantics><msub><mn>77.59</mn><mrow><mo>&#177;</mo><mn>1.29</mn></mrow></msub><annotation encoding=\"application/x-tex\">77.59_{\\pm 1.29}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">55</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">GPT-2-<span class=\"ltx_text ltx_font_typewriter\">large</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"89.36_{\\pm 0.37}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m167\" intent=\":literal\"><semantics><msub><mn>89.36</mn><mrow><mo>&#177;</mo><mn>0.37</mn></mrow></msub><annotation encoding=\"application/x-tex\">89.36_{\\pm 0.37}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.295_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m168\" intent=\":literal\"><semantics><msub><mn>0.295</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.295_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.110_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m169\" intent=\":literal\"><semantics><msub><mn>0.110</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.110_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.795_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m170\" intent=\":literal\"><semantics><msub><mn>0.795</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.795_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.029_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m171\" intent=\":literal\"><semantics><msub><mn>0.029</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.029_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.61_{\\pm 0.46}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m172\" intent=\":literal\"><semantics><msub><mn>87.61</mn><mrow><mo>&#177;</mo><mn>0.46</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.61_{\\pm 0.46}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"78.34_{\\pm 1.58}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m173\" intent=\":literal\"><semantics><msub><mn>78.34</mn><mrow><mo>&#177;</mo><mn>1.58</mn></mrow></msub><annotation encoding=\"application/x-tex\">78.34_{\\pm 1.58}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">33</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"89.80_{\\pm 0.35}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m174\" intent=\":literal\"><semantics><msub><mn>89.80</mn><mrow><mo>&#177;</mo><mn>0.35</mn></mrow></msub><annotation encoding=\"application/x-tex\">89.80_{\\pm 0.35}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.550_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m175\" intent=\":literal\"><semantics><msub><mn>0.550</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.550_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.029_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m176\" intent=\":literal\"><semantics><msub><mn>0.029</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.029_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.815_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m177\" intent=\":literal\"><semantics><msub><mn>0.815</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.815_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.027_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m178\" intent=\":literal\"><semantics><msub><mn>0.027</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.027_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"89.65_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m179\" intent=\":literal\"><semantics><msub><mn>89.65</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">89.65_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"80.11_{\\pm 1.49}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m180\" intent=\":literal\"><semantics><msub><mn>80.11</mn><mrow><mo>&#177;</mo><mn>1.49</mn></mrow></msub><annotation encoding=\"application/x-tex\">80.11_{\\pm 1.49}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">32</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"90.08_{\\pm 0.37}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m181\" intent=\":literal\"><semantics><msub><mn>90.08</mn><mrow><mo>&#177;</mo><mn>0.37</mn></mrow></msub><annotation encoding=\"application/x-tex\">90.08_{\\pm 0.37}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.253_{\\pm 0.013}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m182\" intent=\":literal\"><semantics><msub><mn>0.253</mn><mrow><mo>&#177;</mo><mn>0.013</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.253_{\\pm 0.013}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.108_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m183\" intent=\":literal\"><semantics><msub><mn>0.108</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.108_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.797_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m184\" intent=\":literal\"><semantics><msub><mn>0.797</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.797_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.029_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m185\" intent=\":literal\"><semantics><msub><mn>0.029</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.029_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.81_{\\pm 0.48}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m186\" intent=\":literal\"><semantics><msub><mn>87.81</mn><mrow><mo>&#177;</mo><mn>0.48</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.81_{\\pm 0.48}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"79.67_{\\pm 1.64}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m187\" intent=\":literal\"><semantics><msub><mn>79.67</mn><mrow><mo>&#177;</mo><mn>1.64</mn></mrow></msub><annotation encoding=\"application/x-tex\">79.67_{\\pm 1.64}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">82</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"91.20_{\\pm 0.33}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m188\" intent=\":literal\"><semantics><msub><mn>91.20</mn><mrow><mo>&#177;</mo><mn>0.33</mn></mrow></msub><annotation encoding=\"application/x-tex\">91.20_{\\pm 0.33}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.426_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m189\" intent=\":literal\"><semantics><msub><mn>0.426</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.426_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.038_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m190\" intent=\":literal\"><semantics><msub><mn>0.038</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.038_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.826_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m191\" intent=\":literal\"><semantics><msub><mn>0.826</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.826_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.025_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m192\" intent=\":literal\"><semantics><msub><mn>0.025</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.025_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"90.11_{\\pm 0.39}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m193\" intent=\":literal\"><semantics><msub><mn>90.11</mn><mrow><mo>&#177;</mo><mn>0.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">90.11_{\\pm 0.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"82.67_{\\pm 1.51}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T3.m194\" intent=\":literal\"><semantics><msub><mn>82.67</mn><mrow><mo>&#177;</mo><mn>1.51</mn></mrow></msub><annotation encoding=\"application/x-tex\">82.67_{\\pm 1.51}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">82</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "6469±0706469pm",
            "0021±00030021pm",
            "6300±1196300pm",
            "debertav3large",
            "9298±0319298pm",
            "8965±0408965pm",
            "0826±00060826pm",
            "detection",
            "0686±00130686pm",
            "0359±00080359pm",
            "8275±1488275pm",
            "8169±1668169pm",
            "zeroshot",
            "unbiased",
            "8365±0458365pm",
            "0078±00050078pm",
            "0814±00070814pm",
            "0486±00080486pm",
            "0044±00040044pm",
            "0299±00130299pm",
            "0027±00010027pm",
            "8843±0468843pm",
            "0067±00010067pm",
            "6044±1156044pm",
            "8882±0398882pm",
            "0552±00140552pm",
            "8267±1518267pm",
            "0202±00030202pm",
            "3869±1623869pm",
            "0557±00150557pm",
            "0825±00070825pm",
            "0075±00040075pm",
            "higher",
            "fnr",
            "0033±00030033pm",
            "lower",
            "0046±00040046pm",
            "8710±0408710pm",
            "0782±00070782pm",
            "negative",
            "0752±00120752pm",
            "0127±00040127pm",
            "4596±0824596pm",
            "0295±00140295pm",
            "0038±00030038pm",
            "3787±0553787pm",
            "6223±0606223pm",
            "other",
            "0082±00040082pm",
            "8921±0448921pm",
            "method",
            "7967±1647967pm",
            "qwen2572b",
            "8849±0388849pm",
            "0047±00040047pm",
            "llama3170b",
            "gpt2xl",
            "guard38b",
            "8724±0398724pm",
            "incontext",
            "0028±00010028pm",
            "0029±00030029pm",
            "5468±0805468pm",
            "milliseconds",
            "time",
            "0581±00140581pm",
            "0021±00020021pm",
            "0184±00110184pm",
            "8595±0508595pm",
            "measures",
            "0223±00120223pm",
            "0501±00090501pm",
            "5shot",
            "0192±00120192pm",
            "0024±00010024pm",
            "0104±00020104pm",
            "0136±00060136pm",
            "8781±0488781pm",
            "llama318b",
            "0328±00140328pm",
            "scores",
            "8698±0418698pm",
            "0026±00010026pm",
            "9008±0379008pm",
            "glm49b",
            "4917±0474917pm",
            "0426±00140426pm",
            "0823±00060823pm",
            "4458±0734458pm",
            "8343±0498343pm",
            "indicates",
            "robertabase",
            "0815±00070815pm",
            "9196±0349196pm",
            "8933±0418933pm",
            "0140±00040140pm",
            "7517±0647517pm",
            "0775±00120775pm",
            "7759±1297759pm",
            "reweighted",
            "9011±0399011pm",
            "8482±1288482pm",
            "prompting",
            "better",
            "debertav2xl",
            "0085±00010085pm",
            "f1f1",
            "0089±00050089pm",
            "targets",
            "0253±00120253pm",
            "7733±0557733pm",
            "8980±0358980pm",
            "median",
            "bias",
            "9120±0339120pm",
            "biased",
            "0372±00080372pm",
            "setup",
            "5566±1345566pm",
            "8220±0478220pm",
            "8372±0458372pm",
            "8915±0448915pm",
            "6579±0696579pm",
            "8331±1338331pm",
            "8674±0488674pm",
            "0773±00070773pm",
            "0834±00060834pm",
            "0839±00060839pm",
            "8294±1448294pm",
            "0029±00010029pm",
            "4624±1874624pm",
            "8936±0378936pm",
            "default",
            "0225±00110225pm",
            "8308±0418308pm",
            "9352±0309352pm",
            "0795±00070795pm",
            "0774±00120774pm",
            "finetuning",
            "0110±00050110pm",
            "0746±00130746pm",
            "0047±00010047pm",
            "llama",
            "0060±00020060pm",
            "0687±00130687pm",
            "0097±00050097pm",
            "0358±00090358pm",
            "0126±00060126pm",
            "0583±00080583pm",
            "0083±00050083pm",
            "0shot",
            "7546±1687546pm",
            "gpt2large",
            "0657±00080657pm",
            "0648±00080648pm",
            "0550±00140550pm",
            "0373±00080373pm",
            "9080±0339080pm",
            "model",
            "0186±00110186pm",
            "9035±0409035pm",
            "4468±1824468pm",
            "0440±00080440pm",
            "rew",
            "robertalarge",
            "0046±00010046pm",
            "0153±00060153pm",
            "6646±0486646pm",
            "0253±00130253pm",
            "10shot",
            "multilabel",
            "positive",
            "0208±00040208pm",
            "0050±00040050pm",
            "9120±0369120pm",
            "9384±0309384pm",
            "inference",
            "0023±00030023pm",
            "0108±00050108pm",
            "8761±0468761pm",
            "f1μf1mu",
            "7894±0527894pm",
            "0203±00120203pm",
            "0025±00010025pm",
            "4931±0504931pm",
            "8747±0408747pm",
            "6566±0686566pm",
            "0411±00080411pm",
            "8986±0428986pm",
            "8130±1748130pm",
            "0832±00060832pm",
            "prediction",
            "0600±00090600pm",
            "0769±00120769pm",
            "loss",
            "6894±0716894pm",
            "fpr",
            "0797±00070797pm",
            "f1mf1textm",
            "7343±1697343pm",
            "8328±0428328pm",
            "0221±00120221pm",
            "9270±0329270pm",
            "0485±00080485pm",
            "0816±00070816pm",
            "0527±00140527pm",
            "0275±00080275pm",
            "6219±0686219pm",
            "9084±0409084pm",
            "binary",
            "8727±0408727pm",
            "0065±00020065pm",
            "0036±00010036pm",
            "0023±00010023pm",
            "unw",
            "0809±00070809pm",
            "0551±00140551pm",
            "7834±1587834pm",
            "0098±00010098pm",
            "7316±1367316pm",
            "7507±1397507pm",
            "8738±0418738pm",
            "0325±00130325pm",
            "3601±0603601pm",
            "8911±0428911pm",
            "8214±1458214pm",
            "7516±0647516pm",
            "0034±00010034pm",
            "9204±0339204pm",
            "4996±1604996pm",
            "8011±1498011pm"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">This section illustrates how our comprehensive evaluation study enables the practical assessment of LLM-based methods for detecting demographic-targeted social biases in text. Our analysis reveals both the strengths and current limitations of these approaches. For rigorous assessment of the overall results, we perform 1,000 bootstrap samples with replacement on the combined test set to compute 95% confidence intervals. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> presents a detailed comparison of prompting and fine-tuning, reporting both binary performance (biased vs. unbiased) and multi-label categorization. We also report median inference time (in milliseconds) for each text instance. Moreover, for more fine-grained analysis, Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> reports bias detection performance of select prompted and fine-tuned LLMs for the twelve constituent datasets.</p>\n\n",
            "<p class=\"ltx_p\">Our detailed results in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> show how bias detection with prompting is <em class=\"ltx_emph ltx_font_italic\">highly sensitive to both in-context learning and model capacity</em>.</p>\n\n",
            "<p class=\"ltx_p\">Our results in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> show how the performance of fine-tuned LLM-based bias detectors is <em class=\"ltx_emph ltx_font_italic\">shaped by model size, architecture, and optimization strategy</em>.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora used to train general-purpose AI (GPAI) models often contain harmful demographic-targeted social biases, creating a regulatory need for data auditing and developing scalable bias-detection methods. Although prior work has investigated biases in text datasets and related detection methods, these studies remain narrow in scope. They typically focus on a single content type (e.g., hate speech), cover limited demographic axes, overlook biases affecting multiple demographics simultaneously, and analyze limited techniques. Consequently, practitioners lack a holistic understanding of the strengths and limitations of recent large language models (LLMs) for automated and scalable bias detection in datasets. In this study, we present a comprehensive evaluation framework aimed at English texts to assess the ability of LLMs in detecting demographic-targeted social biases. To align with regulatory requirements, we frame bias detection as a multi-label task using a demographic-focused taxonomy. We then conduct a systematic evaluation with models across scales and techniques, including prompting, in-context learning, and fine-tuning. Using twelve datasets spanning diverse content types and demographics, our study demonstrates the promise of fine-tuned smaller models for scalable detection. However, our analyses also expose persistent gaps across demographic axes and multi-demographic targeted biases, underscoring the need for more effective and scalable auditing frameworks.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "finetuning",
                    "incontext",
                    "prompting",
                    "detection",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><em class=\"ltx_emph ltx_font_bold ltx_font_italic\">K</em><span class=\"ltx_text ltx_font_bold\">eywords</span>&#8194;Social bias  <math alttext=\"\\cdot\" class=\"ltx_Math\" display=\"inline\" id=\"p1.m1\" intent=\":literal\"><semantics><mo>&#8901;</mo><annotation encoding=\"application/x-tex\">\\cdot</annotation></semantics></math>\nBias detection  <math alttext=\"\\cdot\" class=\"ltx_Math\" display=\"inline\" id=\"p1.m2\" intent=\":literal\"><semantics><mo>&#8901;</mo><annotation encoding=\"application/x-tex\">\\cdot</annotation></semantics></math>\nPrompting  <math alttext=\"\\cdot\" class=\"ltx_Math\" display=\"inline\" id=\"p1.m3\" intent=\":literal\"><semantics><mo>&#8901;</mo><annotation encoding=\"application/x-tex\">\\cdot</annotation></semantics></math>\nFine-tuning</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "bias",
                    "finetuning",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Detecting demographic-targeted social biases in data has become both a regulatory and technical requirement&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Tabassi, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib51\" title=\"\">2023</a>; European Union, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib14\" title=\"\">2024</a>)</cite>. For example, the EU&#8217;s GPAI Code of Practice highlights the importance of documenting demographic-centric harms in training corpora. Effective data-level mitigation strategies&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite> also depend on reliably identifying biased instances. While prior studies have examined biases in text corpora&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kreutzer et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib29\" title=\"\">2022</a>; Luccioni and Viviano, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib34\" title=\"\">2021</a>; Dodge et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>)</cite>, they typically rely either on small-scale human annotations or on simplistic automated techniques. Manual inspection, however, poses psychological risks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Steiger et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib49\" title=\"\">2021</a>)</cite>, and despite advances in LLMs, few works offer a comprehensive analysis of the state of the art in social bias detection.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "biased",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Compared to systematic benchmarks that examine LLMs for biased generation&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>; Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>)</cite>, detailed studies of their potential as tools for detecting social biases in text remain underexplored. Existing work is often limited across one or more dimensions: focusing on narrow demographics&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, restricting attention to a single type of content such as hate&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>)</cite>, analyzing only specific contexts like certain subreddits&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kumar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib30\" title=\"\">2024</a>)</cite>, or analyzing only few methods such as zero-shot prompting&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>)</cite>. Moreover, most studies overlook biases that target <em class=\"ltx_emph ltx_font_italic\">multiple demographic axes simultaneously</em>, e.g., intersectionality. These gaps motivate a structured and comprehensive study of the current capabilities of recent LLMs in detecting demographic-targeted social biases.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "zeroshot",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We develop a <em class=\"ltx_emph ltx_font_italic\">demographic-focused</em> taxonomy for social bias detection for better alignment with anti-discrimination principles and multi-axis targeted bias detection.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "better",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We frame bias detection as a multi-label task and build a detection testbed that supports prompting, in-context learning, and fine-tuning.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "finetuning",
                    "incontext",
                    "prompting",
                    "detection",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias in LLMs.</span>\nSeveral works have evaluated biases in LLMs, independently analyzing content types like stereotypes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Nadeem et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib38\" title=\"\">2021</a>; Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>)</cite> and hate/toxic content&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gehman et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib17\" title=\"\">2020</a>)</cite>. Recently, <cite class=\"ltx_cite ltx_citemacro_citet\">Li et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib31\" title=\"\">2023</a>)</cite> also studied the fairness of ChatGPT in binary decision-making. Several benchmarks also analyzed stereotype and toxic characteristics in generations of recently developed LLMs&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib54\" title=\"\">2023</a>; Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "binary",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias detection with LLMs.</span>\nPrior work explored using LLMs in hate-speech moderation&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Barikeri et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib1\" title=\"\">2021</a>; Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>; Kumar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib30\" title=\"\">2024</a>; Zhan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib62\" title=\"\">2025</a>)</cite> or domain-specific bias detection&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Raza et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib45\" title=\"\">2024</a>)</cite>. Recent work&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite> also benchmarked prompt-based bias detection. However, they are restricted to zero-shot settings, cover limited demographics and data. In contrast, we systematically evaluate across multiple LLM-based methods, a broader range of demographics, and holistically analyze across different content types.</p>\n\n",
                "matched_terms": [
                    "zeroshot",
                    "bias",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias analysis of corpora.</span>\nOther work has directly analyzed large text corpora. <cite class=\"ltx_cite ltx_citemacro_citet\">Kreutzer et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib29\" title=\"\">2022</a>)</cite> employed human surveys on a small web-crawled subset to assess multilingual quality and offensive content. Lexicon-based approaches have been used to detect opinion biases in Wikipedia&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Hube and Fetahu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib23\" title=\"\">2018</a>)</cite>. <cite class=\"ltx_cite ltx_citemacro_citet\">Luccioni and Viviano (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib34\" title=\"\">2021</a>)</cite> subsampled Common Crawl to study sexual and hateful content using n-grams, BERT, and logistic regression, while <cite class=\"ltx_cite ltx_citemacro_citet\">Dodge et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>)</cite> analyzed C4, linking sentiment toward racial groups to biased QA outcomes. Although these studies provide valuable insights, they rely on relatively simplistic detection methods. In contrast, our work offers a systematic evaluation of state-of-the-art LLMs for social bias detection, providing deeper insights that can complement and extend prior analyses of large-scale corpora.</p>\n\n",
                "matched_terms": [
                    "other",
                    "bias",
                    "detection",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section outlines the practical setup of our evaluation framework for analyzing the ability of LLMs to detect social biases in texts targeting different demographic groups. We first present the demographic-targeted taxonomy that underpins our framework, then describe how we adapt and integrate existing datasets for a holistic evaluation of bias detection. Finally, we detail the testbed we constructed to ensure comprehensive coverage of LLMs and detection methods.</p>\n\n",
                "matched_terms": [
                    "setup",
                    "bias",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address the limitations, our framework employs a <em class=\"ltx_emph ltx_font_italic\">demographic-centered taxonomy</em> that identifies the demographic axes targeted by biased texts. This approach aligns directly with anti-discrimination regulations and governance measures&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(European Commission, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib13\" title=\"\">2025</a>)</cite>, while also enabling the study of <em class=\"ltx_emph ltx_font_italic\">multi-axis</em> biases: cases where texts simultaneously target multiple groups, an aspect often overlooked. Concretely, our taxonomy spans nine axes with differing legal recognition:</p>\n\n",
                "matched_terms": [
                    "biased",
                    "measures"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Any text not targeting one or more of these axes is considered &#8220;unbiased&#8221; (<span class=\"ltx_text ltx_font_typewriter\">UNB</span>) <em class=\"ltx_emph ltx_font_italic\">within our taxonomy</em>. Each demographic axis serves as a prediction category, making the detection task twofold: (i) identify whether a text expresses demographic-targeted bias, and (ii) determine which demographics are targeted. Unlike prior benchmarks that treat bias detection as single-label or multi-class classification&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, our formulation supports <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em>, capturing both <span class=\"ltx_text ltx_font_italic\">single-axis</span> (e.g., race only) and <span class=\"ltx_text ltx_font_italic\">multi-axis</span> (e.g., gender+race) biases (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T2\" title=\"Table 2 &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>).</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "bias",
                    "detection",
                    "prediction"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Since some datasets were originally designed for evaluating generative biases, we applied minor adaptations similar to&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>. For StereoSet, we concatenate the context with the stereotype options. For BBQ, we construct text instances by pairing disambiguated contexts with answers. For CrowS-Pairs, we retain only the &#8220;more biased&#8221; sentences. For SBIC, we derive a single label using the majority vote across annotators. For ToxiGen, we label texts as biased only when human annotator scores indicate bias.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "biased",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The resulting dataset contains <span class=\"ltx_text ltx_font_bold\">46,781</span> entries, substantially larger than comparable benchmarks (e.g., 11,004 samples in&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>). Biased instances are more prevalent (around 70%), with most targeting a single demographic axis and roughly 12% of biased instances targeting multiple axes simultaneously. Among demographic targets, <span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, <span class=\"ltx_text ltx_font_typewriter\">SO</span>, and <span class=\"ltx_text ltx_font_typewriter\">REL</span> are most common, while <span class=\"ltx_text ltx_font_typewriter\">PHY</span> is least prevalent. Multi-axis biases most frequently combine {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">SO</span>} or {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>}.</p>\n\n",
                "matched_terms": [
                    "targets",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To ensure a comprehensive evaluation, we consider a testbed incorporating LLM-based detection methods that span both prompting and fine-tuning. Furthermore, we operationalize our testbed with a diverse suite of state-of-the-art, open-source, or open-weight LLMs spanning multiple paradigms and configurations.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "finetuning",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_citet\">Brown et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib4\" title=\"\">2020</a>)</cite> demonstrated that <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> LLMs can effectively perform a variety of tasks through textual prompting in <em class=\"ltx_emph ltx_font_italic\">zero-shot</em> scenarios. Following&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>; Palla et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib42\" title=\"\">2025</a>)</cite>, our evaluation framework employs <em class=\"ltx_emph ltx_font_italic\">policy-based</em> prompting for bias detection. Specifically, the prompt includes a policy detailing the bias detection task and our demographic-based social bias taxonomy. To enhance the bias detection capabilities within this prompting framework, we also assess the benefits of incorporating <em class=\"ltx_emph ltx_font_italic\">few-shot</em> examples for <em class=\"ltx_emph ltx_font_italic\">in-context learning</em>. Specifically, we utilize the retrieval-augmented (RAG) framework&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib5\" title=\"\">2024a</a>)</cite>, where an embedding model identifies the most <em class=\"ltx_emph ltx_font_italic\">relevant</em> in-context examples for each input instance from the training/development set.</p>\n\n",
                "matched_terms": [
                    "zeroshot",
                    "incontext",
                    "prompting",
                    "model",
                    "detection",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Models.</span> We consider several <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> models ranging from 8B to 72B parameters, e.g., GLM-4&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(GLM et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib18\" title=\"\">2024</a>)</cite>, Llama-3.1&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Dubey et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib10\" title=\"\">2024</a>)</cite>, and Qwen-2.5&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Yang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib58\" title=\"\">2024</a>)</cite>. We also analyze the guardrail model Llama Guard-3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>)</cite> to explore if such models could directly be applied for general text bias detection. To perform RAG-based in-context sample selection, we use the BGE-M3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib6\" title=\"\">2024b</a>)</cite> model.</p>\n\n",
                "matched_terms": [
                    "llama",
                    "incontext",
                    "model",
                    "detection",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We also evaluate the effectiveness of aligning LLMs to the bias detection task through <em class=\"ltx_emph ltx_font_italic\">fine-tuning</em>. The task is framed as <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em> over the nine demographic axes. We solve it through sequence classification by attaching nine classifier nodes to a pre-trained LLM: to the [CLS] token for encoder-only models and to the final output token for decoder-only models.</p>\n\n",
                "matched_terms": [
                    "finetuning",
                    "bias",
                    "detection",
                    "prediction",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Because detection must perform reliably <em class=\"ltx_emph ltx_font_italic\">across all demographic axes</em>, our evaluation framework also explores the effectiveness of <em class=\"ltx_emph ltx_font_italic\">data reweighting</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kamiran and Calders, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib25\" title=\"\">2012</a>)</cite> to address imbalances. Let <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> denote the number of samples and <math alttext=\"\\mathcal{M}_{\\phi}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m2\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8499;</mi><mi>&#981;</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{M}_{\\phi}</annotation></semantics></math> the model. For a given instance <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m3\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>, its labels <math alttext=\"Y_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m4\" intent=\":literal\"><semantics><msub><mi>Y</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">Y_{i}</annotation></semantics></math> form a binary vector of length nine, where <math alttext=\"Y_{i}^{m}=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m5\" intent=\":literal\"><semantics><mrow><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">Y_{i}^{m}=1</annotation></semantics></math> if the demographic axis <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m6\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> is targeted and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m7\" intent=\":literal\"><mn>0</mn></math> otherwise. The weighted loss is defined as:</p>\n\n",
                "matched_terms": [
                    "model",
                    "binary",
                    "loss",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"\\alpha_{m}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m8\" intent=\":literal\"><semantics><msub><mi>&#945;</mi><mi>m</mi></msub><annotation encoding=\"application/x-tex\">\\alpha_{m}</annotation></semantics></math> balances across demographic axes, and <math alttext=\"w_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m9\" intent=\":literal\"><semantics><msub><mi>w</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">w_{i}</annotation></semantics></math> compensates for binary imbalances regarding biased and unbiased instances. All weights are derived from training data statistics.</p>\n\n",
                "matched_terms": [
                    "binary",
                    "unbiased",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our comprehensive framework uses metrics capturing three dimensions: (i) distinguishing <em class=\"ltx_emph ltx_font_italic\">biased vs. unbiased</em> text, (ii) accurate <em class=\"ltx_emph ltx_font_italic\">multi-label classification</em> of bias types, and (iii) ensuring <em class=\"ltx_emph ltx_font_italic\">parity</em> in detection performance across demographic axes and for multi-targeted texts compared to single-targeted texts.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "unbiased",
                    "biased",
                    "detection",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Binary bias detection.</span>\nWe reduce the multi-label task to a binary one by defining\nground-truth labels <math alttext=\"Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.SS4.p3.m1\" intent=\":literal\"><semantics><mrow><msub><mi>Y</mi><msub><mi>B</mi><mi>i</mi></msub></msub><mo>=</mo><mn>1</mn><mo>&#8722;</mo><mi>&#120128;</mi><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>0</mn><mo>,</mo><mo>,</mo><mo rspace=\"0.167em\">&#8704;</mo><mi>m</mi><mo>&#8712;</mo><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><mn>9</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]</annotation></semantics></math>, with predictions <math alttext=\"\\hat{Y}_{B_{i}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m2\" intent=\":literal\"><semantics><msub><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><msub><mi>B</mi><mi>i</mi></msub></msub><annotation encoding=\"application/x-tex\">\\hat{Y}_{B_{i}}</annotation></semantics></math> defined analogously. A value of <math alttext=\"1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m3\" intent=\":literal\"><semantics><mn>1</mn><annotation encoding=\"application/x-tex\">1</annotation></semantics></math> indicates the presence of any bias, and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m4\" intent=\":literal\"><mn>0</mn></math> indicates none. On these binary labels, we report <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m5\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, false positive rate (FPR), and false negative rate (FNR).</p>\n\n",
                "matched_terms": [
                    "positive",
                    "bias",
                    "indicates",
                    "detection",
                    "f1f1",
                    "fnr",
                    "binary",
                    "fpr",
                    "multilabel",
                    "negative"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-label bias detection.</span>\nAlongside macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p4.m1\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math> and micro <math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p4.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math> scores, we report two multi-label measures&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sorower, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib48\" title=\"\">2010</a>)</cite>:</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "bias",
                    "measures",
                    "detection",
                    "f1mf1textm",
                    "f1μf1mu",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Exact Match Ratio</span>: analyzing correctness of the full predicted label sets, <math alttext=\"\\operatorname{MR}=\\tfrac{1}{N}\\sum_{i=1}^{N}\\mathbb{I}[\\hat{Y}_{i}^{m}=Y_{i}^{m},\\,\\forall m]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.I2.i1.p1.m1\" intent=\":literal\"><semantics><mrow><mi>MR</mi><mo>=</mo><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><msubsup><mo>&#8721;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mi>&#120128;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">[</mo><mrow><msubsup><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mrow><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo rspace=\"0.337em\">,</mo><mrow><mo rspace=\"0.167em\">&#8704;</mo><mi>m</mi></mrow></mrow></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\operatorname{MR}=\\tfrac{1}{N}\\sum_{i=1}^{N}\\mathbb{I}[\\hat{Y}_{i}^{m}=Y_{i}^{m},\\,\\forall m]</annotation></semantics></math>, where higher scores are better.</p>\n\n",
                "matched_terms": [
                    "higher",
                    "better",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Hamming Loss</span>: analyzing the prediction&#8217;s partial coverage of label sets, <math alttext=\"\\operatorname{HL}=\\tfrac{1}{9N}\\sum_{i=1}^{N}\\sum_{m=1}^{9}\\mathbb{I}[Y_{i}^{m}\\neq\\hat{Y}_{i}^{m}]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.I2.i2.p1.m1\" intent=\":literal\"><semantics><mrow><mi>HL</mi><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mn>9</mn><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>N</mi></mrow></mfrac><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><msubsup><mo rspace=\"0em\">&#8721;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><msubsup><mo>&#8721;</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mn>9</mn></msubsup><mrow><mi>&#120128;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">[</mo><mrow><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>&#8800;</mo><msubsup><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><mi>i</mi><mi>m</mi></msubsup></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\operatorname{HL}=\\tfrac{1}{9N}\\sum_{i=1}^{N}\\sum_{m=1}^{9}\\mathbb{I}[Y_{i}^{m}\\neq\\hat{Y}_{i}^{m}]</annotation></semantics></math>, where lower scores are better.</p>\n\n",
                "matched_terms": [
                    "loss",
                    "better",
                    "lower",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Detection disparities.</span>\nOur evaluation also examines whether LLMs not only detect social biases accurately but also exhibit systematic performance gaps across different demographic targets. Given <math alttext=\"\\mathcal{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p5.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><annotation encoding=\"application/x-tex\">\\mathcal{P}</annotation></semantics></math> denotes FPR or FNR, we analyze disparities in the following scenarios:</p>\n\n",
                "matched_terms": [
                    "targets",
                    "fnr",
                    "detection",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-demographic.</span> Inspired by&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite>, we measure if the models make systematically more errors in detecting biases that <em class=\"ltx_emph ltx_font_italic\">specifically</em> target <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em> (e.g., {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}) relative to biases that target <span class=\"ltx_text ltx_font_italic\">each constituent axis</span> (e.g., only <span class=\"ltx_text ltx_font_typewriter\">GEN</span> or <span class=\"ltx_text ltx_font_typewriter\">RAC</span>).\n<math alttext=\"\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.I3.i2.p1.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>=</mo><mrow><munder accentunder=\"true\"><mi>max</mi><mrow><mi>x</mi><mo>&#8712;</mo><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></mrow></munder><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msub><mo>&#8722;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mi>x</mi></msub></mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|</annotation></semantics></math>. This measure helps us understand if the FPR or FNR of multi-axis targeted biased instances is markedly higher, indicating potential blind spots for automated bias detection methods.</p>\n\n",
                "matched_terms": [
                    "biased",
                    "detection",
                    "higher",
                    "fnr",
                    "fpr",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">In-context learning substantially improves detection.</span> Across all models, providing few-shot examples consistently boosts binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, lowers FNR, and increases multi-label metrics (MR, HL, <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>). Gains are significant with as few as five examples, while moving from five to ten shots yields only marginal improvements. However, inference time grows with the number of examples, highlighting the accuracy&#8211;efficiency tradeoff in prompting. Beyond the reported results, we also analyzed alternative in-context setups (in the appendix). We found that (i) RAG-based example selection outperforms random sampling, and (ii) alternative embeddings&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Youdao, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib59\" title=\"\">2023</a>)</cite> yield comparable results.</p>\n\n",
                "matched_terms": [
                    "time",
                    "incontext",
                    "prompting",
                    "detection",
                    "f1f1",
                    "inference",
                    "binary",
                    "fnr",
                    "f1mf1textm",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Model size and architecture strongly shape results.</span> Larger models (e.g., Llama-70B, Qwen-72B) achieve higher binary and multi-label performance than smaller variants. Within model families, scale matters: Llama-70B outperforms Llama-8B across nearly all metrics. However, size alone is not decisive. GLM-4-9B rivals or surpasses larger Llama and Qwen models on multi-label metrics, and Llama-3.1-70B outperforms Qwen-2.5-72B despite similar scale. Larger models tend to reduce FPR but can increase FNR, reflecting greater sensitivity at the cost of more false negatives. Inference time rises steeply with model scale, from 350ms for 8B models to over 600ms for 70B+ models.</p>\n\n",
                "matched_terms": [
                    "time",
                    "llama",
                    "glm49b",
                    "model",
                    "higher",
                    "inference",
                    "binary",
                    "fnr",
                    "fpr",
                    "qwen2572b",
                    "llama3170b",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Guardrail models transfer poorly.</span> Llama Guard, fine-tuned for moderation, consistently underperforms instruction-tuned models of similar size (e.g., Llama-3.1-8B), achieving the lowest binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> and highest FNR. While effective at detecting overt hate speech, it fails to capture subtler biases like stereotypes.</p>\n\n",
                "matched_terms": [
                    "llama",
                    "f1f1",
                    "binary",
                    "fnr",
                    "llama318b"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nFrom Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we see the role of scale from the binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. The 70B Llama model outperforms smaller variants across most datasets. Llama-Guard shows lower overall binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, but performs relatively well on hate/toxic content. It specifically achieves the highest score across all models on Toxigen, which is GPT-generated. This finding is consistent with its design as a GPAI guardrail. Multi-label metrics show that even larger models struggle to correctly identify bias types, especially for stereotyped contents, e.g., StereoSet and RedditBias.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "llama",
                    "model",
                    "f1f1",
                    "binary",
                    "lower",
                    "bias",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nInstruction-tuned LLMs with in-context learning and sufficient capacity provide the most effective prompting-based bias detection, although at the cost of increased inference time. We further show that guardrail-focused models alone are insufficient for holistic social bias identification.</p>\n\n",
                "matched_terms": [
                    "time",
                    "incontext",
                    "detection",
                    "inference",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuning substantially improves detection.</span> Even small models, such as RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>, surpass much larger prompting-only models (Llama-3.1-70B, Qwen-2.5-72B) on binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> (above 90 vs. below 89) and multi-label metrics (MR, HL, micro <math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math> and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m3\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>). Fine-tuned models also achieve lower FNR and higher reliability in detecting biased content. Inference is far faster: RoBERTa completes batches in seconds, whereas prompting with 70B+ LLMs requires hundreds of seconds.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "finetuning",
                    "biased",
                    "prompting",
                    "qwen2572b",
                    "detection",
                    "higher",
                    "inference",
                    "binary",
                    "robertabase",
                    "lower",
                    "fnr",
                    "f1f1",
                    "llama3170b",
                    "f1mf1textm",
                    "f1μf1mu"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Architecture influences performance.</span> Encoder models (RoBERTa, DeBERTa) consistently outperform decoder models (GPT-2), irrespective of scale. GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span> underperforms on binary and multi-label detection. In contrast, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> and RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> achieve higher detection scores. Inference times also reflect architectural complexity: decoder models remain faster, whereas DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> is particularly slow due to disentangled attention&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(He et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib21\" title=\"\">2020</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "detection",
                    "debertav2xl",
                    "robertalarge",
                    "higher",
                    "binary",
                    "inference",
                    "gpt2xl",
                    "multilabel",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Scaling improves detection.</span> Within encoder families, larger variants (RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">XL</span>) achieve better detection results. Importantly, despite being the newer variant, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> performs slightly worse than the larger but older DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>. GPT-2 shows similar scaling trends within decoder models. Inference time increases with model size, reinforcing the tradeoff between accuracy and efficiency.</p>\n\n",
                "matched_terms": [
                    "time",
                    "debertav3large",
                    "model",
                    "better",
                    "detection",
                    "debertav2xl",
                    "robertalarge",
                    "inference"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Loss reweighting has tradeoffs.</span> Reweighted loss consistently improves binary FNR and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p5.m1\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math> (e.g., DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>, RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>) by capturing subtle biases, but can raise FPR, particularly in decoder models. Effects are uneven: DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> shows reduced MR and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p5.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>, suggesting reweighting may destabilize multi-label detection for some scenarios.</p>\n\n",
                "matched_terms": [
                    "reweighted",
                    "debertav3large",
                    "detection",
                    "debertav2xl",
                    "robertalarge",
                    "loss",
                    "binary",
                    "fnr",
                    "fpr",
                    "gpt2xl",
                    "f1mf1textm",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> shows how fine-tuned models achieve stronger binary detection across most datasets compared to prompting-based LLMs. Encoder models (DeBERTa) generally outperform decoder-only GPT-2, which remains competitive on many datasets but struggles with subtle stereotype cases, e.g, RedditBias and Winogender. For multi-label detection, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> shows consistently lower HL, indicating more accurate detection of demographic axes targeted.</p>\n\n",
                "matched_terms": [
                    "detection",
                    "debertav2xl",
                    "binary",
                    "lower",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nFine-tuned encoder models provide the most effective bias detection, outperforming prompting much larger models in both binary detection and identification of the correct bias types. Decoder-based models can perform well but show weaknesses on subtle stereotype datasets. Fine-tuning with reweighted loss improves recall, but may increase false positives, highlighting important tradeoffs that require consideration.</p>\n\n",
                "matched_terms": [
                    "reweighted",
                    "finetuning",
                    "prompting",
                    "detection",
                    "binary",
                    "loss",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use our evaluation framework to examine <em class=\"ltx_emph ltx_font_italic\">potential disparities</em> in social bias detection across models and setups with respect to targeted demographic axes. While the previous analysis provided a global view of model performance, this section focuses on <em class=\"ltx_emph ltx_font_italic\">systematic differences</em> in how effectively models detect biases. We first analyze disparities for individual demographic axes. Next, owing to our multi-label setup, we evaluate model performances on instances targeting <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em>, highlighting current capabilities in detecting multi-targeted biases. We provide the comprehensive disparity analysis in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S5.T5\" title=\"Table 5 &#8227; 5 Evaluating detection disparities &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "model",
                    "setup",
                    "detection",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Prompting shows large disparities.</span> In zero-shot settings, models exhibit significant disparities. For instance, Llama-3.1-8B and GLM-4-9B exhibit <math alttext=\"\\Delta_{\\text{FNR}}\\approx 0.6\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><mo>&#8776;</mo><mn>0.6</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}\\approx 0.6</annotation></semantics></math>, <math alttext=\"\\Delta_{\\text{FPR}}\\approx 0.42\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><mo>&#8776;</mo><mn>0.42</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}\\approx 0.42</annotation></semantics></math>. Few-shot prompting reduces disparities (e.g., for Llama-3.1-8B, <math alttext=\"\\Delta_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m3\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}</annotation></semantics></math> drops to <math alttext=\"\\approx 0.26\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8776;</mo><mn>0.26</mn></mrow><annotation encoding=\"application/x-tex\">\\approx 0.26</annotation></semantics></math>), but performance remains uneven compared to fine-tuned models. Scaling improves parity: Llama-3.1-70B shows lower disparities than its 8B counterpart, and Qwen-2.5-72B achieves the strongest parity among prompting models, especially with few-shot examples.</p>\n\n",
                "matched_terms": [
                    "zeroshot",
                    "glm49b",
                    "prompting",
                    "lower",
                    "qwen2572b",
                    "llama318b",
                    "llama3170b"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuning yields markedly lower disparities.</span> Encoder models such as RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> and DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> reach <math alttext=\"\\Delta_{\\text{FNR}}\\approx 0.2\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><mo>&#8776;</mo><mn>0.2</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}\\approx 0.2</annotation></semantics></math> and <math alttext=\"\\Delta_{\\text{FPR}}\\approx 0.03\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m2\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><mo>&#8776;</mo><mn>0.03</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}\\approx 0.03</annotation></semantics></math>, particularly with reweighted loss. Reweighting reduces FNR gaps but can slightly increase FPR gaps, indicating a tradeoff. Model architecture also matters: encoder models achieve far lower disparities than decoder-only GPT-2, and scaling further improves parity (e.g., RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> outperforms RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>).</p>\n\n",
                "matched_terms": [
                    "finetuning",
                    "reweighted",
                    "model",
                    "debertav2xl",
                    "robertalarge",
                    "fnr",
                    "loss",
                    "lower",
                    "fpr",
                    "robertabase"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nPrompting, even with larger models and few-shot examples, shows substantial per-axis disparities. Fine-tuned models, particularly with reweighted loss, achieve more balanced performance, although notable gaps remain. In additional analyses (in the appendix), we examined <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across the nine demographic axes. We found that certain targets, such as <span class=\"ltx_text ltx_font_typewriter\">NAT</span> and <span class=\"ltx_text ltx_font_typewriter\">PHY</span>, consistently have lower detection accuracy, which contributes to the observed disparities.</p>\n\n",
                "matched_terms": [
                    "reweighted",
                    "prompting",
                    "detection",
                    "f1f1",
                    "loss",
                    "lower",
                    "targets",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Prompting improves with scale and few-shot examples.</span> Few-shot prompting substantially narrows multi-axis gaps. For Llama-3.1-70B, <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m1\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}</annotation></semantics></math> drops from 0.736 (zero-shot) to 0.164 (10-shot), and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m2\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}</annotation></semantics></math> from 0.262 to 0.088. Larger models benefit more from in-context learning: Llama-3.1-70B outperforms Llama-3.1-8B, and disparities are generally higher for {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>} than {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}.</p>\n\n",
                "matched_terms": [
                    "zeroshot",
                    "incontext",
                    "prompting",
                    "higher",
                    "llama318b",
                    "llama3170b",
                    "10shot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuned models show persistent gaps.</span> Despite strong per-axis parity, fine-tuned models underperform on multi-axis instances, reflecting <em class=\"ltx_emph ltx_font_italic\">gerrymandering</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite> in their detection performance. For example, RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> with reweighting achieves <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.436</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436</annotation></semantics></math> and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m2\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.373</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373</annotation></semantics></math>, higher than few-shot Llama-3.1-70B and Qwen-2.5-72B. Encoder models outperform GPT-2, and scaling improves parity (e.g., DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> at <math alttext=\"\\approx 0.28\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m3\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8776;</mo><mn>0.28</mn></mrow><annotation encoding=\"application/x-tex\">\\approx 0.28</annotation></semantics></math> vs. DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> at 0.39 for FNR regarding {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>}). As with per-axis results, reweighting reduces FNR gaps but can slightly raise FPR gaps.</p>\n\n",
                "matched_terms": [
                    "debertav3large",
                    "detection",
                    "debertav2xl",
                    "robertalarge",
                    "higher",
                    "fnr",
                    "fpr",
                    "qwen2572b",
                    "llama3170b"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Inclusive stakeholder input.</span>\nAutomation enables large-scale auditing while minimizing human exposure to harmful content&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Steiger et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib49\" title=\"\">2021</a>)</cite>. However, bias detection remains a <em class=\"ltx_emph ltx_font_italic\">socio-technical challenge</em>: social biases are culturally situated, and the detection pipeline must be guided by participatory processes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Markov et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib36\" title=\"\">2023</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methodological opportunities.</span>\nOur findings highlight both promises and existing limitations of scalable automated bias detection. Future work should further explore advanced prompting (e.g., <span class=\"ltx_text ltx_font_italic\">chain-of-thought</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wei et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib56\" title=\"\">2022</a>)</cite>) and efficient fine-tuning (e.g., using adapters). To handle multimodal data, exploring effective and scalable solutions remains an interesting open challenge. Moreover, while our results offer initial guidance, balancing the potential gains from training and deploying larger models and the scalability required for auditing massive corpora warrants deeper exploration. Finally, our study shows that detecting infrequent, subtle, and multi-axis biases remains a crucial underexplored direction for future research.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "bias",
                    "finetuning",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Mitigation through data bias detection.</span>\nBias detection enables more than regulatory reporting; it allows for leveraging the flagged data instances for more responsible model development through targeted data augmentation, filtering, or fine-tuning&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite>. However, any remedial action <span class=\"ltx_text ltx_font_italic\">must be</span> guided by rigorous ethical considerations and incorporate human oversight.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "model",
                    "finetuning",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Text statistics.</span>\nIn Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F1.sf1\" title=\"In Figure 1 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1(a)</span></a>, we show the token count distribution for all the bias categories, including the <em class=\"ltx_emph ltx_font_italic\">unbiased</em> texts. To obtain tokens, we use the RoBERTa tokenizer. We see that the token counts for each text instance are generally low, indicating our dataset mainly contains short text instances. However, there are some outliers, e.g., in <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">SO</span>, where we see around 400 token length texts. Upon inspection, we observed that such instances primarily come from the BBQ dataset, that have very long context texts.</p>\n\n",
                "matched_terms": [
                    "unbiased",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Label statistics.</span>\nIn Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F2\" title=\"Figure 2 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, we visualize the label statistics in the final curated dataset. The visualizations show label imbalances in the data, highlighting the need for weighted loss for optimization and motivating future work to explore further fairness interventions to ensure equitable bias detection performance. The statistics show that our data contains more biased instances than unbiased ones. Furthermore, we see that most instances target a single demographic axis. However, many instances target two axes. Instances targeting more than two demographic axes are significantly fewer in our dataset. We provide more detailed label co-occurrence statistics in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F1.sf2\" title=\"In Figure 1 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1(b)</span></a>. The figure shows that text instances target specific demographics more often. For instance, texts target <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">GEN</span> more often. Similarly, texts target <span class=\"ltx_text ltx_font_typewriter\">DIS</span>,<span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">PHY</span> relatively less often. Furthermore, we see that <span class=\"ltx_text ltx_font_typewriter\">GEN</span> co-occurs with many other demographic axes, e.g., <span class=\"ltx_text ltx_font_typewriter\">SO</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, and <span class=\"ltx_text ltx_font_typewriter\">DIS</span>. Note that while <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">REL</span> appear together frequently, many of these instances simply target &#8220;Jewish identities.&#8221;</p>\n\n",
                "matched_terms": [
                    "unbiased",
                    "biased",
                    "detection",
                    "other",
                    "loss",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All LLMs are accessed via API through an MLOps platform. We fix <span class=\"ltx_text ltx_font_typewriter\">temperature</span> to 0 and <span class=\"ltx_text ltx_font_typewriter\">top_p</span> to 1, ensuring deterministic outputs by selecting the model&#8217;s most likely generation while still allowing consideration of the full token space. For in-context learning, we embed the training and development sets using BGE-M3 or BCEmbedding models. At inference time, we compute cosine similarity between the query and development set vectors to retrieve the top-<math alttext=\"K\" class=\"ltx_Math\" display=\"inline\" id=\"A2.SS1.p1.m1\" intent=\":literal\"><semantics><mi>K</mi><annotation encoding=\"application/x-tex\">K</annotation></semantics></math> few-shot examples. As a baseline, we also apply a random few-shot selection from the training set, with balanced sampling between biased and unbiased texts. Model predictions are extracted via pattern matching. Responses that cannot be parsed through pattern matching to assign to one of the multiple demographic axes are marked as &#8220;invalid.&#8221; The <span class=\"ltx_text ltx_font_italic\">social bias policy</span> used in the text prompt is shown here.</p>\n\n",
                "matched_terms": [
                    "time",
                    "unbiased",
                    "biased",
                    "incontext",
                    "model",
                    "inference",
                    "bias"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization uses AdamW with linear learning rate decay, weight decay of 0.01, and gradient clipping at 1.0. To address class imbalance, we experiment with reweighted binary cross-entropy loss, where weights are derived from label frequencies in the training set. Models are trained for four epochs without reweighting and six epochs with reweighting. The effective batch size is fixed at 32, with gradient accumulation applied for larger models. Learning rates are <span class=\"ltx_text ltx_font_italic\">tuned by monitoring validation loss</span>. For each model, we use the following learning rates for optimization:</p>\n\n",
                "matched_terms": [
                    "model",
                    "binary",
                    "loss",
                    "reweighted"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><math alttext=\"10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"A2.I1.i4.p1.m1\" intent=\":literal\"><semantics><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>5</mn></mrow></msup><annotation encoding=\"application/x-tex\">10^{-5}</annotation></semantics></math> (RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>)</p>\n\n",
                "matched_terms": [
                    "robertalarge",
                    "debertav2xl"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Learning rates are not changed across loss functions (default or reweighted). Training is performed in <span class=\"ltx_text ltx_font_typewriter\">float32</span> precision, except GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>, which uses <span class=\"ltx_text ltx_font_typewriter\">bfloat16</span>. All experiments run on a single GPU with 32GB VRAM and 128GB host memory.</p>\n\n",
                "matched_terms": [
                    "gpt2xl",
                    "loss",
                    "reweighted",
                    "default"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate the impact of retrieval-augmented generation (RAG) on few-shot example selection compared to random sampling. Results are presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.T6\" title=\"Table 6 &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>. Overall, RAG consistently enhances bias detection performance.</p>\n\n",
                "matched_terms": [
                    "bias",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In binary classification, RAG achieves higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS1.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across all models. Improvements in detection metrics are consistent across model sizes, demonstrating the benefit of providing LLMs with <em class=\"ltx_emph ltx_font_italic\">semantically similar examples</em> during in-context learning. RAG generally reduces False Negative Rates (FNR), though it occasionally causes slight increases in False Positive Rates (FPR), as observed with Llama Guard-3-8B and GLM-4-9B. This tradeoff is typically favorable, since reducing FNR is crucial for minimizing missed detections. Notably, while adding more examples under RAG yields only modest additional gains, increasing the number of randomly selected examples often leads to degraded performance.</p>\n\n",
                "matched_terms": [
                    "guard38b",
                    "positive",
                    "incontext",
                    "llama",
                    "glm49b",
                    "model",
                    "detection",
                    "negative",
                    "higher",
                    "binary",
                    "fnr",
                    "f1f1",
                    "fpr",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For multi-label prediction, RAG delivers even greater improvements over random sampling. As in the binary case, providing more RAG-selected examples enhances performance, whereas adding more random examples consistently worsens detection outcomes. This highlights an important insight: supplying more <em class=\"ltx_emph ltx_font_italic\">relevant</em> examples benefits prompting-based detection, but including <em class=\"ltx_emph ltx_font_italic\">irrelevant</em> examples can be detrimental.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "binary",
                    "detection",
                    "prediction"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In summary, RAG significantly strengthens in-context learning by providing more meaningful examples, resulting in higher accuracy and improved multi-label predictions. Although small increases in FPR can occur, the overall gains clearly favor RAG over random sampling.</p>\n\n",
                "matched_terms": [
                    "incontext",
                    "higher",
                    "multilabel",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We next examine how the choice of embedding model affects in-context learning performance for prompting, comparing BGE-M3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib6\" title=\"\">2024b</a>)</cite> and BCEmbedding&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Youdao, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib59\" title=\"\">2023</a>)</cite> for selecting in-context examples. The results are presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.T7\" title=\"Table 7 &#8227; C.1 Ablation study: in-context learning &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">7</span></a>.</p>\n\n",
                "matched_terms": [
                    "incontext",
                    "prompting",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">BGE-M3 exhibits a slight but consistent advantage in binary bias detection, producing marginally higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across multiple LLMs. However, the overall differences are minimal. In contrast, for multi-label prediction, BCEmbedding performs slightly better on metrics such as MR for many models. This finding suggests that while both embedding models select examples that yield similar overall outcomes, subtle differences exist. Specifically, BGE-M3-selected examples tend to improve binary bias detection by helping models better distinguish biased from unbiased samples, whereas BCEmbedding-selected examples slightly enhance the detection of specific bias types within biased instances.</p>\n\n",
                "matched_terms": [
                    "unbiased",
                    "biased",
                    "bias",
                    "better",
                    "detection",
                    "prediction",
                    "higher",
                    "binary",
                    "f1f1",
                    "multilabel",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Overall, both embedding models deliver strong and comparable performance for in-context learning, with only minor trade-offs. Their results indicate that either embedding model is well-suited for bias detection tasks.</p>\n\n",
                "matched_terms": [
                    "incontext",
                    "model",
                    "bias",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We now analyze model performance across different demographic targets. Specifically, we examine the <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p1.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores for all demographic axes in our taxonomy that may be subject to bias. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F5\" title=\"Figure 5 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents results for various prompted models using <em class=\"ltx_emph ltx_font_italic\">10-shot RAG-based in-context learning</em> with BGE-M3, while Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F6\" title=\"Figure 6 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> compares fine-tuned models and explores the impact of reweighted loss (&#8220;bal&#8221; in the figure) across demographics.</p>\n\n",
                "matched_terms": [
                    "reweighted",
                    "incontext",
                    "model",
                    "f1f1",
                    "loss",
                    "targets",
                    "10shot",
                    "bias",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our analysis shows that fine-tuned models consistently outperform prompting and transfer learning across all bias classes. The most notable <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> score gains appear in the AGE and SES categories, which are less frequent in the dataset.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "bias",
                    "f1f1"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Among the prompted LLMs, Llama-3.1-70B achieves the highest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p3.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across nearly all bias categories, except for <span class=\"ltx_text ltx_font_typewriter\">GEN</span>, where GLM-9B&#8212;despite being much smaller&#8212;slightly outperforms it. Interestingly, Qwen-2.5-72B, though the largest LLM, performs worse in many low-frequency categories such as <span class=\"ltx_text ltx_font_typewriter\">DIS</span>, <span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">SES</span>. It performs comparably to the best prompting models only for <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, which are the most common categories in the benchmark.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "f1f1",
                    "qwen2572b",
                    "llama3170b",
                    "bias",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For fine-tuned models, encoder-only architectures (e.g., RoBERTa and DeBERTa) generally outperform decoder-only language models, i.e., GPT-2, across most demographic axes. The trends mirror those observed in the prompting setup: models achieve their best performance for <span class=\"ltx_text ltx_font_typewriter\">SES</span>, while <span class=\"ltx_text ltx_font_typewriter\">NAT</span> consistently shows the lowest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. Reweighted loss often improves detection performance or yields similar results to the default loss. For example, in <span class=\"ltx_text ltx_font_typewriter\">NAT</span>, the axis that suffered from the weakest detection performance, reweighted loss improves performance across all models. However, improvements are not universal. For instance, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">large</span> experiences slight declines in <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> for some demographics such as <span class=\"ltx_text ltx_font_typewriter\">AGE</span> and <span class=\"ltx_text ltx_font_typewriter\">SES</span> when reweighted loss is applied.</p>\n\n",
                "matched_terms": [
                    "gpt2large",
                    "reweighted",
                    "prompting",
                    "setup",
                    "detection",
                    "f1f1",
                    "loss",
                    "default",
                    "scores"
                ]
            }
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Detection performance (binary F1F_{1}, multi-label MR, HL) per constituent dataset for select models (prompt: 10-shot, fine-tune: rew. loss).",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">Data</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">\n<span class=\"ltx_text ltx_font_bold\">Bin.</span> <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m3\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">MR</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">HL</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">BBQ</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"16.79_{\\pm 4.34}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m4\" intent=\":literal\"><semantics><msub><mn>16.79</mn><mrow><mo>&#177;</mo><mn>4.34</mn></mrow></msub><annotation encoding=\"application/x-tex\">16.79_{\\pm 4.34}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.082_{\\pm 0.025}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m5\" intent=\":literal\"><semantics><msub><mn>0.082</mn><mrow><mo>&#177;</mo><mn>0.025</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.082_{\\pm 0.025}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.103_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m6\" intent=\":literal\"><semantics><msub><mn>0.103</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.103_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"73.70_{\\pm 2.76}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m7\" intent=\":literal\"><semantics><msub><mn>73.70</mn><mrow><mo>&#177;</mo><mn>2.76</mn></mrow></msub><annotation encoding=\"application/x-tex\">73.70_{\\pm 2.76}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.962_{\\pm 0.017}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m8\" intent=\":literal\"><semantics><msub><mn>0.962</mn><mrow><mo>&#177;</mo><mn>0.017</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.962_{\\pm 0.017}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.005_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m9\" intent=\":literal\"><semantics><msub><mn>0.005</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.005_{\\pm 0.002}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"94.65_{\\pm 1.39}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m10\" intent=\":literal\"><semantics><msub><mn>94.65</mn><mrow><mo>&#177;</mo><mn>1.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">94.65_{\\pm 1.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.958_{\\pm 0.018}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m11\" intent=\":literal\"><semantics><msub><mn>0.958</mn><mrow><mo>&#177;</mo><mn>0.018</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.958_{\\pm 0.018}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.006_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m12\" intent=\":literal\"><semantics><msub><mn>0.006</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.006_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"96.42_{\\pm 1.14}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m13\" intent=\":literal\"><semantics><msub><mn>96.42</mn><mrow><mo>&#177;</mo><mn>1.14</mn></mrow></msub><annotation encoding=\"application/x-tex\">96.42_{\\pm 1.14}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.973_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m14\" intent=\":literal\"><semantics><msub><mn>0.973</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.973_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.004_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m15\" intent=\":literal\"><semantics><msub><mn>0.004</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.004_{\\pm 0.002}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"91.11_{\\pm 1.76}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m16\" intent=\":literal\"><semantics><msub><mn>91.11</mn><mrow><mo>&#177;</mo><mn>1.76</mn></mrow></msub><annotation encoding=\"application/x-tex\">91.11_{\\pm 1.76}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.946_{\\pm 0.021}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m17\" intent=\":literal\"><semantics><msub><mn>0.946</mn><mrow><mo>&#177;</mo><mn>0.021</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.946_{\\pm 0.021}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.007_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m18\" intent=\":literal\"><semantics><msub><mn>0.007</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.007_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">BEC-Pro</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.00_{\\pm 0.00}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m19\" intent=\":literal\"><semantics><msub><mn>0.00</mn><mrow><mo>&#177;</mo><mn>0.00</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.00_{\\pm 0.00}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m20\" intent=\":literal\"><semantics><msub><mn>0.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.000_{\\pm 0.000}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.111_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m21\" intent=\":literal\"><semantics><msub><mn>0.111</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.111_{\\pm 0.000}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"91.51_{\\pm 2.09}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m22\" intent=\":literal\"><semantics><msub><mn>91.51</mn><mrow><mo>&#177;</mo><mn>2.09</mn></mrow></msub><annotation encoding=\"application/x-tex\">91.51_{\\pm 2.09}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.982_{\\pm 0.015}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m23\" intent=\":literal\"><semantics><msub><mn>0.982</mn><mrow><mo>&#177;</mo><mn>0.015</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.982_{\\pm 0.015}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.002_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m24\" intent=\":literal\"><semantics><msub><mn>0.002</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.002_{\\pm 0.002}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"100.00_{\\pm 0.00}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m25\" intent=\":literal\"><semantics><msub><mn>100.00</mn><mrow><mo>&#177;</mo><mn>0.00</mn></mrow></msub><annotation encoding=\"application/x-tex\">100.00_{\\pm 0.00}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"1.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m26\" intent=\":literal\"><semantics><msub><mn>1.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">1.000_{\\pm 0.000}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m27\" intent=\":literal\"><semantics><msub><mn>0.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.000_{\\pm 0.000}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"100.00_{\\pm 0.00}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m28\" intent=\":literal\"><semantics><msub><mn>100.00</mn><mrow><mo>&#177;</mo><mn>0.00</mn></mrow></msub><annotation encoding=\"application/x-tex\">100.00_{\\pm 0.00}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"1.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m29\" intent=\":literal\"><semantics><msub><mn>1.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">1.000_{\\pm 0.000}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m30\" intent=\":literal\"><semantics><msub><mn>0.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.000_{\\pm 0.000}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"100.00_{\\pm 0.00}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m31\" intent=\":literal\"><semantics><msub><mn>100.00</mn><mrow><mo>&#177;</mo><mn>0.00</mn></mrow></msub><annotation encoding=\"application/x-tex\">100.00_{\\pm 0.00}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"1.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m32\" intent=\":literal\"><semantics><msub><mn>1.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">1.000_{\\pm 0.000}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m33\" intent=\":literal\"><semantics><msub><mn>0.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.000_{\\pm 0.000}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">CrowS-Pairs</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"50.37_{\\pm 4.25}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m34\" intent=\":literal\"><semantics><msub><mn>50.37</mn><mrow><mo>&#177;</mo><mn>4.25</mn></mrow></msub><annotation encoding=\"application/x-tex\">50.37_{\\pm 4.25}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.276_{\\pm 0.037}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m35\" intent=\":literal\"><semantics><msub><mn>0.276</mn><mrow><mo>&#177;</mo><mn>0.037</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.276_{\\pm 0.037}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.086_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m36\" intent=\":literal\"><semantics><msub><mn>0.086</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.086_{\\pm 0.005}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"95.19_{\\pm 1.29}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m37\" intent=\":literal\"><semantics><msub><mn>95.19</mn><mrow><mo>&#177;</mo><mn>1.29</mn></mrow></msub><annotation encoding=\"application/x-tex\">95.19_{\\pm 1.29}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.640_{\\pm 0.038}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m38\" intent=\":literal\"><semantics><msub><mn>0.640</mn><mrow><mo>&#177;</mo><mn>0.038</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.640_{\\pm 0.038}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.046_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m39\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.006}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"97.38_{\\pm 0.96}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m40\" intent=\":literal\"><semantics><msub><mn>97.38</mn><mrow><mo>&#177;</mo><mn>0.96</mn></mrow></msub><annotation encoding=\"application/x-tex\">97.38_{\\pm 0.96}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.821_{\\pm 0.030}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m41\" intent=\":literal\"><semantics><msub><mn>0.821</mn><mrow><mo>&#177;</mo><mn>0.030</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.821_{\\pm 0.030}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.026_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m42\" intent=\":literal\"><semantics><msub><mn>0.026</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.026_{\\pm 0.005}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"99.14_{\\pm 0.53}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m43\" intent=\":literal\"><semantics><msub><mn>99.14</mn><mrow><mo>&#177;</mo><mn>0.53</mn></mrow></msub><annotation encoding=\"application/x-tex\">99.14_{\\pm 0.53}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.752_{\\pm 0.034}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m44\" intent=\":literal\"><semantics><msub><mn>0.752</mn><mrow><mo>&#177;</mo><mn>0.034</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.752_{\\pm 0.034}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.039_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m45\" intent=\":literal\"><semantics><msub><mn>0.039</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.039_{\\pm 0.006}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"98.61_{\\pm 0.66}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m46\" intent=\":literal\"><semantics><msub><mn>98.61</mn><mrow><mo>&#177;</mo><mn>0.66</mn></mrow></msub><annotation encoding=\"application/x-tex\">98.61_{\\pm 0.66}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.755_{\\pm 0.033}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m47\" intent=\":literal\"><semantics><msub><mn>0.755</mn><mrow><mo>&#177;</mo><mn>0.033</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.755_{\\pm 0.033}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.040_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m48\" intent=\":literal\"><semantics><msub><mn>0.040</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.040_{\\pm 0.006}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">HateXplain</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"90.13_{\\pm 0.92}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m49\" intent=\":literal\"><semantics><msub><mn>90.13</mn><mrow><mo>&#177;</mo><mn>0.92</mn></mrow></msub><annotation encoding=\"application/x-tex\">90.13_{\\pm 0.92}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.558_{\\pm 0.021}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m50\" intent=\":literal\"><semantics><msub><mn>0.558</mn><mrow><mo>&#177;</mo><mn>0.021</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.558_{\\pm 0.021}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.067_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m51\" intent=\":literal\"><semantics><msub><mn>0.067</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.067_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"91.51_{\\pm 0.84}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m52\" intent=\":literal\"><semantics><msub><mn>91.51</mn><mrow><mo>&#177;</mo><mn>0.84</mn></mrow></msub><annotation encoding=\"application/x-tex\">91.51_{\\pm 0.84}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.418_{\\pm 0.021}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m53\" intent=\":literal\"><semantics><msub><mn>0.418</mn><mrow><mo>&#177;</mo><mn>0.021</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.418_{\\pm 0.021}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.083_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m54\" intent=\":literal\"><semantics><msub><mn>0.083</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.083_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"91.24_{\\pm 0.88}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m55\" intent=\":literal\"><semantics><msub><mn>91.24</mn><mrow><mo>&#177;</mo><mn>0.88</mn></mrow></msub><annotation encoding=\"application/x-tex\">91.24_{\\pm 0.88}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.723_{\\pm 0.018}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m56\" intent=\":literal\"><semantics><msub><mn>0.723</mn><mrow><mo>&#177;</mo><mn>0.018</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.723_{\\pm 0.018}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.039_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m57\" intent=\":literal\"><semantics><msub><mn>0.039</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.039_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"91.28_{\\pm 0.89}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m58\" intent=\":literal\"><semantics><msub><mn>91.28</mn><mrow><mo>&#177;</mo><mn>0.89</mn></mrow></msub><annotation encoding=\"application/x-tex\">91.28_{\\pm 0.89}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.717_{\\pm 0.020}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m59\" intent=\":literal\"><semantics><msub><mn>0.717</mn><mrow><mo>&#177;</mo><mn>0.020</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.717_{\\pm 0.020}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.042_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m60\" intent=\":literal\"><semantics><msub><mn>0.042</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.042_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"91.34_{\\pm 0.86}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m61\" intent=\":literal\"><semantics><msub><mn>91.34</mn><mrow><mo>&#177;</mo><mn>0.86</mn></mrow></msub><annotation encoding=\"application/x-tex\">91.34_{\\pm 0.86}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.743_{\\pm 0.019}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m62\" intent=\":literal\"><semantics><msub><mn>0.743</mn><mrow><mo>&#177;</mo><mn>0.019</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.743_{\\pm 0.019}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.036_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m63\" intent=\":literal\"><semantics><msub><mn>0.036</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.036_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">ImplicitHate</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"80.94_{\\pm 1.85}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m64\" intent=\":literal\"><semantics><msub><mn>80.94</mn><mrow><mo>&#177;</mo><mn>1.85</mn></mrow></msub><annotation encoding=\"application/x-tex\">80.94_{\\pm 1.85}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.505_{\\pm 0.026}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m65\" intent=\":literal\"><semantics><msub><mn>0.505</mn><mrow><mo>&#177;</mo><mn>0.026</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.505_{\\pm 0.026}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.066_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m66\" intent=\":literal\"><semantics><msub><mn>0.066</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.066_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"99.03_{\\pm 0.39}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m67\" intent=\":literal\"><semantics><msub><mn>99.03</mn><mrow><mo>&#177;</mo><mn>0.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">99.03_{\\pm 0.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.657_{\\pm 0.026}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m68\" intent=\":literal\"><semantics><msub><mn>0.657</mn><mrow><mo>&#177;</mo><mn>0.026</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.657_{\\pm 0.026}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.047_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m69\" intent=\":literal\"><semantics><msub><mn>0.047</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.047_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"98.80_{\\pm 0.42}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m70\" intent=\":literal\"><semantics><msub><mn>98.80</mn><mrow><mo>&#177;</mo><mn>0.42</mn></mrow></msub><annotation encoding=\"application/x-tex\">98.80_{\\pm 0.42}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.773_{\\pm 0.022}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m71\" intent=\":literal\"><semantics><msub><mn>0.773</mn><mrow><mo>&#177;</mo><mn>0.022</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.773_{\\pm 0.022}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.037_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m72\" intent=\":literal\"><semantics><msub><mn>0.037</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.037_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"99.19_{\\pm 0.35}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m73\" intent=\":literal\"><semantics><msub><mn>99.19</mn><mrow><mo>&#177;</mo><mn>0.35</mn></mrow></msub><annotation encoding=\"application/x-tex\">99.19_{\\pm 0.35}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.751_{\\pm 0.023}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m74\" intent=\":literal\"><semantics><msub><mn>0.751</mn><mrow><mo>&#177;</mo><mn>0.023</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.751_{\\pm 0.023}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.039_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m75\" intent=\":literal\"><semantics><msub><mn>0.039</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.039_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"99.30_{\\pm 0.32}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m76\" intent=\":literal\"><semantics><msub><mn>99.30</mn><mrow><mo>&#177;</mo><mn>0.32</mn></mrow></msub><annotation encoding=\"application/x-tex\">99.30_{\\pm 0.32}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.744_{\\pm 0.022}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m77\" intent=\":literal\"><semantics><msub><mn>0.744</mn><mrow><mo>&#177;</mo><mn>0.022</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.744_{\\pm 0.022}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.039_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m78\" intent=\":literal\"><semantics><msub><mn>0.039</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.039_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">RedditBias</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"66.98_{\\pm 1.58}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m79\" intent=\":literal\"><semantics><msub><mn>66.98</mn><mrow><mo>&#177;</mo><mn>1.58</mn></mrow></msub><annotation encoding=\"application/x-tex\">66.98_{\\pm 1.58}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.454_{\\pm 0.020}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m80\" intent=\":literal\"><semantics><msub><mn>0.454</mn><mrow><mo>&#177;</mo><mn>0.020</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.454_{\\pm 0.020}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.070_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m81\" intent=\":literal\"><semantics><msub><mn>0.070</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.070_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"79.85_{\\pm 1.03}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m82\" intent=\":literal\"><semantics><msub><mn>79.85</mn><mrow><mo>&#177;</mo><mn>1.03</mn></mrow></msub><annotation encoding=\"application/x-tex\">79.85_{\\pm 1.03}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.716_{\\pm 0.017}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m83\" intent=\":literal\"><semantics><msub><mn>0.716</mn><mrow><mo>&#177;</mo><mn>0.017</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.716_{\\pm 0.017}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.036_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m84\" intent=\":literal\"><semantics><msub><mn>0.036</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.036_{\\pm 0.002}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"85.20_{\\pm 1.06}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m85\" intent=\":literal\"><semantics><msub><mn>85.20</mn><mrow><mo>&#177;</mo><mn>1.06</mn></mrow></msub><annotation encoding=\"application/x-tex\">85.20_{\\pm 1.06}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.827_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m86\" intent=\":literal\"><semantics><msub><mn>0.827</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.827_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.023_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m87\" intent=\":literal\"><semantics><msub><mn>0.023</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.023_{\\pm 0.002}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"82.98_{\\pm 1.07}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m88\" intent=\":literal\"><semantics><msub><mn>82.98</mn><mrow><mo>&#177;</mo><mn>1.07</mn></mrow></msub><annotation encoding=\"application/x-tex\">82.98_{\\pm 1.07}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.811_{\\pm 0.015}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m89\" intent=\":literal\"><semantics><msub><mn>0.811</mn><mrow><mo>&#177;</mo><mn>0.015</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.811_{\\pm 0.015}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.025_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m90\" intent=\":literal\"><semantics><msub><mn>0.025</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.025_{\\pm 0.002}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"79.65_{\\pm 1.11}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m91\" intent=\":literal\"><semantics><msub><mn>79.65</mn><mrow><mo>&#177;</mo><mn>1.11</mn></mrow></msub><annotation encoding=\"application/x-tex\">79.65_{\\pm 1.11}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.840_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m92\" intent=\":literal\"><semantics><msub><mn>0.840</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.840_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.020_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m93\" intent=\":literal\"><semantics><msub><mn>0.020</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.020_{\\pm 0.002}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">SBIC</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"80.02_{\\pm 1.45}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m94\" intent=\":literal\"><semantics><msub><mn>80.02</mn><mrow><mo>&#177;</mo><mn>1.45</mn></mrow></msub><annotation encoding=\"application/x-tex\">80.02_{\\pm 1.45}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.431_{\\pm 0.021}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m95\" intent=\":literal\"><semantics><msub><mn>0.431</mn><mrow><mo>&#177;</mo><mn>0.021</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.431_{\\pm 0.021}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.080_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m96\" intent=\":literal\"><semantics><msub><mn>0.080</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.080_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"98.05_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m97\" intent=\":literal\"><semantics><msub><mn>98.05</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">98.05_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.598_{\\pm 0.020}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m98\" intent=\":literal\"><semantics><msub><mn>0.598</mn><mrow><mo>&#177;</mo><mn>0.020</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.598_{\\pm 0.020}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.056_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m99\" intent=\":literal\"><semantics><msub><mn>0.056</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.056_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"99.65_{\\pm 0.17}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m100\" intent=\":literal\"><semantics><msub><mn>99.65</mn><mrow><mo>&#177;</mo><mn>0.17</mn></mrow></msub><annotation encoding=\"application/x-tex\">99.65_{\\pm 0.17}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.754_{\\pm 0.017}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m101\" intent=\":literal\"><semantics><msub><mn>0.754</mn><mrow><mo>&#177;</mo><mn>0.017</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.754_{\\pm 0.017}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.038_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m102\" intent=\":literal\"><semantics><msub><mn>0.038</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.038_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"99.38_{\\pm 0.23}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m103\" intent=\":literal\"><semantics><msub><mn>99.38</mn><mrow><mo>&#177;</mo><mn>0.23</mn></mrow></msub><annotation encoding=\"application/x-tex\">99.38_{\\pm 0.23}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.698_{\\pm 0.018}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m104\" intent=\":literal\"><semantics><msub><mn>0.698</mn><mrow><mo>&#177;</mo><mn>0.018</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.698_{\\pm 0.018}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.048_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m105\" intent=\":literal\"><semantics><msub><mn>0.048</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.048_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"99.49_{\\pm 0.21}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m106\" intent=\":literal\"><semantics><msub><mn>99.49</mn><mrow><mo>&#177;</mo><mn>0.21</mn></mrow></msub><annotation encoding=\"application/x-tex\">99.49_{\\pm 0.21}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.725_{\\pm 0.018}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m107\" intent=\":literal\"><semantics><msub><mn>0.725</mn><mrow><mo>&#177;</mo><mn>0.018</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.725_{\\pm 0.018}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.043_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m108\" intent=\":literal\"><semantics><msub><mn>0.043</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.043_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">StereoSet</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"35.93_{\\pm 5.95}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m109\" intent=\":literal\"><semantics><msub><mn>35.93</mn><mrow><mo>&#177;</mo><mn>5.95</mn></mrow></msub><annotation encoding=\"application/x-tex\">35.93_{\\pm 5.95}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.190_{\\pm 0.040}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m110\" intent=\":literal\"><semantics><msub><mn>0.190</mn><mrow><mo>&#177;</mo><mn>0.040</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.190_{\\pm 0.040}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.094_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m111\" intent=\":literal\"><semantics><msub><mn>0.094</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.094_{\\pm 0.005}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"75.75_{\\pm 3.44}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m112\" intent=\":literal\"><semantics><msub><mn>75.75</mn><mrow><mo>&#177;</mo><mn>3.44</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.75_{\\pm 3.44}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.546_{\\pm 0.050}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m113\" intent=\":literal\"><semantics><msub><mn>0.546</mn><mrow><mo>&#177;</mo><mn>0.050</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.546_{\\pm 0.050}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.056_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m114\" intent=\":literal\"><semantics><msub><mn>0.056</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.056_{\\pm 0.007}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"77.16_{\\pm 3.39}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m115\" intent=\":literal\"><semantics><msub><mn>77.16</mn><mrow><mo>&#177;</mo><mn>3.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">77.16_{\\pm 3.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.770_{\\pm 0.046}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m116\" intent=\":literal\"><semantics><msub><mn>0.770</mn><mrow><mo>&#177;</mo><mn>0.046</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.770_{\\pm 0.046}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.029_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m117\" intent=\":literal\"><semantics><msub><mn>0.029</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.029_{\\pm 0.006}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"79.26_{\\pm 3.23}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m118\" intent=\":literal\"><semantics><msub><mn>79.26</mn><mrow><mo>&#177;</mo><mn>3.23</mn></mrow></msub><annotation encoding=\"application/x-tex\">79.26_{\\pm 3.23}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.744_{\\pm 0.044}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m119\" intent=\":literal\"><semantics><msub><mn>0.744</mn><mrow><mo>&#177;</mo><mn>0.044</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.744_{\\pm 0.044}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.032_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m120\" intent=\":literal\"><semantics><msub><mn>0.032</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.032_{\\pm 0.006}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"74.47_{\\pm 3.35}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m121\" intent=\":literal\"><semantics><msub><mn>74.47</mn><mrow><mo>&#177;</mo><mn>3.35</mn></mrow></msub><annotation encoding=\"application/x-tex\">74.47_{\\pm 3.35}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.749_{\\pm 0.044}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m122\" intent=\":literal\"><semantics><msub><mn>0.749</mn><mrow><mo>&#177;</mo><mn>0.044</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.749_{\\pm 0.044}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.031_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m123\" intent=\":literal\"><semantics><msub><mn>0.031</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.031_{\\pm 0.006}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">ToxiGen</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"84.06_{\\pm 2.73}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m124\" intent=\":literal\"><semantics><msub><mn>84.06</mn><mrow><mo>&#177;</mo><mn>2.73</mn></mrow></msub><annotation encoding=\"application/x-tex\">84.06_{\\pm 2.73}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.622_{\\pm 0.045}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m125\" intent=\":literal\"><semantics><msub><mn>0.622</mn><mrow><mo>&#177;</mo><mn>0.045</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.622_{\\pm 0.045}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.054_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m126\" intent=\":literal\"><semantics><msub><mn>0.054</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.054_{\\pm 0.007}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"82.23_{\\pm 2.58}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m127\" intent=\":literal\"><semantics><msub><mn>82.23</mn><mrow><mo>&#177;</mo><mn>2.58</mn></mrow></msub><annotation encoding=\"application/x-tex\">82.23_{\\pm 2.58}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.659_{\\pm 0.046}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m128\" intent=\":literal\"><semantics><msub><mn>0.659</mn><mrow><mo>&#177;</mo><mn>0.046</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.659_{\\pm 0.046}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.044_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m129\" intent=\":literal\"><semantics><msub><mn>0.044</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.044_{\\pm 0.007}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"82.80_{\\pm 2.67}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m130\" intent=\":literal\"><semantics><msub><mn>82.80</mn><mrow><mo>&#177;</mo><mn>2.67</mn></mrow></msub><annotation encoding=\"application/x-tex\">82.80_{\\pm 2.67}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.754_{\\pm 0.041}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m131\" intent=\":literal\"><semantics><msub><mn>0.754</mn><mrow><mo>&#177;</mo><mn>0.041</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.754_{\\pm 0.041}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.037_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m132\" intent=\":literal\"><semantics><msub><mn>0.037</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.037_{\\pm 0.007}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"81.42_{\\pm 2.79}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m133\" intent=\":literal\"><semantics><msub><mn>81.42</mn><mrow><mo>&#177;</mo><mn>2.79</mn></mrow></msub><annotation encoding=\"application/x-tex\">81.42_{\\pm 2.79}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.728_{\\pm 0.041}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m134\" intent=\":literal\"><semantics><msub><mn>0.728</mn><mrow><mo>&#177;</mo><mn>0.041</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.728_{\\pm 0.041}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.038_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m135\" intent=\":literal\"><semantics><msub><mn>0.038</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.038_{\\pm 0.007}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"73.51_{\\pm 3.02}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m136\" intent=\":literal\"><semantics><msub><mn>73.51</mn><mrow><mo>&#177;</mo><mn>3.02</mn></mrow></msub><annotation encoding=\"application/x-tex\">73.51_{\\pm 3.02}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.760_{\\pm 0.042}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m137\" intent=\":literal\"><semantics><msub><mn>0.760</mn><mrow><mo>&#177;</mo><mn>0.042</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.760_{\\pm 0.042}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.033_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m138\" intent=\":literal\"><semantics><msub><mn>0.033</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.033_{\\pm 0.006}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">WinoBias-1</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.82_{\\pm 1.23}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m139\" intent=\":literal\"><semantics><msub><mn>0.82</mn><mrow><mo>&#177;</mo><mn>1.23</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.82_{\\pm 1.23}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.004_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m140\" intent=\":literal\"><semantics><msub><mn>0.004</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.004_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.111_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m141\" intent=\":literal\"><semantics><msub><mn>0.111</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.111_{\\pm 0.001}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"41.61_{\\pm 5.12}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m142\" intent=\":literal\"><semantics><msub><mn>41.61</mn><mrow><mo>&#177;</mo><mn>5.12</mn></mrow></msub><annotation encoding=\"application/x-tex\">41.61_{\\pm 5.12}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.467_{\\pm 0.063}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m143\" intent=\":literal\"><semantics><msub><mn>0.467</mn><mrow><mo>&#177;</mo><mn>0.063</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.467_{\\pm 0.063}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.060_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m144\" intent=\":literal\"><semantics><msub><mn>0.060</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.060_{\\pm 0.007}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"91.77_{\\pm 2.46}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m145\" intent=\":literal\"><semantics><msub><mn>91.77</mn><mrow><mo>&#177;</mo><mn>2.46</mn></mrow></msub><annotation encoding=\"application/x-tex\">91.77_{\\pm 2.46}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.951_{\\pm 0.026}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m146\" intent=\":literal\"><semantics><msub><mn>0.951</mn><mrow><mo>&#177;</mo><mn>0.026</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.951_{\\pm 0.026}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.005_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m147\" intent=\":literal\"><semantics><msub><mn>0.005</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.005_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"92.98_{\\pm 2.23}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m148\" intent=\":literal\"><semantics><msub><mn>92.98</mn><mrow><mo>&#177;</mo><mn>2.23</mn></mrow></msub><annotation encoding=\"application/x-tex\">92.98_{\\pm 2.23}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.972_{\\pm 0.021}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m149\" intent=\":literal\"><semantics><msub><mn>0.972</mn><mrow><mo>&#177;</mo><mn>0.021</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.972_{\\pm 0.021}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.003_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m150\" intent=\":literal\"><semantics><msub><mn>0.003</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.003_{\\pm 0.002}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"60.34_{\\pm 4.34}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m151\" intent=\":literal\"><semantics><msub><mn>60.34</mn><mrow><mo>&#177;</mo><mn>4.34</mn></mrow></msub><annotation encoding=\"application/x-tex\">60.34_{\\pm 4.34}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.852_{\\pm 0.043}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m152\" intent=\":literal\"><semantics><msub><mn>0.852</mn><mrow><mo>&#177;</mo><mn>0.043</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.852_{\\pm 0.043}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.016_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m153\" intent=\":literal\"><semantics><msub><mn>0.016</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.016_{\\pm 0.005}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">WinoBias-2</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.83_{\\pm 1.32}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m154\" intent=\":literal\"><semantics><msub><mn>0.83</mn><mrow><mo>&#177;</mo><mn>1.32</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.83_{\\pm 1.32}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.004_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m155\" intent=\":literal\"><semantics><msub><mn>0.004</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.004_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.111_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m156\" intent=\":literal\"><semantics><msub><mn>0.111</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.111_{\\pm 0.001}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"49.59_{\\pm 4.83}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m157\" intent=\":literal\"><semantics><msub><mn>49.59</mn><mrow><mo>&#177;</mo><mn>4.83</mn></mrow></msub><annotation encoding=\"application/x-tex\">49.59_{\\pm 4.83}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.581_{\\pm 0.062}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m158\" intent=\":literal\"><semantics><msub><mn>0.581</mn><mrow><mo>&#177;</mo><mn>0.062</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.581_{\\pm 0.062}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.047_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m159\" intent=\":literal\"><semantics><msub><mn>0.047</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.047_{\\pm 0.007}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"98.98_{\\pm 0.89}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m160\" intent=\":literal\"><semantics><msub><mn>98.98</mn><mrow><mo>&#177;</mo><mn>0.89</mn></mrow></msub><annotation encoding=\"application/x-tex\">98.98_{\\pm 0.89}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.992_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m161\" intent=\":literal\"><semantics><msub><mn>0.992</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.992_{\\pm 0.011}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.001_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m162\" intent=\":literal\"><semantics><msub><mn>0.001</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.001_{\\pm 0.001}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"98.77_{\\pm 0.98}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m163\" intent=\":literal\"><semantics><msub><mn>98.77</mn><mrow><mo>&#177;</mo><mn>0.98</mn></mrow></msub><annotation encoding=\"application/x-tex\">98.77_{\\pm 0.98}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.988_{\\pm 0.013}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m164\" intent=\":literal\"><semantics><msub><mn>0.988</mn><mrow><mo>&#177;</mo><mn>0.013</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.988_{\\pm 0.013}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.001_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m165\" intent=\":literal\"><semantics><msub><mn>0.001</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.001_{\\pm 0.001}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"98.98_{\\pm 0.84}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m166\" intent=\":literal\"><semantics><msub><mn>98.98</mn><mrow><mo>&#177;</mo><mn>0.84</mn></mrow></msub><annotation encoding=\"application/x-tex\">98.98_{\\pm 0.84}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"1.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m167\" intent=\":literal\"><semantics><msub><mn>1.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">1.000_{\\pm 0.000}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m168\" intent=\":literal\"><semantics><msub><mn>0.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.000_{\\pm 0.000}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">WinoGender</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.00_{\\pm 0.00}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m169\" intent=\":literal\"><semantics><msub><mn>0.00</mn><mrow><mo>&#177;</mo><mn>0.00</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.00_{\\pm 0.00}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m170\" intent=\":literal\"><semantics><msub><mn>0.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.000_{\\pm 0.000}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.111_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m171\" intent=\":literal\"><semantics><msub><mn>0.111</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.111_{\\pm 0.000}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"63.33_{\\pm 15.17}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m172\" intent=\":literal\"><semantics><msub><mn>63.33</mn><mrow><mo>&#177;</mo><mn>15.17</mn></mrow></msub><annotation encoding=\"application/x-tex\">63.33_{\\pm 15.17}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.623_{\\pm 0.165}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m173\" intent=\":literal\"><semantics><msub><mn>0.623</mn><mrow><mo>&#177;</mo><mn>0.165</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.623_{\\pm 0.165}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.042_{\\pm 0.018}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m174\" intent=\":literal\"><semantics><msub><mn>0.042</mn><mrow><mo>&#177;</mo><mn>0.018</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.042_{\\pm 0.018}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"89.86_{\\pm 7.98}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m175\" intent=\":literal\"><semantics><msub><mn>89.86</mn><mrow><mo>&#177;</mo><mn>7.98</mn></mrow></msub><annotation encoding=\"application/x-tex\">89.86_{\\pm 7.98}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.913_{\\pm 0.100}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m176\" intent=\":literal\"><semantics><msub><mn>0.913</mn><mrow><mo>&#177;</mo><mn>0.100</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.913_{\\pm 0.100}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.010_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m177\" intent=\":literal\"><semantics><msub><mn>0.010</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.010_{\\pm 0.011}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"84.68_{\\pm 9.29}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m178\" intent=\":literal\"><semantics><msub><mn>84.68</mn><mrow><mo>&#177;</mo><mn>9.29</mn></mrow></msub><annotation encoding=\"application/x-tex\">84.68_{\\pm 9.29}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.910_{\\pm 0.097}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m179\" intent=\":literal\"><semantics><msub><mn>0.910</mn><mrow><mo>&#177;</mo><mn>0.097</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.910_{\\pm 0.097}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.010_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m180\" intent=\":literal\"><semantics><msub><mn>0.010</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.010_{\\pm 0.011}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"78.86_{\\pm 10.71}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m181\" intent=\":literal\"><semantics><msub><mn>78.86</mn><mrow><mo>&#177;</mo><mn>10.71</mn></mrow></msub><annotation encoding=\"application/x-tex\">78.86_{\\pm 10.71}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.940_{\\pm 0.076}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m182\" intent=\":literal\"><semantics><msub><mn>0.940</mn><mrow><mo>&#177;</mo><mn>0.076</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.940_{\\pm 0.076}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.007_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m183\" intent=\":literal\"><semantics><msub><mn>0.007</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.007_{\\pm 0.008}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"5\">WinoQueer</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Llama-Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"92.09_{\\pm 0.81}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m184\" intent=\":literal\"><semantics><msub><mn>92.09</mn><mrow><mo>&#177;</mo><mn>0.81</mn></mrow></msub><annotation encoding=\"application/x-tex\">92.09_{\\pm 0.81}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"0.829_{\\pm 0.015}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m185\" intent=\":literal\"><semantics><msub><mn>0.829</mn><mrow><mo>&#177;</mo><mn>0.015</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.829_{\\pm 0.015}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math alttext=\"0.022_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m186\" intent=\":literal\"><semantics><msub><mn>0.022</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.022_{\\pm 0.002}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"99.79_{\\pm 0.14}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m187\" intent=\":literal\"><semantics><msub><mn>99.79</mn><mrow><mo>&#177;</mo><mn>0.14</mn></mrow></msub><annotation encoding=\"application/x-tex\">99.79_{\\pm 0.14}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.755_{\\pm 0.017}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m188\" intent=\":literal\"><semantics><msub><mn>0.755</mn><mrow><mo>&#177;</mo><mn>0.017</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.755_{\\pm 0.017}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.028_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m189\" intent=\":literal\"><semantics><msub><mn>0.028</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.028_{\\pm 0.002}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"100.00_{\\pm 0.00}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m190\" intent=\":literal\"><semantics><msub><mn>100.00</mn><mrow><mo>&#177;</mo><mn>0.00</mn></mrow></msub><annotation encoding=\"application/x-tex\">100.00_{\\pm 0.00}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"1.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m191\" intent=\":literal\"><semantics><msub><mn>1.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">1.000_{\\pm 0.000}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m192\" intent=\":literal\"><semantics><msub><mn>0.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.000_{\\pm 0.000}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"100.00_{\\pm 0.00}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m193\" intent=\":literal\"><semantics><msub><mn>100.00</mn><mrow><mo>&#177;</mo><mn>0.00</mn></mrow></msub><annotation encoding=\"application/x-tex\">100.00_{\\pm 0.00}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"1.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m194\" intent=\":literal\"><semantics><msub><mn>1.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">1.000_{\\pm 0.000}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><math alttext=\"0.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m195\" intent=\":literal\"><semantics><msub><mn>0.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.000_{\\pm 0.000}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">GPT2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><math alttext=\"100.00_{\\pm 0.00}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m196\" intent=\":literal\"><semantics><msub><mn>100.00</mn><mrow><mo>&#177;</mo><mn>0.00</mn></mrow></msub><annotation encoding=\"application/x-tex\">100.00_{\\pm 0.00}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><math alttext=\"1.000_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m197\" intent=\":literal\"><semantics><msub><mn>1.000</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">1.000_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><math alttext=\"0.000_{\\pm 0.000}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T4.m198\" intent=\":literal\"><semantics><msub><mn>0.000</mn><mrow><mo>&#177;</mo><mn>0.000</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.000_{\\pm 0.000}</annotation></semantics></math></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "0754±00170754pm",
            "0048±00030048pm",
            "0003±00020003pm",
            "0940±00760940pm",
            "0958±00180958pm",
            "debertav3large",
            "detection",
            "8986±7988986pm",
            "9151±0849151pm",
            "0913±01000913pm",
            "0982±00150982pm",
            "0016±00050016pm",
            "9965±0179965pm",
            "8468±9298468pm",
            "10000±00010000pm",
            "llamaguard38b",
            "0070±00030070pm",
            "toxigen",
            "0040±00060040pm",
            "0852±00430852pm",
            "0046±00060046pm",
            "0657±00260657pm",
            "select",
            "0505±00260505pm",
            "0032±00060032pm",
            "0026±00050026pm",
            "0760±00420760pm",
            "0039±00040039pm",
            "bbq",
            "0622±00450622pm",
            "9128±0899128pm",
            "0773±00220773pm",
            "4161±5124161pm",
            "0001±00010001pm",
            "0060±00070060pm",
            "0725±00180725pm",
            "0038±00070038pm",
            "0039±00030039pm",
            "0749±00440749pm",
            "0039±00060039pm",
            "0066±00040066pm",
            "constituent",
            "9938±0239938pm",
            "9898±0899898pm",
            "0038±00030038pm",
            "7575±3447575pm",
            "0044±00070044pm",
            "0276±00370276pm",
            "8520±1068520pm",
            "0946±00210946pm",
            "gpt2xl",
            "0047±00040047pm",
            "llama3170b",
            "8298±1078298pm",
            "0056±00070056pm",
            "9465±1399465pm",
            "7351±3027351pm",
            "0020±00020020pm",
            "0022±00020022pm",
            "9519±1299519pm",
            "0951±00260951pm",
            "4959±4834959pm",
            "0111±00000111pm",
            "0002±00020002pm",
            "9111±1769111pm",
            "0067±00040067pm",
            "0036±00030036pm",
            "9642±1149642pm",
            "0821±00300821pm",
            "0755±00170755pm",
            "0728±00410728pm",
            "8142±2798142pm",
            "winobias2",
            "8094±1858094pm",
            "9298±2239298pm",
            "0086±00050086pm",
            "finetune",
            "7370±2767370pm",
            "0962±00170962pm",
            "8406±2738406pm",
            "9979±0149979pm",
            "7447±3357447pm",
            "0992±00110992pm",
            "bin",
            "0005±00020005pm",
            "0770±00460770pm",
            "0023±00020023pm",
            "6333±15176333pm",
            "0031±00060031pm",
            "9919±0359919pm",
            "0103±00030103pm",
            "0080±00030080pm",
            "0744±00220744pm",
            "debertav2xl",
            "f1f1",
            "stereoset",
            "0005±00030005pm",
            "6034±4346034pm",
            "0910±00970910pm",
            "0036±00020036pm",
            "0623±01650623pm",
            "0717±00200717pm",
            "models",
            "0723±00180723pm",
            "0004±00070004pm",
            "0042±00180042pm",
            "000±000000pm",
            "winoqueer",
            "082±123082pm",
            "0827±00140827pm",
            "0028±00020028pm",
            "0037±00040037pm",
            "0190±00400190pm",
            "0829±00150829pm",
            "0840±00140840pm",
            "9914±0539914pm",
            "0754±00410754pm",
            "0010±00110010pm",
            "7716±3397716pm",
            "9877±0989877pm",
            "0467±00630467pm",
            "0581±00620581pm",
            "performance",
            "7965±1117965pm",
            "0598±00200598pm",
            "9177±2469177pm",
            "9898±0849898pm",
            "0082±00250082pm",
            "7985±1037985pm",
            "0752±00340752pm",
            "0431±00210431pm",
            "9209±0819209pm",
            "3593±5953593pm",
            "7926±3237926pm",
            "becpro",
            "9124±0889124pm",
            "6698±1586698pm",
            "0007±00030007pm",
            "0083±00040083pm",
            "1000±00011000pm",
            "0418±00210418pm",
            "0988±00130988pm",
            "9134±0869134pm",
            "prompt",
            "model",
            "rew",
            "data",
            "8280±2678280pm",
            "sbic",
            "10shot",
            "multilabel",
            "8002±1458002pm",
            "0004±00020004pm",
            "9738±0969738pm",
            "0094±00050094pm",
            "0744±00440744pm",
            "083±132083pm",
            "0698±00180698pm",
            "9805±0419805pm",
            "0007±00080007pm",
            "hatexplain",
            "9949±0219949pm",
            "0755±00330755pm",
            "winobias1",
            "1679±4341679pm",
            "0751±00230751pm",
            "9151±2099151pm",
            "0659±00460659pm",
            "0000±00000000pm",
            "winogender",
            "0056±00030056pm",
            "5037±4255037pm",
            "8223±2588223pm",
            "0037±00070037pm",
            "0111±00010111pm",
            "loss",
            "0025±00020025pm",
            "0558±00210558pm",
            "0811±00150811pm",
            "0972±00210972pm",
            "9903±0399903pm",
            "0006±00030006pm",
            "0743±00190743pm",
            "crowspairs",
            "0454±00200454pm",
            "0640±00380640pm",
            "9880±0429880pm",
            "0043±00030043pm",
            "binary",
            "implicithate",
            "1000±00001000pm",
            "0973±00140973pm",
            "0033±00060033pm",
            "9861±0669861pm",
            "redditbias",
            "9013±0929013pm",
            "0042±00030042pm",
            "0047±00070047pm",
            "0029±00060029pm",
            "0716±00170716pm",
            "0054±00070054pm",
            "0546±00500546pm",
            "9930±0329930pm",
            "7886±10717886pm",
            "dataset"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">This section illustrates how our comprehensive evaluation study enables the practical assessment of LLM-based methods for detecting demographic-targeted social biases in text. Our analysis reveals both the strengths and current limitations of these approaches. For rigorous assessment of the overall results, we perform 1,000 bootstrap samples with replacement on the combined test set to compute 95% confidence intervals. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> presents a detailed comparison of prompting and fine-tuning, reporting both binary performance (biased vs. unbiased) and multi-label categorization. We also report median inference time (in milliseconds) for each text instance. Moreover, for more fine-grained analysis, Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> reports bias detection performance of select prompted and fine-tuned LLMs for the twelve constituent datasets.</p>\n\n",
            "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nFrom Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we see the role of scale from the binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. The 70B Llama model outperforms smaller variants across most datasets. Llama-Guard shows lower overall binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, but performs relatively well on hate/toxic content. It specifically achieves the highest score across all models on Toxigen, which is GPT-generated. This finding is consistent with its design as a GPAI guardrail. Multi-label metrics show that even larger models struggle to correctly identify bias types, especially for stereotyped contents, e.g., StereoSet and RedditBias.</p>\n\n",
            "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> shows how fine-tuned models achieve stronger binary detection across most datasets compared to prompting-based LLMs. Encoder models (DeBERTa) generally outperform decoder-only GPT-2, which remains competitive on many datasets but struggles with subtle stereotype cases, e.g, RedditBias and Winogender. For multi-label detection, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> shows consistently lower HL, indicating more accurate detection of demographic axes targeted.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora used to train general-purpose AI (GPAI) models often contain harmful demographic-targeted social biases, creating a regulatory need for data auditing and developing scalable bias-detection methods. Although prior work has investigated biases in text datasets and related detection methods, these studies remain narrow in scope. They typically focus on a single content type (e.g., hate speech), cover limited demographic axes, overlook biases affecting multiple demographics simultaneously, and analyze limited techniques. Consequently, practitioners lack a holistic understanding of the strengths and limitations of recent large language models (LLMs) for automated and scalable bias detection in datasets. In this study, we present a comprehensive evaluation framework aimed at English texts to assess the ability of LLMs in detecting demographic-targeted social biases. To align with regulatory requirements, we frame bias detection as a multi-label task using a demographic-focused taxonomy. We then conduct a systematic evaluation with models across scales and techniques, including prompting, in-context learning, and fine-tuning. Using twelve datasets spanning diverse content types and demographics, our study demonstrates the promise of fine-tuned smaller models for scalable detection. However, our analyses also expose persistent gaps across demographic axes and multi-demographic targeted biases, underscoring the need for more effective and scalable auditing frameworks.</p>\n\n",
                "matched_terms": [
                    "models",
                    "multilabel",
                    "data",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora have significantly driven recent advances in general-purpose AI (GPAI) models. These corpora, however, are often minimally curated and can contain harmful social biases, e.g., hateful, toxic, or stereotypical content <span class=\"ltx_text ltx_font_italic\">targeting various demographic axes</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Navigli et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib40\" title=\"\">2023</a>)</cite>. Consequently, training on such content can lead to unsafe model outputs and real-world harms&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Dodge et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>; Vashney, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib52\" title=\"\">2022</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Detecting demographic-targeted social biases in data has become both a regulatory and technical requirement&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Tabassi, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib51\" title=\"\">2023</a>; European Union, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib14\" title=\"\">2024</a>)</cite>. For example, the EU&#8217;s GPAI Code of Practice highlights the importance of documenting demographic-centric harms in training corpora. Effective data-level mitigation strategies&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite> also depend on reliably identifying biased instances. While prior studies have examined biases in text corpora&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kreutzer et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib29\" title=\"\">2022</a>; Luccioni and Viviano, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib34\" title=\"\">2021</a>; Dodge et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>)</cite>, they typically rely either on small-scale human annotations or on simplistic automated techniques. Manual inspection, however, poses psychological risks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Steiger et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib49\" title=\"\">2021</a>)</cite>, and despite advances in LLMs, few works offer a comprehensive analysis of the state of the art in social bias detection.</p>\n\n",
                "matched_terms": [
                    "data",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We frame bias detection as a multi-label task and build a detection testbed that supports prompting, in-context learning, and fine-tuning.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We conduct an extensive empirical evaluation assessing both detection accuracy and performance disparities across demographic axes.</p>\n\n",
                "matched_terms": [
                    "detection",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias detection with LLMs.</span>\nPrior work explored using LLMs in hate-speech moderation&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Barikeri et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib1\" title=\"\">2021</a>; Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>; Kumar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib30\" title=\"\">2024</a>; Zhan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib62\" title=\"\">2025</a>)</cite> or domain-specific bias detection&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Raza et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib45\" title=\"\">2024</a>)</cite>. Recent work&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite> also benchmarked prompt-based bias detection. However, they are restricted to zero-shot settings, cover limited demographics and data. In contrast, we systematically evaluate across multiple LLM-based methods, a broader range of demographics, and holistically analyze across different content types.</p>\n\n",
                "matched_terms": [
                    "data",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Any text not targeting one or more of these axes is considered &#8220;unbiased&#8221; (<span class=\"ltx_text ltx_font_typewriter\">UNB</span>) <em class=\"ltx_emph ltx_font_italic\">within our taxonomy</em>. Each demographic axis serves as a prediction category, making the detection task twofold: (i) identify whether a text expresses demographic-targeted bias, and (ii) determine which demographics are targeted. Unlike prior benchmarks that treat bias detection as single-label or multi-class classification&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, our formulation supports <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em>, capturing both <span class=\"ltx_text ltx_font_italic\">single-axis</span> (e.g., race only) and <span class=\"ltx_text ltx_font_italic\">multi-axis</span> (e.g., gender+race) biases (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T2\" title=\"Table 2 &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>).</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To enable comprehensive empirical evaluation in realistic settings, we adapt existing English datasets to align with our demographic-targeted social bias taxonomy. We surveyed widely used NLP datasets&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite>, prioritizing diversity across demographic axes and harm types. Unlike prior benchmarks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, which often rely on fully GPT-generated categories (e.g., toxic text), we minimize synthetic data to reduce evaluation artifacts&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Koo et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib28\" title=\"\">2024</a>; Maheshwari et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib35\" title=\"\">2024</a>)</cite>.<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>The only exception is ToxiGen, although it has human-annotated GPT text, unlike&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>.</span></span></span> Based on this review, we curated samples from <span class=\"ltx_text ltx_font_bold\">twelve</span> distinct datasets (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T1\" title=\"Table 1 &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).</p>\n\n",
                "matched_terms": [
                    "toxigen",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Since some datasets were originally designed for evaluating generative biases, we applied minor adaptations similar to&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>. For StereoSet, we concatenate the context with the stereotype options. For BBQ, we construct text instances by pairing disambiguated contexts with answers. For CrowS-Pairs, we retain only the &#8220;more biased&#8221; sentences. For SBIC, we derive a single label using the majority vote across annotators. For ToxiGen, we label texts as biased only when human annotator scores indicate bias.</p>\n\n",
                "matched_terms": [
                    "bbq",
                    "toxigen",
                    "crowspairs",
                    "stereoset",
                    "sbic"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_citet\">Brown et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib4\" title=\"\">2020</a>)</cite> demonstrated that <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> LLMs can effectively perform a variety of tasks through textual prompting in <em class=\"ltx_emph ltx_font_italic\">zero-shot</em> scenarios. Following&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>; Palla et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib42\" title=\"\">2025</a>)</cite>, our evaluation framework employs <em class=\"ltx_emph ltx_font_italic\">policy-based</em> prompting for bias detection. Specifically, the prompt includes a policy detailing the bias detection task and our demographic-based social bias taxonomy. To enhance the bias detection capabilities within this prompting framework, we also assess the benefits of incorporating <em class=\"ltx_emph ltx_font_italic\">few-shot</em> examples for <em class=\"ltx_emph ltx_font_italic\">in-context learning</em>. Specifically, we utilize the retrieval-augmented (RAG) framework&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib5\" title=\"\">2024a</a>)</cite>, where an embedding model identifies the most <em class=\"ltx_emph ltx_font_italic\">relevant</em> in-context examples for each input instance from the training/development set.</p>\n\n",
                "matched_terms": [
                    "model",
                    "prompt",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Models.</span> We consider several <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> models ranging from 8B to 72B parameters, e.g., GLM-4&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(GLM et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib18\" title=\"\">2024</a>)</cite>, Llama-3.1&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Dubey et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib10\" title=\"\">2024</a>)</cite>, and Qwen-2.5&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Yang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib58\" title=\"\">2024</a>)</cite>. We also analyze the guardrail model Llama Guard-3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>)</cite> to explore if such models could directly be applied for general text bias detection. To perform RAG-based in-context sample selection, we use the BGE-M3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib6\" title=\"\">2024b</a>)</cite> model.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We also evaluate the effectiveness of aligning LLMs to the bias detection task through <em class=\"ltx_emph ltx_font_italic\">fine-tuning</em>. The task is framed as <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em> over the nine demographic axes. We solve it through sequence classification by attaching nine classifier nodes to a pre-trained LLM: to the [CLS] token for encoder-only models and to the final output token for decoder-only models.</p>\n\n",
                "matched_terms": [
                    "models",
                    "multilabel",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Because detection must perform reliably <em class=\"ltx_emph ltx_font_italic\">across all demographic axes</em>, our evaluation framework also explores the effectiveness of <em class=\"ltx_emph ltx_font_italic\">data reweighting</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kamiran and Calders, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib25\" title=\"\">2012</a>)</cite> to address imbalances. Let <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> denote the number of samples and <math alttext=\"\\mathcal{M}_{\\phi}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m2\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8499;</mi><mi>&#981;</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{M}_{\\phi}</annotation></semantics></math> the model. For a given instance <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m3\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>, its labels <math alttext=\"Y_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m4\" intent=\":literal\"><semantics><msub><mi>Y</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">Y_{i}</annotation></semantics></math> form a binary vector of length nine, where <math alttext=\"Y_{i}^{m}=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m5\" intent=\":literal\"><semantics><mrow><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">Y_{i}^{m}=1</annotation></semantics></math> if the demographic axis <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m6\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> is targeted and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m7\" intent=\":literal\"><mn>0</mn></math> otherwise. The weighted loss is defined as:</p>\n\n",
                "matched_terms": [
                    "model",
                    "detection",
                    "data",
                    "binary",
                    "loss"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"\\alpha_{m}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m8\" intent=\":literal\"><semantics><msub><mi>&#945;</mi><mi>m</mi></msub><annotation encoding=\"application/x-tex\">\\alpha_{m}</annotation></semantics></math> balances across demographic axes, and <math alttext=\"w_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m9\" intent=\":literal\"><semantics><msub><mi>w</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">w_{i}</annotation></semantics></math> compensates for binary imbalances regarding biased and unbiased instances. All weights are derived from training data statistics.</p>\n\n",
                "matched_terms": [
                    "data",
                    "binary"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Models.</span>\nFor encoder models, we consider RoBERTa&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib33\" title=\"\">2019</a>)</cite> and DeBERTa&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(He et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib21\" title=\"\">2020</a>)</cite> and for decoder-only models we consider GPT-2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Radford et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib44\" title=\"\">2019</a>)</cite>. For each model, we consider various parameter scales where, across models, the parameters range from 125M to 1.5B.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our comprehensive framework uses metrics capturing three dimensions: (i) distinguishing <em class=\"ltx_emph ltx_font_italic\">biased vs. unbiased</em> text, (ii) accurate <em class=\"ltx_emph ltx_font_italic\">multi-label classification</em> of bias types, and (iii) ensuring <em class=\"ltx_emph ltx_font_italic\">parity</em> in detection performance across demographic axes and for multi-targeted texts compared to single-targeted texts.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "detection",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Binary bias detection.</span>\nWe reduce the multi-label task to a binary one by defining\nground-truth labels <math alttext=\"Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.SS4.p3.m1\" intent=\":literal\"><semantics><mrow><msub><mi>Y</mi><msub><mi>B</mi><mi>i</mi></msub></msub><mo>=</mo><mn>1</mn><mo>&#8722;</mo><mi>&#120128;</mi><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>0</mn><mo>,</mo><mo>,</mo><mo rspace=\"0.167em\">&#8704;</mo><mi>m</mi><mo>&#8712;</mo><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><mn>9</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]</annotation></semantics></math>, with predictions <math alttext=\"\\hat{Y}_{B_{i}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m2\" intent=\":literal\"><semantics><msub><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><msub><mi>B</mi><mi>i</mi></msub></msub><annotation encoding=\"application/x-tex\">\\hat{Y}_{B_{i}}</annotation></semantics></math> defined analogously. A value of <math alttext=\"1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m3\" intent=\":literal\"><semantics><mn>1</mn><annotation encoding=\"application/x-tex\">1</annotation></semantics></math> indicates the presence of any bias, and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m4\" intent=\":literal\"><mn>0</mn></math> indicates none. On these binary labels, we report <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m5\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, false positive rate (FPR), and false negative rate (FNR).</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "f1f1",
                    "binary",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-label bias detection.</span>\nAlongside macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p4.m1\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math> and micro <math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p4.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math> scores, we report two multi-label measures&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sorower, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib48\" title=\"\">2010</a>)</cite>:</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Detection disparities.</span>\nOur evaluation also examines whether LLMs not only detect social biases accurately but also exhibit systematic performance gaps across different demographic targets. Given <math alttext=\"\\mathcal{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p5.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><annotation encoding=\"application/x-tex\">\\mathcal{P}</annotation></semantics></math> denotes FPR or FNR, we analyze disparities in the following scenarios:</p>\n\n",
                "matched_terms": [
                    "detection",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-demographic.</span> Inspired by&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite>, we measure if the models make systematically more errors in detecting biases that <em class=\"ltx_emph ltx_font_italic\">specifically</em> target <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em> (e.g., {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}) relative to biases that target <span class=\"ltx_text ltx_font_italic\">each constituent axis</span> (e.g., only <span class=\"ltx_text ltx_font_typewriter\">GEN</span> or <span class=\"ltx_text ltx_font_typewriter\">RAC</span>).\n<math alttext=\"\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.I3.i2.p1.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>=</mo><mrow><munder accentunder=\"true\"><mi>max</mi><mrow><mi>x</mi><mo>&#8712;</mo><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></mrow></munder><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msub><mo>&#8722;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mi>x</mi></msub></mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|</annotation></semantics></math>. This measure helps us understand if the FPR or FNR of multi-axis targeted biased instances is markedly higher, indicating potential blind spots for automated bias detection methods.</p>\n\n",
                "matched_terms": [
                    "models",
                    "constituent",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our detailed results in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> show how bias detection with prompting is <em class=\"ltx_emph ltx_font_italic\">highly sensitive to both in-context learning and model capacity</em>.</p>\n\n",
                "matched_terms": [
                    "model",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">In-context learning substantially improves detection.</span> Across all models, providing few-shot examples consistently boosts binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, lowers FNR, and increases multi-label metrics (MR, HL, <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>). Gains are significant with as few as five examples, while moving from five to ten shots yields only marginal improvements. However, inference time grows with the number of examples, highlighting the accuracy&#8211;efficiency tradeoff in prompting. Beyond the reported results, we also analyzed alternative in-context setups (in the appendix). We found that (i) RAG-based example selection outperforms random sampling, and (ii) alternative embeddings&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Youdao, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib59\" title=\"\">2023</a>)</cite> yield comparable results.</p>\n\n",
                "matched_terms": [
                    "models",
                    "detection",
                    "f1f1",
                    "binary",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Model size and architecture strongly shape results.</span> Larger models (e.g., Llama-70B, Qwen-72B) achieve higher binary and multi-label performance than smaller variants. Within model families, scale matters: Llama-70B outperforms Llama-8B across nearly all metrics. However, size alone is not decisive. GLM-4-9B rivals or surpasses larger Llama and Qwen models on multi-label metrics, and Llama-3.1-70B outperforms Qwen-2.5-72B despite similar scale. Larger models tend to reduce FPR but can increase FNR, reflecting greater sensitivity at the cost of more false negatives. Inference time rises steeply with model scale, from 350ms for 8B models to over 600ms for 70B+ models.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model",
                    "binary",
                    "llama3170b",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Guardrail models transfer poorly.</span> Llama Guard, fine-tuned for moderation, consistently underperforms instruction-tuned models of similar size (e.g., Llama-3.1-8B), achieving the lowest binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> and highest FNR. While effective at detecting overt hate speech, it fails to capture subtler biases like stereotypes.</p>\n\n",
                "matched_terms": [
                    "models",
                    "f1f1",
                    "binary"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nInstruction-tuned LLMs with in-context learning and sufficient capacity provide the most effective prompting-based bias detection, although at the cost of increased inference time. We further show that guardrail-focused models alone are insufficient for holistic social bias identification.</p>\n\n",
                "matched_terms": [
                    "models",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our results in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> show how the performance of fine-tuned LLM-based bias detectors is <em class=\"ltx_emph ltx_font_italic\">shaped by model size, architecture, and optimization strategy</em>.</p>\n\n",
                "matched_terms": [
                    "model",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuning substantially improves detection.</span> Even small models, such as RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>, surpass much larger prompting-only models (Llama-3.1-70B, Qwen-2.5-72B) on binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> (above 90 vs. below 89) and multi-label metrics (MR, HL, micro <math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math> and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m3\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>). Fine-tuned models also achieve lower FNR and higher reliability in detecting biased content. Inference is far faster: RoBERTa completes batches in seconds, whereas prompting with 70B+ LLMs requires hundreds of seconds.</p>\n\n",
                "matched_terms": [
                    "models",
                    "detection",
                    "f1f1",
                    "binary",
                    "llama3170b",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Architecture influences performance.</span> Encoder models (RoBERTa, DeBERTa) consistently outperform decoder models (GPT-2), irrespective of scale. GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span> underperforms on binary and multi-label detection. In contrast, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> and RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> achieve higher detection scores. Inference times also reflect architectural complexity: decoder models remain faster, whereas DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> is particularly slow due to disentangled attention&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(He et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib21\" title=\"\">2020</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "models",
                    "detection",
                    "debertav2xl",
                    "binary",
                    "gpt2xl",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Scaling improves detection.</span> Within encoder families, larger variants (RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">XL</span>) achieve better detection results. Importantly, despite being the newer variant, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> performs slightly worse than the larger but older DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>. GPT-2 shows similar scaling trends within decoder models. Inference time increases with model size, reinforcing the tradeoff between accuracy and efficiency.</p>\n\n",
                "matched_terms": [
                    "models",
                    "debertav3large",
                    "model",
                    "detection",
                    "debertav2xl"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Loss reweighting has tradeoffs.</span> Reweighted loss consistently improves binary FNR and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p5.m1\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math> (e.g., DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>, RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>) by capturing subtle biases, but can raise FPR, particularly in decoder models. Effects are uneven: DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> shows reduced MR and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p5.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>, suggesting reweighting may destabilize multi-label detection for some scenarios.</p>\n\n",
                "matched_terms": [
                    "models",
                    "debertav3large",
                    "detection",
                    "debertav2xl",
                    "binary",
                    "loss",
                    "gpt2xl",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nFine-tuned encoder models provide the most effective bias detection, outperforming prompting much larger models in both binary detection and identification of the correct bias types. Decoder-based models can perform well but show weaknesses on subtle stereotype datasets. Fine-tuning with reweighted loss improves recall, but may increase false positives, highlighting important tradeoffs that require consideration.</p>\n\n",
                "matched_terms": [
                    "models",
                    "binary",
                    "loss",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use our evaluation framework to examine <em class=\"ltx_emph ltx_font_italic\">potential disparities</em> in social bias detection across models and setups with respect to targeted demographic axes. While the previous analysis provided a global view of model performance, this section focuses on <em class=\"ltx_emph ltx_font_italic\">systematic differences</em> in how effectively models detect biases. We first analyze disparities for individual demographic axes. Next, owing to our multi-label setup, we evaluate model performances on instances targeting <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em>, highlighting current capabilities in detecting multi-targeted biases. We provide the comprehensive disparity analysis in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S5.T5\" title=\"Table 5 &#8227; 5 Evaluating detection disparities &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model",
                    "detection",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Prompting shows large disparities.</span> In zero-shot settings, models exhibit significant disparities. For instance, Llama-3.1-8B and GLM-4-9B exhibit <math alttext=\"\\Delta_{\\text{FNR}}\\approx 0.6\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><mo>&#8776;</mo><mn>0.6</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}\\approx 0.6</annotation></semantics></math>, <math alttext=\"\\Delta_{\\text{FPR}}\\approx 0.42\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><mo>&#8776;</mo><mn>0.42</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}\\approx 0.42</annotation></semantics></math>. Few-shot prompting reduces disparities (e.g., for Llama-3.1-8B, <math alttext=\"\\Delta_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m3\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}</annotation></semantics></math> drops to <math alttext=\"\\approx 0.26\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8776;</mo><mn>0.26</mn></mrow><annotation encoding=\"application/x-tex\">\\approx 0.26</annotation></semantics></math>), but performance remains uneven compared to fine-tuned models. Scaling improves parity: Llama-3.1-70B shows lower disparities than its 8B counterpart, and Qwen-2.5-72B achieves the strongest parity among prompting models, especially with few-shot examples.</p>\n\n",
                "matched_terms": [
                    "models",
                    "llama3170b",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuning yields markedly lower disparities.</span> Encoder models such as RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> and DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> reach <math alttext=\"\\Delta_{\\text{FNR}}\\approx 0.2\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><mo>&#8776;</mo><mn>0.2</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}\\approx 0.2</annotation></semantics></math> and <math alttext=\"\\Delta_{\\text{FPR}}\\approx 0.03\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m2\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><mo>&#8776;</mo><mn>0.03</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}\\approx 0.03</annotation></semantics></math>, particularly with reweighted loss. Reweighting reduces FNR gaps but can slightly increase FPR gaps, indicating a tradeoff. Model architecture also matters: encoder models achieve far lower disparities than decoder-only GPT-2, and scaling further improves parity (e.g., RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> outperforms RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>).</p>\n\n",
                "matched_terms": [
                    "model",
                    "models",
                    "loss",
                    "debertav2xl"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nPrompting, even with larger models and few-shot examples, shows substantial per-axis disparities. Fine-tuned models, particularly with reweighted loss, achieve more balanced performance, although notable gaps remain. In additional analyses (in the appendix), we examined <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across the nine demographic axes. We found that certain targets, such as <span class=\"ltx_text ltx_font_typewriter\">NAT</span> and <span class=\"ltx_text ltx_font_typewriter\">PHY</span>, consistently have lower detection accuracy, which contributes to the observed disparities.</p>\n\n",
                "matched_terms": [
                    "models",
                    "detection",
                    "f1f1",
                    "loss",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We now analyze texts targeting <span class=\"ltx_text ltx_font_italic\">multiple axes simultaneously</span>, focusing on {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>} and {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}. We compare performance on these multi-axis instances to that on the instances that target only constituent single axes (e.g., only <span class=\"ltx_text ltx_font_typewriter\">GEN</span> or <span class=\"ltx_text ltx_font_typewriter\">SO</span> for {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>}).</p>\n\n",
                "matched_terms": [
                    "constituent",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Prompting improves with scale and few-shot examples.</span> Few-shot prompting substantially narrows multi-axis gaps. For Llama-3.1-70B, <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m1\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}</annotation></semantics></math> drops from 0.736 (zero-shot) to 0.164 (10-shot), and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m2\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}</annotation></semantics></math> from 0.262 to 0.088. Larger models benefit more from in-context learning: Llama-3.1-70B outperforms Llama-3.1-8B, and disparities are generally higher for {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>} than {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}.</p>\n\n",
                "matched_terms": [
                    "models",
                    "llama3170b",
                    "10shot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuned models show persistent gaps.</span> Despite strong per-axis parity, fine-tuned models underperform on multi-axis instances, reflecting <em class=\"ltx_emph ltx_font_italic\">gerrymandering</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite> in their detection performance. For example, RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> with reweighting achieves <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.436</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436</annotation></semantics></math> and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m2\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.373</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373</annotation></semantics></math>, higher than few-shot Llama-3.1-70B and Qwen-2.5-72B. Encoder models outperform GPT-2, and scaling improves parity (e.g., DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> at <math alttext=\"\\approx 0.28\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m3\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8776;</mo><mn>0.28</mn></mrow><annotation encoding=\"application/x-tex\">\\approx 0.28</annotation></semantics></math> vs. DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> at 0.39 for FNR regarding {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>}). As with per-axis results, reweighting reduces FNR gaps but can slightly raise FPR gaps.</p>\n\n",
                "matched_terms": [
                    "models",
                    "debertav3large",
                    "detection",
                    "debertav2xl",
                    "llama3170b",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Data coverage.</span>\nOur evaluation relies mainly on English datasets reflecting global North contexts, which limits generalizability to other languages and regions. Progress will require multilingual and cross-lingual benchmarks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Corazza et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib8\" title=\"\">2020</a>; Huang and Xiong, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib22\" title=\"\">2023</a>; Neplenbroek et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib41\" title=\"\">2024</a>)</cite>, methods adapted for low-resource settings, and attention to language-specific biases that may not align with English-centric taxonomies. Dataset diversity should also ensure sufficient coverage of social biases that may exist in different cultural contexts. Coverage should also extend to more categories, e.g., political beliefs and biases encoded across multiple data modalities.</p>\n\n",
                "matched_terms": [
                    "dataset",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methodological opportunities.</span>\nOur findings highlight both promises and existing limitations of scalable automated bias detection. Future work should further explore advanced prompting (e.g., <span class=\"ltx_text ltx_font_italic\">chain-of-thought</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wei et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib56\" title=\"\">2022</a>)</cite>) and efficient fine-tuning (e.g., using adapters). To handle multimodal data, exploring effective and scalable solutions remains an interesting open challenge. Moreover, while our results offer initial guidance, balancing the potential gains from training and deploying larger models and the scalability required for auditing massive corpora warrants deeper exploration. Finally, our study shows that detecting infrequent, subtle, and multi-axis biases remains a crucial underexplored direction for future research.</p>\n\n",
                "matched_terms": [
                    "models",
                    "data",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Mitigation through data bias detection.</span>\nBias detection enables more than regulatory reporting; it allows for leveraging the flagged data instances for more responsible model development through targeted data augmentation, filtering, or fine-tuning&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite>. However, any remedial action <span class=\"ltx_text ltx_font_italic\">must be</span> guided by rigorous ethical considerations and incorporate human oversight.</p>\n\n",
                "matched_terms": [
                    "data",
                    "model",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Text statistics.</span>\nIn Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F1.sf1\" title=\"In Figure 1 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1(a)</span></a>, we show the token count distribution for all the bias categories, including the <em class=\"ltx_emph ltx_font_italic\">unbiased</em> texts. To obtain tokens, we use the RoBERTa tokenizer. We see that the token counts for each text instance are generally low, indicating our dataset mainly contains short text instances. However, there are some outliers, e.g., in <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">SO</span>, where we see around 400 token length texts. Upon inspection, we observed that such instances primarily come from the BBQ dataset, that have very long context texts.</p>\n\n",
                "matched_terms": [
                    "dataset",
                    "bbq"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Label statistics.</span>\nIn Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F2\" title=\"Figure 2 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, we visualize the label statistics in the final curated dataset. The visualizations show label imbalances in the data, highlighting the need for weighted loss for optimization and motivating future work to explore further fairness interventions to ensure equitable bias detection performance. The statistics show that our data contains more biased instances than unbiased ones. Furthermore, we see that most instances target a single demographic axis. However, many instances target two axes. Instances targeting more than two demographic axes are significantly fewer in our dataset. We provide more detailed label co-occurrence statistics in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F1.sf2\" title=\"In Figure 1 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1(b)</span></a>. The figure shows that text instances target specific demographics more often. For instance, texts target <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">GEN</span> more often. Similarly, texts target <span class=\"ltx_text ltx_font_typewriter\">DIS</span>,<span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">PHY</span> relatively less often. Furthermore, we see that <span class=\"ltx_text ltx_font_typewriter\">GEN</span> co-occurs with many other demographic axes, e.g., <span class=\"ltx_text ltx_font_typewriter\">SO</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, and <span class=\"ltx_text ltx_font_typewriter\">DIS</span>. Note that while <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">REL</span> appear together frequently, many of these instances simply target &#8220;Jewish identities.&#8221;</p>\n\n",
                "matched_terms": [
                    "detection",
                    "data",
                    "loss",
                    "dataset",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All LLMs are accessed via API through an MLOps platform. We fix <span class=\"ltx_text ltx_font_typewriter\">temperature</span> to 0 and <span class=\"ltx_text ltx_font_typewriter\">top_p</span> to 1, ensuring deterministic outputs by selecting the model&#8217;s most likely generation while still allowing consideration of the full token space. For in-context learning, we embed the training and development sets using BGE-M3 or BCEmbedding models. At inference time, we compute cosine similarity between the query and development set vectors to retrieve the top-<math alttext=\"K\" class=\"ltx_Math\" display=\"inline\" id=\"A2.SS1.p1.m1\" intent=\":literal\"><semantics><mi>K</mi><annotation encoding=\"application/x-tex\">K</annotation></semantics></math> few-shot examples. As a baseline, we also apply a random few-shot selection from the training set, with balanced sampling between biased and unbiased texts. Model predictions are extracted via pattern matching. Responses that cannot be parsed through pattern matching to assign to one of the multiple demographic axes are marked as &#8220;invalid.&#8221; The <span class=\"ltx_text ltx_font_italic\">social bias policy</span> used in the text prompt is shown here.</p>\n\n",
                "matched_terms": [
                    "prompt",
                    "models",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We fine-tune LLMs for sequence classification using HuggingFace&#8217;s <span class=\"ltx_text ltx_font_typewriter\">transformers</span> library&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wolf et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib57\" title=\"\">2020</a>)</cite>, with a maximum input length of 512 tokens. For GPT-2 models, sequences are left-padded with the <span class=\"ltx_text ltx_font_typewriter\">EOS</span> token.</p>\n\n",
                "matched_terms": [
                    "models",
                    "finetune"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization uses AdamW with linear learning rate decay, weight decay of 0.01, and gradient clipping at 1.0. To address class imbalance, we experiment with reweighted binary cross-entropy loss, where weights are derived from label frequencies in the training set. Models are trained for four epochs without reweighting and six epochs with reweighting. The effective batch size is fixed at 32, with gradient accumulation applied for larger models. Learning rates are <span class=\"ltx_text ltx_font_italic\">tuned by monitoring validation loss</span>. For each model, we use the following learning rates for optimization:</p>\n\n",
                "matched_terms": [
                    "model",
                    "models",
                    "binary",
                    "loss"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Learning rates are not changed across loss functions (default or reweighted). Training is performed in <span class=\"ltx_text ltx_font_typewriter\">float32</span> precision, except GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>, which uses <span class=\"ltx_text ltx_font_typewriter\">bfloat16</span>. All experiments run on a single GPU with 32GB VRAM and 128GB host memory.</p>\n\n",
                "matched_terms": [
                    "gpt2xl",
                    "loss"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate the impact of retrieval-augmented generation (RAG) on few-shot example selection compared to random sampling. Results are presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.T6\" title=\"Table 6 &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>. Overall, RAG consistently enhances bias detection performance.</p>\n\n",
                "matched_terms": [
                    "detection",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In binary classification, RAG achieves higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS1.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across all models. Improvements in detection metrics are consistent across model sizes, demonstrating the benefit of providing LLMs with <em class=\"ltx_emph ltx_font_italic\">semantically similar examples</em> during in-context learning. RAG generally reduces False Negative Rates (FNR), though it occasionally causes slight increases in False Positive Rates (FPR), as observed with Llama Guard-3-8B and GLM-4-9B. This tradeoff is typically favorable, since reducing FNR is crucial for minimizing missed detections. Notably, while adding more examples under RAG yields only modest additional gains, increasing the number of randomly selected examples often leads to degraded performance.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model",
                    "detection",
                    "f1f1",
                    "binary",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For multi-label prediction, RAG delivers even greater improvements over random sampling. As in the binary case, providing more RAG-selected examples enhances performance, whereas adding more random examples consistently worsens detection outcomes. This highlights an important insight: supplying more <em class=\"ltx_emph ltx_font_italic\">relevant</em> examples benefits prompting-based detection, but including <em class=\"ltx_emph ltx_font_italic\">irrelevant</em> examples can be detrimental.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "binary",
                    "detection",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We next examine how the choice of embedding model affects in-context learning performance for prompting, comparing BGE-M3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib6\" title=\"\">2024b</a>)</cite> and BCEmbedding&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Youdao, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib59\" title=\"\">2023</a>)</cite> for selecting in-context examples. The results are presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.T7\" title=\"Table 7 &#8227; C.1 Ablation study: in-context learning &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">7</span></a>.</p>\n\n",
                "matched_terms": [
                    "model",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">BGE-M3 exhibits a slight but consistent advantage in binary bias detection, producing marginally higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across multiple LLMs. However, the overall differences are minimal. In contrast, for multi-label prediction, BCEmbedding performs slightly better on metrics such as MR for many models. This finding suggests that while both embedding models select examples that yield similar overall outcomes, subtle differences exist. Specifically, BGE-M3-selected examples tend to improve binary bias detection by helping models better distinguish biased from unbiased samples, whereas BCEmbedding-selected examples slightly enhance the detection of specific bias types within biased instances.</p>\n\n",
                "matched_terms": [
                    "models",
                    "detection",
                    "f1f1",
                    "binary",
                    "select",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Overall, both embedding models deliver strong and comparable performance for in-context learning, with only minor trade-offs. Their results indicate that either embedding model is well-suited for bias detection tasks.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model",
                    "detection",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We now analyze model performance across different demographic targets. Specifically, we examine the <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p1.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores for all demographic axes in our taxonomy that may be subject to bias. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F5\" title=\"Figure 5 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents results for various prompted models using <em class=\"ltx_emph ltx_font_italic\">10-shot RAG-based in-context learning</em> with BGE-M3, while Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F6\" title=\"Figure 6 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> compares fine-tuned models and explores the impact of reweighted loss (&#8220;bal&#8221; in the figure) across demographics.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model",
                    "f1f1",
                    "loss",
                    "10shot",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our analysis shows that fine-tuned models consistently outperform prompting and transfer learning across all bias classes. The most notable <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> score gains appear in the AGE and SES categories, which are less frequent in the dataset.</p>\n\n",
                "matched_terms": [
                    "models",
                    "f1f1",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Among the prompted LLMs, Llama-3.1-70B achieves the highest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p3.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across nearly all bias categories, except for <span class=\"ltx_text ltx_font_typewriter\">GEN</span>, where GLM-9B&#8212;despite being much smaller&#8212;slightly outperforms it. Interestingly, Qwen-2.5-72B, though the largest LLM, performs worse in many low-frequency categories such as <span class=\"ltx_text ltx_font_typewriter\">DIS</span>, <span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">SES</span>. It performs comparably to the best prompting models only for <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, which are the most common categories in the benchmark.</p>\n\n",
                "matched_terms": [
                    "models",
                    "f1f1",
                    "llama3170b"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For fine-tuned models, encoder-only architectures (e.g., RoBERTa and DeBERTa) generally outperform decoder-only language models, i.e., GPT-2, across most demographic axes. The trends mirror those observed in the prompting setup: models achieve their best performance for <span class=\"ltx_text ltx_font_typewriter\">SES</span>, while <span class=\"ltx_text ltx_font_typewriter\">NAT</span> consistently shows the lowest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. Reweighted loss often improves detection performance or yields similar results to the default loss. For example, in <span class=\"ltx_text ltx_font_typewriter\">NAT</span>, the axis that suffered from the weakest detection performance, reweighted loss improves performance across all models. However, improvements are not universal. For instance, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">large</span> experiences slight declines in <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> for some demographics such as <span class=\"ltx_text ltx_font_typewriter\">AGE</span> and <span class=\"ltx_text ltx_font_typewriter\">SES</span> when reweighted loss is applied.</p>\n\n",
                "matched_terms": [
                    "models",
                    "detection",
                    "f1f1",
                    "loss",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">These findings provide additional insight into the <em class=\"ltx_emph ltx_font_italic\">disparity results</em> discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S5\" title=\"5 Evaluating detection disparities &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, which highlight performance gaps across demographic axes. This deeper analysis underscores the need to develop <em class=\"ltx_emph ltx_font_italic\">more nuanced methods</em> that can mitigate detection disparities without substantially compromising overall performance.</p>\n\n",
                "matched_terms": [
                    "detection",
                    "performance"
                ]
            }
        ]
    },
    "S5.T5": {
        "caption": "Table 5: Detection disparity in terms of FPR and FNR (considering singular targets) and disparity for multi-label biased instances (targeting {GEN,SO}, {GEN,RAC})",
        "body": "<table class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text ltx_font_bold\">Setup</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span class=\"ltx_text ltx_font_bold\">Per-demographic disparity</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"4\"><span class=\"ltx_text ltx_font_bold\">Multi-demographic targeted disparity</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"\\Delta_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m1\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"\\Delta_{\\text{FPR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m2\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m3\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FPR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m4\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FPR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FPR}}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m5\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FPR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m6\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FPR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FPR}}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"15\">\n<span class=\"ltx_inline-block ltx_parbox ltx_align_top\" style=\"width:5.7pt;\">\n<span class=\"ltx_p\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:8.8pt;height:46.9pt;vertical-align:-21.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:46.8pt;transform:translate(-19.0pt,-19.0pt) rotate(-90deg) ;\">\n<span class=\"ltx_p\">Prompting</span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"3\">Llama Guard-3-8B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0-shot</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.510_{\\pm 0.037}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m7\" intent=\":literal\"><semantics><msub><mn>0.510</mn><mrow><mo>&#177;</mo><mn>0.037</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.510_{\\pm 0.037}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.046_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m8\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.558_{\\pm 0.019}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m9\" intent=\":literal\"><semantics><msub><mn>0.558</mn><mrow><mo>&#177;</mo><mn>0.019</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.558_{\\pm 0.019}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.020_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m10\" intent=\":literal\"><semantics><msub><mn>0.020</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.020_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.537_{\\pm 0.016}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m11\" intent=\":literal\"><semantics><msub><mn>0.537</mn><mrow><mo>&#177;</mo><mn>0.016</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.537_{\\pm 0.016}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.070_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m12\" intent=\":literal\"><semantics><msub><mn>0.070</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.070_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">5-shot</td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.724_{\\pm 0.031}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m13\" intent=\":literal\"><semantics><msub><mn>0.724</mn><mrow><mo>&#177;</mo><mn>0.031</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.724_{\\pm 0.031}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.045_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m14\" intent=\":literal\"><semantics><msub><mn>0.045</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.045_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.776_{\\pm 0.016}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m15\" intent=\":literal\"><semantics><msub><mn>0.776</mn><mrow><mo>&#177;</mo><mn>0.016</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.776_{\\pm 0.016}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.020_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m16\" intent=\":literal\"><semantics><msub><mn>0.020</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.020_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.717_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m17\" intent=\":literal\"><semantics><msub><mn>0.717</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.717_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.074_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m18\" intent=\":literal\"><semantics><msub><mn>0.074</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.074_{\\pm 0.005}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">10-shot</td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.756_{\\pm 0.028}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m19\" intent=\":literal\"><semantics><msub><mn>0.756</mn><mrow><mo>&#177;</mo><mn>0.028</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.756_{\\pm 0.028}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.047_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m20\" intent=\":literal\"><semantics><msub><mn>0.047</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.047_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.795_{\\pm 0.015}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m21\" intent=\":literal\"><semantics><msub><mn>0.795</mn><mrow><mo>&#177;</mo><mn>0.015</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.795_{\\pm 0.015}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.019_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m22\" intent=\":literal\"><semantics><msub><mn>0.019</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.019_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.718_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m23\" intent=\":literal\"><semantics><msub><mn>0.718</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.718_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.074_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m24\" intent=\":literal\"><semantics><msub><mn>0.074</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.074_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"3\">Llama-3.1-8B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0-shot</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.605_{\\pm 0.070}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m25\" intent=\":literal\"><semantics><msub><mn>0.605</mn><mrow><mo>&#177;</mo><mn>0.070</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.605_{\\pm 0.070}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.424_{\\pm 0.010}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m26\" intent=\":literal\"><semantics><msub><mn>0.424</mn><mrow><mo>&#177;</mo><mn>0.010</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.424_{\\pm 0.010}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.548_{\\pm 0.070}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m27\" intent=\":literal\"><semantics><msub><mn>0.548</mn><mrow><mo>&#177;</mo><mn>0.070</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.548_{\\pm 0.070}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.278_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m28\" intent=\":literal\"><semantics><msub><mn>0.278</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.278_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.428_{\\pm 0.066}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m29\" intent=\":literal\"><semantics><msub><mn>0.428</mn><mrow><mo>&#177;</mo><mn>0.066</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.428_{\\pm 0.066}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.054_{\\pm 0.010}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m30\" intent=\":literal\"><semantics><msub><mn>0.054</mn><mrow><mo>&#177;</mo><mn>0.010</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.054_{\\pm 0.010}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">5-shot</td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.259_{\\pm 0.085}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m31\" intent=\":literal\"><semantics><msub><mn>0.259</mn><mrow><mo>&#177;</mo><mn>0.085</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.259_{\\pm 0.085}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.194_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m32\" intent=\":literal\"><semantics><msub><mn>0.194</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.194_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.212_{\\pm 0.074}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m33\" intent=\":literal\"><semantics><msub><mn>0.212</mn><mrow><mo>&#177;</mo><mn>0.074</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.212_{\\pm 0.074}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.096_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m34\" intent=\":literal\"><semantics><msub><mn>0.096</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.096_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.112_{\\pm 0.052}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m35\" intent=\":literal\"><semantics><msub><mn>0.112</mn><mrow><mo>&#177;</mo><mn>0.052</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.112_{\\pm 0.052}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.028_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m36\" intent=\":literal\"><semantics><msub><mn>0.028</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.028_{\\pm 0.006}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">10-shot</td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.300_{\\pm 0.104}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m37\" intent=\":literal\"><semantics><msub><mn>0.300</mn><mrow><mo>&#177;</mo><mn>0.104</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.300_{\\pm 0.104}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.208_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m38\" intent=\":literal\"><semantics><msub><mn>0.208</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.208_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.277_{\\pm 0.077}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m39\" intent=\":literal\"><semantics><msub><mn>0.277</mn><mrow><mo>&#177;</mo><mn>0.077</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.277_{\\pm 0.077}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.089_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m40\" intent=\":literal\"><semantics><msub><mn>0.089</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.089_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.144_{\\pm 0.064}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m41\" intent=\":literal\"><semantics><msub><mn>0.144</mn><mrow><mo>&#177;</mo><mn>0.064</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.144_{\\pm 0.064}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.051_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m42\" intent=\":literal\"><semantics><msub><mn>0.051</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.051_{\\pm 0.008}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"3\">GLM-4-9B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0-shot</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.603_{\\pm 0.027}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m43\" intent=\":literal\"><semantics><msub><mn>0.603</mn><mrow><mo>&#177;</mo><mn>0.027</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.603_{\\pm 0.027}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.428_{\\pm 0.010}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m44\" intent=\":literal\"><semantics><msub><mn>0.428</mn><mrow><mo>&#177;</mo><mn>0.010</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.428_{\\pm 0.010}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.582_{\\pm 0.072}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m45\" intent=\":literal\"><semantics><msub><mn>0.582</mn><mrow><mo>&#177;</mo><mn>0.072</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.582_{\\pm 0.072}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.187_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m46\" intent=\":literal\"><semantics><msub><mn>0.187</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.187_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.264_{\\pm 0.078}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m47\" intent=\":literal\"><semantics><msub><mn>0.264</mn><mrow><mo>&#177;</mo><mn>0.078</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.264_{\\pm 0.078}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.281_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m48\" intent=\":literal\"><semantics><msub><mn>0.281</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.281_{\\pm 0.009}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">5-shot</td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.378_{\\pm 0.099}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m49\" intent=\":literal\"><semantics><msub><mn>0.378</mn><mrow><mo>&#177;</mo><mn>0.099</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.378_{\\pm 0.099}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.071_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m50\" intent=\":literal\"><semantics><msub><mn>0.071</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.071_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.535_{\\pm 0.074}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m51\" intent=\":literal\"><semantics><msub><mn>0.535</mn><mrow><mo>&#177;</mo><mn>0.074</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.535_{\\pm 0.074}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.095_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m52\" intent=\":literal\"><semantics><msub><mn>0.095</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.095_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.334_{\\pm 0.076}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m53\" intent=\":literal\"><semantics><msub><mn>0.334</mn><mrow><mo>&#177;</mo><mn>0.076</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.334_{\\pm 0.076}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.101_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m54\" intent=\":literal\"><semantics><msub><mn>0.101</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.101_{\\pm 0.006}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">10-shot</td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.349_{\\pm 0.102}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m55\" intent=\":literal\"><semantics><msub><mn>0.349</mn><mrow><mo>&#177;</mo><mn>0.102</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.349_{\\pm 0.102}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.069_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m56\" intent=\":literal\"><semantics><msub><mn>0.069</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.069_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.495_{\\pm 0.075}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m57\" intent=\":literal\"><semantics><msub><mn>0.495</mn><mrow><mo>&#177;</mo><mn>0.075</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.495_{\\pm 0.075}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.097_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m58\" intent=\":literal\"><semantics><msub><mn>0.097</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.097_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.318_{\\pm 0.073}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m59\" intent=\":literal\"><semantics><msub><mn>0.318</mn><mrow><mo>&#177;</mo><mn>0.073</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.318_{\\pm 0.073}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.103_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m60\" intent=\":literal\"><semantics><msub><mn>0.103</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.103_{\\pm 0.006}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"3\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0-shot</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.433_{\\pm 0.074}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m61\" intent=\":literal\"><semantics><msub><mn>0.433</mn><mrow><mo>&#177;</mo><mn>0.074</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.433_{\\pm 0.074}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.312_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m62\" intent=\":literal\"><semantics><msub><mn>0.312</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.312_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.736_{\\pm 0.064}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m63\" intent=\":literal\"><semantics><msub><mn>0.736</mn><mrow><mo>&#177;</mo><mn>0.064</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.736_{\\pm 0.064}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.181_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m64\" intent=\":literal\"><semantics><msub><mn>0.181</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.181_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.262_{\\pm 0.079}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m65\" intent=\":literal\"><semantics><msub><mn>0.262</mn><mrow><mo>&#177;</mo><mn>0.079</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.262_{\\pm 0.079}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.176_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m66\" intent=\":literal\"><semantics><msub><mn>0.176</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.176_{\\pm 0.007}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">5-shot</td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.288_{\\pm 0.105}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m67\" intent=\":literal\"><semantics><msub><mn>0.288</mn><mrow><mo>&#177;</mo><mn>0.105</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.288_{\\pm 0.105}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.147_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m68\" intent=\":literal\"><semantics><msub><mn>0.147</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.147_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.158_{\\pm 0.071}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m69\" intent=\":literal\"><semantics><msub><mn>0.158</mn><mrow><mo>&#177;</mo><mn>0.071</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.158_{\\pm 0.071}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.075_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m70\" intent=\":literal\"><semantics><msub><mn>0.075</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.075_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.039_{\\pm 0.042}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m71\" intent=\":literal\"><semantics><msub><mn>0.039</mn><mrow><mo>&#177;</mo><mn>0.042</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.039_{\\pm 0.042}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.070_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m72\" intent=\":literal\"><semantics><msub><mn>0.070</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.070_{\\pm 0.007}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">10-shot</td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.274_{\\pm 0.098}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m73\" intent=\":literal\"><semantics><msub><mn>0.274</mn><mrow><mo>&#177;</mo><mn>0.098</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.274_{\\pm 0.098}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.176_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m74\" intent=\":literal\"><semantics><msub><mn>0.176</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.176_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.164_{\\pm 0.072}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m75\" intent=\":literal\"><semantics><msub><mn>0.164</mn><mrow><mo>&#177;</mo><mn>0.072</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.164_{\\pm 0.072}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.078_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m76\" intent=\":literal\"><semantics><msub><mn>0.078</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.078_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.088_{\\pm 0.052}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m77\" intent=\":literal\"><semantics><msub><mn>0.088</mn><mrow><mo>&#177;</mo><mn>0.052</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.088_{\\pm 0.052}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.061_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m78\" intent=\":literal\"><semantics><msub><mn>0.061</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.061_{\\pm 0.006}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"3\">Qwen-2.5-72B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">0-shot</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.369_{\\pm 0.020}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m79\" intent=\":literal\"><semantics><msub><mn>0.369</mn><mrow><mo>&#177;</mo><mn>0.020</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.369_{\\pm 0.020}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.372_{\\pm 0.010}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m80\" intent=\":literal\"><semantics><msub><mn>0.372</mn><mrow><mo>&#177;</mo><mn>0.010</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.372_{\\pm 0.010}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.244_{\\pm 0.076}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m81\" intent=\":literal\"><semantics><msub><mn>0.244</mn><mrow><mo>&#177;</mo><mn>0.076</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.244_{\\pm 0.076}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.143_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m82\" intent=\":literal\"><semantics><msub><mn>0.143</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.143_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.466_{\\pm 0.076}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m83\" intent=\":literal\"><semantics><msub><mn>0.466</mn><mrow><mo>&#177;</mo><mn>0.076</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.466_{\\pm 0.076}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.186_{\\pm 0.010}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m84\" intent=\":literal\"><semantics><msub><mn>0.186</mn><mrow><mo>&#177;</mo><mn>0.010</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.186_{\\pm 0.010}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">5-shot</td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.189_{\\pm 0.024}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m85\" intent=\":literal\"><semantics><msub><mn>0.189</mn><mrow><mo>&#177;</mo><mn>0.024</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.189_{\\pm 0.024}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.117_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m86\" intent=\":literal\"><semantics><msub><mn>0.117</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.117_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.268_{\\pm 0.075}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m87\" intent=\":literal\"><semantics><msub><mn>0.268</mn><mrow><mo>&#177;</mo><mn>0.075</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.268_{\\pm 0.075}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.052_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m88\" intent=\":literal\"><semantics><msub><mn>0.052</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.052_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.109_{\\pm 0.061}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m89\" intent=\":literal\"><semantics><msub><mn>0.109</mn><mrow><mo>&#177;</mo><mn>0.061</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.109_{\\pm 0.061}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.048_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m90\" intent=\":literal\"><semantics><msub><mn>0.048</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.048_{\\pm 0.007}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\">10-shot</td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.199_{\\pm 0.050}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m91\" intent=\":literal\"><semantics><msub><mn>0.199</mn><mrow><mo>&#177;</mo><mn>0.050</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.199_{\\pm 0.050}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.108_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m92\" intent=\":literal\"><semantics><msub><mn>0.108</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.108_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.288_{\\pm 0.076}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m93\" intent=\":literal\"><semantics><msub><mn>0.288</mn><mrow><mo>&#177;</mo><mn>0.076</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.288_{\\pm 0.076}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.063_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m94\" intent=\":literal\"><semantics><msub><mn>0.063</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.063_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.097_{\\pm 0.062}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m95\" intent=\":literal\"><semantics><msub><mn>0.097</mn><mrow><mo>&#177;</mo><mn>0.062</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.097_{\\pm 0.062}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.037_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m96\" intent=\":literal\"><semantics><msub><mn>0.037</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.037_{\\pm 0.007}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"12\">\n<span class=\"ltx_inline-block ltx_parbox ltx_align_top\" style=\"width:5.7pt;\">\n<span class=\"ltx_p\">\n<span class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:8.8pt;height:50.9pt;vertical-align:-23.0pt;\"><span class=\"ltx_transformed_inner\" style=\"width:51.0pt;transform:translate(-21.1pt,-21.1pt) rotate(-90deg) ;\">\n<span class=\"ltx_p\">Fine-tuning</span>\n</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\">RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.490_{\\pm 0.104}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m97\" intent=\":literal\"><semantics><msub><mn>0.490</mn><mrow><mo>&#177;</mo><mn>0.104</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.490_{\\pm 0.104}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.032_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m98\" intent=\":literal\"><semantics><msub><mn>0.032</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.032_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.604_{\\pm 0.071}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m99\" intent=\":literal\"><semantics><msub><mn>0.604</mn><mrow><mo>&#177;</mo><mn>0.071</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.604_{\\pm 0.071}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.029_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m100\" intent=\":literal\"><semantics><msub><mn>0.029</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.029_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.549_{\\pm 0.074}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m101\" intent=\":literal\"><semantics><msub><mn>0.549</mn><mrow><mo>&#177;</mo><mn>0.074</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.549_{\\pm 0.074}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.056_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m102\" intent=\":literal\"><semantics><msub><mn>0.056</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.056_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.185_{\\pm 0.073}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m103\" intent=\":literal\"><semantics><msub><mn>0.185</mn><mrow><mo>&#177;</mo><mn>0.073</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.185_{\\pm 0.073}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.054_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m104\" intent=\":literal\"><semantics><msub><mn>0.054</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.054_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.324_{\\pm 0.072}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m105\" intent=\":literal\"><semantics><msub><mn>0.324</mn><mrow><mo>&#177;</mo><mn>0.072</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.324_{\\pm 0.072}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.058_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m106\" intent=\":literal\"><semantics><msub><mn>0.058</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.058_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.251_{\\pm 0.071}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m107\" intent=\":literal\"><semantics><msub><mn>0.251</mn><mrow><mo>&#177;</mo><mn>0.071</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.251_{\\pm 0.071}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.042_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m108\" intent=\":literal\"><semantics><msub><mn>0.042</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.042_{\\pm 0.005}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\">RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.307_{\\pm 0.084}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m109\" intent=\":literal\"><semantics><msub><mn>0.307</mn><mrow><mo>&#177;</mo><mn>0.084</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.307_{\\pm 0.084}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.029_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m110\" intent=\":literal\"><semantics><msub><mn>0.029</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.029_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.713_{\\pm 0.067}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m111\" intent=\":literal\"><semantics><msub><mn>0.713</mn><mrow><mo>&#177;</mo><mn>0.067</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.713_{\\pm 0.067}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.027_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m112\" intent=\":literal\"><semantics><msub><mn>0.027</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.027_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.548_{\\pm 0.073}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m113\" intent=\":literal\"><semantics><msub><mn>0.548</mn><mrow><mo>&#177;</mo><mn>0.073</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.548_{\\pm 0.073}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.041_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m114\" intent=\":literal\"><semantics><msub><mn>0.041</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.041_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.192_{\\pm 0.063}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m115\" intent=\":literal\"><semantics><msub><mn>0.192</mn><mrow><mo>&#177;</mo><mn>0.063</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.192_{\\pm 0.063}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.052_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m116\" intent=\":literal\"><semantics><msub><mn>0.052</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.052_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.436_{\\pm 0.077}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m117\" intent=\":literal\"><semantics><msub><mn>0.436</mn><mrow><mo>&#177;</mo><mn>0.077</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.436_{\\pm 0.077}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.036_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m118\" intent=\":literal\"><semantics><msub><mn>0.036</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.036_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.373_{\\pm 0.078}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m119\" intent=\":literal\"><semantics><msub><mn>0.373</mn><mrow><mo>&#177;</mo><mn>0.078</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.373_{\\pm 0.078}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.044_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m120\" intent=\":literal\"><semantics><msub><mn>0.044</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.044_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.312_{\\pm 0.082}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m121\" intent=\":literal\"><semantics><msub><mn>0.312</mn><mrow><mo>&#177;</mo><mn>0.082</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.312_{\\pm 0.082}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.030_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m122\" intent=\":literal\"><semantics><msub><mn>0.030</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.030_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.393_{\\pm 0.077}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m123\" intent=\":literal\"><semantics><msub><mn>0.393</mn><mrow><mo>&#177;</mo><mn>0.077</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.393_{\\pm 0.077}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.027_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m124\" intent=\":literal\"><semantics><msub><mn>0.027</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.027_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.564_{\\pm 0.072}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m125\" intent=\":literal\"><semantics><msub><mn>0.564</mn><mrow><mo>&#177;</mo><mn>0.072</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.564_{\\pm 0.072}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.042_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m126\" intent=\":literal\"><semantics><msub><mn>0.042</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.042_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.208_{\\pm 0.044}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m127\" intent=\":literal\"><semantics><msub><mn>0.208</mn><mrow><mo>&#177;</mo><mn>0.044</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.208_{\\pm 0.044}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.040_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m128\" intent=\":literal\"><semantics><msub><mn>0.040</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.040_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.278_{\\pm 0.072}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m129\" intent=\":literal\"><semantics><msub><mn>0.278</mn><mrow><mo>&#177;</mo><mn>0.072</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.278_{\\pm 0.072}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.034_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m130\" intent=\":literal\"><semantics><msub><mn>0.034</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.034_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.305_{\\pm 0.075}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m131\" intent=\":literal\"><semantics><msub><mn>0.305</mn><mrow><mo>&#177;</mo><mn>0.075</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.305_{\\pm 0.075}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.029_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m132\" intent=\":literal\"><semantics><msub><mn>0.029</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.029_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\">DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.465_{\\pm 0.107}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m133\" intent=\":literal\"><semantics><msub><mn>0.465</mn><mrow><mo>&#177;</mo><mn>0.107</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.465_{\\pm 0.107}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.026_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m134\" intent=\":literal\"><semantics><msub><mn>0.026</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.026_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.625_{\\pm 0.073}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m135\" intent=\":literal\"><semantics><msub><mn>0.625</mn><mrow><mo>&#177;</mo><mn>0.073</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.625_{\\pm 0.073}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.024_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m136\" intent=\":literal\"><semantics><msub><mn>0.024</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.024_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.628_{\\pm 0.061}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m137\" intent=\":literal\"><semantics><msub><mn>0.628</mn><mrow><mo>&#177;</mo><mn>0.061</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.628_{\\pm 0.061}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.033_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m138\" intent=\":literal\"><semantics><msub><mn>0.033</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.033_{\\pm 0.003}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.258_{\\pm 0.089}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m139\" intent=\":literal\"><semantics><msub><mn>0.258</mn><mrow><mo>&#177;</mo><mn>0.089</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.258_{\\pm 0.089}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.053_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m140\" intent=\":literal\"><semantics><msub><mn>0.053</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.053_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.388_{\\pm 0.079}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m141\" intent=\":literal\"><semantics><msub><mn>0.388</mn><mrow><mo>&#177;</mo><mn>0.079</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.388_{\\pm 0.079}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.058_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m142\" intent=\":literal\"><semantics><msub><mn>0.058</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.058_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.289_{\\pm 0.074}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m143\" intent=\":literal\"><semantics><msub><mn>0.289</mn><mrow><mo>&#177;</mo><mn>0.074</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.289_{\\pm 0.074}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.038_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m144\" intent=\":literal\"><semantics><msub><mn>0.038</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.038_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\">GPT-2-<span class=\"ltx_text ltx_font_typewriter\">large</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.483_{\\pm 0.073}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m145\" intent=\":literal\"><semantics><msub><mn>0.483</mn><mrow><mo>&#177;</mo><mn>0.073</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.483_{\\pm 0.073}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.031_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m146\" intent=\":literal\"><semantics><msub><mn>0.031</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.031_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.470_{\\pm 0.070}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m147\" intent=\":literal\"><semantics><msub><mn>0.470</mn><mrow><mo>&#177;</mo><mn>0.070</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.470_{\\pm 0.070}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.043_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m148\" intent=\":literal\"><semantics><msub><mn>0.043</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.043_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.779_{\\pm 0.041}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m149\" intent=\":literal\"><semantics><msub><mn>0.779</mn><mrow><mo>&#177;</mo><mn>0.041</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.779_{\\pm 0.041}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.051_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m150\" intent=\":literal\"><semantics><msub><mn>0.051</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.051_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.271_{\\pm 0.070}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m151\" intent=\":literal\"><semantics><msub><mn>0.271</mn><mrow><mo>&#177;</mo><mn>0.070</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.271_{\\pm 0.070}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.078_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m152\" intent=\":literal\"><semantics><msub><mn>0.078</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.078_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.477_{\\pm 0.078}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m153\" intent=\":literal\"><semantics><msub><mn>0.477</mn><mrow><mo>&#177;</mo><mn>0.078</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.477_{\\pm 0.078}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.084_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m154\" intent=\":literal\"><semantics><msub><mn>0.084</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.084_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\"><math alttext=\"0.261_{\\pm 0.073}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m155\" intent=\":literal\"><semantics><msub><mn>0.261</mn><mrow><mo>&#177;</mo><mn>0.073</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.261_{\\pm 0.073}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><math alttext=\"0.072_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m156\" intent=\":literal\"><semantics><msub><mn>0.072</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.072_{\\pm 0.005}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"2\">GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_typewriter\">unw.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.367_{\\pm 0.059}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m157\" intent=\":literal\"><semantics><msub><mn>0.367</mn><mrow><mo>&#177;</mo><mn>0.059</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.367_{\\pm 0.059}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.038_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m158\" intent=\":literal\"><semantics><msub><mn>0.038</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.038_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.462_{\\pm 0.075}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m159\" intent=\":literal\"><semantics><msub><mn>0.462</mn><mrow><mo>&#177;</mo><mn>0.075</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.462_{\\pm 0.075}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.031_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m160\" intent=\":literal\"><semantics><msub><mn>0.031</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.031_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><math alttext=\"0.602_{\\pm 0.070}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m161\" intent=\":literal\"><semantics><msub><mn>0.602</mn><mrow><mo>&#177;</mo><mn>0.070</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.602_{\\pm 0.070}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math alttext=\"0.057_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m162\" intent=\":literal\"><semantics><msub><mn>0.057</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.057_{\\pm 0.004}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\"><span class=\"ltx_text ltx_font_typewriter\">rew.</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><math alttext=\"0.300_{\\pm 0.084}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m163\" intent=\":literal\"><semantics><msub><mn>0.300</mn><mrow><mo>&#177;</mo><mn>0.084</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.300_{\\pm 0.084}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\"><math alttext=\"0.060_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m164\" intent=\":literal\"><semantics><msub><mn>0.060</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.060_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><math alttext=\"0.388_{\\pm 0.071}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m165\" intent=\":literal\"><semantics><msub><mn>0.388</mn><mrow><mo>&#177;</mo><mn>0.071</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.388_{\\pm 0.071}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\"><math alttext=\"0.051_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m166\" intent=\":literal\"><semantics><msub><mn>0.051</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.051_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\"><math alttext=\"0.299_{\\pm 0.074}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m167\" intent=\":literal\"><semantics><msub><mn>0.299</mn><mrow><mo>&#177;</mo><mn>0.074</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.299_{\\pm 0.074}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\"><math alttext=\"0.062_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T5.m168\" intent=\":literal\"><semantics><msub><mn>0.062</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.062_{\\pm 0.005}</annotation></semantics></math></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "0305±00750305pm",
            "0186±00100186pm",
            "0713±00670713pm",
            "𝒢fnrgenracmathcalgtextgenractextfnr",
            "0030±00040030pm",
            "0718±00140718pm",
            "debertav3large",
            "detection",
            "0288±00760288pm",
            "0548±00700548pm",
            "0074±00050074pm",
            "0034±00030034pm",
            "multidemographic",
            "0096±00060096pm",
            "0071±00050071pm",
            "0097±00620097pm",
            "genrac",
            "0187±00060187pm",
            "0490±01040490pm",
            "0040±00040040pm",
            "0078±00070078pm",
            "0558±00190558pm",
            "0194±00090194pm",
            "0349±01020349pm",
            "0044±00040044pm",
            "0029±00040029pm",
            "0052±00050052pm",
            "0072±00050072pm",
            "0495±00750495pm",
            "0367±00590367pm",
            "0537±00160537pm",
            "0436±00770436pm",
            "0024±00030024pm",
            "0199±00500199pm",
            "0605±00700605pm",
            "0164±00720164pm",
            "0063±00060063pm",
            "0470±00700470pm",
            "0047±00050047pm",
            "fnr",
            "perdemographic",
            "0045±00050045pm",
            "0176±00080176pm",
            "0549±00740549pm",
            "0033±00030033pm",
            "0103±00060103pm",
            "0108±00060108pm",
            "0604±00710604pm",
            "0483±00730483pm",
            "0312±00820312pm",
            "method",
            "qwen2572b",
            "gpt2xl",
            "llama3170b",
            "0717±00140717pm",
            "0031±00040031pm",
            "0466±00760466pm",
            "guard38b",
            "0061±00060061pm",
            "0428±00100428pm",
            "0262±00790262pm",
            "0074±00040074pm",
            "0278±00720278pm",
            "0029±00030029pm",
            "0020±00020020pm",
            "0334±00760334pm",
            "δfnrdeltatextfnr",
            "0112±00520112pm",
            "0032±00040032pm",
            "0795±00150795pm",
            "0070±00070070pm",
            "0602±00700602pm",
            "𝒢fnrgensomathcalgtextgensotextfnr",
            "5shot",
            "0036±00030036pm",
            "0046±00050046pm",
            "0779±00410779pm",
            "singular",
            "0056±00040056pm",
            "0477±00780477pm",
            "0312±00090312pm",
            "llama318b",
            "0039±00420039pm",
            "0307±00840307pm",
            "0582±00720582pm",
            "instances",
            "0535±00740535pm",
            "glm49b",
            "0027±00030027pm",
            "0109±00610109pm",
            "0041±00040041pm",
            "robertabase",
            "0144±00640144pm",
            "0051±00040051pm",
            "0278±00070278pm",
            "0318±00730318pm",
            "0054±00050054pm",
            "0031±00030031pm",
            "0212±00740212pm",
            "0433±00740433pm",
            "0388±00790388pm",
            "disparity",
            "prompting",
            "0028±00060028pm",
            "0078±00060078pm",
            "debertav2xl",
            "0277±00770277pm",
            "0147±00070147pm",
            "targets",
            "0299±00740299pm",
            "0069±00050069pm",
            "0261±00730261pm",
            "biased",
            "setup",
            "0088±00520088pm",
            "0075±00060075pm",
            "0258±00890258pm",
            "0189±00240189pm",
            "0051±00080051pm",
            "0268±00750268pm",
            "considering",
            "0042±00050042pm",
            "0181±00060181pm",
            "0117±00080117pm",
            "0026±00030026pm",
            "0095±00060095pm",
            "0372±00100372pm",
            "0158±00710158pm",
            "0251±00710251pm",
            "terms",
            "0288±01050288pm",
            "0264±00780264pm",
            "0089±00060089pm",
            "0373±00780373pm",
            "0038±00040038pm",
            "0424±00100424pm",
            "0603±00270603pm",
            "finetuning",
            "0564±00720564pm",
            "llama",
            "0369±00200369pm",
            "0465±01070465pm",
            "0084±00050084pm",
            "0281±00090281pm",
            "0300±00840300pm",
            "0062±00050062pm",
            "0shot",
            "0176±00070176pm",
            "0510±00370510pm",
            "gpt2large",
            "0378±00990378pm",
            "model",
            "0057±00040057pm",
            "rew",
            "robertalarge",
            "0058±00040058pm",
            "0271±00700271pm",
            "0324±00720324pm",
            "10shot",
            "0625±00730625pm",
            "multilabel",
            "0101±00060101pm",
            "0052±00060052pm",
            "0289±00740289pm",
            "0462±00750462pm",
            "0208±00090208pm",
            "0259±00850259pm",
            "targeting",
            "0143±00070143pm",
            "0185±00730185pm",
            "0428±00660428pm",
            "0274±00980274pm",
            "𝒢fprgensomathcalgtextgensotextfpr",
            "0060±00050060pm",
            "δfprdeltatextfpr",
            "0776±00160776pm",
            "0628±00610628pm",
            "0756±00280756pm",
            "0037±00070037pm",
            "genso",
            "fpr",
            "0724±00310724pm",
            "0736±00640736pm",
            "0019±00020019pm",
            "0048±00070048pm",
            "0548±00730548pm",
            "𝒢fprgenracmathcalgtextgenractextfpr",
            "0042±00040042pm",
            "0054±00100054pm",
            "0043±00030043pm",
            "0192±00630192pm",
            "unw",
            "0300±01040300pm",
            "0388±00710388pm",
            "0053±00040053pm",
            "0208±00440208pm",
            "0097±00060097pm",
            "0393±00770393pm",
            "targeted",
            "0244±00760244pm",
            "0070±00040070pm"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">We use our evaluation framework to examine <em class=\"ltx_emph ltx_font_italic\">potential disparities</em> in social bias detection across models and setups with respect to targeted demographic axes. While the previous analysis provided a global view of model performance, this section focuses on <em class=\"ltx_emph ltx_font_italic\">systematic differences</em> in how effectively models detect biases. We first analyze disparities for individual demographic axes. Next, owing to our multi-label setup, we evaluate model performances on instances targeting <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em>, highlighting current capabilities in detecting multi-targeted biases. We provide the comprehensive disparity analysis in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S5.T5\" title=\"Table 5 &#8227; 5 Evaluating detection disparities &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora used to train general-purpose AI (GPAI) models often contain harmful demographic-targeted social biases, creating a regulatory need for data auditing and developing scalable bias-detection methods. Although prior work has investigated biases in text datasets and related detection methods, these studies remain narrow in scope. They typically focus on a single content type (e.g., hate speech), cover limited demographic axes, overlook biases affecting multiple demographics simultaneously, and analyze limited techniques. Consequently, practitioners lack a holistic understanding of the strengths and limitations of recent large language models (LLMs) for automated and scalable bias detection in datasets. In this study, we present a comprehensive evaluation framework aimed at English texts to assess the ability of LLMs in detecting demographic-targeted social biases. To align with regulatory requirements, we frame bias detection as a multi-label task using a demographic-focused taxonomy. We then conduct a systematic evaluation with models across scales and techniques, including prompting, in-context learning, and fine-tuning. Using twelve datasets spanning diverse content types and demographics, our study demonstrates the promise of fine-tuned smaller models for scalable detection. However, our analyses also expose persistent gaps across demographic axes and multi-demographic targeted biases, underscoring the need for more effective and scalable auditing frameworks.</p>\n\n",
                "matched_terms": [
                    "finetuning",
                    "prompting",
                    "detection",
                    "multidemographic",
                    "targeted",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><em class=\"ltx_emph ltx_font_bold ltx_font_italic\">K</em><span class=\"ltx_text ltx_font_bold\">eywords</span>&#8194;Social bias  <math alttext=\"\\cdot\" class=\"ltx_Math\" display=\"inline\" id=\"p1.m1\" intent=\":literal\"><semantics><mo>&#8901;</mo><annotation encoding=\"application/x-tex\">\\cdot</annotation></semantics></math>\nBias detection  <math alttext=\"\\cdot\" class=\"ltx_Math\" display=\"inline\" id=\"p1.m2\" intent=\":literal\"><semantics><mo>&#8901;</mo><annotation encoding=\"application/x-tex\">\\cdot</annotation></semantics></math>\nPrompting  <math alttext=\"\\cdot\" class=\"ltx_Math\" display=\"inline\" id=\"p1.m3\" intent=\":literal\"><semantics><mo>&#8901;</mo><annotation encoding=\"application/x-tex\">\\cdot</annotation></semantics></math>\nFine-tuning</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "finetuning",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora have significantly driven recent advances in general-purpose AI (GPAI) models. These corpora, however, are often minimally curated and can contain harmful social biases, e.g., hateful, toxic, or stereotypical content <span class=\"ltx_text ltx_font_italic\">targeting various demographic axes</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Navigli et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib40\" title=\"\">2023</a>)</cite>. Consequently, training on such content can lead to unsafe model outputs and real-world harms&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Dodge et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>; Vashney, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib52\" title=\"\">2022</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "model",
                    "targeting"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Detecting demographic-targeted social biases in data has become both a regulatory and technical requirement&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Tabassi, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib51\" title=\"\">2023</a>; European Union, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib14\" title=\"\">2024</a>)</cite>. For example, the EU&#8217;s GPAI Code of Practice highlights the importance of documenting demographic-centric harms in training corpora. Effective data-level mitigation strategies&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite> also depend on reliably identifying biased instances. While prior studies have examined biases in text corpora&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kreutzer et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib29\" title=\"\">2022</a>; Luccioni and Viviano, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib34\" title=\"\">2021</a>; Dodge et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>)</cite>, they typically rely either on small-scale human annotations or on simplistic automated techniques. Manual inspection, however, poses psychological risks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Steiger et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib49\" title=\"\">2021</a>)</cite>, and despite advances in LLMs, few works offer a comprehensive analysis of the state of the art in social bias detection.</p>\n\n",
                "matched_terms": [
                    "instances",
                    "biased",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Compared to systematic benchmarks that examine LLMs for biased generation&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>; Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>)</cite>, detailed studies of their potential as tools for detecting social biases in text remain underexplored. Existing work is often limited across one or more dimensions: focusing on narrow demographics&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, restricting attention to a single type of content such as hate&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>)</cite>, analyzing only specific contexts like certain subreddits&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kumar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib30\" title=\"\">2024</a>)</cite>, or analyzing only few methods such as zero-shot prompting&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>)</cite>. Moreover, most studies overlook biases that target <em class=\"ltx_emph ltx_font_italic\">multiple demographic axes simultaneously</em>, e.g., intersectionality. These gaps motivate a structured and comprehensive study of the current capabilities of recent LLMs in detecting demographic-targeted social biases.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We develop a <em class=\"ltx_emph ltx_font_italic\">demographic-focused</em> taxonomy for social bias detection for better alignment with anti-discrimination principles and multi-axis targeted bias detection.</p>\n\n",
                "matched_terms": [
                    "targeted",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We frame bias detection as a multi-label task and build a detection testbed that supports prompting, in-context learning, and fine-tuning.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "prompting",
                    "finetuning",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias analysis of corpora.</span>\nOther work has directly analyzed large text corpora. <cite class=\"ltx_cite ltx_citemacro_citet\">Kreutzer et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib29\" title=\"\">2022</a>)</cite> employed human surveys on a small web-crawled subset to assess multilingual quality and offensive content. Lexicon-based approaches have been used to detect opinion biases in Wikipedia&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Hube and Fetahu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib23\" title=\"\">2018</a>)</cite>. <cite class=\"ltx_cite ltx_citemacro_citet\">Luccioni and Viviano (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib34\" title=\"\">2021</a>)</cite> subsampled Common Crawl to study sexual and hateful content using n-grams, BERT, and logistic regression, while <cite class=\"ltx_cite ltx_citemacro_citet\">Dodge et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>)</cite> analyzed C4, linking sentiment toward racial groups to biased QA outcomes. Although these studies provide valuable insights, they rely on relatively simplistic detection methods. In contrast, our work offers a systematic evaluation of state-of-the-art LLMs for social bias detection, providing deeper insights that can complement and extend prior analyses of large-scale corpora.</p>\n\n",
                "matched_terms": [
                    "detection",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section outlines the practical setup of our evaluation framework for analyzing the ability of LLMs to detect social biases in texts targeting different demographic groups. We first present the demographic-targeted taxonomy that underpins our framework, then describe how we adapt and integrate existing datasets for a holistic evaluation of bias detection. Finally, we detail the testbed we constructed to ensure comprehensive coverage of LLMs and detection methods.</p>\n\n",
                "matched_terms": [
                    "targeting",
                    "setup",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address the limitations, our framework employs a <em class=\"ltx_emph ltx_font_italic\">demographic-centered taxonomy</em> that identifies the demographic axes targeted by biased texts. This approach aligns directly with anti-discrimination regulations and governance measures&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(European Commission, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib13\" title=\"\">2025</a>)</cite>, while also enabling the study of <em class=\"ltx_emph ltx_font_italic\">multi-axis</em> biases: cases where texts simultaneously target multiple groups, an aspect often overlooked. Concretely, our taxonomy spans nine axes with differing legal recognition:</p>\n\n",
                "matched_terms": [
                    "targeted",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Any text not targeting one or more of these axes is considered &#8220;unbiased&#8221; (<span class=\"ltx_text ltx_font_typewriter\">UNB</span>) <em class=\"ltx_emph ltx_font_italic\">within our taxonomy</em>. Each demographic axis serves as a prediction category, making the detection task twofold: (i) identify whether a text expresses demographic-targeted bias, and (ii) determine which demographics are targeted. Unlike prior benchmarks that treat bias detection as single-label or multi-class classification&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, our formulation supports <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em>, capturing both <span class=\"ltx_text ltx_font_italic\">single-axis</span> (e.g., race only) and <span class=\"ltx_text ltx_font_italic\">multi-axis</span> (e.g., gender+race) biases (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T2\" title=\"Table 2 &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>).</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "targeting",
                    "detection",
                    "targeted"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Since some datasets were originally designed for evaluating generative biases, we applied minor adaptations similar to&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>. For StereoSet, we concatenate the context with the stereotype options. For BBQ, we construct text instances by pairing disambiguated contexts with answers. For CrowS-Pairs, we retain only the &#8220;more biased&#8221; sentences. For SBIC, we derive a single label using the majority vote across annotators. For ToxiGen, we label texts as biased only when human annotator scores indicate bias.</p>\n\n",
                "matched_terms": [
                    "instances",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The resulting dataset contains <span class=\"ltx_text ltx_font_bold\">46,781</span> entries, substantially larger than comparable benchmarks (e.g., 11,004 samples in&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>). Biased instances are more prevalent (around 70%), with most targeting a single demographic axis and roughly 12% of biased instances targeting multiple axes simultaneously. Among demographic targets, <span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, <span class=\"ltx_text ltx_font_typewriter\">SO</span>, and <span class=\"ltx_text ltx_font_typewriter\">REL</span> are most common, while <span class=\"ltx_text ltx_font_typewriter\">PHY</span> is least prevalent. Multi-axis biases most frequently combine {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">SO</span>} or {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>}.</p>\n\n",
                "matched_terms": [
                    "targets",
                    "targeting",
                    "instances",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To ensure a comprehensive evaluation, we consider a testbed incorporating LLM-based detection methods that span both prompting and fine-tuning. Furthermore, we operationalize our testbed with a diverse suite of state-of-the-art, open-source, or open-weight LLMs spanning multiple paradigms and configurations.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "finetuning",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_citet\">Brown et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib4\" title=\"\">2020</a>)</cite> demonstrated that <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> LLMs can effectively perform a variety of tasks through textual prompting in <em class=\"ltx_emph ltx_font_italic\">zero-shot</em> scenarios. Following&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>; Palla et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib42\" title=\"\">2025</a>)</cite>, our evaluation framework employs <em class=\"ltx_emph ltx_font_italic\">policy-based</em> prompting for bias detection. Specifically, the prompt includes a policy detailing the bias detection task and our demographic-based social bias taxonomy. To enhance the bias detection capabilities within this prompting framework, we also assess the benefits of incorporating <em class=\"ltx_emph ltx_font_italic\">few-shot</em> examples for <em class=\"ltx_emph ltx_font_italic\">in-context learning</em>. Specifically, we utilize the retrieval-augmented (RAG) framework&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib5\" title=\"\">2024a</a>)</cite>, where an embedding model identifies the most <em class=\"ltx_emph ltx_font_italic\">relevant</em> in-context examples for each input instance from the training/development set.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "model",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Models.</span> We consider several <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> models ranging from 8B to 72B parameters, e.g., GLM-4&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(GLM et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib18\" title=\"\">2024</a>)</cite>, Llama-3.1&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Dubey et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib10\" title=\"\">2024</a>)</cite>, and Qwen-2.5&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Yang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib58\" title=\"\">2024</a>)</cite>. We also analyze the guardrail model Llama Guard-3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>)</cite> to explore if such models could directly be applied for general text bias detection. To perform RAG-based in-context sample selection, we use the BGE-M3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib6\" title=\"\">2024b</a>)</cite> model.</p>\n\n",
                "matched_terms": [
                    "llama",
                    "model",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We also evaluate the effectiveness of aligning LLMs to the bias detection task through <em class=\"ltx_emph ltx_font_italic\">fine-tuning</em>. The task is framed as <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em> over the nine demographic axes. We solve it through sequence classification by attaching nine classifier nodes to a pre-trained LLM: to the [CLS] token for encoder-only models and to the final output token for decoder-only models.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "finetuning",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Because detection must perform reliably <em class=\"ltx_emph ltx_font_italic\">across all demographic axes</em>, our evaluation framework also explores the effectiveness of <em class=\"ltx_emph ltx_font_italic\">data reweighting</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kamiran and Calders, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib25\" title=\"\">2012</a>)</cite> to address imbalances. Let <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> denote the number of samples and <math alttext=\"\\mathcal{M}_{\\phi}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m2\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8499;</mi><mi>&#981;</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{M}_{\\phi}</annotation></semantics></math> the model. For a given instance <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m3\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>, its labels <math alttext=\"Y_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m4\" intent=\":literal\"><semantics><msub><mi>Y</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">Y_{i}</annotation></semantics></math> form a binary vector of length nine, where <math alttext=\"Y_{i}^{m}=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m5\" intent=\":literal\"><semantics><mrow><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">Y_{i}^{m}=1</annotation></semantics></math> if the demographic axis <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m6\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> is targeted and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m7\" intent=\":literal\"><mn>0</mn></math> otherwise. The weighted loss is defined as:</p>\n\n",
                "matched_terms": [
                    "targeted",
                    "model",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"\\alpha_{m}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m8\" intent=\":literal\"><semantics><msub><mi>&#945;</mi><mi>m</mi></msub><annotation encoding=\"application/x-tex\">\\alpha_{m}</annotation></semantics></math> balances across demographic axes, and <math alttext=\"w_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m9\" intent=\":literal\"><semantics><msub><mi>w</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">w_{i}</annotation></semantics></math> compensates for binary imbalances regarding biased and unbiased instances. All weights are derived from training data statistics.</p>\n\n",
                "matched_terms": [
                    "instances",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our comprehensive framework uses metrics capturing three dimensions: (i) distinguishing <em class=\"ltx_emph ltx_font_italic\">biased vs. unbiased</em> text, (ii) accurate <em class=\"ltx_emph ltx_font_italic\">multi-label classification</em> of bias types, and (iii) ensuring <em class=\"ltx_emph ltx_font_italic\">parity</em> in detection performance across demographic axes and for multi-targeted texts compared to single-targeted texts.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "biased",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Let <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> be the number of evaluation instances. For each instance <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m2\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>, annotated labels are represented as <math alttext=\"Y_{i}=\\begin{pmatrix}Y_{i}^{m}\\end{pmatrix}_{m=1}^{9}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m3\" intent=\":literal\"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><msubsup><mrow><mo>(</mo><mtable><mtr><mtd><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup></mtd></mtr></mtable><mo>)</mo></mrow><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mn>9</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">Y_{i}=\\begin{pmatrix}Y_{i}^{m}\\end{pmatrix}_{m=1}^{9}</annotation></semantics></math> and model predictions as <math alttext=\"\\hat{Y}_{i}=\\begin{pmatrix}\\hat{Y}_{i}^{m}\\end{pmatrix}_{m=1}^{9}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m4\" intent=\":literal\"><semantics><mrow><msub><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><mi>i</mi></msub><mo>=</mo><msubsup><mrow><mo>(</mo><mtable><mtr><mtd><msubsup><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><mi>i</mi><mi>m</mi></msubsup></mtd></mtr></mtable><mo>)</mo></mrow><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mn>9</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">\\hat{Y}_{i}=\\begin{pmatrix}\\hat{Y}_{i}^{m}\\end{pmatrix}_{m=1}^{9}</annotation></semantics></math>, where <math alttext=\"Y_{i}^{m},\\hat{Y}_{i}^{m}\\in\\{0,1\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m5\" intent=\":literal\"><semantics><mrow><mrow><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>,</mo><msubsup><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><mi>i</mi><mi>m</mi></msubsup></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">Y_{i}^{m},\\hat{Y}_{i}^{m}\\in\\{0,1\\}</annotation></semantics></math> denote whether axis <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m6\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> is targeted (1) or not (0).</p>\n\n",
                "matched_terms": [
                    "targeted",
                    "model",
                    "instances"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Binary bias detection.</span>\nWe reduce the multi-label task to a binary one by defining\nground-truth labels <math alttext=\"Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.SS4.p3.m1\" intent=\":literal\"><semantics><mrow><msub><mi>Y</mi><msub><mi>B</mi><mi>i</mi></msub></msub><mo>=</mo><mn>1</mn><mo>&#8722;</mo><mi>&#120128;</mi><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>0</mn><mo>,</mo><mo>,</mo><mo rspace=\"0.167em\">&#8704;</mo><mi>m</mi><mo>&#8712;</mo><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><mn>9</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]</annotation></semantics></math>, with predictions <math alttext=\"\\hat{Y}_{B_{i}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m2\" intent=\":literal\"><semantics><msub><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><msub><mi>B</mi><mi>i</mi></msub></msub><annotation encoding=\"application/x-tex\">\\hat{Y}_{B_{i}}</annotation></semantics></math> defined analogously. A value of <math alttext=\"1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m3\" intent=\":literal\"><semantics><mn>1</mn><annotation encoding=\"application/x-tex\">1</annotation></semantics></math> indicates the presence of any bias, and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m4\" intent=\":literal\"><mn>0</mn></math> indicates none. On these binary labels, we report <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m5\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, false positive rate (FPR), and false negative rate (FNR).</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "fnr",
                    "detection",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-label bias detection.</span>\nAlongside macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p4.m1\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math> and micro <math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p4.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math> scores, we report two multi-label measures&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sorower, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib48\" title=\"\">2010</a>)</cite>:</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Detection disparities.</span>\nOur evaluation also examines whether LLMs not only detect social biases accurately but also exhibit systematic performance gaps across different demographic targets. Given <math alttext=\"\\mathcal{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p5.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><annotation encoding=\"application/x-tex\">\\mathcal{P}</annotation></semantics></math> denotes FPR or FNR, we analyze disparities in the following scenarios:</p>\n\n",
                "matched_terms": [
                    "targets",
                    "fnr",
                    "detection",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-demographic.</span> Following predictive fairness&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Hardt et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib19\" title=\"\">2016</a>; Zafar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib60\" title=\"\">2017</a>)</cite>, we compute the <em class=\"ltx_emph ltx_font_italic\">maximum absolute error gap</em>, i.e., <span class=\"ltx_text ltx_font_italic\">overall detection disparity</span> across <span class=\"ltx_text ltx_font_italic\">individual</span> demographic axes:\n<math alttext=\"\\Delta_{\\mathcal{P}}=\\underset{m,m^{\\prime}}{\\text{max}}\\big|\\mathcal{P}_{m}-\\mathcal{P}_{m^{\\prime}}\\big|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.I3.i1.p1.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi></msub><mo>=</mo><mrow><munder accentunder=\"true\"><mtext>max</mtext><mrow><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup></mrow></munder><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mi>m</mi></msub><mo>&#8722;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><msup><mi>m</mi><mo>&#8242;</mo></msup></msub></mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\mathcal{P}}=\\underset{m,m^{\\prime}}{\\text{max}}\\big|\\mathcal{P}_{m}-\\mathcal{P}_{m^{\\prime}}\\big|</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "disparity",
                    "perdemographic",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-demographic.</span> Inspired by&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite>, we measure if the models make systematically more errors in detecting biases that <em class=\"ltx_emph ltx_font_italic\">specifically</em> target <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em> (e.g., {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}) relative to biases that target <span class=\"ltx_text ltx_font_italic\">each constituent axis</span> (e.g., only <span class=\"ltx_text ltx_font_typewriter\">GEN</span> or <span class=\"ltx_text ltx_font_typewriter\">RAC</span>).\n<math alttext=\"\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.I3.i2.p1.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>=</mo><mrow><munder accentunder=\"true\"><mi>max</mi><mrow><mi>x</mi><mo>&#8712;</mo><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></mrow></munder><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msub><mo>&#8722;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mi>x</mi></msub></mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|</annotation></semantics></math>. This measure helps us understand if the FPR or FNR of multi-axis targeted biased instances is markedly higher, indicating potential blind spots for automated bias detection methods.</p>\n\n",
                "matched_terms": [
                    "genrac",
                    "biased",
                    "instances",
                    "detection",
                    "fnr",
                    "fpr",
                    "multidemographic",
                    "targeted"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section illustrates how our comprehensive evaluation study enables the practical assessment of LLM-based methods for detecting demographic-targeted social biases in text. Our analysis reveals both the strengths and current limitations of these approaches. For rigorous assessment of the overall results, we perform 1,000 bootstrap samples with replacement on the combined test set to compute 95% confidence intervals. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> presents a detailed comparison of prompting and fine-tuning, reporting both binary performance (biased vs. unbiased) and multi-label categorization. We also report median inference time (in milliseconds) for each text instance. Moreover, for more fine-grained analysis, Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> reports bias detection performance of select prompted and fine-tuned LLMs for the twelve constituent datasets.</p>\n\n",
                "matched_terms": [
                    "finetuning",
                    "biased",
                    "prompting",
                    "detection",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our detailed results in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> show how bias detection with prompting is <em class=\"ltx_emph ltx_font_italic\">highly sensitive to both in-context learning and model capacity</em>.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "model",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">In-context learning substantially improves detection.</span> Across all models, providing few-shot examples consistently boosts binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, lowers FNR, and increases multi-label metrics (MR, HL, <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>). Gains are significant with as few as five examples, while moving from five to ten shots yields only marginal improvements. However, inference time grows with the number of examples, highlighting the accuracy&#8211;efficiency tradeoff in prompting. Beyond the reported results, we also analyzed alternative in-context setups (in the appendix). We found that (i) RAG-based example selection outperforms random sampling, and (ii) alternative embeddings&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Youdao, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib59\" title=\"\">2023</a>)</cite> yield comparable results.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "prompting",
                    "fnr",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Model size and architecture strongly shape results.</span> Larger models (e.g., Llama-70B, Qwen-72B) achieve higher binary and multi-label performance than smaller variants. Within model families, scale matters: Llama-70B outperforms Llama-8B across nearly all metrics. However, size alone is not decisive. GLM-4-9B rivals or surpasses larger Llama and Qwen models on multi-label metrics, and Llama-3.1-70B outperforms Qwen-2.5-72B despite similar scale. Larger models tend to reduce FPR but can increase FNR, reflecting greater sensitivity at the cost of more false negatives. Inference time rises steeply with model scale, from 350ms for 8B models to over 600ms for 70B+ models.</p>\n\n",
                "matched_terms": [
                    "llama",
                    "glm49b",
                    "model",
                    "fnr",
                    "fpr",
                    "qwen2572b",
                    "llama3170b",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Guardrail models transfer poorly.</span> Llama Guard, fine-tuned for moderation, consistently underperforms instruction-tuned models of similar size (e.g., Llama-3.1-8B), achieving the lowest binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> and highest FNR. While effective at detecting overt hate speech, it fails to capture subtler biases like stereotypes.</p>\n\n",
                "matched_terms": [
                    "llama",
                    "llama318b",
                    "fnr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nFrom Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we see the role of scale from the binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. The 70B Llama model outperforms smaller variants across most datasets. Llama-Guard shows lower overall binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, but performs relatively well on hate/toxic content. It specifically achieves the highest score across all models on Toxigen, which is GPT-generated. This finding is consistent with its design as a GPAI guardrail. Multi-label metrics show that even larger models struggle to correctly identify bias types, especially for stereotyped contents, e.g., StereoSet and RedditBias.</p>\n\n",
                "matched_terms": [
                    "llama",
                    "model",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuning substantially improves detection.</span> Even small models, such as RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>, surpass much larger prompting-only models (Llama-3.1-70B, Qwen-2.5-72B) on binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> (above 90 vs. below 89) and multi-label metrics (MR, HL, micro <math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math> and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m3\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>). Fine-tuned models also achieve lower FNR and higher reliability in detecting biased content. Inference is far faster: RoBERTa completes batches in seconds, whereas prompting with 70B+ LLMs requires hundreds of seconds.</p>\n\n",
                "matched_terms": [
                    "finetuning",
                    "biased",
                    "prompting",
                    "detection",
                    "fnr",
                    "robertabase",
                    "qwen2572b",
                    "llama3170b",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Architecture influences performance.</span> Encoder models (RoBERTa, DeBERTa) consistently outperform decoder models (GPT-2), irrespective of scale. GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span> underperforms on binary and multi-label detection. In contrast, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> and RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> achieve higher detection scores. Inference times also reflect architectural complexity: decoder models remain faster, whereas DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> is particularly slow due to disentangled attention&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(He et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib21\" title=\"\">2020</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "detection",
                    "debertav2xl",
                    "robertalarge",
                    "gpt2xl",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Scaling improves detection.</span> Within encoder families, larger variants (RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">XL</span>) achieve better detection results. Importantly, despite being the newer variant, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> performs slightly worse than the larger but older DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>. GPT-2 shows similar scaling trends within decoder models. Inference time increases with model size, reinforcing the tradeoff between accuracy and efficiency.</p>\n\n",
                "matched_terms": [
                    "debertav3large",
                    "model",
                    "detection",
                    "debertav2xl",
                    "robertalarge"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Loss reweighting has tradeoffs.</span> Reweighted loss consistently improves binary FNR and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p5.m1\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math> (e.g., DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>, RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>) by capturing subtle biases, but can raise FPR, particularly in decoder models. Effects are uneven: DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> shows reduced MR and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p5.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>, suggesting reweighting may destabilize multi-label detection for some scenarios.</p>\n\n",
                "matched_terms": [
                    "debertav3large",
                    "detection",
                    "debertav2xl",
                    "robertalarge",
                    "fnr",
                    "fpr",
                    "gpt2xl",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> shows how fine-tuned models achieve stronger binary detection across most datasets compared to prompting-based LLMs. Encoder models (DeBERTa) generally outperform decoder-only GPT-2, which remains competitive on many datasets but struggles with subtle stereotype cases, e.g, RedditBias and Winogender. For multi-label detection, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> shows consistently lower HL, indicating more accurate detection of demographic axes targeted.</p>\n\n",
                "matched_terms": [
                    "targeted",
                    "multilabel",
                    "detection",
                    "debertav2xl"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nFine-tuned encoder models provide the most effective bias detection, outperforming prompting much larger models in both binary detection and identification of the correct bias types. Decoder-based models can perform well but show weaknesses on subtle stereotype datasets. Fine-tuning with reweighted loss improves recall, but may increase false positives, highlighting important tradeoffs that require consideration.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "finetuning",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We assess systemic performance disparities using <math alttext=\"\\Delta_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p1.m1\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}</annotation></semantics></math> and <math alttext=\"\\Delta_{\\text{FPR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p1.m2\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}</annotation></semantics></math>, which measure the maximum performance gaps across the nine social bias demographic target axes in our taxonomy.</p>\n\n",
                "matched_terms": [
                    "δfnrdeltatextfnr",
                    "δfprdeltatextfpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Prompting shows large disparities.</span> In zero-shot settings, models exhibit significant disparities. For instance, Llama-3.1-8B and GLM-4-9B exhibit <math alttext=\"\\Delta_{\\text{FNR}}\\approx 0.6\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><mo>&#8776;</mo><mn>0.6</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}\\approx 0.6</annotation></semantics></math>, <math alttext=\"\\Delta_{\\text{FPR}}\\approx 0.42\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><mo>&#8776;</mo><mn>0.42</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}\\approx 0.42</annotation></semantics></math>. Few-shot prompting reduces disparities (e.g., for Llama-3.1-8B, <math alttext=\"\\Delta_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m3\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}</annotation></semantics></math> drops to <math alttext=\"\\approx 0.26\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8776;</mo><mn>0.26</mn></mrow><annotation encoding=\"application/x-tex\">\\approx 0.26</annotation></semantics></math>), but performance remains uneven compared to fine-tuned models. Scaling improves parity: Llama-3.1-70B shows lower disparities than its 8B counterpart, and Qwen-2.5-72B achieves the strongest parity among prompting models, especially with few-shot examples.</p>\n\n",
                "matched_terms": [
                    "δfnrdeltatextfnr",
                    "glm49b",
                    "prompting",
                    "qwen2572b",
                    "llama318b",
                    "llama3170b"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuning yields markedly lower disparities.</span> Encoder models such as RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> and DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> reach <math alttext=\"\\Delta_{\\text{FNR}}\\approx 0.2\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><mo>&#8776;</mo><mn>0.2</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}\\approx 0.2</annotation></semantics></math> and <math alttext=\"\\Delta_{\\text{FPR}}\\approx 0.03\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m2\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><mo>&#8776;</mo><mn>0.03</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}\\approx 0.03</annotation></semantics></math>, particularly with reweighted loss. Reweighting reduces FNR gaps but can slightly increase FPR gaps, indicating a tradeoff. Model architecture also matters: encoder models achieve far lower disparities than decoder-only GPT-2, and scaling further improves parity (e.g., RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> outperforms RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>).</p>\n\n",
                "matched_terms": [
                    "finetuning",
                    "model",
                    "debertav2xl",
                    "robertalarge",
                    "fnr",
                    "robertabase",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nPrompting, even with larger models and few-shot examples, shows substantial per-axis disparities. Fine-tuned models, particularly with reweighted loss, achieve more balanced performance, although notable gaps remain. In additional analyses (in the appendix), we examined <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across the nine demographic axes. We found that certain targets, such as <span class=\"ltx_text ltx_font_typewriter\">NAT</span> and <span class=\"ltx_text ltx_font_typewriter\">PHY</span>, consistently have lower detection accuracy, which contributes to the observed disparities.</p>\n\n",
                "matched_terms": [
                    "targets",
                    "prompting",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We now analyze texts targeting <span class=\"ltx_text ltx_font_italic\">multiple axes simultaneously</span>, focusing on {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>} and {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}. We compare performance on these multi-axis instances to that on the instances that target only constituent single axes (e.g., only <span class=\"ltx_text ltx_font_typewriter\">GEN</span> or <span class=\"ltx_text ltx_font_typewriter\">SO</span> for {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>}).</p>\n\n",
                "matched_terms": [
                    "genrac",
                    "genso",
                    "targeting",
                    "instances"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Prompting improves with scale and few-shot examples.</span> Few-shot prompting substantially narrows multi-axis gaps. For Llama-3.1-70B, <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m1\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}</annotation></semantics></math> drops from 0.736 (zero-shot) to 0.164 (10-shot), and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m2\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}</annotation></semantics></math> from 0.262 to 0.088. Larger models benefit more from in-context learning: Llama-3.1-70B outperforms Llama-3.1-8B, and disparities are generally higher for {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>} than {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}.</p>\n\n",
                "matched_terms": [
                    "genrac",
                    "𝒢fnrgenracmathcalgtextgenractextfnr",
                    "prompting",
                    "𝒢fnrgensomathcalgtextgensotextfnr",
                    "genso",
                    "llama318b",
                    "llama3170b",
                    "10shot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuned models show persistent gaps.</span> Despite strong per-axis parity, fine-tuned models underperform on multi-axis instances, reflecting <em class=\"ltx_emph ltx_font_italic\">gerrymandering</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite> in their detection performance. For example, RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> with reweighting achieves <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.436</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436</annotation></semantics></math> and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m2\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.373</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373</annotation></semantics></math>, higher than few-shot Llama-3.1-70B and Qwen-2.5-72B. Encoder models outperform GPT-2, and scaling improves parity (e.g., DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> at <math alttext=\"\\approx 0.28\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m3\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8776;</mo><mn>0.28</mn></mrow><annotation encoding=\"application/x-tex\">\\approx 0.28</annotation></semantics></math> vs. DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> at 0.39 for FNR regarding {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>}). As with per-axis results, reweighting reduces FNR gaps but can slightly raise FPR gaps.</p>\n\n",
                "matched_terms": [
                    "instances",
                    "debertav3large",
                    "detection",
                    "debertav2xl",
                    "robertalarge",
                    "genso",
                    "fnr",
                    "fpr",
                    "qwen2572b",
                    "llama3170b"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nDetecting multi-demographic biases remains particularly difficult for LLM-based methods. Fine-tuned models achieve relatively low disparities regarding single axes but struggle with biases targeting multiple demographics. These results highlight intersectional disparities as an important direction for future research.</p>\n\n",
                "matched_terms": [
                    "multidemographic",
                    "targeting"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methodological opportunities.</span>\nOur findings highlight both promises and existing limitations of scalable automated bias detection. Future work should further explore advanced prompting (e.g., <span class=\"ltx_text ltx_font_italic\">chain-of-thought</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wei et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib56\" title=\"\">2022</a>)</cite>) and efficient fine-tuning (e.g., using adapters). To handle multimodal data, exploring effective and scalable solutions remains an interesting open challenge. Moreover, while our results offer initial guidance, balancing the potential gains from training and deploying larger models and the scalability required for auditing massive corpora warrants deeper exploration. Finally, our study shows that detecting infrequent, subtle, and multi-axis biases remains a crucial underexplored direction for future research.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "finetuning",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Mitigation through data bias detection.</span>\nBias detection enables more than regulatory reporting; it allows for leveraging the flagged data instances for more responsible model development through targeted data augmentation, filtering, or fine-tuning&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite>. However, any remedial action <span class=\"ltx_text ltx_font_italic\">must be</span> guided by rigorous ethical considerations and incorporate human oversight.</p>\n\n",
                "matched_terms": [
                    "finetuning",
                    "instances",
                    "model",
                    "detection",
                    "targeted"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Label statistics.</span>\nIn Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F2\" title=\"Figure 2 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, we visualize the label statistics in the final curated dataset. The visualizations show label imbalances in the data, highlighting the need for weighted loss for optimization and motivating future work to explore further fairness interventions to ensure equitable bias detection performance. The statistics show that our data contains more biased instances than unbiased ones. Furthermore, we see that most instances target a single demographic axis. However, many instances target two axes. Instances targeting more than two demographic axes are significantly fewer in our dataset. We provide more detailed label co-occurrence statistics in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A1.F1.sf2\" title=\"In Figure 1 &#8227; Appendix A Data characteristics &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">1(b)</span></a>. The figure shows that text instances target specific demographics more often. For instance, texts target <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">GEN</span> more often. Similarly, texts target <span class=\"ltx_text ltx_font_typewriter\">DIS</span>,<span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">PHY</span> relatively less often. Furthermore, we see that <span class=\"ltx_text ltx_font_typewriter\">GEN</span> co-occurs with many other demographic axes, e.g., <span class=\"ltx_text ltx_font_typewriter\">SO</span>, <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, and <span class=\"ltx_text ltx_font_typewriter\">DIS</span>. Note that while <span class=\"ltx_text ltx_font_typewriter\">RAC</span> and <span class=\"ltx_text ltx_font_typewriter\">REL</span> appear together frequently, many of these instances simply target &#8220;Jewish identities.&#8221;</p>\n\n",
                "matched_terms": [
                    "targeting",
                    "instances",
                    "detection",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All LLMs are accessed via API through an MLOps platform. We fix <span class=\"ltx_text ltx_font_typewriter\">temperature</span> to 0 and <span class=\"ltx_text ltx_font_typewriter\">top_p</span> to 1, ensuring deterministic outputs by selecting the model&#8217;s most likely generation while still allowing consideration of the full token space. For in-context learning, we embed the training and development sets using BGE-M3 or BCEmbedding models. At inference time, we compute cosine similarity between the query and development set vectors to retrieve the top-<math alttext=\"K\" class=\"ltx_Math\" display=\"inline\" id=\"A2.SS1.p1.m1\" intent=\":literal\"><semantics><mi>K</mi><annotation encoding=\"application/x-tex\">K</annotation></semantics></math> few-shot examples. As a baseline, we also apply a random few-shot selection from the training set, with balanced sampling between biased and unbiased texts. Model predictions are extracted via pattern matching. Responses that cannot be parsed through pattern matching to assign to one of the multiple demographic axes are marked as &#8220;invalid.&#8221; The <span class=\"ltx_text ltx_font_italic\">social bias policy</span> used in the text prompt is shown here.</p>\n\n",
                "matched_terms": [
                    "model",
                    "biased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><math alttext=\"10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"A2.I1.i4.p1.m1\" intent=\":literal\"><semantics><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>5</mn></mrow></msup><annotation encoding=\"application/x-tex\">10^{-5}</annotation></semantics></math> (RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>)</p>\n\n",
                "matched_terms": [
                    "robertalarge",
                    "debertav2xl"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In binary classification, RAG achieves higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS1.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across all models. Improvements in detection metrics are consistent across model sizes, demonstrating the benefit of providing LLMs with <em class=\"ltx_emph ltx_font_italic\">semantically similar examples</em> during in-context learning. RAG generally reduces False Negative Rates (FNR), though it occasionally causes slight increases in False Positive Rates (FPR), as observed with Llama Guard-3-8B and GLM-4-9B. This tradeoff is typically favorable, since reducing FNR is crucial for minimizing missed detections. Notably, while adding more examples under RAG yields only modest additional gains, increasing the number of randomly selected examples often leads to degraded performance.</p>\n\n",
                "matched_terms": [
                    "guard38b",
                    "llama",
                    "glm49b",
                    "model",
                    "detection",
                    "fnr",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For multi-label prediction, RAG delivers even greater improvements over random sampling. As in the binary case, providing more RAG-selected examples enhances performance, whereas adding more random examples consistently worsens detection outcomes. This highlights an important insight: supplying more <em class=\"ltx_emph ltx_font_italic\">relevant</em> examples benefits prompting-based detection, but including <em class=\"ltx_emph ltx_font_italic\">irrelevant</em> examples can be detrimental.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In summary, RAG significantly strengthens in-context learning by providing more meaningful examples, resulting in higher accuracy and improved multi-label predictions. Although small increases in FPR can occur, the overall gains clearly favor RAG over random sampling.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We next examine how the choice of embedding model affects in-context learning performance for prompting, comparing BGE-M3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib6\" title=\"\">2024b</a>)</cite> and BCEmbedding&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Youdao, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib59\" title=\"\">2023</a>)</cite> for selecting in-context examples. The results are presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.T7\" title=\"Table 7 &#8227; C.1 Ablation study: in-context learning &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">7</span></a>.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">BGE-M3 exhibits a slight but consistent advantage in binary bias detection, producing marginally higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across multiple LLMs. However, the overall differences are minimal. In contrast, for multi-label prediction, BCEmbedding performs slightly better on metrics such as MR for many models. This finding suggests that while both embedding models select examples that yield similar overall outcomes, subtle differences exist. Specifically, BGE-M3-selected examples tend to improve binary bias detection by helping models better distinguish biased from unbiased samples, whereas BCEmbedding-selected examples slightly enhance the detection of specific bias types within biased instances.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "instances",
                    "biased",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Overall, both embedding models deliver strong and comparable performance for in-context learning, with only minor trade-offs. Their results indicate that either embedding model is well-suited for bias detection tasks.</p>\n\n",
                "matched_terms": [
                    "model",
                    "detection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We now analyze model performance across different demographic targets. Specifically, we examine the <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p1.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores for all demographic axes in our taxonomy that may be subject to bias. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F5\" title=\"Figure 5 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents results for various prompted models using <em class=\"ltx_emph ltx_font_italic\">10-shot RAG-based in-context learning</em> with BGE-M3, while Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F6\" title=\"Figure 6 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> compares fine-tuned models and explores the impact of reweighted loss (&#8220;bal&#8221; in the figure) across demographics.</p>\n\n",
                "matched_terms": [
                    "model",
                    "targets",
                    "10shot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Among the prompted LLMs, Llama-3.1-70B achieves the highest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p3.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across nearly all bias categories, except for <span class=\"ltx_text ltx_font_typewriter\">GEN</span>, where GLM-9B&#8212;despite being much smaller&#8212;slightly outperforms it. Interestingly, Qwen-2.5-72B, though the largest LLM, performs worse in many low-frequency categories such as <span class=\"ltx_text ltx_font_typewriter\">DIS</span>, <span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">SES</span>. It performs comparably to the best prompting models only for <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, which are the most common categories in the benchmark.</p>\n\n",
                "matched_terms": [
                    "qwen2572b",
                    "prompting",
                    "llama3170b"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For fine-tuned models, encoder-only architectures (e.g., RoBERTa and DeBERTa) generally outperform decoder-only language models, i.e., GPT-2, across most demographic axes. The trends mirror those observed in the prompting setup: models achieve their best performance for <span class=\"ltx_text ltx_font_typewriter\">SES</span>, while <span class=\"ltx_text ltx_font_typewriter\">NAT</span> consistently shows the lowest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. Reweighted loss often improves detection performance or yields similar results to the default loss. For example, in <span class=\"ltx_text ltx_font_typewriter\">NAT</span>, the axis that suffered from the weakest detection performance, reweighted loss improves performance across all models. However, improvements are not universal. For instance, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">large</span> experiences slight declines in <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> for some demographics such as <span class=\"ltx_text ltx_font_typewriter\">AGE</span> and <span class=\"ltx_text ltx_font_typewriter\">SES</span> when reweighted loss is applied.</p>\n\n",
                "matched_terms": [
                    "gpt2large",
                    "setup",
                    "detection",
                    "prompting"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">These findings provide additional insight into the <em class=\"ltx_emph ltx_font_italic\">disparity results</em> discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S5\" title=\"5 Evaluating detection disparities &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, which highlight performance gaps across demographic axes. This deeper analysis underscores the need to develop <em class=\"ltx_emph ltx_font_italic\">more nuanced methods</em> that can mitigate detection disparities without substantially compromising overall performance.</p>\n\n",
                "matched_terms": [
                    "disparity",
                    "detection"
                ]
            }
        ]
    },
    "A3.T6": {
        "caption": "Table 6: Analyzing the importance of retrieval augmented (RAG-based using BGE-M3) example selection for few-shot prompting by comparing performance to random sampling.",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Model</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Setup</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Few-shot</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Binary Prediction</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Multi-label Prediction</span></th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">FPR</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">FNR</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">MR</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">HL</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m3\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Llama-Guard-8B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Random</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"66.97_{\\pm 0.76}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m4\" intent=\":literal\"><semantics><msub><mn>66.97</mn><mrow><mo>&#177;</mo><mn>0.76</mn></mrow></msub><annotation encoding=\"application/x-tex\">66.97_{\\pm 0.76}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.152_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m5\" intent=\":literal\"><semantics><msub><mn>0.152</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.152_{\\pm 0.011}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.470_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m6\" intent=\":literal\"><semantics><msub><mn>0.470</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.470_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.339_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m7\" intent=\":literal\"><semantics><msub><mn>0.339</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.339_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.089_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m8\" intent=\":literal\"><semantics><msub><mn>0.089</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.089_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"51.39_{\\pm 0.80}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m9\" intent=\":literal\"><semantics><msub><mn>51.39</mn><mrow><mo>&#177;</mo><mn>0.80</mn></mrow></msub><annotation encoding=\"application/x-tex\">51.39_{\\pm 0.80}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"33.39_{\\pm 1.62}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m10\" intent=\":literal\"><semantics><msub><mn>33.39</mn><mrow><mo>&#177;</mo><mn>1.62</mn></mrow></msub><annotation encoding=\"application/x-tex\">33.39_{\\pm 1.62}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"65.55_{\\pm 0.77}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m11\" intent=\":literal\"><semantics><msub><mn>65.55</mn><mrow><mo>&#177;</mo><mn>0.77</mn></mrow></msub><annotation encoding=\"application/x-tex\">65.55_{\\pm 0.77}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.147_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m12\" intent=\":literal\"><semantics><msub><mn>0.147</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.147_{\\pm 0.011}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.488_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m13\" intent=\":literal\"><semantics><msub><mn>0.488</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.488_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.288_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m14\" intent=\":literal\"><semantics><msub><mn>0.288</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.288_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.099_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m15\" intent=\":literal\"><semantics><msub><mn>0.099</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.099_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"45.65_{\\pm 0.85}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m16\" intent=\":literal\"><semantics><msub><mn>45.65</mn><mrow><mo>&#177;</mo><mn>0.85</mn></mrow></msub><annotation encoding=\"application/x-tex\">45.65_{\\pm 0.85}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"30.81_{\\pm 1.67}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m17\" intent=\":literal\"><semantics><msub><mn>30.81</mn><mrow><mo>&#177;</mo><mn>1.67</mn></mrow></msub><annotation encoding=\"application/x-tex\">30.81_{\\pm 1.67}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">RAG</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.16_{\\pm 0.64}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m18\" intent=\":literal\"><semantics><msub><mn>75.16</mn><mrow><mo>&#177;</mo><mn>0.64</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.16_{\\pm 0.64}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.192_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m19\" intent=\":literal\"><semantics><msub><mn>0.192</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.192_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.358_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m20\" intent=\":literal\"><semantics><msub><mn>0.358</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.358_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.485_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m21\" intent=\":literal\"><semantics><msub><mn>0.485</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.485_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.067_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m22\" intent=\":literal\"><semantics><msub><mn>0.067</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.067_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"65.66_{\\pm 0.68}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m23\" intent=\":literal\"><semantics><msub><mn>65.66</mn><mrow><mo>&#177;</mo><mn>0.68</mn></mrow></msub><annotation encoding=\"application/x-tex\">65.66_{\\pm 0.68}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"46.24_{\\pm 1.87}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m24\" intent=\":literal\"><semantics><msub><mn>46.24</mn><mrow><mo>&#177;</mo><mn>1.87</mn></mrow></msub><annotation encoding=\"application/x-tex\">46.24_{\\pm 1.87}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.17_{\\pm 0.64}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m25\" intent=\":literal\"><semantics><msub><mn>75.17</mn><mrow><mo>&#177;</mo><mn>0.64</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.17_{\\pm 0.64}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.186_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m26\" intent=\":literal\"><semantics><msub><mn>0.186</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.186_{\\pm 0.011}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.359_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m27\" intent=\":literal\"><semantics><msub><mn>0.359</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.359_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.486_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m28\" intent=\":literal\"><semantics><msub><mn>0.486</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.486_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.067_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m29\" intent=\":literal\"><semantics><msub><mn>0.067</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.067_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"65.79_{\\pm 0.69}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m30\" intent=\":literal\"><semantics><msub><mn>65.79</mn><mrow><mo>&#177;</mo><mn>0.69</mn></mrow></msub><annotation encoding=\"application/x-tex\">65.79_{\\pm 0.69}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"44.68_{\\pm 1.82}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m31\" intent=\":literal\"><semantics><msub><mn>44.68</mn><mrow><mo>&#177;</mo><mn>1.82</mn></mrow></msub><annotation encoding=\"application/x-tex\">44.68_{\\pm 1.82}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Llama-3.1-8B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Random</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"84.50_{\\pm 0.45}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m32\" intent=\":literal\"><semantics><msub><mn>84.50</mn><mrow><mo>&#177;</mo><mn>0.45</mn></mrow></msub><annotation encoding=\"application/x-tex\">84.50_{\\pm 0.45}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.832_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m33\" intent=\":literal\"><semantics><msub><mn>0.832</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.832_{\\pm 0.011}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.057_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m34\" intent=\":literal\"><semantics><msub><mn>0.057</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.057_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.075_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m35\" intent=\":literal\"><semantics><msub><mn>0.075</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.075_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.236_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m36\" intent=\":literal\"><semantics><msub><mn>0.236</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.236_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"47.73_{\\pm 0.49}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m37\" intent=\":literal\"><semantics><msub><mn>47.73</mn><mrow><mo>&#177;</mo><mn>0.49</mn></mrow></msub><annotation encoding=\"application/x-tex\">47.73_{\\pm 0.49}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"33.74_{\\pm 0.49}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m38\" intent=\":literal\"><semantics><msub><mn>33.74</mn><mrow><mo>&#177;</mo><mn>0.49</mn></mrow></msub><annotation encoding=\"application/x-tex\">33.74_{\\pm 0.49}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"84.19_{\\pm 0.46}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m39\" intent=\":literal\"><semantics><msub><mn>84.19</mn><mrow><mo>&#177;</mo><mn>0.46</mn></mrow></msub><annotation encoding=\"application/x-tex\">84.19_{\\pm 0.46}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.698_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m40\" intent=\":literal\"><semantics><msub><mn>0.698</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.698_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.097_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m41\" intent=\":literal\"><semantics><msub><mn>0.097</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.097_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.051_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m42\" intent=\":literal\"><semantics><msub><mn>0.051</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.051_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.252_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m43\" intent=\":literal\"><semantics><msub><mn>0.252</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.252_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"45.21_{\\pm 0.48}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m44\" intent=\":literal\"><semantics><msub><mn>45.21</mn><mrow><mo>&#177;</mo><mn>0.48</mn></mrow></msub><annotation encoding=\"application/x-tex\">45.21_{\\pm 0.48}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"33.38_{\\pm 0.43}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m45\" intent=\":literal\"><semantics><msub><mn>33.38</mn><mrow><mo>&#177;</mo><mn>0.43</mn></mrow></msub><annotation encoding=\"application/x-tex\">33.38_{\\pm 0.43}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">RAG</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.27_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m46\" intent=\":literal\"><semantics><msub><mn>87.27</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.27_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.752_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m47\" intent=\":literal\"><semantics><msub><mn>0.752</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.752_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.023_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m48\" intent=\":literal\"><semantics><msub><mn>0.023</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.023_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.411_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m49\" intent=\":literal\"><semantics><msub><mn>0.411</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.411_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.140_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m50\" intent=\":literal\"><semantics><msub><mn>0.140</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.140_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"62.19_{\\pm 0.68}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m51\" intent=\":literal\"><semantics><msub><mn>62.19</mn><mrow><mo>&#177;</mo><mn>0.68</mn></mrow></msub><annotation encoding=\"application/x-tex\">62.19_{\\pm 0.68}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"44.58_{\\pm 0.73}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m52\" intent=\":literal\"><semantics><msub><mn>44.58</mn><mrow><mo>&#177;</mo><mn>0.73</mn></mrow></msub><annotation encoding=\"application/x-tex\">44.58_{\\pm 0.73}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.47_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m53\" intent=\":literal\"><semantics><msub><mn>87.47</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.47_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.746_{\\pm 0.013}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m54\" intent=\":literal\"><semantics><msub><mn>0.746</mn><mrow><mo>&#177;</mo><mn>0.013</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.746_{\\pm 0.013}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.021_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m55\" intent=\":literal\"><semantics><msub><mn>0.021</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.021_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.501_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m56\" intent=\":literal\"><semantics><msub><mn>0.501</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.501_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.127_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m57\" intent=\":literal\"><semantics><msub><mn>0.127</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.127_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"64.69_{\\pm 0.70}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m58\" intent=\":literal\"><semantics><msub><mn>64.69</mn><mrow><mo>&#177;</mo><mn>0.70</mn></mrow></msub><annotation encoding=\"application/x-tex\">64.69_{\\pm 0.70}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"45.96_{\\pm 0.82}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m59\" intent=\":literal\"><semantics><msub><mn>45.96</mn><mrow><mo>&#177;</mo><mn>0.82</mn></mrow></msub><annotation encoding=\"application/x-tex\">45.96_{\\pm 0.82}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">GLM-4-9B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Random</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.81_{\\pm 0.46}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m60\" intent=\":literal\"><semantics><msub><mn>83.81</mn><mrow><mo>&#177;</mo><mn>0.46</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.81_{\\pm 0.46}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.783_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m61\" intent=\":literal\"><semantics><msub><mn>0.783</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.783_{\\pm 0.011}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.082_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m62\" intent=\":literal\"><semantics><msub><mn>0.082</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.082_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.457_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m63\" intent=\":literal\"><semantics><msub><mn>0.457</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.457_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.095_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m64\" intent=\":literal\"><semantics><msub><mn>0.095</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.095_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"63.37_{\\pm 0.71}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m65\" intent=\":literal\"><semantics><msub><mn>63.37</mn><mrow><mo>&#177;</mo><mn>0.71</mn></mrow></msub><annotation encoding=\"application/x-tex\">63.37_{\\pm 0.71}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"51.23_{\\pm 1.57}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m66\" intent=\":literal\"><semantics><msub><mn>51.23</mn><mrow><mo>&#177;</mo><mn>1.57</mn></mrow></msub><annotation encoding=\"application/x-tex\">51.23_{\\pm 1.57}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.65_{\\pm 0.47}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m67\" intent=\":literal\"><semantics><msub><mn>83.65</mn><mrow><mo>&#177;</mo><mn>0.47</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.65_{\\pm 0.47}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.761_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m68\" intent=\":literal\"><semantics><msub><mn>0.761</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.761_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.091_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m69\" intent=\":literal\"><semantics><msub><mn>0.091</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.091_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.475_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m70\" intent=\":literal\"><semantics><msub><mn>0.475</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.475_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.090_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m71\" intent=\":literal\"><semantics><msub><mn>0.090</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.090_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"64.69_{\\pm 0.67}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m72\" intent=\":literal\"><semantics><msub><mn>64.69</mn><mrow><mo>&#177;</mo><mn>0.67</mn></mrow></msub><annotation encoding=\"application/x-tex\">64.69_{\\pm 0.67}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"52.79_{\\pm 1.56}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m73\" intent=\":literal\"><semantics><msub><mn>52.79</mn><mrow><mo>&#177;</mo><mn>1.56</mn></mrow></msub><annotation encoding=\"application/x-tex\">52.79_{\\pm 1.56}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">RAG</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.10_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m74\" intent=\":literal\"><semantics><msub><mn>87.10</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.10_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.774_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m75\" intent=\":literal\"><semantics><msub><mn>0.774</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.774_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.021_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m76\" intent=\":literal\"><semantics><msub><mn>0.021</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.021_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.773_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m77\" intent=\":literal\"><semantics><msub><mn>0.773</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.773_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.036_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m78\" intent=\":literal\"><semantics><msub><mn>0.036</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.036_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"85.95_{\\pm 0.50}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m79\" intent=\":literal\"><semantics><msub><mn>85.95</mn><mrow><mo>&#177;</mo><mn>0.50</mn></mrow></msub><annotation encoding=\"application/x-tex\">85.95_{\\pm 0.50}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"73.43_{\\pm 1.69}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m80\" intent=\":literal\"><semantics><msub><mn>73.43</mn><mrow><mo>&#177;</mo><mn>1.69</mn></mrow></msub><annotation encoding=\"application/x-tex\">73.43_{\\pm 1.69}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"86.98_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m81\" intent=\":literal\"><semantics><msub><mn>86.98</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">86.98_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.775_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m82\" intent=\":literal\"><semantics><msub><mn>0.775</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.775_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.023_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m83\" intent=\":literal\"><semantics><msub><mn>0.023</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.023_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.782_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m84\" intent=\":literal\"><semantics><msub><mn>0.782</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.782_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.034_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m85\" intent=\":literal\"><semantics><msub><mn>0.034</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.034_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"86.74_{\\pm 0.48}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m86\" intent=\":literal\"><semantics><msub><mn>86.74</mn><mrow><mo>&#177;</mo><mn>0.48</mn></mrow></msub><annotation encoding=\"application/x-tex\">86.74_{\\pm 0.48}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.46_{\\pm 1.68}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m87\" intent=\":literal\"><semantics><msub><mn>75.46</mn><mrow><mo>&#177;</mo><mn>1.68</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.46_{\\pm 1.68}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Random</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"84.28_{\\pm 0.47}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m88\" intent=\":literal\"><semantics><msub><mn>84.28</mn><mrow><mo>&#177;</mo><mn>0.47</mn></mrow></msub><annotation encoding=\"application/x-tex\">84.28_{\\pm 0.47}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.541_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m89\" intent=\":literal\"><semantics><msub><mn>0.541</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.541_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.134_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m90\" intent=\":literal\"><semantics><msub><mn>0.134</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.134_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.284_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m91\" intent=\":literal\"><semantics><msub><mn>0.284</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.284_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.095_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m92\" intent=\":literal\"><semantics><msub><mn>0.095</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.095_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"67.96_{\\pm 0.45}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m93\" intent=\":literal\"><semantics><msub><mn>67.96</mn><mrow><mo>&#177;</mo><mn>0.45</mn></mrow></msub><annotation encoding=\"application/x-tex\">67.96_{\\pm 0.45}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"58.86_{\\pm 1.54}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m94\" intent=\":literal\"><semantics><msub><mn>58.86</mn><mrow><mo>&#177;</mo><mn>1.54</mn></mrow></msub><annotation encoding=\"application/x-tex\">58.86_{\\pm 1.54}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"84.01_{\\pm 0.46}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m95\" intent=\":literal\"><semantics><msub><mn>84.01</mn><mrow><mo>&#177;</mo><mn>0.46</mn></mrow></msub><annotation encoding=\"application/x-tex\">84.01_{\\pm 0.46}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.511_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m96\" intent=\":literal\"><semantics><msub><mn>0.511</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.511_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.147_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m97\" intent=\":literal\"><semantics><msub><mn>0.147</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.147_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.289_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m98\" intent=\":literal\"><semantics><msub><mn>0.289</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.289_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.098_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m99\" intent=\":literal\"><semantics><msub><mn>0.098</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.098_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"66.29_{\\pm 0.47}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m100\" intent=\":literal\"><semantics><msub><mn>66.29</mn><mrow><mo>&#177;</mo><mn>0.47</mn></mrow></msub><annotation encoding=\"application/x-tex\">66.29_{\\pm 0.47}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"56.95_{\\pm 1.49}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m101\" intent=\":literal\"><semantics><msub><mn>56.95</mn><mrow><mo>&#177;</mo><mn>1.49</mn></mrow></msub><annotation encoding=\"application/x-tex\">56.95_{\\pm 1.49}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">RAG</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"88.49_{\\pm 0.38}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m102\" intent=\":literal\"><semantics><msub><mn>88.49</mn><mrow><mo>&#177;</mo><mn>0.38</mn></mrow></msub><annotation encoding=\"application/x-tex\">88.49_{\\pm 0.38}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.581_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m103\" intent=\":literal\"><semantics><msub><mn>0.581</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.581_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.046_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m104\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.657_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m105\" intent=\":literal\"><semantics><msub><mn>0.657</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.657_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.046_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m106\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.28_{\\pm 0.42}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m107\" intent=\":literal\"><semantics><msub><mn>83.28</mn><mrow><mo>&#177;</mo><mn>0.42</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.28_{\\pm 0.42}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"73.16_{\\pm 1.36}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m108\" intent=\":literal\"><semantics><msub><mn>73.16</mn><mrow><mo>&#177;</mo><mn>1.36</mn></mrow></msub><annotation encoding=\"application/x-tex\">73.16_{\\pm 1.36}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"88.82_{\\pm 0.39}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m109\" intent=\":literal\"><semantics><msub><mn>88.82</mn><mrow><mo>&#177;</mo><mn>0.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">88.82_{\\pm 0.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.557_{\\pm 0.015}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m110\" intent=\":literal\"><semantics><msub><mn>0.557</mn><mrow><mo>&#177;</mo><mn>0.015</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.557_{\\pm 0.015}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.046_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m111\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.648_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m112\" intent=\":literal\"><semantics><msub><mn>0.648</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.648_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.047_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m113\" intent=\":literal\"><semantics><msub><mn>0.047</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.047_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.08_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m114\" intent=\":literal\"><semantics><msub><mn>83.08</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.08_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.07_{\\pm 1.39}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m115\" intent=\":literal\"><semantics><msub><mn>75.07</mn><mrow><mo>&#177;</mo><mn>1.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.07_{\\pm 1.39}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Qwen-2.5-72B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Random</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"82.02_{\\pm 0.51}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m116\" intent=\":literal\"><semantics><msub><mn>82.02</mn><mrow><mo>&#177;</mo><mn>0.51</mn></mrow></msub><annotation encoding=\"application/x-tex\">82.02_{\\pm 0.51}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.638_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m117\" intent=\":literal\"><semantics><msub><mn>0.638</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.638_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.151_{\\pm 0.006}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m118\" intent=\":literal\"><semantics><msub><mn>0.151</mn><mrow><mo>&#177;</mo><mn>0.006</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.151_{\\pm 0.006}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.208_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m119\" intent=\":literal\"><semantics><msub><mn>0.208</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.208_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.135_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m120\" intent=\":literal\"><semantics><msub><mn>0.135</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.135_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"58.98_{\\pm 0.54}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m121\" intent=\":literal\"><semantics><msub><mn>58.98</mn><mrow><mo>&#177;</mo><mn>0.54</mn></mrow></msub><annotation encoding=\"application/x-tex\">58.98_{\\pm 0.54}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"44.85_{\\pm 0.79}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m122\" intent=\":literal\"><semantics><msub><mn>44.85</mn><mrow><mo>&#177;</mo><mn>0.79</mn></mrow></msub><annotation encoding=\"application/x-tex\">44.85_{\\pm 0.79}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"80.81_{\\pm 0.51}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m123\" intent=\":literal\"><semantics><msub><mn>80.81</mn><mrow><mo>&#177;</mo><mn>0.51</mn></mrow></msub><annotation encoding=\"application/x-tex\">80.81_{\\pm 0.51}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.600_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m124\" intent=\":literal\"><semantics><msub><mn>0.600</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.600_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.181_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m125\" intent=\":literal\"><semantics><msub><mn>0.181</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.181_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.177_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m126\" intent=\":literal\"><semantics><msub><mn>0.177</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.177_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.143_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m127\" intent=\":literal\"><semantics><msub><mn>0.143</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.143_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"55.87_{\\pm 0.54}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m128\" intent=\":literal\"><semantics><msub><mn>55.87</mn><mrow><mo>&#177;</mo><mn>0.54</mn></mrow></msub><annotation encoding=\"application/x-tex\">55.87_{\\pm 0.54}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"43.85_{\\pm 0.80}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m129\" intent=\":literal\"><semantics><msub><mn>43.85</mn><mrow><mo>&#177;</mo><mn>0.80</mn></mrow></msub><annotation encoding=\"application/x-tex\">43.85_{\\pm 0.80}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">RAG</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.24_{\\pm 0.39}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m130\" intent=\":literal\"><semantics><msub><mn>87.24</mn><mrow><mo>&#177;</mo><mn>0.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.24_{\\pm 0.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.551_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m131\" intent=\":literal\"><semantics><msub><mn>0.551</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.551_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.078_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m132\" intent=\":literal\"><semantics><msub><mn>0.078</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.078_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.583_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m133\" intent=\":literal\"><semantics><msub><mn>0.583</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.583_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.065_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m134\" intent=\":literal\"><semantics><msub><mn>0.065</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.065_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"77.33_{\\pm 0.55}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m135\" intent=\":literal\"><semantics><msub><mn>77.33</mn><mrow><mo>&#177;</mo><mn>0.55</mn></mrow></msub><annotation encoding=\"application/x-tex\">77.33_{\\pm 0.55}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"60.44_{\\pm 1.15}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m136\" intent=\":literal\"><semantics><msub><mn>60.44</mn><mrow><mo>&#177;</mo><mn>1.15</mn></mrow></msub><annotation encoding=\"application/x-tex\">60.44_{\\pm 1.15}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.38_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m137\" intent=\":literal\"><semantics><msub><mn>87.38</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.38_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.552_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m138\" intent=\":literal\"><semantics><msub><mn>0.552</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.552_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.075_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m139\" intent=\":literal\"><semantics><msub><mn>0.075</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.075_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.600_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m140\" intent=\":literal\"><semantics><msub><mn>0.600</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.600_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.060_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m141\" intent=\":literal\"><semantics><msub><mn>0.060</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.060_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"78.94_{\\pm 0.52}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m142\" intent=\":literal\"><semantics><msub><mn>78.94</mn><mrow><mo>&#177;</mo><mn>0.52</mn></mrow></msub><annotation encoding=\"application/x-tex\">78.94_{\\pm 0.52}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"63.00_{\\pm 1.19}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T6.m143\" intent=\":literal\"><semantics><msub><mn>63.00</mn><mrow><mo>&#177;</mo><mn>1.19</mn></mrow></msub><annotation encoding=\"application/x-tex\">63.00_{\\pm 1.19}</annotation></semantics></math></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "0832±00110832pm",
            "0099±00010099pm",
            "0208±00070208pm",
            "6469±0706469pm",
            "0021±00030021pm",
            "6300±1196300pm",
            "8202±0518202pm",
            "llamaguard8b",
            "8081±0518081pm",
            "0147±00110147pm",
            "0359±00080359pm",
            "0078±00050078pm",
            "0486±00080486pm",
            "augmented",
            "0067±00010067pm",
            "6044±1156044pm",
            "8882±0398882pm",
            "rag",
            "0552±00140552pm",
            "6629±0476629pm",
            "6796±0456796pm",
            "0557±00150557pm",
            "5898±0545898pm",
            "0783±00110783pm",
            "5886±1545886pm",
            "0075±00040075pm",
            "fnr",
            "0046±00040046pm",
            "8710±0408710pm",
            "0782±00070782pm",
            "0752±00120752pm",
            "0127±00040127pm",
            "4596±0824596pm",
            "3374±0493374pm",
            "0511±00140511pm",
            "8428±0478428pm",
            "qwen2572b",
            "8849±0388849pm",
            "0470±00080470pm",
            "6697±0766697pm",
            "llama3170b",
            "8724±0398724pm",
            "0089±00010089pm",
            "4485±0794485pm",
            "example",
            "3339±1623339pm",
            "0581±00140581pm",
            "0021±00020021pm",
            "8595±0508595pm",
            "0501±00090501pm",
            "0192±00120192pm",
            "5587±0545587pm",
            "0152±00110152pm",
            "llama318b",
            "8450±0458450pm",
            "5695±1495695pm",
            "8698±0418698pm",
            "glm49b",
            "4458±0734458pm",
            "0488±00090488pm",
            "importance",
            "5123±1575123pm",
            "0051±00040051pm",
            "0140±00040140pm",
            "7517±0647517pm",
            "0236±00040236pm",
            "0095±00020095pm",
            "0775±00120775pm",
            "0147±00060147pm",
            "0177±00070177pm",
            "prompting",
            "0475±00080475pm",
            "f1f1",
            "0135±00020135pm",
            "7733±0557733pm",
            "0151±00060151pm",
            "6469±0676469pm",
            "setup",
            "6579±0696579pm",
            "0252±00040252pm",
            "8674±0488674pm",
            "0600±00140600pm",
            "0773±00070773pm",
            "0095±00010095pm",
            "sampling",
            "0288±00080288pm",
            "4385±0804385pm",
            "4624±1874624pm",
            "0339±00080339pm",
            "bgem3",
            "8308±0418308pm",
            "selection",
            "retrieval",
            "5139±0805139pm",
            "performance",
            "analyzing",
            "0774±00120774pm",
            "0746±00130746pm",
            "0047±00010047pm",
            "0060±00020060pm",
            "8365±0478365pm",
            "0097±00050097pm",
            "0143±00020143pm",
            "0358±00090358pm",
            "0082±00050082pm",
            "0583±00080583pm",
            "4773±0494773pm",
            "0284±00080284pm",
            "7546±1687546pm",
            "0657±00080657pm",
            "0648±00080648pm",
            "0057±00040057pm",
            "model",
            "0186±00110186pm",
            "4468±1824468pm",
            "8401±0468401pm",
            "0181±00070181pm",
            "0046±00010046pm",
            "multilabel",
            "5279±1565279pm",
            "0698±00140698pm",
            "0023±00030023pm",
            "fewshot",
            "0134±00060134pm",
            "f1μf1mu",
            "7894±0527894pm",
            "4521±0484521pm",
            "8747±0408747pm",
            "6566±0686566pm",
            "0411±00080411pm",
            "prediction",
            "0600±00090600pm",
            "0541±00140541pm",
            "fpr",
            "f1mf1textm",
            "3081±1673081pm",
            "ragbased",
            "0761±00120761pm",
            "7343±1697343pm",
            "8328±0428328pm",
            "comparing",
            "0289±00080289pm",
            "8381±0468381pm",
            "0485±00080485pm",
            "8419±0468419pm",
            "6219±0686219pm",
            "0091±00050091pm",
            "binary",
            "8727±0408727pm",
            "0090±00020090pm",
            "0036±00010036pm",
            "0638±00140638pm",
            "0065±00020065pm",
            "6555±0776555pm",
            "0551±00140551pm",
            "3338±0433338pm",
            "random",
            "0098±00010098pm",
            "7316±1367316pm",
            "7507±1397507pm",
            "8738±0418738pm",
            "0457±00090457pm",
            "7516±0647516pm",
            "6337±0716337pm",
            "0034±00010034pm",
            "4565±0854565pm"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">We evaluate the impact of retrieval-augmented generation (RAG) on few-shot example selection compared to random sampling. Results are presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.T6\" title=\"Table 6 &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>. Overall, RAG consistently enhances bias detection performance.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora used to train general-purpose AI (GPAI) models often contain harmful demographic-targeted social biases, creating a regulatory need for data auditing and developing scalable bias-detection methods. Although prior work has investigated biases in text datasets and related detection methods, these studies remain narrow in scope. They typically focus on a single content type (e.g., hate speech), cover limited demographic axes, overlook biases affecting multiple demographics simultaneously, and analyze limited techniques. Consequently, practitioners lack a holistic understanding of the strengths and limitations of recent large language models (LLMs) for automated and scalable bias detection in datasets. In this study, we present a comprehensive evaluation framework aimed at English texts to assess the ability of LLMs in detecting demographic-targeted social biases. To align with regulatory requirements, we frame bias detection as a multi-label task using a demographic-focused taxonomy. We then conduct a systematic evaluation with models across scales and techniques, including prompting, in-context learning, and fine-tuning. Using twelve datasets spanning diverse content types and demographics, our study demonstrates the promise of fine-tuned smaller models for scalable detection. However, our analyses also expose persistent gaps across demographic axes and multi-demographic targeted biases, underscoring the need for more effective and scalable auditing frameworks.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Detecting demographic-targeted social biases in data has become both a regulatory and technical requirement&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Tabassi, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib51\" title=\"\">2023</a>; European Union, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib14\" title=\"\">2024</a>)</cite>. For example, the EU&#8217;s GPAI Code of Practice highlights the importance of documenting demographic-centric harms in training corpora. Effective data-level mitigation strategies&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gallegos et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib16\" title=\"\">2024</a>)</cite> also depend on reliably identifying biased instances. While prior studies have examined biases in text corpora&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kreutzer et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib29\" title=\"\">2022</a>; Luccioni and Viviano, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib34\" title=\"\">2021</a>; Dodge et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>)</cite>, they typically rely either on small-scale human annotations or on simplistic automated techniques. Manual inspection, however, poses psychological risks&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Steiger et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib49\" title=\"\">2021</a>)</cite>, and despite advances in LLMs, few works offer a comprehensive analysis of the state of the art in social bias detection.</p>\n\n",
                "matched_terms": [
                    "example",
                    "importance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Compared to systematic benchmarks that examine LLMs for biased generation&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>; Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>)</cite>, detailed studies of their potential as tools for detecting social biases in text remain underexplored. Existing work is often limited across one or more dimensions: focusing on narrow demographics&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, restricting attention to a single type of content such as hate&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>)</cite>, analyzing only specific contexts like certain subreddits&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kumar et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib30\" title=\"\">2024</a>)</cite>, or analyzing only few methods such as zero-shot prompting&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>)</cite>. Moreover, most studies overlook biases that target <em class=\"ltx_emph ltx_font_italic\">multiple demographic axes simultaneously</em>, e.g., intersectionality. These gaps motivate a structured and comprehensive study of the current capabilities of recent LLMs in detecting demographic-targeted social biases.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "analyzing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We frame bias detection as a multi-label task and build a detection testbed that supports prompting, in-context learning, and fine-tuning.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Bias in LLMs.</span>\nSeveral works have evaluated biases in LLMs, independently analyzing content types like stereotypes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Nadeem et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib38\" title=\"\">2021</a>; Parrish et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib43\" title=\"\">2022</a>)</cite> and hate/toxic content&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Gehman et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib17\" title=\"\">2020</a>)</cite>. Recently, <cite class=\"ltx_cite ltx_citemacro_citet\">Li et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib31\" title=\"\">2023</a>)</cite> also studied the fairness of ChatGPT in binary decision-making. Several benchmarks also analyzed stereotype and toxic characteristics in generations of recently developed LLMs&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib54\" title=\"\">2023</a>; Sun et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib50\" title=\"\">2024</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "binary",
                    "analyzing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section outlines the practical setup of our evaluation framework for analyzing the ability of LLMs to detect social biases in texts targeting different demographic groups. We first present the demographic-targeted taxonomy that underpins our framework, then describe how we adapt and integrate existing datasets for a holistic evaluation of bias detection. Finally, we detail the testbed we constructed to ensure comprehensive coverage of LLMs and detection methods.</p>\n\n",
                "matched_terms": [
                    "setup",
                    "analyzing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Any text not targeting one or more of these axes is considered &#8220;unbiased&#8221; (<span class=\"ltx_text ltx_font_typewriter\">UNB</span>) <em class=\"ltx_emph ltx_font_italic\">within our taxonomy</em>. Each demographic axis serves as a prediction category, making the detection task twofold: (i) identify whether a text expresses demographic-targeted bias, and (ii) determine which demographics are targeted. Unlike prior benchmarks that treat bias detection as single-label or multi-class classification&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, our formulation supports <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em>, capturing both <span class=\"ltx_text ltx_font_italic\">single-axis</span> (e.g., race only) and <span class=\"ltx_text ltx_font_italic\">multi-axis</span> (e.g., gender+race) biases (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T2\" title=\"Table 2 &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>).</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "prediction"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_citet\">Brown et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib4\" title=\"\">2020</a>)</cite> demonstrated that <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> LLMs can effectively perform a variety of tasks through textual prompting in <em class=\"ltx_emph ltx_font_italic\">zero-shot</em> scenarios. Following&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>; Palla et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib42\" title=\"\">2025</a>)</cite>, our evaluation framework employs <em class=\"ltx_emph ltx_font_italic\">policy-based</em> prompting for bias detection. Specifically, the prompt includes a policy detailing the bias detection task and our demographic-based social bias taxonomy. To enhance the bias detection capabilities within this prompting framework, we also assess the benefits of incorporating <em class=\"ltx_emph ltx_font_italic\">few-shot</em> examples for <em class=\"ltx_emph ltx_font_italic\">in-context learning</em>. Specifically, we utilize the retrieval-augmented (RAG) framework&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib5\" title=\"\">2024a</a>)</cite>, where an embedding model identifies the most <em class=\"ltx_emph ltx_font_italic\">relevant</em> in-context examples for each input instance from the training/development set.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "rag",
                    "model",
                    "fewshot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Models.</span> We consider several <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> models ranging from 8B to 72B parameters, e.g., GLM-4&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(GLM et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib18\" title=\"\">2024</a>)</cite>, Llama-3.1&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Dubey et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib10\" title=\"\">2024</a>)</cite>, and Qwen-2.5&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Yang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib58\" title=\"\">2024</a>)</cite>. We also analyze the guardrail model Llama Guard-3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>)</cite> to explore if such models could directly be applied for general text bias detection. To perform RAG-based in-context sample selection, we use the BGE-M3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib6\" title=\"\">2024b</a>)</cite> model.</p>\n\n",
                "matched_terms": [
                    "model",
                    "bgem3",
                    "ragbased",
                    "selection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We also evaluate the effectiveness of aligning LLMs to the bias detection task through <em class=\"ltx_emph ltx_font_italic\">fine-tuning</em>. The task is framed as <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em> over the nine demographic axes. We solve it through sequence classification by attaching nine classifier nodes to a pre-trained LLM: to the [CLS] token for encoder-only models and to the final output token for decoder-only models.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "prediction"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Because detection must perform reliably <em class=\"ltx_emph ltx_font_italic\">across all demographic axes</em>, our evaluation framework also explores the effectiveness of <em class=\"ltx_emph ltx_font_italic\">data reweighting</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kamiran and Calders, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib25\" title=\"\">2012</a>)</cite> to address imbalances. Let <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> denote the number of samples and <math alttext=\"\\mathcal{M}_{\\phi}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m2\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8499;</mi><mi>&#981;</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{M}_{\\phi}</annotation></semantics></math> the model. For a given instance <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m3\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>, its labels <math alttext=\"Y_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m4\" intent=\":literal\"><semantics><msub><mi>Y</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">Y_{i}</annotation></semantics></math> form a binary vector of length nine, where <math alttext=\"Y_{i}^{m}=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m5\" intent=\":literal\"><semantics><mrow><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">Y_{i}^{m}=1</annotation></semantics></math> if the demographic axis <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m6\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> is targeted and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m7\" intent=\":literal\"><mn>0</mn></math> otherwise. The weighted loss is defined as:</p>\n\n",
                "matched_terms": [
                    "model",
                    "binary"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our comprehensive framework uses metrics capturing three dimensions: (i) distinguishing <em class=\"ltx_emph ltx_font_italic\">biased vs. unbiased</em> text, (ii) accurate <em class=\"ltx_emph ltx_font_italic\">multi-label classification</em> of bias types, and (iii) ensuring <em class=\"ltx_emph ltx_font_italic\">parity</em> in detection performance across demographic axes and for multi-targeted texts compared to single-targeted texts.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Binary bias detection.</span>\nWe reduce the multi-label task to a binary one by defining\nground-truth labels <math alttext=\"Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.SS4.p3.m1\" intent=\":literal\"><semantics><mrow><msub><mi>Y</mi><msub><mi>B</mi><mi>i</mi></msub></msub><mo>=</mo><mn>1</mn><mo>&#8722;</mo><mi>&#120128;</mi><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>0</mn><mo>,</mo><mo>,</mo><mo rspace=\"0.167em\">&#8704;</mo><mi>m</mi><mo>&#8712;</mo><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><mn>9</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]</annotation></semantics></math>, with predictions <math alttext=\"\\hat{Y}_{B_{i}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m2\" intent=\":literal\"><semantics><msub><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><msub><mi>B</mi><mi>i</mi></msub></msub><annotation encoding=\"application/x-tex\">\\hat{Y}_{B_{i}}</annotation></semantics></math> defined analogously. A value of <math alttext=\"1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m3\" intent=\":literal\"><semantics><mn>1</mn><annotation encoding=\"application/x-tex\">1</annotation></semantics></math> indicates the presence of any bias, and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m4\" intent=\":literal\"><mn>0</mn></math> indicates none. On these binary labels, we report <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m5\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, false positive rate (FPR), and false negative rate (FNR).</p>\n\n",
                "matched_terms": [
                    "f1f1",
                    "fnr",
                    "binary",
                    "fpr",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-label bias detection.</span>\nAlongside macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p4.m1\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math> and micro <math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p4.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math> scores, we report two multi-label measures&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sorower, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib48\" title=\"\">2010</a>)</cite>:</p>\n\n",
                "matched_terms": [
                    "f1μf1mu",
                    "f1mf1textm",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Detection disparities.</span>\nOur evaluation also examines whether LLMs not only detect social biases accurately but also exhibit systematic performance gaps across different demographic targets. Given <math alttext=\"\\mathcal{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p5.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><annotation encoding=\"application/x-tex\">\\mathcal{P}</annotation></semantics></math> denotes FPR or FNR, we analyze disparities in the following scenarios:</p>\n\n",
                "matched_terms": [
                    "fnr",
                    "performance",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-demographic.</span> Inspired by&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite>, we measure if the models make systematically more errors in detecting biases that <em class=\"ltx_emph ltx_font_italic\">specifically</em> target <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em> (e.g., {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}) relative to biases that target <span class=\"ltx_text ltx_font_italic\">each constituent axis</span> (e.g., only <span class=\"ltx_text ltx_font_typewriter\">GEN</span> or <span class=\"ltx_text ltx_font_typewriter\">RAC</span>).\n<math alttext=\"\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.I3.i2.p1.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>=</mo><mrow><munder accentunder=\"true\"><mi>max</mi><mrow><mi>x</mi><mo>&#8712;</mo><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></mrow></munder><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msub><mo>&#8722;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mi>x</mi></msub></mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|</annotation></semantics></math>. This measure helps us understand if the FPR or FNR of multi-axis targeted biased instances is markedly higher, indicating potential blind spots for automated bias detection methods.</p>\n\n",
                "matched_terms": [
                    "fnr",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section illustrates how our comprehensive evaluation study enables the practical assessment of LLM-based methods for detecting demographic-targeted social biases in text. Our analysis reveals both the strengths and current limitations of these approaches. For rigorous assessment of the overall results, we perform 1,000 bootstrap samples with replacement on the combined test set to compute 95% confidence intervals. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> presents a detailed comparison of prompting and fine-tuning, reporting both binary performance (biased vs. unbiased) and multi-label categorization. We also report median inference time (in milliseconds) for each text instance. Moreover, for more fine-grained analysis, Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> reports bias detection performance of select prompted and fine-tuned LLMs for the twelve constituent datasets.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "binary",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our detailed results in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> show how bias detection with prompting is <em class=\"ltx_emph ltx_font_italic\">highly sensitive to both in-context learning and model capacity</em>.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">In-context learning substantially improves detection.</span> Across all models, providing few-shot examples consistently boosts binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, lowers FNR, and increases multi-label metrics (MR, HL, <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>). Gains are significant with as few as five examples, while moving from five to ten shots yields only marginal improvements. However, inference time grows with the number of examples, highlighting the accuracy&#8211;efficiency tradeoff in prompting. Beyond the reported results, we also analyzed alternative in-context setups (in the appendix). We found that (i) RAG-based example selection outperforms random sampling, and (ii) alternative embeddings&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Youdao, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib59\" title=\"\">2023</a>)</cite> yield comparable results.</p>\n\n",
                "matched_terms": [
                    "random",
                    "multilabel",
                    "sampling",
                    "prompting",
                    "example",
                    "f1f1",
                    "binary",
                    "fnr",
                    "selection",
                    "fewshot",
                    "f1mf1textm",
                    "ragbased"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Model size and architecture strongly shape results.</span> Larger models (e.g., Llama-70B, Qwen-72B) achieve higher binary and multi-label performance than smaller variants. Within model families, scale matters: Llama-70B outperforms Llama-8B across nearly all metrics. However, size alone is not decisive. GLM-4-9B rivals or surpasses larger Llama and Qwen models on multi-label metrics, and Llama-3.1-70B outperforms Qwen-2.5-72B despite similar scale. Larger models tend to reduce FPR but can increase FNR, reflecting greater sensitivity at the cost of more false negatives. Inference time rises steeply with model scale, from 350ms for 8B models to over 600ms for 70B+ models.</p>\n\n",
                "matched_terms": [
                    "glm49b",
                    "model",
                    "fnr",
                    "binary",
                    "fpr",
                    "qwen2572b",
                    "llama3170b",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Guardrail models transfer poorly.</span> Llama Guard, fine-tuned for moderation, consistently underperforms instruction-tuned models of similar size (e.g., Llama-3.1-8B), achieving the lowest binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> and highest FNR. While effective at detecting overt hate speech, it fails to capture subtler biases like stereotypes.</p>\n\n",
                "matched_terms": [
                    "llama318b",
                    "f1f1",
                    "binary",
                    "fnr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nFrom Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we see the role of scale from the binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. The 70B Llama model outperforms smaller variants across most datasets. Llama-Guard shows lower overall binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, but performs relatively well on hate/toxic content. It specifically achieves the highest score across all models on Toxigen, which is GPT-generated. This finding is consistent with its design as a GPAI guardrail. Multi-label metrics show that even larger models struggle to correctly identify bias types, especially for stereotyped contents, e.g., StereoSet and RedditBias.</p>\n\n",
                "matched_terms": [
                    "model",
                    "f1f1",
                    "binary",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our results in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> show how the performance of fine-tuned LLM-based bias detectors is <em class=\"ltx_emph ltx_font_italic\">shaped by model size, architecture, and optimization strategy</em>.</p>\n\n",
                "matched_terms": [
                    "model",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuning substantially improves detection.</span> Even small models, such as RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>, surpass much larger prompting-only models (Llama-3.1-70B, Qwen-2.5-72B) on binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> (above 90 vs. below 89) and multi-label metrics (MR, HL, micro <math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math> and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m3\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>). Fine-tuned models also achieve lower FNR and higher reliability in detecting biased content. Inference is far faster: RoBERTa completes batches in seconds, whereas prompting with 70B+ LLMs requires hundreds of seconds.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "prompting",
                    "f1f1",
                    "binary",
                    "fnr",
                    "qwen2572b",
                    "llama3170b",
                    "f1mf1textm",
                    "f1μf1mu"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Architecture influences performance.</span> Encoder models (RoBERTa, DeBERTa) consistently outperform decoder models (GPT-2), irrespective of scale. GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span> underperforms on binary and multi-label detection. In contrast, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> and RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> achieve higher detection scores. Inference times also reflect architectural complexity: decoder models remain faster, whereas DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> is particularly slow due to disentangled attention&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(He et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib21\" title=\"\">2020</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "binary",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Loss reweighting has tradeoffs.</span> Reweighted loss consistently improves binary FNR and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p5.m1\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math> (e.g., DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>, RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>) by capturing subtle biases, but can raise FPR, particularly in decoder models. Effects are uneven: DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> shows reduced MR and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p5.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>, suggesting reweighting may destabilize multi-label detection for some scenarios.</p>\n\n",
                "matched_terms": [
                    "fnr",
                    "binary",
                    "fpr",
                    "f1mf1textm",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> shows how fine-tuned models achieve stronger binary detection across most datasets compared to prompting-based LLMs. Encoder models (DeBERTa) generally outperform decoder-only GPT-2, which remains competitive on many datasets but struggles with subtle stereotype cases, e.g, RedditBias and Winogender. For multi-label detection, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> shows consistently lower HL, indicating more accurate detection of demographic axes targeted.</p>\n\n",
                "matched_terms": [
                    "binary",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nFine-tuned encoder models provide the most effective bias detection, outperforming prompting much larger models in both binary detection and identification of the correct bias types. Decoder-based models can perform well but show weaknesses on subtle stereotype datasets. Fine-tuning with reweighted loss improves recall, but may increase false positives, highlighting important tradeoffs that require consideration.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "binary"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use our evaluation framework to examine <em class=\"ltx_emph ltx_font_italic\">potential disparities</em> in social bias detection across models and setups with respect to targeted demographic axes. While the previous analysis provided a global view of model performance, this section focuses on <em class=\"ltx_emph ltx_font_italic\">systematic differences</em> in how effectively models detect biases. We first analyze disparities for individual demographic axes. Next, owing to our multi-label setup, we evaluate model performances on instances targeting <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em>, highlighting current capabilities in detecting multi-targeted biases. We provide the comprehensive disparity analysis in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S5.T5\" title=\"Table 5 &#8227; 5 Evaluating detection disparities &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>.</p>\n\n",
                "matched_terms": [
                    "model",
                    "setup",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Prompting shows large disparities.</span> In zero-shot settings, models exhibit significant disparities. For instance, Llama-3.1-8B and GLM-4-9B exhibit <math alttext=\"\\Delta_{\\text{FNR}}\\approx 0.6\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><mo>&#8776;</mo><mn>0.6</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}\\approx 0.6</annotation></semantics></math>, <math alttext=\"\\Delta_{\\text{FPR}}\\approx 0.42\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><mo>&#8776;</mo><mn>0.42</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}\\approx 0.42</annotation></semantics></math>. Few-shot prompting reduces disparities (e.g., for Llama-3.1-8B, <math alttext=\"\\Delta_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m3\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}</annotation></semantics></math> drops to <math alttext=\"\\approx 0.26\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8776;</mo><mn>0.26</mn></mrow><annotation encoding=\"application/x-tex\">\\approx 0.26</annotation></semantics></math>), but performance remains uneven compared to fine-tuned models. Scaling improves parity: Llama-3.1-70B shows lower disparities than its 8B counterpart, and Qwen-2.5-72B achieves the strongest parity among prompting models, especially with few-shot examples.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "glm49b",
                    "fewshot",
                    "qwen2572b",
                    "llama318b",
                    "llama3170b",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuning yields markedly lower disparities.</span> Encoder models such as RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> and DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> reach <math alttext=\"\\Delta_{\\text{FNR}}\\approx 0.2\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><mo>&#8776;</mo><mn>0.2</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}\\approx 0.2</annotation></semantics></math> and <math alttext=\"\\Delta_{\\text{FPR}}\\approx 0.03\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m2\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><mo>&#8776;</mo><mn>0.03</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}\\approx 0.03</annotation></semantics></math>, particularly with reweighted loss. Reweighting reduces FNR gaps but can slightly increase FPR gaps, indicating a tradeoff. Model architecture also matters: encoder models achieve far lower disparities than decoder-only GPT-2, and scaling further improves parity (e.g., RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> outperforms RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>).</p>\n\n",
                "matched_terms": [
                    "model",
                    "fnr",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nPrompting, even with larger models and few-shot examples, shows substantial per-axis disparities. Fine-tuned models, particularly with reweighted loss, achieve more balanced performance, although notable gaps remain. In additional analyses (in the appendix), we examined <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across the nine demographic axes. We found that certain targets, such as <span class=\"ltx_text ltx_font_typewriter\">NAT</span> and <span class=\"ltx_text ltx_font_typewriter\">PHY</span>, consistently have lower detection accuracy, which contributes to the observed disparities.</p>\n\n",
                "matched_terms": [
                    "f1f1",
                    "prompting",
                    "performance",
                    "fewshot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Prompting improves with scale and few-shot examples.</span> Few-shot prompting substantially narrows multi-axis gaps. For Llama-3.1-70B, <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m1\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}</annotation></semantics></math> drops from 0.736 (zero-shot) to 0.164 (10-shot), and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m2\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}</annotation></semantics></math> from 0.262 to 0.088. Larger models benefit more from in-context learning: Llama-3.1-70B outperforms Llama-3.1-8B, and disparities are generally higher for {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>} than {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}.</p>\n\n",
                "matched_terms": [
                    "llama3170b",
                    "llama318b",
                    "prompting",
                    "fewshot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuned models show persistent gaps.</span> Despite strong per-axis parity, fine-tuned models underperform on multi-axis instances, reflecting <em class=\"ltx_emph ltx_font_italic\">gerrymandering</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite> in their detection performance. For example, RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> with reweighting achieves <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.436</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436</annotation></semantics></math> and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m2\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.373</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373</annotation></semantics></math>, higher than few-shot Llama-3.1-70B and Qwen-2.5-72B. Encoder models outperform GPT-2, and scaling improves parity (e.g., DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> at <math alttext=\"\\approx 0.28\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m3\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8776;</mo><mn>0.28</mn></mrow><annotation encoding=\"application/x-tex\">\\approx 0.28</annotation></semantics></math> vs. DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> at 0.39 for FNR regarding {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>}). As with per-axis results, reweighting reduces FNR gaps but can slightly raise FPR gaps.</p>\n\n",
                "matched_terms": [
                    "example",
                    "fewshot",
                    "fnr",
                    "fpr",
                    "qwen2572b",
                    "llama3170b",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All LLMs are accessed via API through an MLOps platform. We fix <span class=\"ltx_text ltx_font_typewriter\">temperature</span> to 0 and <span class=\"ltx_text ltx_font_typewriter\">top_p</span> to 1, ensuring deterministic outputs by selecting the model&#8217;s most likely generation while still allowing consideration of the full token space. For in-context learning, we embed the training and development sets using BGE-M3 or BCEmbedding models. At inference time, we compute cosine similarity between the query and development set vectors to retrieve the top-<math alttext=\"K\" class=\"ltx_Math\" display=\"inline\" id=\"A2.SS1.p1.m1\" intent=\":literal\"><semantics><mi>K</mi><annotation encoding=\"application/x-tex\">K</annotation></semantics></math> few-shot examples. As a baseline, we also apply a random few-shot selection from the training set, with balanced sampling between biased and unbiased texts. Model predictions are extracted via pattern matching. Responses that cannot be parsed through pattern matching to assign to one of the multiple demographic axes are marked as &#8220;invalid.&#8221; The <span class=\"ltx_text ltx_font_italic\">social bias policy</span> used in the text prompt is shown here.</p>\n\n",
                "matched_terms": [
                    "random",
                    "sampling",
                    "model",
                    "bgem3",
                    "fewshot",
                    "selection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization uses AdamW with linear learning rate decay, weight decay of 0.01, and gradient clipping at 1.0. To address class imbalance, we experiment with reweighted binary cross-entropy loss, where weights are derived from label frequencies in the training set. Models are trained for four epochs without reweighting and six epochs with reweighting. The effective batch size is fixed at 32, with gradient accumulation applied for larger models. Learning rates are <span class=\"ltx_text ltx_font_italic\">tuned by monitoring validation loss</span>. For each model, we use the following learning rates for optimization:</p>\n\n",
                "matched_terms": [
                    "model",
                    "binary"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In binary classification, RAG achieves higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS1.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across all models. Improvements in detection metrics are consistent across model sizes, demonstrating the benefit of providing LLMs with <em class=\"ltx_emph ltx_font_italic\">semantically similar examples</em> during in-context learning. RAG generally reduces False Negative Rates (FNR), though it occasionally causes slight increases in False Positive Rates (FPR), as observed with Llama Guard-3-8B and GLM-4-9B. This tradeoff is typically favorable, since reducing FNR is crucial for minimizing missed detections. Notably, while adding more examples under RAG yields only modest additional gains, increasing the number of randomly selected examples often leads to degraded performance.</p>\n\n",
                "matched_terms": [
                    "glm49b",
                    "model",
                    "rag",
                    "binary",
                    "fnr",
                    "f1f1",
                    "fpr",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For multi-label prediction, RAG delivers even greater improvements over random sampling. As in the binary case, providing more RAG-selected examples enhances performance, whereas adding more random examples consistently worsens detection outcomes. This highlights an important insight: supplying more <em class=\"ltx_emph ltx_font_italic\">relevant</em> examples benefits prompting-based detection, but including <em class=\"ltx_emph ltx_font_italic\">irrelevant</em> examples can be detrimental.</p>\n\n",
                "matched_terms": [
                    "random",
                    "sampling",
                    "prediction",
                    "rag",
                    "binary",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In summary, RAG significantly strengthens in-context learning by providing more meaningful examples, resulting in higher accuracy and improved multi-label predictions. Although small increases in FPR can occur, the overall gains clearly favor RAG over random sampling.</p>\n\n",
                "matched_terms": [
                    "random",
                    "sampling",
                    "rag",
                    "fpr",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We next examine how the choice of embedding model affects in-context learning performance for prompting, comparing BGE-M3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib6\" title=\"\">2024b</a>)</cite> and BCEmbedding&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Youdao, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib59\" title=\"\">2023</a>)</cite> for selecting in-context examples. The results are presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.T7\" title=\"Table 7 &#8227; C.1 Ablation study: in-context learning &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">7</span></a>.</p>\n\n",
                "matched_terms": [
                    "comparing",
                    "prompting",
                    "model",
                    "bgem3",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">BGE-M3 exhibits a slight but consistent advantage in binary bias detection, producing marginally higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across multiple LLMs. However, the overall differences are minimal. In contrast, for multi-label prediction, BCEmbedding performs slightly better on metrics such as MR for many models. This finding suggests that while both embedding models select examples that yield similar overall outcomes, subtle differences exist. Specifically, BGE-M3-selected examples tend to improve binary bias detection by helping models better distinguish biased from unbiased samples, whereas BCEmbedding-selected examples slightly enhance the detection of specific bias types within biased instances.</p>\n\n",
                "matched_terms": [
                    "prediction",
                    "f1f1",
                    "binary",
                    "bgem3",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Overall, both embedding models deliver strong and comparable performance for in-context learning, with only minor trade-offs. Their results indicate that either embedding model is well-suited for bias detection tasks.</p>\n\n",
                "matched_terms": [
                    "model",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We now analyze model performance across different demographic targets. Specifically, we examine the <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p1.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores for all demographic axes in our taxonomy that may be subject to bias. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F5\" title=\"Figure 5 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents results for various prompted models using <em class=\"ltx_emph ltx_font_italic\">10-shot RAG-based in-context learning</em> with BGE-M3, while Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F6\" title=\"Figure 6 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> compares fine-tuned models and explores the impact of reweighted loss (&#8220;bal&#8221; in the figure) across demographics.</p>\n\n",
                "matched_terms": [
                    "model",
                    "f1f1",
                    "bgem3",
                    "ragbased",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our analysis shows that fine-tuned models consistently outperform prompting and transfer learning across all bias classes. The most notable <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> score gains appear in the AGE and SES categories, which are less frequent in the dataset.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "f1f1"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Among the prompted LLMs, Llama-3.1-70B achieves the highest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p3.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across nearly all bias categories, except for <span class=\"ltx_text ltx_font_typewriter\">GEN</span>, where GLM-9B&#8212;despite being much smaller&#8212;slightly outperforms it. Interestingly, Qwen-2.5-72B, though the largest LLM, performs worse in many low-frequency categories such as <span class=\"ltx_text ltx_font_typewriter\">DIS</span>, <span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">SES</span>. It performs comparably to the best prompting models only for <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, which are the most common categories in the benchmark.</p>\n\n",
                "matched_terms": [
                    "qwen2572b",
                    "prompting",
                    "llama3170b",
                    "f1f1"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For fine-tuned models, encoder-only architectures (e.g., RoBERTa and DeBERTa) generally outperform decoder-only language models, i.e., GPT-2, across most demographic axes. The trends mirror those observed in the prompting setup: models achieve their best performance for <span class=\"ltx_text ltx_font_typewriter\">SES</span>, while <span class=\"ltx_text ltx_font_typewriter\">NAT</span> consistently shows the lowest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. Reweighted loss often improves detection performance or yields similar results to the default loss. For example, in <span class=\"ltx_text ltx_font_typewriter\">NAT</span>, the axis that suffered from the weakest detection performance, reweighted loss improves performance across all models. However, improvements are not universal. For instance, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">large</span> experiences slight declines in <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> for some demographics such as <span class=\"ltx_text ltx_font_typewriter\">AGE</span> and <span class=\"ltx_text ltx_font_typewriter\">SES</span> when reweighted loss is applied.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "setup",
                    "example",
                    "f1f1",
                    "performance"
                ]
            }
        ]
    },
    "A3.T7": {
        "caption": "Table 7: Comparing few-shot prompting performance when using different retrieval embedding models BGE-M3 and BCEmbedding (BCEmb.).",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Model</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Setup</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Few-shot</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"3\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Binary Prediction</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><span class=\"ltx_text ltx_font_bold\">Multi-label Prediction</span></th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">FPR</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">FNR</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">MR</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">HL</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m3\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Llama-Guard-8B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">BGE-M3</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.16_{\\pm 0.64}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m4\" intent=\":literal\"><semantics><msub><mn>75.16</mn><mrow><mo>&#177;</mo><mn>0.64</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.16_{\\pm 0.64}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.192_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m5\" intent=\":literal\"><semantics><msub><mn>0.192</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.192_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.358_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m6\" intent=\":literal\"><semantics><msub><mn>0.358</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.358_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.485_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m7\" intent=\":literal\"><semantics><msub><mn>0.485</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.485_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.067_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m8\" intent=\":literal\"><semantics><msub><mn>0.067</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.067_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"65.66_{\\pm 0.68}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m9\" intent=\":literal\"><semantics><msub><mn>65.66</mn><mrow><mo>&#177;</mo><mn>0.68</mn></mrow></msub><annotation encoding=\"application/x-tex\">65.66_{\\pm 0.68}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"46.24_{\\pm 1.87}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m10\" intent=\":literal\"><semantics><msub><mn>46.24</mn><mrow><mo>&#177;</mo><mn>1.87</mn></mrow></msub><annotation encoding=\"application/x-tex\">46.24_{\\pm 1.87}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.17_{\\pm 0.64}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m11\" intent=\":literal\"><semantics><msub><mn>75.17</mn><mrow><mo>&#177;</mo><mn>0.64</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.17_{\\pm 0.64}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.186_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m12\" intent=\":literal\"><semantics><msub><mn>0.186</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.186_{\\pm 0.011}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.359_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m13\" intent=\":literal\"><semantics><msub><mn>0.359</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.359_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.486_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m14\" intent=\":literal\"><semantics><msub><mn>0.486</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.486_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.067_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m15\" intent=\":literal\"><semantics><msub><mn>0.067</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.067_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"65.79_{\\pm 0.69}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m16\" intent=\":literal\"><semantics><msub><mn>65.79</mn><mrow><mo>&#177;</mo><mn>0.69</mn></mrow></msub><annotation encoding=\"application/x-tex\">65.79_{\\pm 0.69}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"44.68_{\\pm 1.82}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m17\" intent=\":literal\"><semantics><msub><mn>44.68</mn><mrow><mo>&#177;</mo><mn>1.82</mn></mrow></msub><annotation encoding=\"application/x-tex\">44.68_{\\pm 1.82}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">BCEmb.</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"73.90_{\\pm 0.66}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m18\" intent=\":literal\"><semantics><msub><mn>73.90</mn><mrow><mo>&#177;</mo><mn>0.66</mn></mrow></msub><annotation encoding=\"application/x-tex\">73.90_{\\pm 0.66}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.196_{\\pm 0.011}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m19\" intent=\":literal\"><semantics><msub><mn>0.196</mn><mrow><mo>&#177;</mo><mn>0.011</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.196_{\\pm 0.011}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.374_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m20\" intent=\":literal\"><semantics><msub><mn>0.374</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.374_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.478_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m21\" intent=\":literal\"><semantics><msub><mn>0.478</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.478_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.067_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m22\" intent=\":literal\"><semantics><msub><mn>0.067</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.067_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"65.32_{\\pm 0.68}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m23\" intent=\":literal\"><semantics><msub><mn>65.32</mn><mrow><mo>&#177;</mo><mn>0.68</mn></mrow></msub><annotation encoding=\"application/x-tex\">65.32_{\\pm 0.68}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"44.21_{\\pm 1.78}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m24\" intent=\":literal\"><semantics><msub><mn>44.21</mn><mrow><mo>&#177;</mo><mn>1.78</mn></mrow></msub><annotation encoding=\"application/x-tex\">44.21_{\\pm 1.78}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"74.07_{\\pm 0.66}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m25\" intent=\":literal\"><semantics><msub><mn>74.07</mn><mrow><mo>&#177;</mo><mn>0.66</mn></mrow></msub><annotation encoding=\"application/x-tex\">74.07_{\\pm 0.66}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.184_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m26\" intent=\":literal\"><semantics><msub><mn>0.184</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.184_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.374_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m27\" intent=\":literal\"><semantics><msub><mn>0.374</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.374_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.482_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m28\" intent=\":literal\"><semantics><msub><mn>0.482</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.482_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.067_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m29\" intent=\":literal\"><semantics><msub><mn>0.067</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.067_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"65.60_{\\pm 0.70}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m30\" intent=\":literal\"><semantics><msub><mn>65.60</mn><mrow><mo>&#177;</mo><mn>0.70</mn></mrow></msub><annotation encoding=\"application/x-tex\">65.60_{\\pm 0.70}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"42.99_{\\pm 1.83}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m31\" intent=\":literal\"><semantics><msub><mn>42.99</mn><mrow><mo>&#177;</mo><mn>1.83</mn></mrow></msub><annotation encoding=\"application/x-tex\">42.99_{\\pm 1.83}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Llama-3.1-8B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">BGE-M3</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.27_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m32\" intent=\":literal\"><semantics><msub><mn>87.27</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.27_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.752_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m33\" intent=\":literal\"><semantics><msub><mn>0.752</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.752_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.023_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m34\" intent=\":literal\"><semantics><msub><mn>0.023</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.023_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.411_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m35\" intent=\":literal\"><semantics><msub><mn>0.411</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.411_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.140_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m36\" intent=\":literal\"><semantics><msub><mn>0.140</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.140_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"62.19_{\\pm 0.68}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m37\" intent=\":literal\"><semantics><msub><mn>62.19</mn><mrow><mo>&#177;</mo><mn>0.68</mn></mrow></msub><annotation encoding=\"application/x-tex\">62.19_{\\pm 0.68}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"44.58_{\\pm 0.73}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m38\" intent=\":literal\"><semantics><msub><mn>44.58</mn><mrow><mo>&#177;</mo><mn>0.73</mn></mrow></msub><annotation encoding=\"application/x-tex\">44.58_{\\pm 0.73}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.47_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m39\" intent=\":literal\"><semantics><msub><mn>87.47</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.47_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.746_{\\pm 0.013}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m40\" intent=\":literal\"><semantics><msub><mn>0.746</mn><mrow><mo>&#177;</mo><mn>0.013</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.746_{\\pm 0.013}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.021_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m41\" intent=\":literal\"><semantics><msub><mn>0.021</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.021_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.501_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m42\" intent=\":literal\"><semantics><msub><mn>0.501</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.501_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.127_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m43\" intent=\":literal\"><semantics><msub><mn>0.127</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.127_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"64.69_{\\pm 0.70}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m44\" intent=\":literal\"><semantics><msub><mn>64.69</mn><mrow><mo>&#177;</mo><mn>0.70</mn></mrow></msub><annotation encoding=\"application/x-tex\">64.69_{\\pm 0.70}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"45.96_{\\pm 0.82}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m45\" intent=\":literal\"><semantics><msub><mn>45.96</mn><mrow><mo>&#177;</mo><mn>0.82</mn></mrow></msub><annotation encoding=\"application/x-tex\">45.96_{\\pm 0.82}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">BCEmb.</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.18_{\\pm 0.38}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m46\" intent=\":literal\"><semantics><msub><mn>87.18</mn><mrow><mo>&#177;</mo><mn>0.38</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.18_{\\pm 0.38}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.750_{\\pm 0.013}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m47\" intent=\":literal\"><semantics><msub><mn>0.750</mn><mrow><mo>&#177;</mo><mn>0.013</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.750_{\\pm 0.013}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.026_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m48\" intent=\":literal\"><semantics><msub><mn>0.026</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.026_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.464_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m49\" intent=\":literal\"><semantics><msub><mn>0.464</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.464_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.125_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m50\" intent=\":literal\"><semantics><msub><mn>0.125</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.125_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"64.84_{\\pm 0.68}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m51\" intent=\":literal\"><semantics><msub><mn>64.84</mn><mrow><mo>&#177;</mo><mn>0.68</mn></mrow></msub><annotation encoding=\"application/x-tex\">64.84_{\\pm 0.68}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"46.36_{\\pm 0.76}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m52\" intent=\":literal\"><semantics><msub><mn>46.36</mn><mrow><mo>&#177;</mo><mn>0.76</mn></mrow></msub><annotation encoding=\"application/x-tex\">46.36_{\\pm 0.76}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.46_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m53\" intent=\":literal\"><semantics><msub><mn>87.46</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.46_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.740_{\\pm 0.013}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m54\" intent=\":literal\"><semantics><msub><mn>0.740</mn><mrow><mo>&#177;</mo><mn>0.013</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.740_{\\pm 0.013}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.023_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m55\" intent=\":literal\"><semantics><msub><mn>0.023</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.023_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.552_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m56\" intent=\":literal\"><semantics><msub><mn>0.552</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.552_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.113_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m57\" intent=\":literal\"><semantics><msub><mn>0.113</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.113_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"67.22_{\\pm 0.72}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m58\" intent=\":literal\"><semantics><msub><mn>67.22</mn><mrow><mo>&#177;</mo><mn>0.72</mn></mrow></msub><annotation encoding=\"application/x-tex\">67.22_{\\pm 0.72}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"47.69_{\\pm 0.85}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m59\" intent=\":literal\"><semantics><msub><mn>47.69</mn><mrow><mo>&#177;</mo><mn>0.85</mn></mrow></msub><annotation encoding=\"application/x-tex\">47.69_{\\pm 0.85}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">GLM-4-9B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">BGE-M3</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.10_{\\pm 0.40}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m60\" intent=\":literal\"><semantics><msub><mn>87.10</mn><mrow><mo>&#177;</mo><mn>0.40</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.10_{\\pm 0.40}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.774_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m61\" intent=\":literal\"><semantics><msub><mn>0.774</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.774_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.021_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m62\" intent=\":literal\"><semantics><msub><mn>0.021</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.021_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.773_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m63\" intent=\":literal\"><semantics><msub><mn>0.773</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.773_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.036_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m64\" intent=\":literal\"><semantics><msub><mn>0.036</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.036_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"85.95_{\\pm 0.50}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m65\" intent=\":literal\"><semantics><msub><mn>85.95</mn><mrow><mo>&#177;</mo><mn>0.50</mn></mrow></msub><annotation encoding=\"application/x-tex\">85.95_{\\pm 0.50}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"73.43_{\\pm 1.69}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m66\" intent=\":literal\"><semantics><msub><mn>73.43</mn><mrow><mo>&#177;</mo><mn>1.69</mn></mrow></msub><annotation encoding=\"application/x-tex\">73.43_{\\pm 1.69}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"86.98_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m67\" intent=\":literal\"><semantics><msub><mn>86.98</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">86.98_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.775_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m68\" intent=\":literal\"><semantics><msub><mn>0.775</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.775_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.023_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m69\" intent=\":literal\"><semantics><msub><mn>0.023</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.023_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.782_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m70\" intent=\":literal\"><semantics><msub><mn>0.782</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.782_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.034_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m71\" intent=\":literal\"><semantics><msub><mn>0.034</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.034_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"86.74_{\\pm 0.48}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m72\" intent=\":literal\"><semantics><msub><mn>86.74</mn><mrow><mo>&#177;</mo><mn>0.48</mn></mrow></msub><annotation encoding=\"application/x-tex\">86.74_{\\pm 0.48}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.46_{\\pm 1.68}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m73\" intent=\":literal\"><semantics><msub><mn>75.46</mn><mrow><mo>&#177;</mo><mn>1.68</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.46_{\\pm 1.68}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">BCEmb.</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"86.79_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m74\" intent=\":literal\"><semantics><msub><mn>86.79</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">86.79_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.783_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m75\" intent=\":literal\"><semantics><msub><mn>0.783</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.783_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.025_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m76\" intent=\":literal\"><semantics><msub><mn>0.025</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.025_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.802_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m77\" intent=\":literal\"><semantics><msub><mn>0.802</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.802_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.032_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m78\" intent=\":literal\"><semantics><msub><mn>0.032</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.032_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.50_{\\pm 0.48}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m79\" intent=\":literal\"><semantics><msub><mn>87.50</mn><mrow><mo>&#177;</mo><mn>0.48</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.50_{\\pm 0.48}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"74.80_{\\pm 1.71}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m80\" intent=\":literal\"><semantics><msub><mn>74.80</mn><mrow><mo>&#177;</mo><mn>1.71</mn></mrow></msub><annotation encoding=\"application/x-tex\">74.80_{\\pm 1.71}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"86.95_{\\pm 0.43}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m81\" intent=\":literal\"><semantics><msub><mn>86.95</mn><mrow><mo>&#177;</mo><mn>0.43</mn></mrow></msub><annotation encoding=\"application/x-tex\">86.95_{\\pm 0.43}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.769_{\\pm 0.012}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m82\" intent=\":literal\"><semantics><msub><mn>0.769</mn><mrow><mo>&#177;</mo><mn>0.012</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.769_{\\pm 0.012}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.025_{\\pm 0.003}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m83\" intent=\":literal\"><semantics><msub><mn>0.025</mn><mrow><mo>&#177;</mo><mn>0.003</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.025_{\\pm 0.003}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.808_{\\pm 0.007}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m84\" intent=\":literal\"><semantics><msub><mn>0.808</mn><mrow><mo>&#177;</mo><mn>0.007</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.808_{\\pm 0.007}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.031_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m85\" intent=\":literal\"><semantics><msub><mn>0.031</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.031_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.90_{\\pm 0.47}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m86\" intent=\":literal\"><semantics><msub><mn>87.90</mn><mrow><mo>&#177;</mo><mn>0.47</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.90_{\\pm 0.47}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.27_{\\pm 1.66}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m87\" intent=\":literal\"><semantics><msub><mn>75.27</mn><mrow><mo>&#177;</mo><mn>1.66</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.27_{\\pm 1.66}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Llama-3.1-70B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">BGE-M3</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"88.49_{\\pm 0.38}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m88\" intent=\":literal\"><semantics><msub><mn>88.49</mn><mrow><mo>&#177;</mo><mn>0.38</mn></mrow></msub><annotation encoding=\"application/x-tex\">88.49_{\\pm 0.38}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.581_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m89\" intent=\":literal\"><semantics><msub><mn>0.581</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.581_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.046_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m90\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.657_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m91\" intent=\":literal\"><semantics><msub><mn>0.657</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.657_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.046_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m92\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.28_{\\pm 0.42}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m93\" intent=\":literal\"><semantics><msub><mn>83.28</mn><mrow><mo>&#177;</mo><mn>0.42</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.28_{\\pm 0.42}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"73.16_{\\pm 1.36}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m94\" intent=\":literal\"><semantics><msub><mn>73.16</mn><mrow><mo>&#177;</mo><mn>1.36</mn></mrow></msub><annotation encoding=\"application/x-tex\">73.16_{\\pm 1.36}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"88.82_{\\pm 0.39}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m95\" intent=\":literal\"><semantics><msub><mn>88.82</mn><mrow><mo>&#177;</mo><mn>0.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">88.82_{\\pm 0.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.557_{\\pm 0.015}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m96\" intent=\":literal\"><semantics><msub><mn>0.557</mn><mrow><mo>&#177;</mo><mn>0.015</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.557_{\\pm 0.015}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.046_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m97\" intent=\":literal\"><semantics><msub><mn>0.046</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.046_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.648_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m98\" intent=\":literal\"><semantics><msub><mn>0.648</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.648_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.047_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m99\" intent=\":literal\"><semantics><msub><mn>0.047</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.047_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"83.08_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m100\" intent=\":literal\"><semantics><msub><mn>83.08</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">83.08_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"75.07_{\\pm 1.39}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m101\" intent=\":literal\"><semantics><msub><mn>75.07</mn><mrow><mo>&#177;</mo><mn>1.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">75.07_{\\pm 1.39}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">BCEmb.</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"88.41_{\\pm 0.39}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m102\" intent=\":literal\"><semantics><msub><mn>88.41</mn><mrow><mo>&#177;</mo><mn>0.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">88.41_{\\pm 0.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.577_{\\pm 0.015}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m103\" intent=\":literal\"><semantics><msub><mn>0.577</mn><mrow><mo>&#177;</mo><mn>0.015</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.577_{\\pm 0.015}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.049_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m104\" intent=\":literal\"><semantics><msub><mn>0.049</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.049_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.692_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m105\" intent=\":literal\"><semantics><msub><mn>0.692</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.692_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.041_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m106\" intent=\":literal\"><semantics><msub><mn>0.041</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.041_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"84.63_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m107\" intent=\":literal\"><semantics><msub><mn>84.63</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">84.63_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"74.11_{\\pm 1.51}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m108\" intent=\":literal\"><semantics><msub><mn>74.11</mn><mrow><mo>&#177;</mo><mn>1.51</mn></mrow></msub><annotation encoding=\"application/x-tex\">74.11_{\\pm 1.51}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"88.75_{\\pm 0.39}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m109\" intent=\":literal\"><semantics><msub><mn>88.75</mn><mrow><mo>&#177;</mo><mn>0.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">88.75_{\\pm 0.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.546_{\\pm 0.015}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m110\" intent=\":literal\"><semantics><msub><mn>0.546</mn><mrow><mo>&#177;</mo><mn>0.015</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.546_{\\pm 0.015}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.051_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m111\" intent=\":literal\"><semantics><msub><mn>0.051</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.051_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.693_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m112\" intent=\":literal\"><semantics><msub><mn>0.693</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.693_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.041_{\\pm 0.001}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m113\" intent=\":literal\"><semantics><msub><mn>0.041</mn><mrow><mo>&#177;</mo><mn>0.001</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.041_{\\pm 0.001}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"84.80_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m114\" intent=\":literal\"><semantics><msub><mn>84.80</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">84.80_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"76.60_{\\pm 1.61}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m115\" intent=\":literal\"><semantics><msub><mn>76.60</mn><mrow><mo>&#177;</mo><mn>1.61</mn></mrow></msub><annotation encoding=\"application/x-tex\">76.60_{\\pm 1.61}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"4\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">Qwen-2.5-72B</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">BGE-M3</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.24_{\\pm 0.39}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m116\" intent=\":literal\"><semantics><msub><mn>87.24</mn><mrow><mo>&#177;</mo><mn>0.39</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.24_{\\pm 0.39}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.551_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m117\" intent=\":literal\"><semantics><msub><mn>0.551</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.551_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.078_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m118\" intent=\":literal\"><semantics><msub><mn>0.078</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.078_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.583_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m119\" intent=\":literal\"><semantics><msub><mn>0.583</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.583_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.065_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m120\" intent=\":literal\"><semantics><msub><mn>0.065</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.065_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"77.33_{\\pm 0.55}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m121\" intent=\":literal\"><semantics><msub><mn>77.33</mn><mrow><mo>&#177;</mo><mn>0.55</mn></mrow></msub><annotation encoding=\"application/x-tex\">77.33_{\\pm 0.55}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"60.44_{\\pm 1.15}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m122\" intent=\":literal\"><semantics><msub><mn>60.44</mn><mrow><mo>&#177;</mo><mn>1.15</mn></mrow></msub><annotation encoding=\"application/x-tex\">60.44_{\\pm 1.15}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.38_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m123\" intent=\":literal\"><semantics><msub><mn>87.38</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.38_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.552_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m124\" intent=\":literal\"><semantics><msub><mn>0.552</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.552_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.075_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m125\" intent=\":literal\"><semantics><msub><mn>0.075</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.075_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.600_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m126\" intent=\":literal\"><semantics><msub><mn>0.600</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.600_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.060_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m127\" intent=\":literal\"><semantics><msub><mn>0.060</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.060_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"78.94_{\\pm 0.52}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m128\" intent=\":literal\"><semantics><msub><mn>78.94</mn><mrow><mo>&#177;</mo><mn>0.52</mn></mrow></msub><annotation encoding=\"application/x-tex\">78.94_{\\pm 0.52}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"63.00_{\\pm 1.19}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m129\" intent=\":literal\"><semantics><msub><mn>63.00</mn><mrow><mo>&#177;</mo><mn>1.19</mn></mrow></msub><annotation encoding=\"application/x-tex\">63.00_{\\pm 1.19}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">BCEmb.</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">5</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"86.76_{\\pm 0.44}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m130\" intent=\":literal\"><semantics><msub><mn>86.76</mn><mrow><mo>&#177;</mo><mn>0.44</mn></mrow></msub><annotation encoding=\"application/x-tex\">86.76_{\\pm 0.44}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.565_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m131\" intent=\":literal\"><semantics><msub><mn>0.565</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.565_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.083_{\\pm 0.005}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m132\" intent=\":literal\"><semantics><msub><mn>0.083</mn><mrow><mo>&#177;</mo><mn>0.005</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.083_{\\pm 0.005}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.617_{\\pm 0.009}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m133\" intent=\":literal\"><semantics><msub><mn>0.617</mn><mrow><mo>&#177;</mo><mn>0.009</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.617_{\\pm 0.009}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.060_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m134\" intent=\":literal\"><semantics><msub><mn>0.060</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.060_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"78.54_{\\pm 0.56}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m135\" intent=\":literal\"><semantics><msub><mn>78.54</mn><mrow><mo>&#177;</mo><mn>0.56</mn></mrow></msub><annotation encoding=\"application/x-tex\">78.54_{\\pm 0.56}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"60.96_{\\pm 1.22}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m136\" intent=\":literal\"><semantics><msub><mn>60.96</mn><mrow><mo>&#177;</mo><mn>1.22</mn></mrow></msub><annotation encoding=\"application/x-tex\">60.96_{\\pm 1.22}</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\">10</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"87.25_{\\pm 0.41}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m137\" intent=\":literal\"><semantics><msub><mn>87.25</mn><mrow><mo>&#177;</mo><mn>0.41</mn></mrow></msub><annotation encoding=\"application/x-tex\">87.25_{\\pm 0.41}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.557_{\\pm 0.014}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m138\" intent=\":literal\"><semantics><msub><mn>0.557</mn><mrow><mo>&#177;</mo><mn>0.014</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.557_{\\pm 0.014}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.076_{\\pm 0.004}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m139\" intent=\":literal\"><semantics><msub><mn>0.076</mn><mrow><mo>&#177;</mo><mn>0.004</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.076_{\\pm 0.004}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.638_{\\pm 0.008}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m140\" intent=\":literal\"><semantics><msub><mn>0.638</mn><mrow><mo>&#177;</mo><mn>0.008</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.638_{\\pm 0.008}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"0.054_{\\pm 0.002}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m141\" intent=\":literal\"><semantics><msub><mn>0.054</mn><mrow><mo>&#177;</mo><mn>0.002</mn></mrow></msub><annotation encoding=\"application/x-tex\">0.054_{\\pm 0.002}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"80.42_{\\pm 0.52}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m142\" intent=\":literal\"><semantics><msub><mn>80.42</mn><mrow><mo>&#177;</mo><mn>0.52</mn></mrow></msub><annotation encoding=\"application/x-tex\">80.42_{\\pm 0.52}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\" style=\"padding-top:0.25pt;padding-bottom:0.25pt;\"><math alttext=\"64.07_{\\pm 1.29}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.T7.m143\" intent=\":literal\"><semantics><msub><mn>64.07</mn><mrow><mo>&#177;</mo><mn>1.29</mn></mrow></msub><annotation encoding=\"application/x-tex\">64.07_{\\pm 1.29}</annotation></semantics></math></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "6469±0706469pm",
            "0021±00030021pm",
            "0693±00080693pm",
            "6300±1196300pm",
            "llamaguard8b",
            "0808±00070808pm",
            "0359±00080359pm",
            "0078±00050078pm",
            "4636±0764636pm",
            "0486±00080486pm",
            "0067±00010067pm",
            "6044±1156044pm",
            "8882±0398882pm",
            "8679±0418679pm",
            "0464±00080464pm",
            "8746±0418746pm",
            "0552±00140552pm",
            "0750±00130750pm",
            "0802±00070802pm",
            "0557±00150557pm",
            "0075±00040075pm",
            "fnr",
            "0046±00040046pm",
            "8710±0408710pm",
            "0782±00070782pm",
            "0374±00090374pm",
            "0752±00120752pm",
            "0127±00040127pm",
            "4596±0824596pm",
            "4299±1834299pm",
            "7854±0567854pm",
            "7660±1617660pm",
            "qwen2572b",
            "8849±0388849pm",
            "8750±0488750pm",
            "llama3170b",
            "8724±0398724pm",
            "embedding",
            "8480±0418480pm",
            "0478±00080478pm",
            "0184±00120184pm",
            "4769±0854769pm",
            "0581±00140581pm",
            "0021±00020021pm",
            "8595±0508595pm",
            "0196±00110196pm",
            "0501±00090501pm",
            "0041±00010041pm",
            "0740±00130740pm",
            "0783±00120783pm",
            "0192±00120192pm",
            "7527±1667527pm",
            "llama318b",
            "8698±0418698pm",
            "0025±00030025pm",
            "6532±0686532pm",
            "0577±00150577pm",
            "0565±00140565pm",
            "0482±00080482pm",
            "glm49b",
            "0054±00020054pm",
            "6560±0706560pm",
            "4458±0734458pm",
            "0051±00040051pm",
            "0552±00080552pm",
            "7390±0667390pm",
            "0140±00040140pm",
            "7517±0647517pm",
            "0775±00120775pm",
            "0692±00080692pm",
            "prompting",
            "f1f1",
            "7733±0557733pm",
            "models",
            "7411±1517411pm",
            "setup",
            "0125±00040125pm",
            "0032±00010032pm",
            "when",
            "0638±00080638pm",
            "6579±0696579pm",
            "8674±0488674pm",
            "0026±00030026pm",
            "0773±00070773pm",
            "4624±1874624pm",
            "bgem3",
            "0557±00140557pm",
            "8308±0418308pm",
            "retrieval",
            "8725±0418725pm",
            "performance",
            "8875±0398875pm",
            "0774±00120774pm",
            "0746±00130746pm",
            "0047±00010047pm",
            "0060±00020060pm",
            "8841±0398841pm",
            "8695±0438695pm",
            "0546±00150546pm",
            "0358±00090358pm",
            "0583±00080583pm",
            "0083±00050083pm",
            "7546±1687546pm",
            "0657±00080657pm",
            "0648±00080648pm",
            "model",
            "0186±00110186pm",
            "4468±1824468pm",
            "0046±00010046pm",
            "8790±0478790pm",
            "6096±1226096pm",
            "0031±00010031pm",
            "different",
            "multilabel",
            "8042±0528042pm",
            "0023±00030023pm",
            "fewshot",
            "f1μf1mu",
            "7894±0527894pm",
            "6407±1296407pm",
            "8747±0408747pm",
            "6566±0686566pm",
            "0411±00080411pm",
            "0374±00080374pm",
            "prediction",
            "0600±00090600pm",
            "0769±00120769pm",
            "0049±00040049pm",
            "fpr",
            "8463±0418463pm",
            "bcembedding",
            "f1mf1textm",
            "4421±1784421pm",
            "6484±0686484pm",
            "7343±1697343pm",
            "8328±0428328pm",
            "7407±0667407pm",
            "comparing",
            "bcemb",
            "8718±0388718pm",
            "0617±00090617pm",
            "0485±00080485pm",
            "6219±0686219pm",
            "0113±00040113pm",
            "binary",
            "8727±0408727pm",
            "0065±00020065pm",
            "0036±00010036pm",
            "0076±00040076pm",
            "7480±1717480pm",
            "0551±00140551pm",
            "7316±1367316pm",
            "7507±1397507pm",
            "6722±0726722pm",
            "8738±0418738pm",
            "7516±0647516pm",
            "0034±00010034pm",
            "8676±0448676pm"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">We next examine how the choice of embedding model affects in-context learning performance for prompting, comparing BGE-M3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib6\" title=\"\">2024b</a>)</cite> and BCEmbedding&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Youdao, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib59\" title=\"\">2023</a>)</cite> for selecting in-context examples. The results are presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.T7\" title=\"Table 7 &#8227; C.1 Ablation study: in-context learning &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">7</span></a>.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora used to train general-purpose AI (GPAI) models often contain harmful demographic-targeted social biases, creating a regulatory need for data auditing and developing scalable bias-detection methods. Although prior work has investigated biases in text datasets and related detection methods, these studies remain narrow in scope. They typically focus on a single content type (e.g., hate speech), cover limited demographic axes, overlook biases affecting multiple demographics simultaneously, and analyze limited techniques. Consequently, practitioners lack a holistic understanding of the strengths and limitations of recent large language models (LLMs) for automated and scalable bias detection in datasets. In this study, we present a comprehensive evaluation framework aimed at English texts to assess the ability of LLMs in detecting demographic-targeted social biases. To align with regulatory requirements, we frame bias detection as a multi-label task using a demographic-focused taxonomy. We then conduct a systematic evaluation with models across scales and techniques, including prompting, in-context learning, and fine-tuning. Using twelve datasets spanning diverse content types and demographics, our study demonstrates the promise of fine-tuned smaller models for scalable detection. However, our analyses also expose persistent gaps across demographic axes and multi-demographic targeted biases, underscoring the need for more effective and scalable auditing frameworks.</p>\n\n",
                "matched_terms": [
                    "models",
                    "prompting",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Large-scale web-scraped text corpora have significantly driven recent advances in general-purpose AI (GPAI) models. These corpora, however, are often minimally curated and can contain harmful social biases, e.g., hateful, toxic, or stereotypical content <span class=\"ltx_text ltx_font_italic\">targeting various demographic axes</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Navigli et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib40\" title=\"\">2023</a>)</cite>. Consequently, training on such content can lead to unsafe model outputs and real-world harms&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Dodge et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib9\" title=\"\">2021</a>; Vashney, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib52\" title=\"\">2022</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We frame bias detection as a multi-label task and build a detection testbed that supports prompting, in-context learning, and fine-tuning.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section outlines the practical setup of our evaluation framework for analyzing the ability of LLMs to detect social biases in texts targeting different demographic groups. We first present the demographic-targeted taxonomy that underpins our framework, then describe how we adapt and integrate existing datasets for a holistic evaluation of bias detection. Finally, we detail the testbed we constructed to ensure comprehensive coverage of LLMs and detection methods.</p>\n\n",
                "matched_terms": [
                    "different",
                    "setup"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Any text not targeting one or more of these axes is considered &#8220;unbiased&#8221; (<span class=\"ltx_text ltx_font_typewriter\">UNB</span>) <em class=\"ltx_emph ltx_font_italic\">within our taxonomy</em>. Each demographic axis serves as a prediction category, making the detection task twofold: (i) identify whether a text expresses demographic-targeted bias, and (ii) determine which demographics are targeted. Unlike prior benchmarks that treat bias detection as single-label or multi-class classification&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Mathew et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib37\" title=\"\">2021</a>; Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib55\" title=\"\">2024</a>)</cite>, our formulation supports <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em>, capturing both <span class=\"ltx_text ltx_font_italic\">single-axis</span> (e.g., race only) and <span class=\"ltx_text ltx_font_italic\">multi-axis</span> (e.g., gender+race) biases (Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T2\" title=\"Table 2 &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>).</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "prediction"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><cite class=\"ltx_cite ltx_citemacro_citet\">Brown et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib4\" title=\"\">2020</a>)</cite> demonstrated that <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> LLMs can effectively perform a variety of tasks through textual prompting in <em class=\"ltx_emph ltx_font_italic\">zero-shot</em> scenarios. Following&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>; Palla et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib42\" title=\"\">2025</a>)</cite>, our evaluation framework employs <em class=\"ltx_emph ltx_font_italic\">policy-based</em> prompting for bias detection. Specifically, the prompt includes a policy detailing the bias detection task and our demographic-based social bias taxonomy. To enhance the bias detection capabilities within this prompting framework, we also assess the benefits of incorporating <em class=\"ltx_emph ltx_font_italic\">few-shot</em> examples for <em class=\"ltx_emph ltx_font_italic\">in-context learning</em>. Specifically, we utilize the retrieval-augmented (RAG) framework&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib5\" title=\"\">2024a</a>)</cite>, where an embedding model identifies the most <em class=\"ltx_emph ltx_font_italic\">relevant</em> in-context examples for each input instance from the training/development set.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "embedding",
                    "model",
                    "fewshot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Models.</span> We consider several <span class=\"ltx_text ltx_font_italic\">instruction-tuned</span> models ranging from 8B to 72B parameters, e.g., GLM-4&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(GLM et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib18\" title=\"\">2024</a>)</cite>, Llama-3.1&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Dubey et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib10\" title=\"\">2024</a>)</cite>, and Qwen-2.5&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Yang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib58\" title=\"\">2024</a>)</cite>. We also analyze the guardrail model Llama Guard-3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Inan et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib24\" title=\"\">2023</a>)</cite> to explore if such models could directly be applied for general text bias detection. To perform RAG-based in-context sample selection, we use the BGE-M3&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib6\" title=\"\">2024b</a>)</cite> model.</p>\n\n",
                "matched_terms": [
                    "model",
                    "models",
                    "bgem3"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We also evaluate the effectiveness of aligning LLMs to the bias detection task through <em class=\"ltx_emph ltx_font_italic\">fine-tuning</em>. The task is framed as <em class=\"ltx_emph ltx_font_italic\">multi-label prediction</em> over the nine demographic axes. We solve it through sequence classification by attaching nine classifier nodes to a pre-trained LLM: to the [CLS] token for encoder-only models and to the final output token for decoder-only models.</p>\n\n",
                "matched_terms": [
                    "models",
                    "multilabel",
                    "prediction"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Because detection must perform reliably <em class=\"ltx_emph ltx_font_italic\">across all demographic axes</em>, our evaluation framework also explores the effectiveness of <em class=\"ltx_emph ltx_font_italic\">data reweighting</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kamiran and Calders, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib25\" title=\"\">2012</a>)</cite> to address imbalances. Let <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math> denote the number of samples and <math alttext=\"\\mathcal{M}_{\\phi}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m2\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8499;</mi><mi>&#981;</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{M}_{\\phi}</annotation></semantics></math> the model. For a given instance <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m3\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>, its labels <math alttext=\"Y_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m4\" intent=\":literal\"><semantics><msub><mi>Y</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">Y_{i}</annotation></semantics></math> form a binary vector of length nine, where <math alttext=\"Y_{i}^{m}=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m5\" intent=\":literal\"><semantics><mrow><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">Y_{i}^{m}=1</annotation></semantics></math> if the demographic axis <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m6\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> is targeted and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS2.p2.m7\" intent=\":literal\"><mn>0</mn></math> otherwise. The weighted loss is defined as:</p>\n\n",
                "matched_terms": [
                    "model",
                    "binary"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Models.</span>\nFor encoder models, we consider RoBERTa&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib33\" title=\"\">2019</a>)</cite> and DeBERTa&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(He et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib21\" title=\"\">2020</a>)</cite> and for decoder-only models we consider GPT-2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Radford et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib44\" title=\"\">2019</a>)</cite>. For each model, we consider various parameter scales where, across models, the parameters range from 125M to 1.5B.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our comprehensive framework uses metrics capturing three dimensions: (i) distinguishing <em class=\"ltx_emph ltx_font_italic\">biased vs. unbiased</em> text, (ii) accurate <em class=\"ltx_emph ltx_font_italic\">multi-label classification</em> of bias types, and (iii) ensuring <em class=\"ltx_emph ltx_font_italic\">parity</em> in detection performance across demographic axes and for multi-targeted texts compared to single-targeted texts.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Binary bias detection.</span>\nWe reduce the multi-label task to a binary one by defining\nground-truth labels <math alttext=\"Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S3.SS4.p3.m1\" intent=\":literal\"><semantics><mrow><msub><mi>Y</mi><msub><mi>B</mi><mi>i</mi></msub></msub><mo>=</mo><mn>1</mn><mo>&#8722;</mo><mi>&#120128;</mi><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>Y</mi><mi>i</mi><mi>m</mi></msubsup><mo>=</mo><mn>0</mn><mo>,</mo><mo>,</mo><mo rspace=\"0.167em\">&#8704;</mo><mi>m</mi><mo>&#8712;</mo><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><mn>9</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">Y_{B_{i}}=1-\\mathbb{I}[Y_{i}^{m}=0,,\\forall m\\in{1,\\dots,9}]</annotation></semantics></math>, with predictions <math alttext=\"\\hat{Y}_{B_{i}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m2\" intent=\":literal\"><semantics><msub><mover accent=\"true\"><mi>Y</mi><mo>^</mo></mover><msub><mi>B</mi><mi>i</mi></msub></msub><annotation encoding=\"application/x-tex\">\\hat{Y}_{B_{i}}</annotation></semantics></math> defined analogously. A value of <math alttext=\"1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m3\" intent=\":literal\"><semantics><mn>1</mn><annotation encoding=\"application/x-tex\">1</annotation></semantics></math> indicates the presence of any bias, and <math alttext=\"0\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m4\" intent=\":literal\"><mn>0</mn></math> indicates none. On these binary labels, we report <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m5\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, false positive rate (FPR), and false negative rate (FNR).</p>\n\n",
                "matched_terms": [
                    "f1f1",
                    "fnr",
                    "binary",
                    "fpr",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-label bias detection.</span>\nAlongside macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p4.m1\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math> and micro <math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p4.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math> scores, we report two multi-label measures&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Sorower, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib48\" title=\"\">2010</a>)</cite>:</p>\n\n",
                "matched_terms": [
                    "f1μf1mu",
                    "f1mf1textm",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Detection disparities.</span>\nOur evaluation also examines whether LLMs not only detect social biases accurately but also exhibit systematic performance gaps across different demographic targets. Given <math alttext=\"\\mathcal{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p5.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><annotation encoding=\"application/x-tex\">\\mathcal{P}</annotation></semantics></math> denotes FPR or FNR, we analyze disparities in the following scenarios:</p>\n\n",
                "matched_terms": [
                    "different",
                    "fnr",
                    "performance",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Multi-demographic.</span> Inspired by&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite>, we measure if the models make systematically more errors in detecting biases that <em class=\"ltx_emph ltx_font_italic\">specifically</em> target <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em> (e.g., {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}) relative to biases that target <span class=\"ltx_text ltx_font_italic\">each constituent axis</span> (e.g., only <span class=\"ltx_text ltx_font_typewriter\">GEN</span> or <span class=\"ltx_text ltx_font_typewriter\">RAC</span>).\n<math alttext=\"\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|\" class=\"ltx_Math\" display=\"inline\" id=\"S3.I3.i2.p1.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>=</mo><mrow><munder accentunder=\"true\"><mi>max</mi><mrow><mi>x</mi><mo>&#8712;</mo><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></mrow></munder><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mrow><mo stretchy=\"false\">{</mo><mi>m</mi><mo>,</mo><msup><mi>m</mi><mo>&#8242;</mo></msup><mo stretchy=\"false\">}</mo></mrow></msub><mo>&#8722;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mi>x</mi></msub></mrow><mo maxsize=\"1.200em\" minsize=\"1.200em\" stretchy=\"true\">|</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{m,m^{\\prime}\\}}_{\\mathcal{P}}=\\underset{x\\in\\{m,m^{\\prime}\\}}{\\operatorname{max}}\\big|\\mathcal{P}_{\\{m,m^{\\prime}\\}}-\\mathcal{P}_{x}\\big|</annotation></semantics></math>. This measure helps us understand if the FPR or FNR of multi-axis targeted biased instances is markedly higher, indicating potential blind spots for automated bias detection methods.</p>\n\n",
                "matched_terms": [
                    "models",
                    "fnr",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section illustrates how our comprehensive evaluation study enables the practical assessment of LLM-based methods for detecting demographic-targeted social biases in text. Our analysis reveals both the strengths and current limitations of these approaches. For rigorous assessment of the overall results, we perform 1,000 bootstrap samples with replacement on the combined test set to compute 95% confidence intervals. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> presents a detailed comparison of prompting and fine-tuning, reporting both binary performance (biased vs. unbiased) and multi-label categorization. We also report median inference time (in milliseconds) for each text instance. Moreover, for more fine-grained analysis, Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> reports bias detection performance of select prompted and fine-tuned LLMs for the twelve constituent datasets.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "binary",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our detailed results in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> show how bias detection with prompting is <em class=\"ltx_emph ltx_font_italic\">highly sensitive to both in-context learning and model capacity</em>.</p>\n\n",
                "matched_terms": [
                    "prompting",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">In-context learning substantially improves detection.</span> Across all models, providing few-shot examples consistently boosts binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, lowers FNR, and increases multi-label metrics (MR, HL, <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>). Gains are significant with as few as five examples, while moving from five to ten shots yields only marginal improvements. However, inference time grows with the number of examples, highlighting the accuracy&#8211;efficiency tradeoff in prompting. Beyond the reported results, we also analyzed alternative in-context setups (in the appendix). We found that (i) RAG-based example selection outperforms random sampling, and (ii) alternative embeddings&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Youdao, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib59\" title=\"\">2023</a>)</cite> yield comparable results.</p>\n\n",
                "matched_terms": [
                    "models",
                    "prompting",
                    "f1f1",
                    "fnr",
                    "binary",
                    "fewshot",
                    "f1mf1textm",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Model size and architecture strongly shape results.</span> Larger models (e.g., Llama-70B, Qwen-72B) achieve higher binary and multi-label performance than smaller variants. Within model families, scale matters: Llama-70B outperforms Llama-8B across nearly all metrics. However, size alone is not decisive. GLM-4-9B rivals or surpasses larger Llama and Qwen models on multi-label metrics, and Llama-3.1-70B outperforms Qwen-2.5-72B despite similar scale. Larger models tend to reduce FPR but can increase FNR, reflecting greater sensitivity at the cost of more false negatives. Inference time rises steeply with model scale, from 350ms for 8B models to over 600ms for 70B+ models.</p>\n\n",
                "matched_terms": [
                    "models",
                    "glm49b",
                    "model",
                    "binary",
                    "fnr",
                    "fpr",
                    "qwen2572b",
                    "llama3170b",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Guardrail models transfer poorly.</span> Llama Guard, fine-tuned for moderation, consistently underperforms instruction-tuned models of similar size (e.g., Llama-3.1-8B), achieving the lowest binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> and highest FNR. While effective at detecting overt hate speech, it fails to capture subtler biases like stereotypes.</p>\n\n",
                "matched_terms": [
                    "models",
                    "f1f1",
                    "binary",
                    "fnr",
                    "llama318b"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nFrom Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, we see the role of scale from the binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. The 70B Llama model outperforms smaller variants across most datasets. Llama-Guard shows lower overall binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p5.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math>, but performs relatively well on hate/toxic content. It specifically achieves the highest score across all models on Toxigen, which is GPT-generated. This finding is consistent with its design as a GPAI guardrail. Multi-label metrics show that even larger models struggle to correctly identify bias types, especially for stereotyped contents, e.g., StereoSet and RedditBias.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model",
                    "f1f1",
                    "binary",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our results in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S3.T3\" title=\"Table 3 &#8227; 3.4 Evaluation metrics &#8227; 3 Framework setup &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> show how the performance of fine-tuned LLM-based bias detectors is <em class=\"ltx_emph ltx_font_italic\">shaped by model size, architecture, and optimization strategy</em>.</p>\n\n",
                "matched_terms": [
                    "model",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuning substantially improves detection.</span> Even small models, such as RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>, surpass much larger prompting-only models (Llama-3.1-70B, Qwen-2.5-72B) on binary <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> (above 90 vs. below 89) and multi-label metrics (MR, HL, micro <math alttext=\"F_{1}^{\\mu}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mi>&#956;</mi></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\mu}</annotation></semantics></math> and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m3\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>). Fine-tuned models also achieve lower FNR and higher reliability in detecting biased content. Inference is far faster: RoBERTa completes batches in seconds, whereas prompting with 70B+ LLMs requires hundreds of seconds.</p>\n\n",
                "matched_terms": [
                    "models",
                    "multilabel",
                    "prompting",
                    "f1f1",
                    "binary",
                    "fnr",
                    "qwen2572b",
                    "llama3170b",
                    "f1mf1textm",
                    "f1μf1mu"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Architecture influences performance.</span> Encoder models (RoBERTa, DeBERTa) consistently outperform decoder models (GPT-2), irrespective of scale. GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span> underperforms on binary and multi-label detection. In contrast, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> and RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> achieve higher detection scores. Inference times also reflect architectural complexity: decoder models remain faster, whereas DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> is particularly slow due to disentangled attention&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(He et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib21\" title=\"\">2020</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "models",
                    "binary",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Scaling improves detection.</span> Within encoder families, larger variants (RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">XL</span>) achieve better detection results. Importantly, despite being the newer variant, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> performs slightly worse than the larger but older DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>. GPT-2 shows similar scaling trends within decoder models. Inference time increases with model size, reinforcing the tradeoff between accuracy and efficiency.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Loss reweighting has tradeoffs.</span> Reweighted loss consistently improves binary FNR and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p5.m1\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math> (e.g., DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span>, RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span>, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">XL</span>) by capturing subtle biases, but can raise FPR, particularly in decoder models. Effects are uneven: DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> shows reduced MR and macro <math alttext=\"F_{1}^{\\text{M}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p5.m2\" intent=\":literal\"><semantics><msubsup><mi>F</mi><mn>1</mn><mtext>M</mtext></msubsup><annotation encoding=\"application/x-tex\">F_{1}^{\\text{M}}</annotation></semantics></math>, suggesting reweighting may destabilize multi-label detection for some scenarios.</p>\n\n",
                "matched_terms": [
                    "models",
                    "fnr",
                    "binary",
                    "fpr",
                    "f1mf1textm",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Per-dataset analysis.</span>\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S4.T4\" title=\"Table 4 &#8227; 4.1 Prompting methods &#8227; 4 Evaluating social bias detection &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> shows how fine-tuned models achieve stronger binary detection across most datasets compared to prompting-based LLMs. Encoder models (DeBERTa) generally outperform decoder-only GPT-2, which remains competitive on many datasets but struggles with subtle stereotype cases, e.g, RedditBias and Winogender. For multi-label detection, DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> shows consistently lower HL, indicating more accurate detection of demographic axes targeted.</p>\n\n",
                "matched_terms": [
                    "models",
                    "binary",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nFine-tuned encoder models provide the most effective bias detection, outperforming prompting much larger models in both binary detection and identification of the correct bias types. Decoder-based models can perform well but show weaknesses on subtle stereotype datasets. Fine-tuning with reweighted loss improves recall, but may increase false positives, highlighting important tradeoffs that require consideration.</p>\n\n",
                "matched_terms": [
                    "models",
                    "prompting",
                    "binary"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use our evaluation framework to examine <em class=\"ltx_emph ltx_font_italic\">potential disparities</em> in social bias detection across models and setups with respect to targeted demographic axes. While the previous analysis provided a global view of model performance, this section focuses on <em class=\"ltx_emph ltx_font_italic\">systematic differences</em> in how effectively models detect biases. We first analyze disparities for individual demographic axes. Next, owing to our multi-label setup, we evaluate model performances on instances targeting <em class=\"ltx_emph ltx_font_italic\">multiple axes simultaneously</em>, highlighting current capabilities in detecting multi-targeted biases. We provide the comprehensive disparity analysis in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#S5.T5\" title=\"Table 5 &#8227; 5 Evaluating detection disparities &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model",
                    "setup",
                    "multilabel",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Prompting shows large disparities.</span> In zero-shot settings, models exhibit significant disparities. For instance, Llama-3.1-8B and GLM-4-9B exhibit <math alttext=\"\\Delta_{\\text{FNR}}\\approx 0.6\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><mo>&#8776;</mo><mn>0.6</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}\\approx 0.6</annotation></semantics></math>, <math alttext=\"\\Delta_{\\text{FPR}}\\approx 0.42\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><mo>&#8776;</mo><mn>0.42</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}\\approx 0.42</annotation></semantics></math>. Few-shot prompting reduces disparities (e.g., for Llama-3.1-8B, <math alttext=\"\\Delta_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m3\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}</annotation></semantics></math> drops to <math alttext=\"\\approx 0.26\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8776;</mo><mn>0.26</mn></mrow><annotation encoding=\"application/x-tex\">\\approx 0.26</annotation></semantics></math>), but performance remains uneven compared to fine-tuned models. Scaling improves parity: Llama-3.1-70B shows lower disparities than its 8B counterpart, and Qwen-2.5-72B achieves the strongest parity among prompting models, especially with few-shot examples.</p>\n\n",
                "matched_terms": [
                    "models",
                    "glm49b",
                    "prompting",
                    "fewshot",
                    "qwen2572b",
                    "llama318b",
                    "llama3170b",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuning yields markedly lower disparities.</span> Encoder models such as RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> and DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> reach <math alttext=\"\\Delta_{\\text{FNR}}\\approx 0.2\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m1\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FNR</mtext></msub><mo>&#8776;</mo><mn>0.2</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FNR}}\\approx 0.2</annotation></semantics></math> and <math alttext=\"\\Delta_{\\text{FPR}}\\approx 0.03\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m2\" intent=\":literal\"><semantics><mrow><msub><mi mathvariant=\"normal\">&#916;</mi><mtext>FPR</mtext></msub><mo>&#8776;</mo><mn>0.03</mn></mrow><annotation encoding=\"application/x-tex\">\\Delta_{\\text{FPR}}\\approx 0.03</annotation></semantics></math>, particularly with reweighted loss. Reweighting reduces FNR gaps but can slightly increase FPR gaps, indicating a tradeoff. Model architecture also matters: encoder models achieve far lower disparities than decoder-only GPT-2, and scaling further improves parity (e.g., RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> outperforms RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">base</span>).</p>\n\n",
                "matched_terms": [
                    "model",
                    "models",
                    "fnr",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Takeaway.</span>\nPrompting, even with larger models and few-shot examples, shows substantial per-axis disparities. Fine-tuned models, particularly with reweighted loss, achieve more balanced performance, although notable gaps remain. In additional analyses (in the appendix), we examined <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across the nine demographic axes. We found that certain targets, such as <span class=\"ltx_text ltx_font_typewriter\">NAT</span> and <span class=\"ltx_text ltx_font_typewriter\">PHY</span>, consistently have lower detection accuracy, which contributes to the observed disparities.</p>\n\n",
                "matched_terms": [
                    "models",
                    "prompting",
                    "f1f1",
                    "fewshot",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Prompting improves with scale and few-shot examples.</span> Few-shot prompting substantially narrows multi-axis gaps. For Llama-3.1-70B, <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m1\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}</annotation></semantics></math> drops from 0.736 (zero-shot) to 0.164 (10-shot), and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p2.m2\" intent=\":literal\"><semantics><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}</annotation></semantics></math> from 0.262 to 0.088. Larger models benefit more from in-context learning: Llama-3.1-70B outperforms Llama-3.1-8B, and disparities are generally higher for {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>} than {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">RAC</span>}.</p>\n\n",
                "matched_terms": [
                    "models",
                    "prompting",
                    "fewshot",
                    "llama318b",
                    "llama3170b"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Fine-tuned models show persistent gaps.</span> Despite strong per-axis parity, fine-tuned models underperform on multi-axis instances, reflecting <em class=\"ltx_emph ltx_font_italic\">gerrymandering</em>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Kearns et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib26\" title=\"\">2018</a>)</cite> in their detection performance. For example, RoBERTa-<span class=\"ltx_text ltx_font_typewriter\">large</span> with reweighting achieves <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m1\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,SO</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.436</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,SO}\\}}_{\\text{FNR}}\\approx 0.436</annotation></semantics></math> and <math alttext=\"\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m2\" intent=\":literal\"><semantics><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">&#119970;</mi><mtext>FNR</mtext><mrow><mo stretchy=\"false\">{</mo><mtext>GEN,RAC</mtext><mo stretchy=\"false\">}</mo></mrow></msubsup><mo>&#8776;</mo><mn>0.373</mn></mrow><annotation encoding=\"application/x-tex\">\\mathcal{G}^{\\{\\text{GEN,RAC}\\}}_{\\text{FNR}}\\approx 0.373</annotation></semantics></math>, higher than few-shot Llama-3.1-70B and Qwen-2.5-72B. Encoder models outperform GPT-2, and scaling improves parity (e.g., DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v2-XL</span> at <math alttext=\"\\approx 0.28\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m3\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8776;</mo><mn>0.28</mn></mrow><annotation encoding=\"application/x-tex\">\\approx 0.28</annotation></semantics></math> vs. DeBERTa-<span class=\"ltx_text ltx_font_typewriter\">v3-large</span> at 0.39 for FNR regarding {<span class=\"ltx_text ltx_font_typewriter\">GEN</span>,<span class=\"ltx_text ltx_font_typewriter\">SO</span>}). As with per-axis results, reweighting reduces FNR gaps but can slightly raise FPR gaps.</p>\n\n",
                "matched_terms": [
                    "models",
                    "fewshot",
                    "fnr",
                    "fpr",
                    "qwen2572b",
                    "llama3170b",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Methodological opportunities.</span>\nOur findings highlight both promises and existing limitations of scalable automated bias detection. Future work should further explore advanced prompting (e.g., <span class=\"ltx_text ltx_font_italic\">chain-of-thought</span>&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(Wei et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#bib.bib56\" title=\"\">2022</a>)</cite>) and efficient fine-tuning (e.g., using adapters). To handle multimodal data, exploring effective and scalable solutions remains an interesting open challenge. Moreover, while our results offer initial guidance, balancing the potential gains from training and deploying larger models and the scalability required for auditing massive corpora warrants deeper exploration. Finally, our study shows that detecting infrequent, subtle, and multi-axis biases remains a crucial underexplored direction for future research.</p>\n\n",
                "matched_terms": [
                    "models",
                    "prompting"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All LLMs are accessed via API through an MLOps platform. We fix <span class=\"ltx_text ltx_font_typewriter\">temperature</span> to 0 and <span class=\"ltx_text ltx_font_typewriter\">top_p</span> to 1, ensuring deterministic outputs by selecting the model&#8217;s most likely generation while still allowing consideration of the full token space. For in-context learning, we embed the training and development sets using BGE-M3 or BCEmbedding models. At inference time, we compute cosine similarity between the query and development set vectors to retrieve the top-<math alttext=\"K\" class=\"ltx_Math\" display=\"inline\" id=\"A2.SS1.p1.m1\" intent=\":literal\"><semantics><mi>K</mi><annotation encoding=\"application/x-tex\">K</annotation></semantics></math> few-shot examples. As a baseline, we also apply a random few-shot selection from the training set, with balanced sampling between biased and unbiased texts. Model predictions are extracted via pattern matching. Responses that cannot be parsed through pattern matching to assign to one of the multiple demographic axes are marked as &#8220;invalid.&#8221; The <span class=\"ltx_text ltx_font_italic\">social bias policy</span> used in the text prompt is shown here.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model",
                    "bgem3",
                    "fewshot",
                    "bcembedding"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization uses AdamW with linear learning rate decay, weight decay of 0.01, and gradient clipping at 1.0. To address class imbalance, we experiment with reweighted binary cross-entropy loss, where weights are derived from label frequencies in the training set. Models are trained for four epochs without reweighting and six epochs with reweighting. The effective batch size is fixed at 32, with gradient accumulation applied for larger models. Learning rates are <span class=\"ltx_text ltx_font_italic\">tuned by monitoring validation loss</span>. For each model, we use the following learning rates for optimization:</p>\n\n",
                "matched_terms": [
                    "model",
                    "models",
                    "binary"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate the impact of retrieval-augmented generation (RAG) on few-shot example selection compared to random sampling. Results are presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.T6\" title=\"Table 6 &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>. Overall, RAG consistently enhances bias detection performance.</p>\n\n",
                "matched_terms": [
                    "performance",
                    "fewshot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In binary classification, RAG achieves higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS1.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across all models. Improvements in detection metrics are consistent across model sizes, demonstrating the benefit of providing LLMs with <em class=\"ltx_emph ltx_font_italic\">semantically similar examples</em> during in-context learning. RAG generally reduces False Negative Rates (FNR), though it occasionally causes slight increases in False Positive Rates (FPR), as observed with Llama Guard-3-8B and GLM-4-9B. This tradeoff is typically favorable, since reducing FNR is crucial for minimizing missed detections. Notably, while adding more examples under RAG yields only modest additional gains, increasing the number of randomly selected examples often leads to degraded performance.</p>\n\n",
                "matched_terms": [
                    "models",
                    "glm49b",
                    "model",
                    "f1f1",
                    "binary",
                    "fnr",
                    "fpr",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For multi-label prediction, RAG delivers even greater improvements over random sampling. As in the binary case, providing more RAG-selected examples enhances performance, whereas adding more random examples consistently worsens detection outcomes. This highlights an important insight: supplying more <em class=\"ltx_emph ltx_font_italic\">relevant</em> examples benefits prompting-based detection, but including <em class=\"ltx_emph ltx_font_italic\">irrelevant</em> examples can be detrimental.</p>\n\n",
                "matched_terms": [
                    "binary",
                    "performance",
                    "multilabel",
                    "prediction"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In summary, RAG significantly strengthens in-context learning by providing more meaningful examples, resulting in higher accuracy and improved multi-label predictions. Although small increases in FPR can occur, the overall gains clearly favor RAG over random sampling.</p>\n\n",
                "matched_terms": [
                    "multilabel",
                    "fpr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">BGE-M3 exhibits a slight but consistent advantage in binary bias detection, producing marginally higher <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across multiple LLMs. However, the overall differences are minimal. In contrast, for multi-label prediction, BCEmbedding performs slightly better on metrics such as MR for many models. This finding suggests that while both embedding models select examples that yield similar overall outcomes, subtle differences exist. Specifically, BGE-M3-selected examples tend to improve binary bias detection by helping models better distinguish biased from unbiased samples, whereas BCEmbedding-selected examples slightly enhance the detection of specific bias types within biased instances.</p>\n\n",
                "matched_terms": [
                    "models",
                    "embedding",
                    "prediction",
                    "f1f1",
                    "bgem3",
                    "binary",
                    "bcembedding",
                    "multilabel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Overall, both embedding models deliver strong and comparable performance for in-context learning, with only minor trade-offs. Their results indicate that either embedding model is well-suited for bias detection tasks.</p>\n\n",
                "matched_terms": [
                    "models",
                    "embedding",
                    "model",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We now analyze model performance across different demographic targets. Specifically, we examine the <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p1.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores for all demographic axes in our taxonomy that may be subject to bias. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F5\" title=\"Figure 5 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents results for various prompted models using <em class=\"ltx_emph ltx_font_italic\">10-shot RAG-based in-context learning</em> with BGE-M3, while Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.04641v2#A3.F6\" title=\"Figure 6 &#8227; C.2 Ablation study: Embedding model &#8227; Appendix C Additional evaluations &#8227; Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> compares fine-tuned models and explores the impact of reweighted loss (&#8220;bal&#8221; in the figure) across demographics.</p>\n\n",
                "matched_terms": [
                    "models",
                    "model",
                    "f1f1",
                    "bgem3",
                    "different",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our analysis shows that fine-tuned models consistently outperform prompting and transfer learning across all bias classes. The most notable <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p2.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> score gains appear in the AGE and SES categories, which are less frequent in the dataset.</p>\n\n",
                "matched_terms": [
                    "models",
                    "prompting",
                    "f1f1"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Among the prompted LLMs, Llama-3.1-70B achieves the highest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p3.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores across nearly all bias categories, except for <span class=\"ltx_text ltx_font_typewriter\">GEN</span>, where GLM-9B&#8212;despite being much smaller&#8212;slightly outperforms it. Interestingly, Qwen-2.5-72B, though the largest LLM, performs worse in many low-frequency categories such as <span class=\"ltx_text ltx_font_typewriter\">DIS</span>, <span class=\"ltx_text ltx_font_typewriter\">AGE</span>, and <span class=\"ltx_text ltx_font_typewriter\">SES</span>. It performs comparably to the best prompting models only for <span class=\"ltx_text ltx_font_typewriter\">GEN</span> and <span class=\"ltx_text ltx_font_typewriter\">RAC</span>, which are the most common categories in the benchmark.</p>\n\n",
                "matched_terms": [
                    "models",
                    "prompting",
                    "f1f1",
                    "qwen2572b",
                    "llama3170b"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For fine-tuned models, encoder-only architectures (e.g., RoBERTa and DeBERTa) generally outperform decoder-only language models, i.e., GPT-2, across most demographic axes. The trends mirror those observed in the prompting setup: models achieve their best performance for <span class=\"ltx_text ltx_font_typewriter\">SES</span>, while <span class=\"ltx_text ltx_font_typewriter\">NAT</span> consistently shows the lowest <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m1\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> scores. Reweighted loss often improves detection performance or yields similar results to the default loss. For example, in <span class=\"ltx_text ltx_font_typewriter\">NAT</span>, the axis that suffered from the weakest detection performance, reweighted loss improves performance across all models. However, improvements are not universal. For instance, GPT-2-<span class=\"ltx_text ltx_font_typewriter\">large</span> experiences slight declines in <math alttext=\"F_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"A3.SS3.p4.m2\" intent=\":literal\"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">F_{1}</annotation></semantics></math> for some demographics such as <span class=\"ltx_text ltx_font_typewriter\">AGE</span> and <span class=\"ltx_text ltx_font_typewriter\">SES</span> when reweighted loss is applied.</p>\n\n",
                "matched_terms": [
                    "models",
                    "prompting",
                    "setup",
                    "f1f1",
                    "when",
                    "performance"
                ]
            }
        ]
    }
}