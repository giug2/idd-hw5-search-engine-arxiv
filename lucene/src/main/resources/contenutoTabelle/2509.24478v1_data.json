{
    "S1.T1": {
        "source_file": "A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems",
        "caption": "Table 1: Handcrafted example: While both alignments result in five errors, our approach capture more plausible alignments.",
        "body": "Levenshtein-based word-level alignment (1 of 11 equal paths)\n\n\n\n\nOur approach (1 best path)\n\n\n\n\nref\n\n\n|some|xthingsxx|xarex|xworthx|noting|\n\n\n\n\n|somex|things|are|worth|notingx|xxxxxx|\n\n\n\n\n\n\n\nxdelxxxxxsubxxxxxsubxxxxsubxxxxsubxxx\n\n\n\n\nxxsubxxxsubxxxdelxmatchxxxsubxxxxinsxxx\n\n\n\n\nhyp\n\n\n|xxxx|something|worth|nothing|period|\n\n\n\n\n|some-|-thing|xxx|worth|nothing|period|",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"/>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Levenshtein-based word-level alignment<span class=\"ltx_text ltx_font_upright\"> <span class=\"ltx_text\" style=\"font-size:78%;\">(1 of 11 equal paths)</span></span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Our approach<span class=\"ltx_text ltx_font_upright\"> <span class=\"ltx_text\" style=\"font-size:78%;\">(1 best path)</span></span></span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">ref</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">|some|<span class=\"ltx_text ltx_phantom\"><span style=\"visibility:hidden\">x</span></span>things<span class=\"ltx_text ltx_phantom\"><span style=\"visibility:hidden\">xx</span></span>|<span class=\"ltx_text ltx_phantom\"><span style=\"visibility:hidden\">x</span></span>are<span class=\"ltx_text ltx_phantom\"><span style=\"visibility:hidden\">x</span></span>|<span class=\"ltx_text ltx_phantom\"><span style=\"visibility:hidden\">x</span></span>worth<span class=\"ltx_text ltx_phantom\"><span style=\"visibility:hidden\">x</span></span>|noting|</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">|some<span class=\"ltx_text ltx_phantom\"><span style=\"visibility:hidden\">x</span></span>|things|are|worth|noting<span class=\"ltx_text ltx_phantom\"><span style=\"visibility:hidden\">x</span></span>|<span class=\"ltx_text ltx_phantom\"><span style=\"visibility:hidden\">xxxxxx</span></span>|</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_border_l ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"/>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">x</span></span><span class=\"ltx_text ltx_font_typewriter ltx_font_smallcaps\" style=\"font-size:90%;--ltx-bg-color:#000000;\">del</span><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">xxxxx</span></span><span class=\"ltx_text ltx_font_typewriter ltx_font_smallcaps\" style=\"font-size:90%;--ltx-bg-color:#000000;\">sub</span><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">xxxxx</span></span><span class=\"ltx_text ltx_font_typewriter ltx_font_smallcaps\" style=\"font-size:90%;--ltx-bg-color:#000000;\">sub</span><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">xxxx</span></span><span class=\"ltx_text ltx_font_typewriter ltx_font_smallcaps\" style=\"font-size:90%;--ltx-bg-color:#000000;\">sub</span><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">xxxx</span></span><span class=\"ltx_text ltx_font_typewriter ltx_font_smallcaps\" style=\"font-size:90%;--ltx-bg-color:#000000;\">sub</span><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">xxx</span></span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">xx</span></span><span class=\"ltx_text ltx_font_typewriter ltx_font_smallcaps\" style=\"font-size:90%;--ltx-bg-color:#000000;\">sub</span><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">xxx</span></span><span class=\"ltx_text ltx_font_typewriter ltx_font_smallcaps\" style=\"font-size:90%;--ltx-bg-color:#000000;\">sub</span><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">xxx</span></span><span class=\"ltx_text ltx_font_typewriter ltx_font_smallcaps\" style=\"font-size:90%;--ltx-bg-color:#000000;\">del</span><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">x</span></span><span class=\"ltx_text ltx_font_typewriter ltx_font_smallcaps\" style=\"font-size:90%;--ltx-bg-color:#000000;\">match</span><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">xxx</span></span><span class=\"ltx_text ltx_font_typewriter ltx_font_smallcaps\" style=\"font-size:90%;--ltx-bg-color:#000000;\">sub</span><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">xxxx</span></span><span class=\"ltx_text ltx_font_typewriter ltx_font_smallcaps\" style=\"font-size:90%;--ltx-bg-color:#000000;\">ins</span><span class=\"ltx_text ltx_phantom ltx_font_typewriter\" style=\"font-size:90%;\"><span style=\"visibility:hidden\">xxx</span></span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span class=\"ltx_text ltx_font_smallcaps\" style=\"font-size:90%;\">hyp</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">|<span class=\"ltx_text ltx_phantom\"><span style=\"visibility:hidden\">xxxx</span></span>|something|worth|nothing|period|</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_r\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">|some-|-thing|<span class=\"ltx_text ltx_phantom\"><span style=\"visibility:hidden\">xxx</span></span>|worth|nothing|period|</span></span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "equal",
            "path",
            "more",
            "hyp",
            "our",
            "example",
            "levenshteinbased",
            "errors",
            "somexthingsxxxarexxworthxnoting",
            "five",
            "plausible",
            "paths",
            "capture",
            "both",
            "alignments",
            "xxxxsomethingworthnothingperiod",
            "wordlevel",
            "handcrafted",
            "somexthingsareworthnotingxxxxxxx",
            "result",
            "xdelxxxxxsubxxxxxsubxxxxsubxxxxsubxxx",
            "xxsubxxxsubxxxdelxmatchxxxsubxxxxinsxxx",
            "alignment",
            "ref",
            "somethingxxxworthnothingperiod",
            "best",
            "while",
            "approach"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">We identify two primary failure cases of Levenshtein-based word-level alignment. First, substitutions are constrained to be strictly one-to-one. In other words, a reference word cannot be mapped to multiple words or subwords in the hypothesis. This limitation is especially problematic for agglutinative languages or languages with a high degree of noun compounding. For example, in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S1.T1\" title=\"Table 1 &#8227; 1 Introduction &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, the phrase <span class=\"ltx_text ltx_font_typewriter\">some things</span> is incorrectly transcribed as <span class=\"ltx_text ltx_font_typewriter\">something</span>, but is incorrectly aligned by the word-level method.</p>\n\n",
            "<p class=\"ltx_p\">Second, substitutions that occur adjacent to insertions or deletions introduce ambiguity. Returning to the example in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S1.T1\" title=\"Table 1 &#8227; 1 Introduction &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, the Levenshtein-based alignment produces four substitutions and a single deletion. However, any of the reference words could have been labeled as the deletion, yielding five distinct alignments with the same optimal Levenshtein distance. This demonstrates that treating words as canonical units is insufficient when aiming for unambiguous alignment.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Modern neural networks have greatly improved performance across speech recognition benchmarks. However, gains are often driven by frequent words with limited semantic weight, which can obscure meaningful differences in word error rate, the primary evaluation metric. Errors in rare terms, named entities, and domain-specific vocabulary are more consequential, but remain hidden by aggregate metrics. This highlights the need for finer-grained error analysis, which depends on accurate alignment between reference and model transcripts. However, conventional alignment methods are not designed for such precision. We propose a novel alignment algorithm that couples dynamic programming with beam search scoring. Compared to traditional text alignment methods, our approach provides more accurate alignment of individual errors, enabling reliable error analysis. The algorithm is made available via PyPI.<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>https://github.com/borgholt/error-align</span></span></span></p>\n\n",
                "matched_terms": [
                    "errors",
                    "alignment",
                    "more",
                    "approach",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent advances in neural architectures and large-scale weakly-supervised training have enabled automatic speech recognition (ASR) systems to reach unprecedented accuracy <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#bib.bib3\" title=\"\">3</a>]</cite>. However, evaluation methods have not kept pace. The <span class=\"ltx_text ltx_font_italic\">word error rate</span> (WER), based on Levenshtein distance, remains the de facto standard for benchmarking performance. While WER provides a simple and interpretable summary metric, there is a need for more fine-grained error analysis to better understand, diagnose, and improve model behavior.</p>\n\n",
                "matched_terms": [
                    "while",
                    "more"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Reliable error analysis requires accurate alignment between words in the reference transcript and the model transcript. High-quality alignments allow researchers and practitioners to query the model output for specific words or phrases that were mistranscribed, enabling rapid assessment of error severity for critical vocabulary items. Levenshtein-based alignment is widely used for this purpose, but as we will show, it often fails to capture plausible correspondences.</p>\n\n",
                "matched_terms": [
                    "levenshteinbased",
                    "plausible",
                    "capture",
                    "alignments",
                    "alignment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We address this limitation by proposing a new alignment approach that integrates dynamic programming with beam search scoring. The contributions of this work are threefold:</p>\n\n",
                "matched_terms": [
                    "approach",
                    "alignment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We identify key limitations of Levenshtein-based alignment when applied to speech recognition outputs.</p>\n\n",
                "matched_terms": [
                    "levenshteinbased",
                    "alignment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Consider a single reference&#8211;hypothesis pair <math alttext=\"(r,h)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(r,h)</annotation></semantics></math>. We define a valid alignment <math alttext=\"a\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m2\" intent=\":literal\"><semantics><mi>a</mi><annotation encoding=\"application/x-tex\">a</annotation></semantics></math> between the two strings as a sequence of index range pairs, such that <math alttext=\"a_{n}=(i\\!:\\!j,k\\!:\\!l)\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S2.p2.m3\" intent=\":literal\"><semantics><mrow><msub><mi>a</mi><mi>n</mi></msub><mo>=</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo lspace=\"0.108em\" rspace=\"0.108em\">:</mo><mi>j</mi><mo>,</mo><mi>k</mi><mo lspace=\"0.108em\" rspace=\"0.108em\">:</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">a_{n}=(i\\!:\\!j,k\\!:\\!l)</annotation></semantics></math>. Following the edit distance convention, each mapping may represent an insertion (<math alttext=\"r_{i:j}=\\varepsilon\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m4\" intent=\":literal\"><semantics><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>j</mi></mrow></msub><mo>=</mo><mi>&#949;</mi></mrow><annotation encoding=\"application/x-tex\">r_{i:j}=\\varepsilon</annotation></semantics></math>), deletion (<math alttext=\"h_{k:l}=\\varepsilon\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m5\" intent=\":literal\"><semantics><mrow><msub><mi>h</mi><mrow><mi>k</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>l</mi></mrow></msub><mo>=</mo><mi>&#949;</mi></mrow><annotation encoding=\"application/x-tex\">h_{k:l}=\\varepsilon</annotation></semantics></math>), substitution (<math alttext=\"h_{k:l}\\neq r_{i:j}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m6\" intent=\":literal\"><semantics><mrow><msub><mi>h</mi><mrow><mi>k</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>l</mi></mrow></msub><mo>&#8800;</mo><msub><mi>r</mi><mrow><mi>i</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>j</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">h_{k:l}\\neq r_{i:j}</annotation></semantics></math>), or match (<math alttext=\"h_{k:l}=r_{i:j}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m7\" intent=\":literal\"><semantics><mrow><msub><mi>h</mi><mrow><mi>k</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>l</mi></mrow></msub><mo>=</mo><msub><mi>r</mi><mrow><mi>i</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>j</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">h_{k:l}=r_{i:j}</annotation></semantics></math>). Index ranges must increase monotonically between consecutive pairs <math alttext=\"a_{n}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m8\" intent=\":literal\"><semantics><msub><mi>a</mi><mi>n</mi></msub><annotation encoding=\"application/x-tex\">a_{n}</annotation></semantics></math> and <math alttext=\"a_{n+1}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m9\" intent=\":literal\"><semantics><msub><mi>a</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding=\"application/x-tex\">a_{n+1}</annotation></semantics></math> for both the reference and the hypothesis. Finally, the alignment must cover all voiced characters, while unvoiced characters such as spaces and punctuation can be ignored.</p>\n\n",
                "matched_terms": [
                    "both",
                    "while",
                    "alignment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For our purposes, each reference substring <math alttext=\"r_{i:j}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p3.m1\" intent=\":literal\"><semantics><msub><mi>r</mi><mrow><mi>i</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>j</mi></mrow></msub><annotation encoding=\"application/x-tex\">r_{i:j}</annotation></semantics></math> must correspond to exactly one word. This restriction enables users to query instances of individual words or predefined vocabularies, facilitating fine-grained error analysis. The proposed algorithm can be configured to capture phrases, if desirable.</p>\n\n",
                "matched_terms": [
                    "capture",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Levenshtein distance <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#bib.bib4\" title=\"\">4</a>]</cite>is computed using a dynamic programming table, where the optimal value is determined recursively by comparing all positions in the two input sequences <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#bib.bib5\" title=\"\">5</a>]</cite>. The corresponding alignment can be extracted through a <span class=\"ltx_text ltx_font_italic\">backtrace</span> constructed by recording the path taken to reach each cell in the table. However, the minimum distance might be attained by multiple distinct paths, which introduces ambiguity into the resulting alignment.</p>\n\n",
                "matched_terms": [
                    "path",
                    "alignment",
                    "paths"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">From the examples above, the lack of character-level information is clearly a key limitation of word-level alignment.\nA better approach is to work fully at the character level, though plain character-level alignment also has drawbacks.\nFirst, our goal is to map each reference word to a corresponding segment of the hypothesis transcript &#8212; something that character-level alignment does not provide.\nSecond, this approach offers no measure of proximity between matched characters within a single word. For example, if a model fails to capture the last letter of a word and proceeds to hallucinate a sequence of words containing the missing letter, it will be erroneously matched to the hallucinated part, resulting in a highly implausible alignment that may span multiple words.</p>\n\n",
                "matched_terms": [
                    "example",
                    "capture",
                    "alignment",
                    "approach",
                    "wordlevel",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The table commonly used for alignment via dynamic programming can also be viewed as a directed acyclic graph, where cells correspond to nodes and insertions, deletions, and substitutions or matches are represented by vertical, horizontal, and diagonal edges, respectively. The backtrace defines a subgraph that captures all optimal alignments. See Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S2.F1\" title=\"Figure 1 &#8227; 2.3 Failure cases of character-level Levenshtein &#8227; 2 Background and Challenges &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>.</p>\n\n",
                "matched_terms": [
                    "alignments",
                    "alignment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our objective is to identify the minimal-cost path through this graph and establish a ruleset for mapping character-level operations to word-level alignments. The proposed algorithm leverages the backtrace subgraph as an anchor for a beam search over the full graph.</p>\n\n",
                "matched_terms": [
                    "wordlevel",
                    "path",
                    "our",
                    "alignments"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Word tokens are normalized by lower casing, removing accents, and replacing unvoiced characters, such as apostrophes and hyphens, with a placeholder symbol (<span class=\"ltx_text ltx_font_typewriter\">#</span>). Finally, words are enclosed in angle brackets (i.e., <span class=\"ltx_text ltx_font_typewriter\">&lt;word&gt;</span>), which we use for our ruleset for extracting word-level alignments from character-level input.</p>\n\n",
                "matched_terms": [
                    "wordlevel",
                    "alignments",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We find that an unrestricted search over the entire graph is computationally infeasible. To prioritize the most promising paths, we introduce a penalty term when a path deviates from the backtrace graph <math alttext=\"G_{b}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\"><semantics><msub><mi>G</mi><mi>b</mi></msub><annotation encoding=\"application/x-tex\">G_{b}</annotation></semantics></math>, which substantially improves both the robustness and efficiency of the beam search.</p>\n\n",
                "matched_terms": [
                    "both",
                    "path",
                    "paths"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For graph construction, we adopt a slightly modified version of the standard unit-cost Levenshtein distance by doubling the cost of substitutions. In this formulation, every substitution can equivalently be represented as a deletion&#8211;insertion pair, which has the effect of expanding the backtrace graph. Relaxing the unit-cost constraint on the search space in this way leads to more accurate alignments.</p>\n\n",
                "matched_terms": [
                    "alignments",
                    "more"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We initialize the beam with a single candidate path <math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p1.m1\" intent=\":literal\"><semantics><mi>p</mi><annotation encoding=\"application/x-tex\">p</annotation></semantics></math> starting at the root node <math alttext=\"(0,0)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p1.m2\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(0,0)</annotation></semantics></math>. At each iteration, candidates expand by transitioning to their child nodes. Word-level alignments are traced out as the candidate paths traverse the graph.</p>\n\n",
                "matched_terms": [
                    "wordlevel",
                    "path",
                    "alignments",
                    "paths"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">If we consider a path at node <math alttext=\"v=(i,j)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m1\" intent=\":literal\"><semantics><mrow><mi>v</mi><mo>=</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">v=(i,j)</annotation></semantics></math> with the last word-level alignment of that path ending at node <math alttext=\"u=(k,l)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m2\" intent=\":literal\"><semantics><mrow><mi>u</mi><mo>=</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">u=(k,l)</annotation></semantics></math>, the normalized cost is defined as</p>\n\n",
                "matched_terms": [
                    "wordlevel",
                    "path",
                    "alignment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"c_{c}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m3\" intent=\":literal\"><semantics><msub><mi>c</mi><mi>c</mi></msub><annotation encoding=\"application/x-tex\">c_{c}</annotation></semantics></math> denotes the cumulative cost of <span class=\"ltx_text ltx_font_italic\">closed</span> word-level alignments, <math alttext=\"c_{o}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m4\" intent=\":literal\"><semantics><msub><mi>c</mi><mi>o</mi></msub><annotation encoding=\"application/x-tex\">c_{o}</annotation></semantics></math> is the cost of the current <span class=\"ltx_text ltx_font_italic\">open</span> word-level alignment, and <math alttext=\"i+j+1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m5\" intent=\":literal\"><semantics><mrow><mi>i</mi><mo>+</mo><mi>j</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">i+j+1</annotation></semantics></math> is a normalization term accounting for the number of characters covered thus far. The indicator function <math alttext=\"[(i-k)(j-l)&gt;0]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m6\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>i</mi><mo>&#8722;</mo><mi>k</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>j</mi><mo>&#8722;</mo><mi>l</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mn>0</mn></mrow><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[(i-k)(j-l)&gt;0]</annotation></semantics></math> imposes a penalty by doubling <math alttext=\"c_{o}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m7\" intent=\":literal\"><semantics><msub><mi>c</mi><mi>o</mi></msub><annotation encoding=\"application/x-tex\">c_{o}</annotation></semantics></math> for substitutions, ensuring that dissimilar words are not aligned. Importantly, because this penalty doubles the cost of previous actions accumulated by <math alttext=\"c_{o}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m8\" intent=\":literal\"><semantics><msub><mi>c</mi><mi>o</mi></msub><annotation encoding=\"application/x-tex\">c_{o}</annotation></semantics></math>, the problem does not have an optimal substructure, which is why a strict dynamic programming solution is not possible.</p>\n\n",
                "matched_terms": [
                    "wordlevel",
                    "alignments",
                    "alignment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To determine if a segment should be closed, we define a function that is evaluated at each transition and updates <math alttext=\"u\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p7.m1\" intent=\":literal\"><semantics><mi>u</mi><annotation encoding=\"application/x-tex\">u</annotation></semantics></math>, if the alignment is to be concluded. Again, consider a path transitioning from <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p7.m2\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> to <math alttext=\"v\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p7.m3\" intent=\":literal\"><semantics><mi>v</mi><annotation encoding=\"application/x-tex\">v</annotation></semantics></math> with <math alttext=\"u\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p7.m4\" intent=\":literal\"><semantics><mi>u</mi><annotation encoding=\"application/x-tex\">u</annotation></semantics></math> as the end node of the previously recorded alignment. We then have</p>\n\n",
                "matched_terms": [
                    "path",
                    "alignment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <span class=\"ltx_text ltx_font_typewriter\">&lt;</span> and <span class=\"ltx_text ltx_font_typewriter\">&gt;</span> are the start- and end-of-token delimiters. If the output is not <math alttext=\"u\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p8.m1\" intent=\":literal\"><semantics><mi>u</mi><annotation encoding=\"application/x-tex\">u</annotation></semantics></math>, the segment is closed, the word-level alignment is recorded, and equations (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S3.E2\" title=\"In 3.3 Path scoring &#8227; 3 Method &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>) and (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S3.E3\" title=\"In 3.3 Path scoring &#8227; 3 Method &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>) are applied.</p>\n\n",
                "matched_terms": [
                    "wordlevel",
                    "alignment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">&#8226;&#8196;<span class=\"ltx_text ltx_font_italic\">Levenshtein-based word-level alignment</span> (<span class=\"ltx_text ltx_font_smallcaps\">lwa</span>): The RapidFuzz toolkit <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#bib.bib6\" title=\"\">6</a>]</cite> provides one of the fastest implementations of Levenshtein distance computation, including extraction of alignments. The computed alignments represent an arbitrary optimal path through the Levenshtein backtrace graph.</p>\n\n",
                "matched_terms": [
                    "levenshteinbased",
                    "path",
                    "alignment",
                    "alignments",
                    "wordlevel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">&#8226;&#8196;<span class=\"ltx_text ltx_font_italic\">Optimized word-level alignment</span> (<span class=\"ltx_text ltx_font_smallcaps\">owa</span>): We implement a custom word-level alignment where transitions are scored according to (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S4.E10\" title=\"In 4.1 Metric: Global-to-local edits (GLE) &#8227; 4 Evaluation procedure &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">10</span></a>). In essence, this yields a word-level oracle with reference to the proposed metric, and will help to highlight the limitations of simple one-to-one alignment.</p>\n\n",
                "matched_terms": [
                    "wordlevel",
                    "alignment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">&#8226;&#8196;<span class=\"ltx_text ltx_font_italic\">Power alignment</span> (<span class=\"ltx_text ltx_font_smallcaps\">pwr</span>): The Power aligner <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#bib.bib7\" title=\"\">7</a>]</cite> realigns Levenshtein substitution spans after converting words to phonetic representations. The resulting alignments may span multiple words in the reference transcript, which can give a small advantage in relation to the proposed metric described above. While the Power aligner is the most relevant baseline, it only supports English, as it relies on manually curated linguistic resources for character-to-phoneme conversion.</p>\n\n",
                "matched_terms": [
                    "while",
                    "alignments",
                    "alignment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">As shown in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S3.T4\" title=\"Table 4 &#8227; 3.3 Path scoring &#8227; 3 Method &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, our method (beam size = 100) consistently outperforms all baselines at both the character and phoneme levels. Although the Power aligner is explicitly optimized for phonetic similarity, our approach achieves higher phoneme-level scores across every dataset and model. This indicates that our alignments capture more robust cross-granularity correspondences.</p>\n\n",
                "matched_terms": [
                    "capture",
                    "both",
                    "alignments",
                    "more",
                    "approach",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S3.T4\" title=\"Table 4 &#8227; 3.3 Path scoring &#8227; 3 Method &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> (top) shows that our method also outperforms the baselines across all non-English languages. Relative improvements are generally larger for most non-English languages compared to English. We hypothesize that this effect arises from the relatively weaker performance of Whisper on these languages, which makes alignments more challenging and amplifies the benefits of our approach over the baselines.</p>\n\n",
                "matched_terms": [
                    "our",
                    "approach",
                    "alignments",
                    "more"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S3.T4\" title=\"Table 4 &#8227; 3.3 Path scoring &#8227; 3 Method &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> (bottom) further highlights the benefit of key algorithmic choices. While each choice improves performance, the largest gain results from eliminating the one-to-one constraint of word-level alignment, discussed in section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S2.SS2\" title=\"2.2 Failure cases of word-level Levenshtein &#8227; 2 Background and Challenges &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">2.2</span></a>, as seen by the difference between our approach and the <span class=\"ltx_text ltx_font_smallcaps\">owa</span> baseline (-13.0, <span class=\"ltx_text ltx_font_smallcaps\">cv-en</span> + <span class=\"ltx_text ltx_font_smallcaps\">whspr</span>, Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S3.T4\" title=\"Table 4 &#8227; 3.3 Path scoring &#8227; 3 Method &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>).</p>\n\n",
                "matched_terms": [
                    "while",
                    "alignment",
                    "approach",
                    "wordlevel",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Finally, while our algorithm is slower than the highly-optimized word-level methods (<math alttext=\"\\sim 100\\times\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S5.p4.m1\" intent=\":literal\"><semantics><mrow><mo>&#8764;</mo><mn>100</mn><mo lspace=\"0.222em\">&#215;</mo></mrow><annotation encoding=\"application/x-tex\">\\sim 100\\times</annotation></semantics></math> slower), it compares favorable to the Power aligner (<math alttext=\"\\sim 2\\times\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S5.p4.m2\" intent=\":literal\"><semantics><mrow><mo>&#8764;</mo><mn>2</mn><mo lspace=\"0.222em\">&#215;</mo></mrow><annotation encoding=\"application/x-tex\">\\sim 2\\times</annotation></semantics></math> faster). We aim to provide a significantly faster C++ version with Python bindings.</p>\n\n",
                "matched_terms": [
                    "wordlevel",
                    "while",
                    "our"
                ]
            }
        ]
    },
    "S3.T2": {
        "source_file": "A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems",
        "caption": "Table 2: Description of the transition rules from eq. (5). Substitutions involving unvoiced characters are prohibited.",
        "body": "Cost\n\n\n\n\nTransition description\n\n\n\n\n\n\n0\n\n\n\n\nMatch of any characters.\n\n\n\n\n\n\n1\n\n\n\n\nInsertion or deletion of unvoiced characters.\n\n\n\n\n\n\n2\n\n\n\n\nInsertion or deletion of voiced character.\n\n\n\n\n\n\n2\n\n\n\n\nSubstitution of vowel or consonant pair.\n\n\n\n\n\n\n3\n\n\n\n\nSubstitution of vowel and consonant.",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t\" style=\"width:22.8pt;padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_italic\">Cost</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_italic\">Transition description</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t\" style=\"width:22.8pt;padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">Match of any characters.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t\" style=\"width:22.8pt;padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">Insertion or deletion of unvoiced characters.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t\" style=\"width:22.8pt;padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">2</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">Insertion or deletion of voiced character.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t\" style=\"width:22.8pt;padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">2</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">Substitution of vowel or consonant pair.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"width:22.8pt;padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">3</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">Substitution of vowel and consonant.</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "consonant",
            "voiced",
            "rules",
            "deletion",
            "cost",
            "from",
            "prohibited",
            "unvoiced",
            "transition",
            "vowel",
            "match",
            "description",
            "pair",
            "characters",
            "involving",
            "substitutions",
            "insertion",
            "character",
            "substitution",
            "any"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">The rules are summarized in natural language in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S3.T2\" title=\"Table 2 &#8227; 3.2 Backtrace graph extraction &#8227; 3 Method &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. The arrow notation is a symbolic shorthand for graph transitions and is logically equivalent to</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Consider a single reference&#8211;hypothesis pair <math alttext=\"(r,h)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(r,h)</annotation></semantics></math>. We define a valid alignment <math alttext=\"a\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m2\" intent=\":literal\"><semantics><mi>a</mi><annotation encoding=\"application/x-tex\">a</annotation></semantics></math> between the two strings as a sequence of index range pairs, such that <math alttext=\"a_{n}=(i\\!:\\!j,k\\!:\\!l)\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"S2.p2.m3\" intent=\":literal\"><semantics><mrow><msub><mi>a</mi><mi>n</mi></msub><mo>=</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo lspace=\"0.108em\" rspace=\"0.108em\">:</mo><mi>j</mi><mo>,</mo><mi>k</mi><mo lspace=\"0.108em\" rspace=\"0.108em\">:</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">a_{n}=(i\\!:\\!j,k\\!:\\!l)</annotation></semantics></math>. Following the edit distance convention, each mapping may represent an insertion (<math alttext=\"r_{i:j}=\\varepsilon\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m4\" intent=\":literal\"><semantics><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>j</mi></mrow></msub><mo>=</mo><mi>&#949;</mi></mrow><annotation encoding=\"application/x-tex\">r_{i:j}=\\varepsilon</annotation></semantics></math>), deletion (<math alttext=\"h_{k:l}=\\varepsilon\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m5\" intent=\":literal\"><semantics><mrow><msub><mi>h</mi><mrow><mi>k</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>l</mi></mrow></msub><mo>=</mo><mi>&#949;</mi></mrow><annotation encoding=\"application/x-tex\">h_{k:l}=\\varepsilon</annotation></semantics></math>), substitution (<math alttext=\"h_{k:l}\\neq r_{i:j}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m6\" intent=\":literal\"><semantics><mrow><msub><mi>h</mi><mrow><mi>k</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>l</mi></mrow></msub><mo>&#8800;</mo><msub><mi>r</mi><mrow><mi>i</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>j</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">h_{k:l}\\neq r_{i:j}</annotation></semantics></math>), or match (<math alttext=\"h_{k:l}=r_{i:j}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m7\" intent=\":literal\"><semantics><mrow><msub><mi>h</mi><mrow><mi>k</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>l</mi></mrow></msub><mo>=</mo><msub><mi>r</mi><mrow><mi>i</mi><mo lspace=\"0.278em\" rspace=\"0.278em\">:</mo><mi>j</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">h_{k:l}=r_{i:j}</annotation></semantics></math>). Index ranges must increase monotonically between consecutive pairs <math alttext=\"a_{n}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m8\" intent=\":literal\"><semantics><msub><mi>a</mi><mi>n</mi></msub><annotation encoding=\"application/x-tex\">a_{n}</annotation></semantics></math> and <math alttext=\"a_{n+1}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.p2.m9\" intent=\":literal\"><semantics><msub><mi>a</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding=\"application/x-tex\">a_{n+1}</annotation></semantics></math> for both the reference and the hypothesis. Finally, the alignment must cover all voiced characters, while unvoiced characters such as spaces and punctuation can be ignored.</p>\n\n",
                "matched_terms": [
                    "match",
                    "voiced",
                    "deletion",
                    "substitution",
                    "pair",
                    "characters",
                    "insertion",
                    "unvoiced"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, substitutions that occur adjacent to insertions or deletions introduce ambiguity. Returning to the example in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S1.T1\" title=\"Table 1 &#8227; 1 Introduction &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, the Levenshtein-based alignment produces four substitutions and a single deletion. However, any of the reference words could have been labeled as the deletion, yielding five distinct alignments with the same optimal Levenshtein distance. This demonstrates that treating words as canonical units is insufficient when aiming for unambiguous alignment.</p>\n\n",
                "matched_terms": [
                    "deletion",
                    "any",
                    "substitutions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">From the examples above, the lack of character-level information is clearly a key limitation of word-level alignment.\nA better approach is to work fully at the character level, though plain character-level alignment also has drawbacks.\nFirst, our goal is to map each reference word to a corresponding segment of the hypothesis transcript &#8212; something that character-level alignment does not provide.\nSecond, this approach offers no measure of proximity between matched characters within a single word. For example, if a model fails to capture the last letter of a word and proceeds to hallucinate a sequence of words containing the missing letter, it will be erroneously matched to the hallucinated part, resulting in a highly implausible alignment that may span multiple words.</p>\n\n",
                "matched_terms": [
                    "from",
                    "character",
                    "characters"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Word tokens are normalized by lower casing, removing accents, and replacing unvoiced characters, such as apostrophes and hyphens, with a placeholder symbol (<span class=\"ltx_text ltx_font_typewriter\">#</span>). Finally, words are enclosed in angle brackets (i.e., <span class=\"ltx_text ltx_font_typewriter\">&lt;word&gt;</span>), which we use for our ruleset for extracting word-level alignments from character-level input.</p>\n\n",
                "matched_terms": [
                    "from",
                    "unvoiced",
                    "characters"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For graph construction, we adopt a slightly modified version of the standard unit-cost Levenshtein distance by doubling the cost of substitutions. In this formulation, every substitution can equivalently be represented as a deletion&#8211;insertion pair, which has the effect of expanding the backtrace graph. Relaxing the unit-cost constraint on the search space in this way leads to more accurate alignments.</p>\n\n",
                "matched_terms": [
                    "pair",
                    "cost",
                    "substitutions",
                    "substitution"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"c_{c}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m3\" intent=\":literal\"><semantics><msub><mi>c</mi><mi>c</mi></msub><annotation encoding=\"application/x-tex\">c_{c}</annotation></semantics></math> denotes the cumulative cost of <span class=\"ltx_text ltx_font_italic\">closed</span> word-level alignments, <math alttext=\"c_{o}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m4\" intent=\":literal\"><semantics><msub><mi>c</mi><mi>o</mi></msub><annotation encoding=\"application/x-tex\">c_{o}</annotation></semantics></math> is the cost of the current <span class=\"ltx_text ltx_font_italic\">open</span> word-level alignment, and <math alttext=\"i+j+1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m5\" intent=\":literal\"><semantics><mrow><mi>i</mi><mo>+</mo><mi>j</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">i+j+1</annotation></semantics></math> is a normalization term accounting for the number of characters covered thus far. The indicator function <math alttext=\"[(i-k)(j-l)&gt;0]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m6\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>i</mi><mo>&#8722;</mo><mi>k</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>j</mi><mo>&#8722;</mo><mi>l</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mn>0</mn></mrow><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[(i-k)(j-l)&gt;0]</annotation></semantics></math> imposes a penalty by doubling <math alttext=\"c_{o}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m7\" intent=\":literal\"><semantics><msub><mi>c</mi><mi>o</mi></msub><annotation encoding=\"application/x-tex\">c_{o}</annotation></semantics></math> for substitutions, ensuring that dissimilar words are not aligned. Importantly, because this penalty doubles the cost of previous actions accumulated by <math alttext=\"c_{o}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m8\" intent=\":literal\"><semantics><msub><mi>c</mi><mi>o</mi></msub><annotation encoding=\"application/x-tex\">c_{o}</annotation></semantics></math>, the problem does not have an optimal substructure, which is why a strict dynamic programming solution is not possible.</p>\n\n",
                "matched_terms": [
                    "cost",
                    "substitutions",
                    "characters"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"t_{w\\rightarrow v}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p4.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mrow><mi>w</mi><mo stretchy=\"false\">&#8594;</mo><mi>v</mi></mrow></msub><annotation encoding=\"application/x-tex\">t_{w\\rightarrow v}</annotation></semantics></math> is the cost of transitioning from node <math alttext=\"w=(m,n)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p4.m2\" intent=\":literal\"><semantics><mrow><mi>w</mi><mo>=</mo><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo>,</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">w=(m,n)</annotation></semantics></math> to <math alttext=\"v=(i,j)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p4.m3\" intent=\":literal\"><semantics><mrow><mi>v</mi><mo>=</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">v=(i,j)</annotation></semantics></math> and <math alttext=\"[w\\notin V(G_{b})]\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p4.m4\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mrow><mi>w</mi><mo>&#8713;</mo><mrow><mi>V</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mi>b</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[w\\notin V(G_{b})]</annotation></semantics></math> is an indicator function penalizing deviations from the backtrace graph node set.</p>\n\n",
                "matched_terms": [
                    "from",
                    "cost"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For the transition cost, we use a coarse phonemic classification <math alttext=\"P(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p5.m1\" intent=\":literal\"><semantics><mrow><mi>P</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">P(\\cdot)</annotation></semantics></math> by grouping characters into vowels and consonants. In addition, the set of unvoiced characters <math alttext=\"U=\\{\\texttt{&lt;},\\texttt{&gt;},\\texttt{\\#}\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p5.m2\" intent=\":literal\"><semantics><mrow><mi>U</mi><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mtext class=\"ltx_mathvariant_monospace\">&lt;</mtext><mo>,</mo><mtext class=\"ltx_mathvariant_monospace\">&gt;</mtext><mo>,</mo><mtext class=\"ltx_mathvariant_monospace\">#</mtext><mo stretchy=\"false\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">U=\\{\\texttt{&lt;},\\texttt{&gt;},\\texttt{\\#}\\}</annotation></semantics></math> is subject to separate rules:</p>\n\n",
                "matched_terms": [
                    "rules",
                    "transition",
                    "cost",
                    "characters",
                    "unvoiced"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To determine if a segment should be closed, we define a function that is evaluated at each transition and updates <math alttext=\"u\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p7.m1\" intent=\":literal\"><semantics><mi>u</mi><annotation encoding=\"application/x-tex\">u</annotation></semantics></math>, if the alignment is to be concluded. Again, consider a path transitioning from <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p7.m2\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> to <math alttext=\"v\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p7.m3\" intent=\":literal\"><semantics><mi>v</mi><annotation encoding=\"application/x-tex\">v</annotation></semantics></math> with <math alttext=\"u\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p7.m4\" intent=\":literal\"><semantics><mi>u</mi><annotation encoding=\"application/x-tex\">u</annotation></semantics></math> as the end node of the previously recorded alignment. We then have</p>\n\n",
                "matched_terms": [
                    "from",
                    "transition"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Using only insertions and deletions prevents rewarding substitutions where the substrings contain no shared information, since an insert&#8211;delete pair receives the same score. The second term further prevents rewarding alignments for treating words as substitutions when they should be inserted.</p>\n\n",
                "matched_terms": [
                    "pair",
                    "substitutions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To compute the GLE metric, we first sum <math alttext=\"d_{\\text{ID}}(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p4.m1\" intent=\":literal\"><semantics><mrow><msub><mi>d</mi><mtext>ID</mtext></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">d_{\\text{ID}}(\\cdot)</annotation></semantics></math> for all reference-hypothesis pairs in a dataset and divide it by the sum of <math alttext=\"d(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p4.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">d(\\cdot)</annotation></semantics></math> over all individual alignments. We remove all unvoiced characters before evaluation, ensuring that the numerator and denominator are computed over identical strings.</p>\n\n",
                "matched_terms": [
                    "unvoiced",
                    "characters"
                ]
            }
        ]
    },
    "S3.T4.fig1": {
        "source_file": "A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems",
        "caption": "Table 3: English-only evaluation across multiple models and datasets.\\dagger",
        "body": "cv-en",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\"><span class=\"ltx_text ltx_font_smallcaps\">cv-en</span></td>\n</tr>\n</table> \n",
        "informative_terms_identified": [
            "across",
            "models",
            "englishonly",
            "evaluation",
            "multiple",
            "datasetsdagger",
            "cven"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Modern neural networks have greatly improved performance across speech recognition benchmarks. However, gains are often driven by frequent words with limited semantic weight, which can obscure meaningful differences in word error rate, the primary evaluation metric. Errors in rare terms, named entities, and domain-specific vocabulary are more consequential, but remain hidden by aggregate metrics. This highlights the need for finer-grained error analysis, which depends on accurate alignment between reference and model transcripts. However, conventional alignment methods are not designed for such precision. We propose a novel alignment algorithm that couples dynamic programming with beam search scoring. Compared to traditional text alignment methods, our approach provides more accurate alignment of individual errors, enabling reliable error analysis. The algorithm is made available via PyPI.<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>https://github.com/borgholt/error-align</span></span></span></p>\n\n",
                "matched_terms": [
                    "evaluation",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We empirically evaluate the method across multiple models and languages, showing consistent improvements over conventional techniques and previous work.</p>\n\n",
                "matched_terms": [
                    "models",
                    "multiple",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To ensure that the results generalize across model classes, we use four open-source speech recognition models: Whisper (v3, 1.6B) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#bib.bib1\" title=\"\">1</a>]</cite>, Phi-4-multimodal (5.6B) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#bib.bib11\" title=\"\">11</a>]</cite>, Parakeet TDT (v2, 0.6B) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#bib.bib12\" title=\"\">12</a>]</cite>, and Parakeet CTC (0.6B) <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#bib.bib13\" title=\"\">13</a>]</cite>. For the non-English evaluation, we use only Whisper, as it is the only model that supports a sufficiently diverse set of languages.</p>\n\n",
                "matched_terms": [
                    "models",
                    "evaluation",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We proposed a new alignment algorithm that significantly outperforms conventional methods across models, domains, and languages. The implementation is publicly released to support the community in developing and evaluating speech recognition systems.</p>\n\n",
                "matched_terms": [
                    "models",
                    "across"
                ]
            }
        ]
    },
    "S3.T4.fig2": {
        "source_file": "A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems",
        "caption": "Table 4: Multilingual eval. and ablations.\\dagger",
        "body": "Language\n\nCharacter GLE [%] \\uparrow\n\n\n\n\n\nOurs\n\n\n\n\nowa\n\n\nlwa\n\n\nPortuguese\n\n\n78.3\n\n\n\n\n59.2\n\n\n48.1\n\n\nSpanish\n\n\n77.8\n\n\n\n\n60.9\n\n\n53.3\n\n\nTurkish\n\n\n77.7\n\n\n\n\n40.4\n\n\n32.7\n\n\nGerman\n\n\n76.9\n\n\n\n\n47.0\n\n\n40.7\n\n\nPolish\n\n\n76.7\n\n\n\n\n54.0\n\n\n44.9\n\n\nIndonesian\n\n\n76.5\n\n\n\n\n56.5\n\n\n49.5\n\n\nSwahili\n\n\n73.9\n\n\n\n\n45.3\n\n\n34.4\n\n\nFrench\n\n\n73.5\n\n\n\n\n53.6\n\n\n45.4\n\n\n\nAblations: cv-en + whspr\n\n\\Delta\n\n\nEq. (1) w/o substitution pen.\n-4.3\n\n\nEq. (5) w/ unit-cost\n-1.3\n\n\nSearch restricted to GbG_{b}\n\n-2.2",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\"><span class=\"ltx_text ltx_font_italic\">Language</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_text ltx_font_italic\">Character GLE</span> [%] <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T4.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">Ours</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_smallcaps\">owa</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\"><span class=\"ltx_text ltx_font_smallcaps\">lwa</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Portuguese</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">78.3</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">59.2</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">48.1</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Spanish</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">77.8</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">60.9</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">53.3</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Turkish</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">77.7</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">40.4</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">32.7</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">German</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">76.9</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">47.0</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">40.7</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Polish</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">76.7</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">54.0</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">44.9</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Indonesian</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">76.5</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">56.5</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">49.5</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Swahili</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">73.9</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">45.3</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">34.4</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">French</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">73.5</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">53.6</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">45.4</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" colspan=\"3\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">\n<span class=\"ltx_text ltx_font_italic\">Ablations</span>: <span class=\"ltx_text ltx_font_smallcaps\">cv-en</span> + <span class=\"ltx_text ltx_font_smallcaps\">whspr</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\"><math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T4.m6\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#916;</mi><annotation encoding=\"application/x-tex\">\\Delta</annotation></semantics></math></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\" colspan=\"3\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Eq. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S3.E1\" title=\"In 3.3 Path scoring &#8227; 3 Method &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>) w/o substitution pen.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">-4.3</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\" colspan=\"3\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Eq. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S3.E5\" title=\"In 3.3 Path scoring &#8227; 3 Method &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>) w/ unit-cost</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">-1.3</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r\" colspan=\"3\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Search restricted to <math alttext=\"G_{b}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T4.m7\" intent=\":literal\"><semantics><msub><mi>G</mi><mi>b</mi></msub><annotation encoding=\"application/x-tex\">G_{b}</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">-2.2</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "french",
            "gbgb",
            "ours",
            "german",
            "swahili",
            "restricted",
            "turkish",
            "owa",
            "ablationsdagger",
            "multilingual",
            "language",
            "whspr",
            "portuguese",
            "pen",
            "cven",
            "uparrow",
            "unitcost",
            "spanish",
            "character",
            "ablations",
            "eval",
            "substitution",
            "gle",
            "search",
            "polish",
            "delta",
            "lwa",
            "indonesian"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">We find that an unrestricted search over the entire graph is computationally infeasible. To prioritize the most promising paths, we introduce a penalty term when a path deviates from the backtrace graph <math alttext=\"G_{b}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\"><semantics><msub><mi>G</mi><mi>b</mi></msub><annotation encoding=\"application/x-tex\">G_{b}</annotation></semantics></math>, which substantially improves both the robustness and efficiency of the beam search.</p>\n\n",
                "matched_terms": [
                    "search",
                    "gbgb"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For graph construction, we adopt a slightly modified version of the standard unit-cost Levenshtein distance by doubling the cost of substitutions. In this formulation, every substitution can equivalently be represented as a deletion&#8211;insertion pair, which has the effect of expanding the backtrace graph. Relaxing the unit-cost constraint on the search space in this way leads to more accurate alignments.</p>\n\n",
                "matched_terms": [
                    "search",
                    "substitution",
                    "unitcost"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S3.T4\" title=\"Table 4 &#8227; 3.3 Path scoring &#8227; 3 Method &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> (bottom) further highlights the benefit of key algorithmic choices. While each choice improves performance, the largest gain results from eliminating the one-to-one constraint of word-level alignment, discussed in section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S2.SS2\" title=\"2.2 Failure cases of word-level Levenshtein &#8227; 2 Background and Challenges &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">2.2</span></a>, as seen by the difference between our approach and the <span class=\"ltx_text ltx_font_smallcaps\">owa</span> baseline (-13.0, <span class=\"ltx_text ltx_font_smallcaps\">cv-en</span> + <span class=\"ltx_text ltx_font_smallcaps\">whspr</span>, Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.24478v1#S3.T4\" title=\"Table 4 &#8227; 3.3 Path scoring &#8227; 3 Method &#8227; A text-to-text Alignment Algorithm for better evaluation of modern speech recognition systems\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>).</p>\n\n",
                "matched_terms": [
                    "cven",
                    "whspr",
                    "owa"
                ]
            }
        ]
    }
}