{
    "S3.T1": {
        "source_file": "Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations",
        "caption": "Table 1: The non-refusal rate (NRR, %) and unsafe rate (UR, %) of the investigated LALMs. “Text-only” denotes results obtained by directly using the original textual queries instead of synthesized speech instructions. “μ\\mu,” “σ\\sigma,” and “Δ\\Delta” indicate the average, standard deviation, and range (maximum minus minimum) of the metrics across the six emotions. For each metric, the highest values across the six emotions are highlighted in bold, and the second-highest values are underlined.",
        "body": "Models\nText-only (↓\\downarrow)\nNeutral (↓\\downarrow)\nAngry (↓\\downarrow)\nDisgusted (↓\\downarrow)\nFear (↓\\downarrow)\nHappy (↓\\downarrow)\nSad (↓\\downarrow)\n\nμ\\mu (↓\\downarrow)\n\n\nσ\\sigma (↓\\downarrow)\n\n\nΔ\\Delta (↓\\downarrow)\n\n\n\nNon-refusal Rate (NRR) (%)\n\n\nQwen2-Audio\n0.96\n6.92\n2.95\n4.87\n5.51\n4.94\n4.68\n4.98\n1.29\n3.97\n\n\nQwen2.5-Omni\n1.92\n0.38\n0.13\n0.64\n0.70\n0.70\n0.32\n0.48\n0.24\n0.57\n\n\nDeSTA2.5-Audio\n2.69\n2.88\n1.73\n3.59\n3.14\n3.97\n2.18\n2.92\n0.84\n2.24\n\n\nSALMONN 7B\n19.81\n82.69\n91.28\n86.60\n89.61\n86.19\n85.32\n86.95\n3.08\n8.59\n\n\nSALMONN 13B\n30.38\n79.62\n71.47\n75.77\n74.04\n76.80\n73.46\n75.19\n2.85\n8.15\n\n\nTyphoon-audio\n56.35\n84.23\n78.72\n78.65\n79.74\n78.01\n78.21\n79.59\n2.35\n6.22\n\n\nSpeechGPT\n8.85\n34.62\n22.31\n30.39\n30.77\n28.98\n30.58\n29.61\n4.04\n12.31\n\n\nMiniCPM-o-2.6\n1.15\n5.19\n23.72\n9.61\n10.32\n7.31\n4.62\n10.13\n7.04\n19.10\n\n\nGemini-1.5-flash\n2.88\n3.65\n3.97\n4.49\n4.04\n4.74\n3.78\n4.11\n0.42\n1.09\n\n\nGemini-2.0-flash\n1.92\n8.46\n9.49\n13.01\n9.81\n11.03\n7.82\n9.94\n1.87\n5.19\n\n\nUnsafe Rate (UR) (%)\n\n\nQwen2-Audio\n2.31\n1.54\n1.15\n2.11\n1.47\n1.99\n2.76\n1.84\n0.57\n1.61\n\n\nQwen2.5-Omni\n0.96\n0.19\n0.13\n0.25\n0.26\n0.25\n0.38\n0.24\n0.08\n0.25\n\n\nDeSTA2.5-Audio\n2.88\n0.38\n0.38\n0.64\n1.03\n0.71\n0.83\n0.66\n0.26\n0.65\n\n\nSALMONN 7B\n23.65\n34.23\n22.31\n28.08\n21.73\n32.18\n30.19\n28.12\n5.15\n12.50\n\n\nSALMONN 13B\n48.46\n72.88\n70.77\n81.03\n72.88\n71.15\n72.56\n73.55\n3.78\n10.26\n\n\nTyphoon-audio\n45.19\n64.04\n71.79\n67.76\n67.50\n68.85\n69.29\n68.21\n2.55\n7.75\n\n\nSpeechGPT\n19.04\n17.50\n12.82\n14.87\n14.36\n14.48\n16.35\n15.06\n1.64\n4.68\n\n\nMiniCPM-o-2.6\n1.15\n3.27\n8.01\n5.58\n4.62\n4.68\n3.14\n4.88\n1.79\n4.87\n\n\nGemini-1.5-flash\n2.12\n1.73\n3.01\n3.14\n2.63\n3.14\n1.99\n2.61\n0.61\n1.41\n\n\nGemini-2.0-flash\n1.35\n3.08\n2.76\n4.81\n2.89\n3.98\n2.82\n3.39\n0.83\n2.05",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Models</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Text-only (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m7\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Neutral (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m8\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Angry (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m9\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Disgusted (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m10\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Fear (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m11\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Happy (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m12\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Sad (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m13\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\">\n<math alttext=\"\\mu\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m14\" intent=\":literal\"><semantics><mi mathsize=\"0.900em\">&#956;</mi><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\"> (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m15\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\">\n<math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m16\" intent=\":literal\"><semantics><mi mathsize=\"0.900em\">&#963;</mi><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\"> (</span><math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m17\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\">)</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\">\n<math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m18\" intent=\":literal\"><semantics><mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi><annotation encoding=\"application/x-tex\">\\Delta</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\"> (</span><math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m19\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\">)</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"11\"><span class=\"ltx_text\" style=\"font-size:90%;\">Non-refusal Rate (NRR) (%)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2-Audio</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.96</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">6.92</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.95</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.87</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">5.51</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.94</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.68</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.98</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.29</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.97</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2.5-Omni</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.92</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.38</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">0.64</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.70</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.70</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.32</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.48</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.24</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.57</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">DeSTA2.5-Audio</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.69</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.88</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.73</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">3.59</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.14</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.97</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.18</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.92</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.84</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.24</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">SALMONN 7B</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">19.81</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">82.69</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">91.28</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">86.60</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">89.61</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">86.19</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.32</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">86.95</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.08</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">8.59</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">SALMONN 13B</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">30.38</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">79.62</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">71.47</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">75.77</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">74.04</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">76.80</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">73.46</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">75.19</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.85</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">8.15</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Typhoon-audio</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">56.35</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">84.23</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.72</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.65</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">79.74</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.01</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.21</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">79.59</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.35</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">6.22</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">SpeechGPT</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">8.85</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">34.62</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">22.31</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">30.39</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">30.77</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">28.98</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">30.58</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">29.61</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.04</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">12.31</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">MiniCPM-o-2.6</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.15</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.19</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">23.72</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">9.61</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">10.32</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">7.31</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.62</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">10.13</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">7.04</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">19.10</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini-1.5-flash</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.88</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.65</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.97</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">4.49</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.04</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">4.74</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.78</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.11</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.42</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.09</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini-2.0-flash</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.92</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">8.46</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">9.49</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">13.01</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">9.81</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">11.03</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">7.82</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">9.94</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.87</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.19</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"11\"><span class=\"ltx_text\" style=\"font-size:90%;\">Unsafe Rate (UR) (%)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2-Audio</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.31</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.54</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.15</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">2.11</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.47</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.99</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">2.76</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.84</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.57</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.61</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2.5-Omni</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.96</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.19</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.13</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.25</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">0.26</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.25</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.38</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.24</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.08</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.25</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">DeSTA2.5-Audio</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.88</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.38</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.38</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.64</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">1.03</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.71</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">0.83</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.66</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.26</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.65</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">SALMONN 7B</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">23.65</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">34.23</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">22.31</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">28.08</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">21.73</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">32.18</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">30.19</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">28.12</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.15</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">12.50</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">SALMONN 13B</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">48.46</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">72.88</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.77</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">81.03</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">72.88</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">71.15</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">72.56</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">73.55</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.78</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">10.26</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Typhoon-audio</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">45.19</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">64.04</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">71.79</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">67.76</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">67.50</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">68.85</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">69.29</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">68.21</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.55</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">7.75</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">SpeechGPT</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">19.04</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">17.50</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">12.82</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">14.87</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">14.36</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">14.48</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">16.35</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">15.06</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.64</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.68</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">MiniCPM-o-2.6</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.15</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.27</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">8.01</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">5.58</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.62</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.68</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.14</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.88</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.79</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.87</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini-1.5-flash</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.12</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.73</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">3.01</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.14</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.63</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.14</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.99</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.61</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.61</span></td>\n<td class=\"ltx_td ltx_align_right\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.41</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini-2.0-flash</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.35</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.08</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.76</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">4.81</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.89</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">3.98</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.82</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.39</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.83</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.05</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "nonrefusal",
            "original",
            "angry",
            "obtained",
            "speech",
            "maximum",
            "underlined",
            "qwen25omni",
            "“μmu”",
            "neutral",
            "qwen2audio",
            "instead",
            "metric",
            "fear",
            "range",
            "“δdelta”",
            "secondhighest",
            "minicpmo26",
            "denotes",
            "investigated",
            "disgusted",
            "rate",
            "minus",
            "results",
            "“textonly”",
            "lalms",
            "each",
            "queries",
            "σsigma",
            "bold",
            "instructions",
            "metrics",
            "salmonn",
            "synthesized",
            "deviation",
            "13b",
            "↓downarrow",
            "desta25audio",
            "gemini15flash",
            "minimum",
            "sad",
            "δdelta",
            "μmu",
            "emotions",
            "average",
            "happy",
            "directly",
            "unsafe",
            "standard",
            "highest",
            "gemini20flash",
            "highlighted",
            "speechgpt",
            "across",
            "indicate",
            "typhoonaudio",
            "nrr",
            "textual",
            "models",
            "six",
            "“σsigma”",
            "values",
            "textonly"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We present the main results in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S3.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 3.2 Speech Query Synthesis &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The models show a clear dichotomy: a relatively safer group with lower NRR and UR (Qwen2-Audio, Qwen2.5-Omni, DeSTA2.5-Audio, MiniCPM-o-2.6, Gemini series) and a less safe group (SALMONN 7B and 13B, Typhoon-audio, SpeechGPT). This division indicates that the inherent safety alignment of certain models remains insufficiently robust.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Large audio-language models (LALMs) extend text-based LLMs with auditory understanding, offering new opportunities for multimodal applications. While their perception, reasoning, and task performance have been widely studied, their safety alignment under paralinguistic variation remains underexplored. This work systematically investigates the role of speaker emotion. We construct a dataset of malicious speech instructions expressed across multiple emotions and intensities, and evaluate several state-of-the-art LALMs. Our results reveal substantial safety inconsistencies: different emotions elicit varying levels of unsafe responses, and the effect of intensity is non-monotonic, with medium expressions often posing the greatest risk. These findings highlight an overlooked vulnerability in LALMs and call for alignment strategies explicitly designed to ensure robustness under emotional variation, a prerequisite for trustworthy deployment in real-world settings.</span>\n</p>\n\n",
                "matched_terms": [
                    "across",
                    "models",
                    "speech",
                    "results",
                    "emotions",
                    "lalms",
                    "unsafe",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Recent advances in large language models (LLMs)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib2\" title=\"\">2</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> have revolutionized AI research, extending their impact to speech processing&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib4\" title=\"\">4</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. In particular, large audio-language models (LALMs)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib5\" title=\"\">5</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib6\" title=\"\">6</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib7\" title=\"\">7</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib8\" title=\"\">8</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib9\" title=\"\">9</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib10\" title=\"\">10</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib11\" title=\"\">11</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib12\" title=\"\">12</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib15\" title=\"\">15</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib16\" title=\"\">16</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> augment text-based LLMs with auditory understanding, opening new possibilities for multimodal models and speech technologies.</span>\n</p>\n\n",
                "matched_terms": [
                    "models",
                    "speech",
                    "lalms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Investigating whether emotions can trigger safety vulnerabilities is essential for two reasons. First, if certain emotional expressions consistently elicit harmful behaviors, they may provide a new pathway for </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">jailbreaking</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib30\" title=\"\">30</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where models are manipulated to bypass safety guardrails. Second, even when users act in good faith, they may unintentionally provoke unsafe responses from LALMs, which could in turn lead to real-world social harms.</span>\n</p>\n\n",
                "matched_terms": [
                    "unsafe",
                    "emotions",
                    "models",
                    "lalms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Motivated by this, we systematically investigate how speaker emotion affects LALM safety. We construct a dataset of malicious speech instructions synthesized with a text-to-speech model&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib31\" title=\"\">31</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> under controlled conditions: each instruction is expressed across multiple emotions and intensities, with semantic content and speaker identity held identical. Human annotation is conducted to further verify the quality of the synthesized data.</span>\n</p>\n\n",
                "matched_terms": [
                    "synthesized",
                    "across",
                    "speech",
                    "emotions",
                    "each",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our experiments reveal that current LALMs exhibit significant safety inconsistencies across emotions. Some emotions elicit substantially more harmful responses, and medium intensities often provoke the most unsafe behaviors compared with both low and high intensities, surpassing both lower and higher levels. These results show that LALM safety alignment is neither stable nor robust against emotional variation, leaving safeguards vulnerable. Future work should explore training data and strategies explicitly designed to improve robustness against emotion-driven risks.</span>\n</p>\n\n",
                "matched_terms": [
                    "across",
                    "results",
                    "emotions",
                    "lalms",
                    "unsafe"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Overall, our contributions are: (1) the first study to examine the interaction between speakers&#8217; emotions and the safety alignment of LALMs, and (2) uncovering the inconsistency of LALMs&#8217; safety alignment under emotional variations, where certain emotions and intensities disproportionately provoke unsafe and harmful responses. Our dataset is available at </span>\n  <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/LALM-emotional-vulnerability\" style=\"font-size:90%;\" title=\"\">https://huggingface.co/LALM-emotional-vulnerability</a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "unsafe",
                    "emotions",
                    "lalms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Prior studies have examined how the safety alignment of LALMs can be compromised through the speech modality. Yang et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib26\" title=\"\">26</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> show that LALMs are more susceptible to safety failures from spoken inputs than from textual inputs with the same semantic content. Xiao et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Hughes et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib28\" title=\"\">28</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrate that paralinguistic and acoustic cues such as tone, emphasis, speaking rate, and noises can further destabilize model behavior. Roh et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib29\" title=\"\">29</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> investigate jailbreak attempts that exploit variations in languages and accents of spoken instructions. There are also several benchmarks assessing the safety alignment of LALMs&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib32\" title=\"\">32</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib33\" title=\"\">33</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nHowever, these efforts do not provide a systematic study of how emotional cues may introduce safety vulnerabilities, despite emotion being a central component of human communication. This gap motivates this study.</span>\n</p>\n\n",
                "matched_terms": [
                    "textual",
                    "rate",
                    "speech",
                    "lalms",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We describe the dataset construction process, illustrated in Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S2.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 2 Related Work &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, to analyze the safety vulnerabilities of LALMs under different speaker emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "emotions",
                    "lalms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The dataset construction process consists of three phases: (1) </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">harmful query collection</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where we first gather harmful queries, (2) </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">speech query synthesis</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where the collected queries are verbalized as emotional speech using a text-to-speech (TTS) model, and (3) </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">human annotation</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where annotators label both the emotion and its corresponding intensity for subsequent analysis. The details of these phases are described in the following subsections.</span>\n</p>\n\n",
                "matched_terms": [
                    "queries",
                    "speech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We begin by collecting harmful queries to synthesize malicious speech instructions. Harmful queries are prompts that request unsafe information or actions, such as instructions for producing illegal drugs. Following prior work&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib26\" title=\"\">26</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib27\" title=\"\">27</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib32\" title=\"\">32</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we adopt AdvBench&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib34\" title=\"\">34</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which contains 520 textual queries across five security categories: misinformation, disinformation, toxicity, spam, and sensitive information. Its diversity and broad use in LLM safety research&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib35\" title=\"\">35</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> make it a suitable basis for our study.</span>\n</p>\n\n",
                "matched_terms": [
                    "across",
                    "queries",
                    "textual",
                    "speech",
                    "unsafe",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We employ CosyVoice 2 0.5B&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib31\" title=\"\">31</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as the TTS model to synthesize emotional speech instructions from the harmful queries collected in AdvBench. The speech instructions are generated in six emotions: neutral, angry, disgusted, fearful, happy, and sad. To ensure that the synthesized instructions express the intended emotions, we use CREMA-D&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib36\" title=\"\">36</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as the reference dataset. CREMA-D provides detailed annotations for both emotion categories (the six emotions above) and emotion levels (low, medium, high, and unspecified).</span>\n</p>\n\n",
                "matched_terms": [
                    "synthesized",
                    "angry",
                    "disgusted",
                    "speech",
                    "sad",
                    "six",
                    "neutral",
                    "emotions",
                    "happy",
                    "queries",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Specifically, given a textual query, we synthesize emotional speech instructions by sampling a reference speech from CREMA-D for each non-neutral emotion and each specified intensity level, while keeping speaker characteristics fixed. For the neutral case, a neutral reference sample is used. Each synthesized sample is then manually verified for naturalness, emotional expressiveness, and correctness of the annotated emotion level, as detailed in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S3.SS3\" style=\"font-size:90%;\" title=\"3.3 Human Annotation &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3.3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "synthesized",
                    "textual",
                    "speech",
                    "neutral",
                    "each",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To ensure that the synthesized speech instructions accurately convey the intended emotions and intensity levels, we conduct a manual inspection. Each annotator is instructed to (1) check that the speech is natural and free from noticeable artifacts, (2) verify whether the synthesized speech faithfully represents the original textual query, and (3) assign both an emotion label (among the six defined categories) and an intensity label (low, medium, or high).</span>\n</p>\n\n",
                "matched_terms": [
                    "original",
                    "synthesized",
                    "textual",
                    "speech",
                    "six",
                    "emotions",
                    "each",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Each synthesized speech instruction is annotated by at least three annotators and retained only if they unanimously agree on the emotion and intensity (except neutral). Otherwise, it is re-synthesized and re-annotated until consensus is reached.</span>\n</p>\n\n",
                "matched_terms": [
                    "neutral",
                    "speech",
                    "synthesized",
                    "each"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The finalized dataset contains 8,320 malicious speech instructions, comprising 520 instructions with neutral emotion and 520</span>\n  <math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">&#215;</mo>\n      <annotation encoding=\"application/x-tex\">\\times</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">3 instructions for each of the other emotions, corresponding to the three intensity levels (low, medium, and high). Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S3.SS4\" style=\"font-size:90%;\" title=\"3.4 Dataset Statistics &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3.4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> reports the statistics of the word counts in the original text prompts and the duration statistics of the generated speech samples across different emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "original",
                    "across",
                    "speech",
                    "neutral",
                    "emotions",
                    "each",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this work, we investigate how speaker emotions affect the safety alignment of several representative LALMs, including both open-source and proprietary models. The open-source set comprises Qwen2-Audio&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib5\" title=\"\">5</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, Qwen2.5-Omni&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib6\" title=\"\">6</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, DeSTA2.5-Audio&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib8\" title=\"\">8</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, SALMONN&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib7\" title=\"\">7</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (7B and 13B), Typhoon-audio&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib9\" title=\"\">9</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, SpeechGPT&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib10\" title=\"\">10</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and MiniCPM-o-2.6&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib11\" title=\"\">11</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while the proprietary set includes Gemini-1.5-flash&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Gemini-2.0-flash&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib13\" title=\"\">13</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This broad coverage makes our analysis both comprehensive and representative. We provide the models with speech instructions along with a text prompt requiring them to respond to the speech. For comparison, we also evaluate a text-only setup, where the original text queries are given without speech. All experiments use greedy decoding.</span>\n</p>\n\n",
                "matched_terms": [
                    "gemini20flash",
                    "original",
                    "lalms",
                    "salmonn",
                    "speechgpt",
                    "minicpmo26",
                    "13b",
                    "typhoonaudio",
                    "desta25audio",
                    "models",
                    "speech",
                    "gemini15flash",
                    "qwen25omni",
                    "emotions",
                    "qwen2audio",
                    "queries",
                    "textonly",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Following prior work&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib37\" title=\"\">37</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib38\" title=\"\">38</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we adopt two metrics to evaluate the safety alignment of LALMs&#8217; responses: </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">non-refusal rate (NRR)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">unsafe rate (UR)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, as shown in Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S2.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 2 Related Work &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Both measure the extent to which models behave unsafely, but they differ in how &#8220;unsafe&#8221; is defined. The NRR is computed through pattern matching for typical refusal expressions such as &#8220;I am sorry&#8221; or &#8220;I cannot do this.&#8221; Responses that lack these refusal patterns are considered to accept and follow the malicious instructions, and are thus judged unsafe.</span>\n</p>\n\n",
                "matched_terms": [
                    "nonrefusal",
                    "nrr",
                    "rate",
                    "models",
                    "instructions",
                    "unsafe",
                    "metrics"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">However, this pattern-matching approach captures only superficial refusals and overlooks the actual semantics of the responses. To address this, we employ the UR metric, which uses the LLM-as-a-judge framework&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib39\" title=\"\">39</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> to evaluate whether the response content is unsafe. Specifically, we adopt GPT-4o</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\">\n    <sup class=\"ltx_note_mark\">1</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>gpt-4o-2024-08-06</span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib1\" title=\"\">1</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as the judge to assess whether a response (1) follows the malicious query and (2) provides harmful or unsafe information. This ensures that only responses containing genuinely harmful content are classified as unsafe.</span>\n</p>\n\n",
                "matched_terms": [
                    "unsafe",
                    "metric"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Finally, both NRR and UR are calculated as the proportion of queries in our dataset that elicit unsafe responses, according to the respective definitions of &#8220;unsafe&#8221; used in each metric. By comparing these metrics across instructions with different emotions and intensities, we quantify the extent to which the safety alignment of LALMs is influenced by speaker emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "across",
                    "nrr",
                    "instructions",
                    "emotions",
                    "unsafe",
                    "lalms",
                    "each",
                    "queries",
                    "metric",
                    "metrics"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">When comparing performance across modalities, we find that most models exhibit higher NRR and UR under speech instructions (averaged across six emotions) than under text-only instructions. For example, SALMONN 7B shows an increase of 67.14% in NRR and 4.47% in UR when inputs shift from text to speech. This pattern indicates that the safety alignment of current LALMs is more vulnerable in the speech modality than in the textual modality, consistent with the findings of Yang et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib26\" title=\"\">26</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Ensuring that the safety alignment established in text-based LLMs is preserved during adaptation to speech, therefore, emerges as a critical direction for future work.</span>\n</p>\n\n",
                "matched_terms": [
                    "salmonn",
                    "across",
                    "nrr",
                    "textual",
                    "models",
                    "speech",
                    "six",
                    "emotions",
                    "lalms",
                    "textonly",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Within the speech modality, many models show substantial safety discrepancies across emotions, as indicated by large standard deviations (</span>\n  <math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#963;</mi>\n      <annotation encoding=\"application/x-tex\">\\sigma</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) and ranges (</span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">). These discrepancies highlight the instability of model safety under emotionally varied inputs. For example, SALMONN 7B and 13B display marked variability, with </span>\n  <math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#963;</mi>\n      <annotation encoding=\"application/x-tex\">\\sigma</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> values of 3.08% and 2.85% for NRR and 5.15% and 3.78% for UR, together with </span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m4\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> values of 8.59% and 8.15% for NRR and 12.50% and 10.26% for UR. Such pronounced fluctuations suggest that the safety alignment of these models is highly sensitive to emotional cues, exposing potential vulnerabilities to both deliberate adversarial exploitation and inadvertent triggering of unsafe behaviors.</span>\n</p>\n\n",
                "matched_terms": [
                    "salmonn",
                    "across",
                    "13b",
                    "nrr",
                    "models",
                    "speech",
                    "δdelta",
                    "standard",
                    "emotions",
                    "values",
                    "unsafe",
                    "σsigma"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Crucially, this instability is not limited to relatively unsafe models. Even models with lower overall risk levels can fluctuate across emotions. For instance, MiniCPM-o-2.6 shows considerable </span>\n  <math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#963;</mi>\n      <annotation encoding=\"application/x-tex\">\\sigma</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> values for both metrics, despite maintaining moderately low mean scores. Likewise, Qwen2-Audio and Gemini-2.0-flash yield </span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> values that are comparable to their average NRRs and URs, indicating that safety alignment can remain unstable under emotional variation even when models appear sufficiently safe on average.</span>\n</p>\n\n",
                "matched_terms": [
                    "gemini20flash",
                    "across",
                    "minicpmo26",
                    "models",
                    "δdelta",
                    "emotions",
                    "average",
                    "values",
                    "qwen2audio",
                    "unsafe",
                    "σsigma",
                    "metrics"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Finally, no single emotion consistently induces unsafe behavior across all models. Instead, each model reveals its own blind spot, namely a particular emotion that tends to trigger unsafe behaviors, suggesting that such variability is an inherent characteristic of current LALMs. These findings underscore the necessity of rigorously assessing safety instability before real-world deployment, in order to better understand model behavior and to guide the development of effective filtering and safeguarding mechanisms.</span>\n</p>\n\n",
                "matched_terms": [
                    "across",
                    "models",
                    "unsafe",
                    "lalms",
                    "each",
                    "instead"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S5.SS1\" style=\"font-size:90%;\" title=\"5.1 Main Results &#8227; 5 Results &#8227; 4.2 Evaluation Metrics &#8227; 4 Experimental Setups &#8227; 3.4 Dataset Statistics &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">5.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we observed that emotions can induce notable safety fluctuations and instabilities. A natural follow-up question is whether the intensity of emotional expression also plays a role. Since certain emotions already elicit more unsafe responses than others, it is reasonable to hypothesize that stronger intensities of these emotions may further amplify unsafe behaviors. In this section, we empirically investigate this hypothesis.</span>\n</p>\n\n",
                "matched_terms": [
                    "unsafe",
                    "emotions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Given that the UR metric provides a more comprehensive assessment than the NRR metric by incorporating the semantic content of model responses, we focus our analysis on UR in this section. As described in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S3\" style=\"font-size:90%;\" title=\"3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, the dataset includes synthesized speech queries at three intensity levels. For each model, we examine the non-neutral emotion</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\">\n    <sup class=\"ltx_note_mark\">2</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>We exclude the neutral emotion from this analysis, as it lacks defined and annotated intensity levels.</span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> that produces the highest UR value to assess the impact of emotional intensity on safety alignment. The resulting URs across different intensity levels for these emotions are presented in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S5.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 5.2 Effects of Emotion Intensity Levels &#8227; 5 Results &#8227; 4.2 Evaluation Metrics &#8227; 4 Experimental Setups &#8227; 3.4 Dataset Statistics &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "synthesized",
                    "across",
                    "nrr",
                    "speech",
                    "neutral",
                    "emotions",
                    "each",
                    "queries",
                    "metric",
                    "highest"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We first observe that, beyond the variation across different emotions, some models also display substantial instability across different intensity levels of the same emotion. For instance, SALMONN 13B and MiniCPM-o-2.6 show large values of </span>\n  <math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#963;</mi>\n      <annotation encoding=\"application/x-tex\">\\sigma</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, indicating pronounced fluctuations between low, medium, and high intensities.</span>\n</p>\n\n",
                "matched_terms": [
                    "salmonn",
                    "across",
                    "minicpmo26",
                    "13b",
                    "models",
                    "δdelta",
                    "emotions",
                    "values",
                    "σsigma"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Contrary to our initial hypothesis, however, the results reveal that most LALMs reach their highest URs at medium intensity rather than at high intensity. This suggests that while certain emotions are indeed effective at inducing unsafe behavior, stronger expressions of those emotions do not necessarily further increase the likelihood of unsafe responses. Instead, medium-intensity expressions appear to elicit the most harmful responses.</span>\n</p>\n\n",
                "matched_terms": [
                    "results",
                    "emotions",
                    "lalms",
                    "unsafe",
                    "instead",
                    "highest"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Finally, different models exhibit distinct patterns. For example, Qwen2.5-Omni remains stable across intensities, whereas MiniCPM-o-2.6 is highly sensitive to high-intensity emotions, showing markedly higher UR compared with lower levels.</span>\n</p>\n\n",
                "matched_terms": [
                    "across",
                    "minicpmo26",
                    "models",
                    "qwen25omni",
                    "emotions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Emotion is a crucial component of both human communication and human-AI interaction. In this work, we investigate whether emotions can induce safety vulnerabilities in LALMs. By evaluating several current LALMs with malicious speech instructions that share identical semantic content and speaker characteristics but differ in emotional expressions and intensities, we systematically uncover instabilities in their safety alignment under emotional cues.</span>\n</p>\n\n",
                "matched_terms": [
                    "emotions",
                    "speech",
                    "instructions",
                    "lalms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We find that LALMs&#8217; safety alignment varies substantially across emotions: some emotions elicit far more unsafe behaviors than others. However, even when an emotion induces such vulnerability, stronger expressions do not necessarily make models more unsafe. Instead, moderate intensities often pose the greatest risk. These findings highlight an inherent instability of LALMs under emotional cues, posing challenges for safe deployment if not properly understood and mitigated. Our study takes a first step toward uncovering this instability. Further investigation is needed to uncover the causes of this instability and explore possible mitigation strategies, which we consider an important direction for future work.</span>\n</p>\n\n",
                "matched_terms": [
                    "across",
                    "models",
                    "emotions",
                    "lalms",
                    "unsafe",
                    "instead"
                ]
            }
        ]
    },
    "S3.SS4.tab1": {
        "source_file": "Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations",
        "caption": "Table 2: Statistics of the word counts in original text prompts and the durations (seconds) of the speech instructions. AVG and SD denote the average and the standard deviation.",
        "body": "\\rowcolorgray!30      Textual Queries\n\n\n\nDataset\n# of Samples\nMax\nMin\nAVG\nSD\n\n\nAdvBench\n520\n25\n6\n12.10\n2.81\n\n\n\n\\rowcolorgray!30      Speech Instructions\n\n\n\nEmotion\n# of Samples\nMax\nMin\nAVG\nSD\n\n\nNeutral\n520\n13.20\n3.04\n7.41\n1.74\n\n\nAngry\n1560\n14.28\n3.04\n7.41\n1.74\n\n\nDisgusted\n1560\n16.80\n2.96\n8.35\n2.09\n\n\nFearful\n1560\n14.40\n2.92\n6.98\n1.80\n\n\nHappy\n1560\n14.96\n2.52\n7.17\n2.07\n\n\nSad\n1560\n15.20\n2.80\n6.99\n1.87\n\n\nTotal\n8320\n16.80\n2.52\n7.34\n1.98",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" colspan=\"6\">\n<span class=\"ltx_ERROR undefined\">\\rowcolor</span><span class=\"ltx_text\" style=\"font-size:90%;\">gray!30 &#8194;&#8198;&#8194;&#8198; Textual Queries</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Dataset</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\"># of Samples</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Max</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Min</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">AVG</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SD</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">AdvBench</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">520</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">25</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">12.10</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.81</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"6\">\n<span class=\"ltx_ERROR undefined\">\\rowcolor</span><span class=\"ltx_text\" style=\"font-size:90%;\">gray!30 &#8194;&#8198;&#8194;&#8198; Speech Instructions</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Emotion</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\"># of Samples</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Max</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Min</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">AVG</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SD</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Neutral</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">520</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">13.20</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.04</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">7.41</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.74</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Angry</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1560</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">14.28</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.04</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">7.41</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.74</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Disgusted</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1560</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">16.80</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.96</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">8.35</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.09</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Fearful</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1560</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">14.40</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.92</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">6.98</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.80</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Happy</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1560</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">14.96</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.52</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">7.17</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.07</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\"><span class=\"ltx_text\" style=\"font-size:90%;\">Sad</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1560</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">15.20</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.80</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">6.99</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.87</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Total</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">8320</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">16.80</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.52</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">7.34</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.98</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "original",
            "angry",
            "speech",
            "rowcolorgray30",
            "neutral",
            "emotion",
            "fearful",
            "avg",
            "text",
            "samples",
            "disgusted",
            "total",
            "min",
            "statistics",
            "seconds",
            "max",
            "queries",
            "instructions",
            "deviation",
            "sad",
            "durations",
            "advbench",
            "average",
            "happy",
            "standard",
            "dataset",
            "counts",
            "word",
            "textual",
            "denote",
            "prompts"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Large audio-language models (LALMs) extend text-based LLMs with auditory understanding, offering new opportunities for multimodal applications. While their perception, reasoning, and task performance have been widely studied, their safety alignment under paralinguistic variation remains underexplored. This work systematically investigates the role of speaker emotion. We construct a dataset of malicious speech instructions expressed across multiple emotions and intensities, and evaluate several state-of-the-art LALMs. Our results reveal substantial safety inconsistencies: different emotions elicit varying levels of unsafe responses, and the effect of intensity is non-monotonic, with medium expressions often posing the greatest risk. These findings highlight an overlooked vulnerability in LALMs and call for alignment strategies explicitly designed to ensure robustness under emotional variation, a prerequisite for trustworthy deployment in real-world settings.</span>\n</p>\n\n",
                "matched_terms": [
                    "speech",
                    "emotion",
                    "dataset",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Motivated by this, we systematically investigate how speaker emotion affects LALM safety. We construct a dataset of malicious speech instructions synthesized with a text-to-speech model&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib31\" title=\"\">31</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> under controlled conditions: each instruction is expressed across multiple emotions and intensities, with semantic content and speaker identity held identical. Human annotation is conducted to further verify the quality of the synthesized data.</span>\n</p>\n\n",
                "matched_terms": [
                    "speech",
                    "emotion",
                    "dataset",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Prior studies have examined how the safety alignment of LALMs can be compromised through the speech modality. Yang et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib26\" title=\"\">26</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> show that LALMs are more susceptible to safety failures from spoken inputs than from textual inputs with the same semantic content. Xiao et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Hughes et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib28\" title=\"\">28</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrate that paralinguistic and acoustic cues such as tone, emphasis, speaking rate, and noises can further destabilize model behavior. Roh et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib29\" title=\"\">29</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> investigate jailbreak attempts that exploit variations in languages and accents of spoken instructions. There are also several benchmarks assessing the safety alignment of LALMs&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib32\" title=\"\">32</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib33\" title=\"\">33</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nHowever, these efforts do not provide a systematic study of how emotional cues may introduce safety vulnerabilities, despite emotion being a central component of human communication. This gap motivates this study.</span>\n</p>\n\n",
                "matched_terms": [
                    "textual",
                    "speech",
                    "emotion",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The dataset construction process consists of three phases: (1) </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">harmful query collection</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where we first gather harmful queries, (2) </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">speech query synthesis</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where the collected queries are verbalized as emotional speech using a text-to-speech (TTS) model, and (3) </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">human annotation</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where annotators label both the emotion and its corresponding intensity for subsequent analysis. The details of these phases are described in the following subsections.</span>\n</p>\n\n",
                "matched_terms": [
                    "queries",
                    "speech",
                    "emotion",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We begin by collecting harmful queries to synthesize malicious speech instructions. Harmful queries are prompts that request unsafe information or actions, such as instructions for producing illegal drugs. Following prior work&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib26\" title=\"\">26</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib27\" title=\"\">27</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib32\" title=\"\">32</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we adopt AdvBench&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib34\" title=\"\">34</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which contains 520 textual queries across five security categories: misinformation, disinformation, toxicity, spam, and sensitive information. Its diversity and broad use in LLM safety research&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib35\" title=\"\">35</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> make it a suitable basis for our study.</span>\n</p>\n\n",
                "matched_terms": [
                    "textual",
                    "speech",
                    "advbench",
                    "queries",
                    "prompts",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We employ CosyVoice 2 0.5B&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib31\" title=\"\">31</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as the TTS model to synthesize emotional speech instructions from the harmful queries collected in AdvBench. The speech instructions are generated in six emotions: neutral, angry, disgusted, fearful, happy, and sad. To ensure that the synthesized instructions express the intended emotions, we use CREMA-D&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib36\" title=\"\">36</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as the reference dataset. CREMA-D provides detailed annotations for both emotion categories (the six emotions above) and emotion levels (low, medium, high, and unspecified).</span>\n</p>\n\n",
                "matched_terms": [
                    "angry",
                    "disgusted",
                    "speech",
                    "sad",
                    "neutral",
                    "advbench",
                    "happy",
                    "emotion",
                    "fearful",
                    "queries",
                    "instructions",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Specifically, given a textual query, we synthesize emotional speech instructions by sampling a reference speech from CREMA-D for each non-neutral emotion and each specified intensity level, while keeping speaker characteristics fixed. For the neutral case, a neutral reference sample is used. Each synthesized sample is then manually verified for naturalness, emotional expressiveness, and correctness of the annotated emotion level, as detailed in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S3.SS3\" style=\"font-size:90%;\" title=\"3.3 Human Annotation &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3.3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "textual",
                    "speech",
                    "neutral",
                    "emotion",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To ensure that the synthesized speech instructions accurately convey the intended emotions and intensity levels, we conduct a manual inspection. Each annotator is instructed to (1) check that the speech is natural and free from noticeable artifacts, (2) verify whether the synthesized speech faithfully represents the original textual query, and (3) assign both an emotion label (among the six defined categories) and an intensity label (low, medium, or high).</span>\n</p>\n\n",
                "matched_terms": [
                    "original",
                    "textual",
                    "speech",
                    "emotion",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To promote quality and consistency, we introduce an annotation calibration step. Prior to the main annotation, annotators complete a trial using CREMA-D samples with predefined emotion and intensity labels. Only those who achieve at least 95% accuracy with respect to the ground-truth labels are allowed to proceed to the full annotation process. This calibration step aligns annotators&#8217; criteria and ensures consistency throughout the dataset.</span>\n</p>\n\n",
                "matched_terms": [
                    "samples",
                    "emotion",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Each synthesized speech instruction is annotated by at least three annotators and retained only if they unanimously agree on the emotion and intensity (except neutral). Otherwise, it is re-synthesized and re-annotated until consensus is reached.</span>\n</p>\n\n",
                "matched_terms": [
                    "neutral",
                    "speech",
                    "emotion"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The finalized dataset contains 8,320 malicious speech instructions, comprising 520 instructions with neutral emotion and 520</span>\n  <math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">&#215;</mo>\n      <annotation encoding=\"application/x-tex\">\\times</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">3 instructions for each of the other emotions, corresponding to the three intensity levels (low, medium, and high). Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S3.SS4\" style=\"font-size:90%;\" title=\"3.4 Dataset Statistics &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3.4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> reports the statistics of the word counts in the original text prompts and the duration statistics of the generated speech samples across different emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "original",
                    "samples",
                    "word",
                    "speech",
                    "counts",
                    "neutral",
                    "emotion",
                    "statistics",
                    "prompts",
                    "instructions",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this work, we investigate how speaker emotions affect the safety alignment of several representative LALMs, including both open-source and proprietary models. The open-source set comprises Qwen2-Audio&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib5\" title=\"\">5</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, Qwen2.5-Omni&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib6\" title=\"\">6</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, DeSTA2.5-Audio&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib8\" title=\"\">8</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, SALMONN&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib7\" title=\"\">7</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (7B and 13B), Typhoon-audio&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib9\" title=\"\">9</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, SpeechGPT&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib10\" title=\"\">10</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and MiniCPM-o-2.6&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib11\" title=\"\">11</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while the proprietary set includes Gemini-1.5-flash&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Gemini-2.0-flash&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib13\" title=\"\">13</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This broad coverage makes our analysis both comprehensive and representative. We provide the models with speech instructions along with a text prompt requiring them to respond to the speech. For comparison, we also evaluate a text-only setup, where the original text queries are given without speech. All experiments use greedy decoding.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "original",
                    "speech",
                    "queries",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Finally, both NRR and UR are calculated as the proportion of queries in our dataset that elicit unsafe responses, according to the respective definitions of &#8220;unsafe&#8221; used in each metric. By comparing these metrics across instructions with different emotions and intensities, we quantify the extent to which the safety alignment of LALMs is influenced by speaker emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "queries",
                    "instructions",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">When comparing performance across modalities, we find that most models exhibit higher NRR and UR under speech instructions (averaged across six emotions) than under text-only instructions. For example, SALMONN 7B shows an increase of 67.14% in NRR and 4.47% in UR when inputs shift from text to speech. This pattern indicates that the safety alignment of current LALMs is more vulnerable in the speech modality than in the textual modality, consistent with the findings of Yang et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib26\" title=\"\">26</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Ensuring that the safety alignment established in text-based LLMs is preserved during adaptation to speech, therefore, emerges as a critical direction for future work.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "speech",
                    "instructions",
                    "textual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Within the speech modality, many models show substantial safety discrepancies across emotions, as indicated by large standard deviations (</span>\n  <math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#963;</mi>\n      <annotation encoding=\"application/x-tex\">\\sigma</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) and ranges (</span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">). These discrepancies highlight the instability of model safety under emotionally varied inputs. For example, SALMONN 7B and 13B display marked variability, with </span>\n  <math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#963;</mi>\n      <annotation encoding=\"application/x-tex\">\\sigma</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> values of 3.08% and 2.85% for NRR and 5.15% and 3.78% for UR, together with </span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m4\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> values of 8.59% and 8.15% for NRR and 12.50% and 10.26% for UR. Such pronounced fluctuations suggest that the safety alignment of these models is highly sensitive to emotional cues, exposing potential vulnerabilities to both deliberate adversarial exploitation and inadvertent triggering of unsafe behaviors.</span>\n</p>\n\n",
                "matched_terms": [
                    "standard",
                    "speech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Given that the UR metric provides a more comprehensive assessment than the NRR metric by incorporating the semantic content of model responses, we focus our analysis on UR in this section. As described in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S3\" style=\"font-size:90%;\" title=\"3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, the dataset includes synthesized speech queries at three intensity levels. For each model, we examine the non-neutral emotion</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\">\n    <sup class=\"ltx_note_mark\">2</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>We exclude the neutral emotion from this analysis, as it lacks defined and annotated intensity levels.</span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> that produces the highest UR value to assess the impact of emotional intensity on safety alignment. The resulting URs across different intensity levels for these emotions are presented in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S5.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 5.2 Effects of Emotion Intensity Levels &#8227; 5 Results &#8227; 4.2 Evaluation Metrics &#8227; 4 Experimental Setups &#8227; 3.4 Dataset Statistics &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "speech",
                    "neutral",
                    "emotion",
                    "queries",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Emotion is a crucial component of both human communication and human-AI interaction. In this work, we investigate whether emotions can induce safety vulnerabilities in LALMs. By evaluating several current LALMs with malicious speech instructions that share identical semantic content and speaker characteristics but differ in emotional expressions and intensities, we systematically uncover instabilities in their safety alignment under emotional cues.</span>\n</p>\n\n",
                "matched_terms": [
                    "speech",
                    "emotion",
                    "instructions"
                ]
            }
        ]
    },
    "S5.T3": {
        "source_file": "Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations",
        "caption": "Table 3: The unsafe rate (UR) of the investigated LALMs on speech instructions corresponding to the emotions that yield the highest UR in Table 1. “Low,” “Medium,” and “High” denote the respective intensity levels. “μ\\mu,” “σ\\sigma,” and “Δ\\Delta” indicate the average, standard deviation, and range (maximum minus minimum) of the metrics across the three intensity levels. The highest UR values among the three levels for each model are marked in bold.",
        "body": "Models (Emotion)\nLow (↓\\downarrow)\nMed. (↓\\downarrow)\nHigh (↓\\downarrow)\n\nμ\\mu (↓\\downarrow)\n\n\nσ\\sigma (↓\\downarrow)\n\n\nΔ\\Delta (↓\\downarrow)\n\n\n\nQwen2-Audio (Sad)\n2.31\n3.46\n2.50\n2.76\n0.62\n1.15\n\n\nQwen2.5-Omni (Sad)\n0.38\n0.38\n0.38\n0.38\n0\n0\n\n\nDeSTA2.5-Audio (Fear)\n1.15\n1.35\n0.58\n1.03\n0.40\n0.77\n\n\nSALMONN 7B (Happy)\n34.62\n29.04\n32.88\n32.18\n2.86\n5.58\n\n\nSALMONN 13B (Disgusted)\n88.08\n72.31\n82.69\n81.03\n8.02\n15.77\n\n\nTyphoon-audio (Angry)\n70.96\n74.23\n70.19\n71.79\n2.15\n4.04\n\n\nSpeechGPT (Sad)\n15.58\n17.69\n15.77\n16.35\n1.17\n2.11\n\n\nMiniCPM-o-2.6 (Angry)\n3.46\n3.65\n16.92\n8.01\n7.72\n13.46\n\n\nGemini-1.5-flash (Disgusted)\n2.69\n3.27\n3.46\n3.14\n0.4\n0.77\n\n\nGemini-2.0-flash (Disgusted)\n3.27\n6.15\n5.00\n4.81\n1.45\n2.88",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Models (Emotion)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Low (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m7\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Med. (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m8\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">High (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m9\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding:-0.45pt 3.0pt;\">\n<math alttext=\"\\mu\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m10\" intent=\":literal\"><semantics><mi mathsize=\"0.900em\">&#956;</mi><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\"> (<math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m11\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>)</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding:-0.45pt 3.0pt;\">\n<math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m12\" intent=\":literal\"><semantics><mi mathsize=\"0.900em\">&#963;</mi><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\"> (</span><math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m13\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\">)</span>\n</td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding:-0.45pt 3.0pt;\">\n<math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m14\" intent=\":literal\"><semantics><mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi><annotation encoding=\"application/x-tex\">\\Delta</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\"> (</span><math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S5.T3.m15\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\">)</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2-Audio (Sad)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.31</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.46</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.50</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.76</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.62</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.15</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Qwen2.5-Omni (Sad)</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.38</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.38</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.38</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.38</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">DeSTA2.5-Audio (Fear)</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.15</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">1.35</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.58</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.03</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.40</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.77</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">SALMONN 7B (Happy)</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">34.62</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">29.04</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">32.88</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">32.18</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.86</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.58</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">SALMONN 13B (Disgusted)</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">88.08</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">72.31</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">82.69</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.03</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">8.02</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">15.77</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Typhoon-audio (Angry)</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.96</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">74.23</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.19</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">71.79</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.15</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.04</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">SpeechGPT (Sad)</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">15.58</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">17.69</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">15.77</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">16.35</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.17</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.11</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">MiniCPM-o-2.6 (Angry)</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.46</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.65</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">16.92</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">8.01</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">7.72</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">13.46</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini-1.5-flash (Disgusted)</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.69</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.27</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.46</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.14</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.4</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">0.77</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Gemini-2.0-flash (Disgusted)</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.27</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">6.15</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.00</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">4.81</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.45</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding:-0.45pt 3.0pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.88</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "levels",
            "angry",
            "speech",
            "maximum",
            "qwen25omni",
            "high",
            "“μmu”",
            "“high”",
            "emotion",
            "qwen2audio",
            "fear",
            "range",
            "med",
            "“δdelta”",
            "yield",
            "minicpmo26",
            "investigated",
            "disgusted",
            "rate",
            "minus",
            "lalms",
            "each",
            "marked",
            "σsigma",
            "bold",
            "instructions",
            "metrics",
            "among",
            "salmonn",
            "deviation",
            "13b",
            "↓downarrow",
            "desta25audio",
            "gemini15flash",
            "minimum",
            "intensity",
            "δdelta",
            "sad",
            "μmu",
            "emotions",
            "average",
            "happy",
            "unsafe",
            "standard",
            "highest",
            "gemini20flash",
            "speechgpt",
            "across",
            "indicate",
            "three",
            "typhoonaudio",
            "models",
            "“σsigma”",
            "denote",
            "“medium”",
            "corresponding",
            "values",
            "“low”",
            "respective",
            "low",
            "model"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Given that the UR metric provides a more comprehensive assessment than the NRR metric by incorporating the semantic content of model responses, we focus our analysis on UR in this section. As described in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S3\" style=\"font-size:90%;\" title=\"3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, the dataset includes synthesized speech queries at three intensity levels. For each model, we examine the non-neutral emotion</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\">\n    <sup class=\"ltx_note_mark\">2</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>We exclude the neutral emotion from this analysis, as it lacks defined and annotated intensity levels.</span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> that produces the highest UR value to assess the impact of emotional intensity on safety alignment. The resulting URs across different intensity levels for these emotions are presented in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S5.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 5.2 Effects of Emotion Intensity Levels &#8227; 5 Results &#8227; 4.2 Evaluation Metrics &#8227; 4 Experimental Setups &#8227; 3.4 Dataset Statistics &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Large audio-language models (LALMs) extend text-based LLMs with auditory understanding, offering new opportunities for multimodal applications. While their perception, reasoning, and task performance have been widely studied, their safety alignment under paralinguistic variation remains underexplored. This work systematically investigates the role of speaker emotion. We construct a dataset of malicious speech instructions expressed across multiple emotions and intensities, and evaluate several state-of-the-art LALMs. Our results reveal substantial safety inconsistencies: different emotions elicit varying levels of unsafe responses, and the effect of intensity is non-monotonic, with medium expressions often posing the greatest risk. These findings highlight an overlooked vulnerability in LALMs and call for alignment strategies explicitly designed to ensure robustness under emotional variation, a prerequisite for trustworthy deployment in real-world settings.</span>\n</p>\n\n",
                "matched_terms": [
                    "levels",
                    "across",
                    "models",
                    "speech",
                    "intensity",
                    "emotions",
                    "emotion",
                    "lalms",
                    "unsafe",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Recent advances in large language models (LLMs)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib2\" title=\"\">2</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> have revolutionized AI research, extending their impact to speech processing&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib4\" title=\"\">4</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. In particular, large audio-language models (LALMs)&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib5\" title=\"\">5</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib6\" title=\"\">6</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib7\" title=\"\">7</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib8\" title=\"\">8</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib9\" title=\"\">9</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib10\" title=\"\">10</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib11\" title=\"\">11</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib12\" title=\"\">12</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib15\" title=\"\">15</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib16\" title=\"\">16</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> augment text-based LLMs with auditory understanding, opening new possibilities for multimodal models and speech technologies.</span>\n</p>\n\n",
                "matched_terms": [
                    "models",
                    "speech",
                    "lalms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Although LALMs&#8217; auditory perception&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib17\" title=\"\">17</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, downstream performance&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib18\" title=\"\">18</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib19\" title=\"\">19</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib20\" title=\"\">20</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib21\" title=\"\">21</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, reasoning ability&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib22\" title=\"\">22</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib23\" title=\"\">23</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib24\" title=\"\">24</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and biases&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib25\" title=\"\">25</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> have been extensively studied, research on their safety alignment has only just begun&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib26\" title=\"\">26</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib27\" title=\"\">27</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib28\" title=\"\">28</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib29\" title=\"\">29</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Safety alignment, which aims to prevent harmful outputs such as misinformation or self-harm, is particularly challenging for LALMs because their behavior can be influenced not only by semantic content but also by paralinguistic and acoustic cues. Prior work has shown that factors such as sound effects&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, languages&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib29\" title=\"\">29</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, accents&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib27\" title=\"\">27</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib29\" title=\"\">29</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and intonation&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> can bypass safety mechanisms, yet the impact of speaker emotion, a fundamental aspect of communication, remains underexplored.</span>\n</p>\n\n",
                "matched_terms": [
                    "emotion",
                    "lalms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Investigating whether emotions can trigger safety vulnerabilities is essential for two reasons. First, if certain emotional expressions consistently elicit harmful behaviors, they may provide a new pathway for </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">jailbreaking</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib30\" title=\"\">30</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where models are manipulated to bypass safety guardrails. Second, even when users act in good faith, they may unintentionally provoke unsafe responses from LALMs, which could in turn lead to real-world social harms.</span>\n</p>\n\n",
                "matched_terms": [
                    "unsafe",
                    "emotions",
                    "models",
                    "lalms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Motivated by this, we systematically investigate how speaker emotion affects LALM safety. We construct a dataset of malicious speech instructions synthesized with a text-to-speech model&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib31\" title=\"\">31</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> under controlled conditions: each instruction is expressed across multiple emotions and intensities, with semantic content and speaker identity held identical. Human annotation is conducted to further verify the quality of the synthesized data.</span>\n</p>\n\n",
                "matched_terms": [
                    "across",
                    "speech",
                    "emotions",
                    "emotion",
                    "each",
                    "model",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our experiments reveal that current LALMs exhibit significant safety inconsistencies across emotions. Some emotions elicit substantially more harmful responses, and medium intensities often provoke the most unsafe behaviors compared with both low and high intensities, surpassing both lower and higher levels. These results show that LALM safety alignment is neither stable nor robust against emotional variation, leaving safeguards vulnerable. Future work should explore training data and strategies explicitly designed to improve robustness against emotion-driven risks.</span>\n</p>\n\n",
                "matched_terms": [
                    "levels",
                    "across",
                    "high",
                    "emotions",
                    "lalms",
                    "low",
                    "unsafe"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Overall, our contributions are: (1) the first study to examine the interaction between speakers&#8217; emotions and the safety alignment of LALMs, and (2) uncovering the inconsistency of LALMs&#8217; safety alignment under emotional variations, where certain emotions and intensities disproportionately provoke unsafe and harmful responses. Our dataset is available at </span>\n  <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/LALM-emotional-vulnerability\" style=\"font-size:90%;\" title=\"\">https://huggingface.co/LALM-emotional-vulnerability</a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "unsafe",
                    "emotions",
                    "lalms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Prior studies have examined how the safety alignment of LALMs can be compromised through the speech modality. Yang et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib26\" title=\"\">26</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> show that LALMs are more susceptible to safety failures from spoken inputs than from textual inputs with the same semantic content. Xiao et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Hughes et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib28\" title=\"\">28</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrate that paralinguistic and acoustic cues such as tone, emphasis, speaking rate, and noises can further destabilize model behavior. Roh et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib29\" title=\"\">29</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> investigate jailbreak attempts that exploit variations in languages and accents of spoken instructions. There are also several benchmarks assessing the safety alignment of LALMs&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib32\" title=\"\">32</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib33\" title=\"\">33</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nHowever, these efforts do not provide a systematic study of how emotional cues may introduce safety vulnerabilities, despite emotion being a central component of human communication. This gap motivates this study.</span>\n</p>\n\n",
                "matched_terms": [
                    "rate",
                    "speech",
                    "emotion",
                    "lalms",
                    "model",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We describe the dataset construction process, illustrated in Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S2.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 2 Related Work &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, to analyze the safety vulnerabilities of LALMs under different speaker emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "emotions",
                    "lalms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The dataset construction process consists of three phases: (1) </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">harmful query collection</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where we first gather harmful queries, (2) </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">speech query synthesis</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where the collected queries are verbalized as emotional speech using a text-to-speech (TTS) model, and (3) </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">human annotation</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, where annotators label both the emotion and its corresponding intensity for subsequent analysis. The details of these phases are described in the following subsections.</span>\n</p>\n\n",
                "matched_terms": [
                    "three",
                    "speech",
                    "intensity",
                    "corresponding",
                    "emotion",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We begin by collecting harmful queries to synthesize malicious speech instructions. Harmful queries are prompts that request unsafe information or actions, such as instructions for producing illegal drugs. Following prior work&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib26\" title=\"\">26</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib27\" title=\"\">27</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib32\" title=\"\">32</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we adopt AdvBench&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib34\" title=\"\">34</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which contains 520 textual queries across five security categories: misinformation, disinformation, toxicity, spam, and sensitive information. Its diversity and broad use in LLM safety research&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib35\" title=\"\">35</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> make it a suitable basis for our study.</span>\n</p>\n\n",
                "matched_terms": [
                    "unsafe",
                    "speech",
                    "across",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We employ CosyVoice 2 0.5B&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib31\" title=\"\">31</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as the TTS model to synthesize emotional speech instructions from the harmful queries collected in AdvBench. The speech instructions are generated in six emotions: neutral, angry, disgusted, fearful, happy, and sad. To ensure that the synthesized instructions express the intended emotions, we use CREMA-D&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib36\" title=\"\">36</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as the reference dataset. CREMA-D provides detailed annotations for both emotion categories (the six emotions above) and emotion levels (low, medium, high, and unspecified).</span>\n</p>\n\n",
                "matched_terms": [
                    "levels",
                    "angry",
                    "disgusted",
                    "speech",
                    "sad",
                    "high",
                    "emotions",
                    "happy",
                    "emotion",
                    "low",
                    "model",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Specifically, given a textual query, we synthesize emotional speech instructions by sampling a reference speech from CREMA-D for each non-neutral emotion and each specified intensity level, while keeping speaker characteristics fixed. For the neutral case, a neutral reference sample is used. Each synthesized sample is then manually verified for naturalness, emotional expressiveness, and correctness of the annotated emotion level, as detailed in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S3.SS3\" style=\"font-size:90%;\" title=\"3.3 Human Annotation &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3.3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "speech",
                    "intensity",
                    "emotion",
                    "each",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To ensure that the synthesized speech instructions accurately convey the intended emotions and intensity levels, we conduct a manual inspection. Each annotator is instructed to (1) check that the speech is natural and free from noticeable artifacts, (2) verify whether the synthesized speech faithfully represents the original textual query, and (3) assign both an emotion label (among the six defined categories) and an intensity label (low, medium, or high).</span>\n</p>\n\n",
                "matched_terms": [
                    "levels",
                    "low",
                    "speech",
                    "intensity",
                    "high",
                    "emotions",
                    "emotion",
                    "among",
                    "each",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To promote quality and consistency, we introduce an annotation calibration step. Prior to the main annotation, annotators complete a trial using CREMA-D samples with predefined emotion and intensity labels. Only those who achieve at least 95% accuracy with respect to the ground-truth labels are allowed to proceed to the full annotation process. This calibration step aligns annotators&#8217; criteria and ensures consistency throughout the dataset.</span>\n</p>\n\n",
                "matched_terms": [
                    "intensity",
                    "emotion"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Each synthesized speech instruction is annotated by at least three annotators and retained only if they unanimously agree on the emotion and intensity (except neutral). Otherwise, it is re-synthesized and re-annotated until consensus is reached.</span>\n</p>\n\n",
                "matched_terms": [
                    "three",
                    "speech",
                    "intensity",
                    "emotion",
                    "each"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The finalized dataset contains 8,320 malicious speech instructions, comprising 520 instructions with neutral emotion and 520</span>\n  <math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mo mathsize=\"0.900em\">&#215;</mo>\n      <annotation encoding=\"application/x-tex\">\\times</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">3 instructions for each of the other emotions, corresponding to the three intensity levels (low, medium, and high). Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S3.SS4\" style=\"font-size:90%;\" title=\"3.4 Dataset Statistics &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">3.4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> reports the statistics of the word counts in the original text prompts and the duration statistics of the generated speech samples across different emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "levels",
                    "across",
                    "three",
                    "low",
                    "speech",
                    "intensity",
                    "high",
                    "emotions",
                    "corresponding",
                    "emotion",
                    "each",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this work, we investigate how speaker emotions affect the safety alignment of several representative LALMs, including both open-source and proprietary models. The open-source set comprises Qwen2-Audio&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib5\" title=\"\">5</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, Qwen2.5-Omni&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib6\" title=\"\">6</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, DeSTA2.5-Audio&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib8\" title=\"\">8</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, SALMONN&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib7\" title=\"\">7</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (7B and 13B), Typhoon-audio&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib9\" title=\"\">9</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, SpeechGPT&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib10\" title=\"\">10</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and MiniCPM-o-2.6&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib11\" title=\"\">11</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while the proprietary set includes Gemini-1.5-flash&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Gemini-2.0-flash&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib13\" title=\"\">13</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This broad coverage makes our analysis both comprehensive and representative. We provide the models with speech instructions along with a text prompt requiring them to respond to the speech. For comparison, we also evaluate a text-only setup, where the original text queries are given without speech. All experiments use greedy decoding.</span>\n</p>\n\n",
                "matched_terms": [
                    "gemini20flash",
                    "speechgpt",
                    "salmonn",
                    "minicpmo26",
                    "13b",
                    "typhoonaudio",
                    "desta25audio",
                    "models",
                    "speech",
                    "qwen2audio",
                    "qwen25omni",
                    "gemini15flash",
                    "emotions",
                    "lalms",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Following prior work&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib37\" title=\"\">37</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib38\" title=\"\">38</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we adopt two metrics to evaluate the safety alignment of LALMs&#8217; responses: </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">non-refusal rate (NRR)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">unsafe rate (UR)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, as shown in Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S2.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 2 Related Work &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Both measure the extent to which models behave unsafely, but they differ in how &#8220;unsafe&#8221; is defined. The NRR is computed through pattern matching for typical refusal expressions such as &#8220;I am sorry&#8221; or &#8220;I cannot do this.&#8221; Responses that lack these refusal patterns are considered to accept and follow the malicious instructions, and are thus judged unsafe.</span>\n</p>\n\n",
                "matched_terms": [
                    "rate",
                    "models",
                    "instructions",
                    "unsafe",
                    "metrics"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Finally, both NRR and UR are calculated as the proportion of queries in our dataset that elicit unsafe responses, according to the respective definitions of &#8220;unsafe&#8221; used in each metric. By comparing these metrics across instructions with different emotions and intensities, we quantify the extent to which the safety alignment of LALMs is influenced by speaker emotions.</span>\n</p>\n\n",
                "matched_terms": [
                    "lalms",
                    "across",
                    "respective",
                    "emotions",
                    "instructions",
                    "each",
                    "unsafe",
                    "metrics"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We present the main results in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S3.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 3.2 Speech Query Synthesis &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The models show a clear dichotomy: a relatively safer group with lower NRR and UR (Qwen2-Audio, Qwen2.5-Omni, DeSTA2.5-Audio, MiniCPM-o-2.6, Gemini series) and a less safe group (SALMONN 7B and 13B, Typhoon-audio, SpeechGPT). This division indicates that the inherent safety alignment of certain models remains insufficiently robust.</span>\n</p>\n\n",
                "matched_terms": [
                    "speechgpt",
                    "salmonn",
                    "minicpmo26",
                    "13b",
                    "typhoonaudio",
                    "desta25audio",
                    "models",
                    "qwen25omni",
                    "qwen2audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">When comparing performance across modalities, we find that most models exhibit higher NRR and UR under speech instructions (averaged across six emotions) than under text-only instructions. For example, SALMONN 7B shows an increase of 67.14% in NRR and 4.47% in UR when inputs shift from text to speech. This pattern indicates that the safety alignment of current LALMs is more vulnerable in the speech modality than in the textual modality, consistent with the findings of Yang et al.&#160;</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#bib.bib26\" title=\"\">26</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Ensuring that the safety alignment established in text-based LLMs is preserved during adaptation to speech, therefore, emerges as a critical direction for future work.</span>\n</p>\n\n",
                "matched_terms": [
                    "salmonn",
                    "across",
                    "models",
                    "speech",
                    "emotions",
                    "lalms",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Within the speech modality, many models show substantial safety discrepancies across emotions, as indicated by large standard deviations (</span>\n  <math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#963;</mi>\n      <annotation encoding=\"application/x-tex\">\\sigma</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) and ranges (</span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">). These discrepancies highlight the instability of model safety under emotionally varied inputs. For example, SALMONN 7B and 13B display marked variability, with </span>\n  <math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#963;</mi>\n      <annotation encoding=\"application/x-tex\">\\sigma</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> values of 3.08% and 2.85% for NRR and 5.15% and 3.78% for UR, together with </span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p3.m4\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> values of 8.59% and 8.15% for NRR and 12.50% and 10.26% for UR. Such pronounced fluctuations suggest that the safety alignment of these models is highly sensitive to emotional cues, exposing potential vulnerabilities to both deliberate adversarial exploitation and inadvertent triggering of unsafe behaviors.</span>\n</p>\n\n",
                "matched_terms": [
                    "salmonn",
                    "across",
                    "13b",
                    "models",
                    "speech",
                    "δdelta",
                    "standard",
                    "emotions",
                    "values",
                    "marked",
                    "unsafe",
                    "σsigma",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Crucially, this instability is not limited to relatively unsafe models. Even models with lower overall risk levels can fluctuate across emotions. For instance, MiniCPM-o-2.6 shows considerable </span>\n  <math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#963;</mi>\n      <annotation encoding=\"application/x-tex\">\\sigma</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> values for both metrics, despite maintaining moderately low mean scores. Likewise, Qwen2-Audio and Gemini-2.0-flash yield </span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS1.p4.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> values that are comparable to their average NRRs and URs, indicating that safety alignment can remain unstable under emotional variation even when models appear sufficiently safe on average.</span>\n</p>\n\n",
                "matched_terms": [
                    "gemini20flash",
                    "levels",
                    "across",
                    "yield",
                    "minicpmo26",
                    "models",
                    "δdelta",
                    "emotions",
                    "average",
                    "values",
                    "qwen2audio",
                    "low",
                    "unsafe",
                    "σsigma",
                    "metrics"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Finally, no single emotion consistently induces unsafe behavior across all models. Instead, each model reveals its own blind spot, namely a particular emotion that tends to trigger unsafe behaviors, suggesting that such variability is an inherent characteristic of current LALMs. These findings underscore the necessity of rigorously assessing safety instability before real-world deployment, in order to better understand model behavior and to guide the development of effective filtering and safeguarding mechanisms.</span>\n</p>\n\n",
                "matched_terms": [
                    "across",
                    "models",
                    "emotion",
                    "lalms",
                    "each",
                    "unsafe",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.16893v1#S5.SS1\" style=\"font-size:90%;\" title=\"5.1 Main Results &#8227; 5 Results &#8227; 4.2 Evaluation Metrics &#8227; 4 Experimental Setups &#8227; 3.4 Dataset Statistics &#8227; 3 Dataset Construction &#8227; Investigating Safety Vulnerabilities of Large Audio-Language Models under Speaker Emotional Variations\">\n    <span class=\"ltx_text ltx_ref_tag\">5.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, we observed that emotions can induce notable safety fluctuations and instabilities. A natural follow-up question is whether the intensity of emotional expression also plays a role. Since certain emotions already elicit more unsafe responses than others, it is reasonable to hypothesize that stronger intensities of these emotions may further amplify unsafe behaviors. In this section, we empirically investigate this hypothesis.</span>\n</p>\n\n",
                "matched_terms": [
                    "unsafe",
                    "emotions",
                    "intensity"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We first observe that, beyond the variation across different emotions, some models also display substantial instability across different intensity levels of the same emotion. For instance, SALMONN 13B and MiniCPM-o-2.6 show large values of </span>\n  <math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#963;</mi>\n      <annotation encoding=\"application/x-tex\">\\sigma</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS2.p3.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n      <annotation encoding=\"application/x-tex\">\\Delta</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, indicating pronounced fluctuations between low, medium, and high intensities.</span>\n</p>\n\n",
                "matched_terms": [
                    "levels",
                    "salmonn",
                    "across",
                    "minicpmo26",
                    "13b",
                    "models",
                    "intensity",
                    "δdelta",
                    "high",
                    "emotions",
                    "emotion",
                    "values",
                    "low",
                    "σsigma"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Contrary to our initial hypothesis, however, the results reveal that most LALMs reach their highest URs at medium intensity rather than at high intensity. This suggests that while certain emotions are indeed effective at inducing unsafe behavior, stronger expressions of those emotions do not necessarily further increase the likelihood of unsafe responses. Instead, medium-intensity expressions appear to elicit the most harmful responses.</span>\n</p>\n\n",
                "matched_terms": [
                    "intensity",
                    "high",
                    "emotions",
                    "lalms",
                    "unsafe",
                    "highest"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Finally, different models exhibit distinct patterns. For example, Qwen2.5-Omni remains stable across intensities, whereas MiniCPM-o-2.6 is highly sensitive to high-intensity emotions, showing markedly higher UR compared with lower levels.</span>\n</p>\n\n",
                "matched_terms": [
                    "levels",
                    "across",
                    "minicpmo26",
                    "models",
                    "qwen25omni",
                    "emotions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In summary, our findings reveal that the effect of emotional intensity on safety alignment is not monotonic: medium-intensity expressions often elicit the most harmful responses. This suggests that LALMs may be more vulnerable to subtle and naturalistic variations rather than exaggerated cues. Future work could explore whether this sensitivity stems from data distribution biases or insufficient robustness in alignment, and develop safety mechanisms explicitly resilient to paralinguistic variation.</span>\n</p>\n\n",
                "matched_terms": [
                    "intensity",
                    "lalms"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Emotion is a crucial component of both human communication and human-AI interaction. In this work, we investigate whether emotions can induce safety vulnerabilities in LALMs. By evaluating several current LALMs with malicious speech instructions that share identical semantic content and speaker characteristics but differ in emotional expressions and intensities, we systematically uncover instabilities in their safety alignment under emotional cues.</span>\n</p>\n\n",
                "matched_terms": [
                    "speech",
                    "emotions",
                    "emotion",
                    "lalms",
                    "instructions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We find that LALMs&#8217; safety alignment varies substantially across emotions: some emotions elicit far more unsafe behaviors than others. However, even when an emotion induces such vulnerability, stronger expressions do not necessarily make models more unsafe. Instead, moderate intensities often pose the greatest risk. These findings highlight an inherent instability of LALMs under emotional cues, posing challenges for safe deployment if not properly understood and mitigated. Our study takes a first step toward uncovering this instability. Further investigation is needed to uncover the causes of this instability and explore possible mitigation strategies, which we consider an important direction for future work.</span>\n</p>\n\n",
                "matched_terms": [
                    "across",
                    "models",
                    "emotions",
                    "emotion",
                    "lalms",
                    "unsafe"
                ]
            }
        ]
    }
}