{
    "S2.T1": {
        "caption": "Table 1: Accuracy (Acc), Character Error Rate (CER), and bad case ratio (Bad) across different models. The best and second-best results are highlighted in bold and underline, respectively.",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" rowspan=\"2\">Model</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" rowspan=\"2\">PO Data</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"3\">Female</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\">Male</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\">Acc &#8593;</td>\n<td class=\"ltx_td ltx_align_center\">CER &#8595;</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">Bad &#8595;</td>\n<td class=\"ltx_td ltx_align_center\">Acc &#8593;</td>\n<td class=\"ltx_td ltx_align_center\">CER &#8595;</td>\n<td class=\"ltx_td ltx_align_center\">Bad &#8595;</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">gpt-4o-mini-tts</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">-</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.900</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.109</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.079</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.939</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.111</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.062</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">gemini-2.5-flash-preview-tts</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">-</th>\n<td class=\"ltx_td ltx_align_center\">0.776</td>\n<td class=\"ltx_td ltx_align_center\">0.140</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.105</td>\n<td class=\"ltx_td ltx_align_center\">0.769</td>\n<td class=\"ltx_td ltx_align_center\">0.134</td>\n<td class=\"ltx_td ltx_align_center\">0.091</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">gemini-2.5-pro-preview-tts</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">-</th>\n<td class=\"ltx_td ltx_align_center\">0.871</td>\n<td class=\"ltx_td ltx_align_center\">0.127</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.094</td>\n<td class=\"ltx_td ltx_align_center\">0.885</td>\n<td class=\"ltx_td ltx_align_center\">0.119</td>\n<td class=\"ltx_td ltx_align_center\">0.073</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">F5-TTS <cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib1\" title=\"\">2025</a>)</cite>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">-</th>\n<td class=\"ltx_td ltx_align_center\">0.498</td>\n<td class=\"ltx_td ltx_align_center\">0.173</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.189</td>\n<td class=\"ltx_td ltx_align_center\">0.500</td>\n<td class=\"ltx_td ltx_align_center\">0.177</td>\n<td class=\"ltx_td ltx_align_center\">0.183</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">F5-TTS with G2P <cite class=\"ltx_cite ltx_citemacro_citep\">(Oura et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib12\" title=\"\">2010</a>)</cite>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">-</th>\n<td class=\"ltx_td ltx_align_center\">0.500</td>\n<td class=\"ltx_td ltx_align_center\">0.136</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.100</td>\n<td class=\"ltx_td ltx_align_center\">0.500</td>\n<td class=\"ltx_td ltx_align_center\">0.146</td>\n<td class=\"ltx_td ltx_align_center\">0.107</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Base model <cite class=\"ltx_cite ltx_citemacro_citep\">(Du et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib2\" title=\"\">2024</a>)</cite>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">-</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.683</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.128</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.090</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.668</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.138</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.095</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Supervised Fine-Tuning (SFT)</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Desirable</th>\n<td class=\"ltx_td ltx_align_center\">0.674</td>\n<td class=\"ltx_td ltx_align_center\">0.119</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.076</td>\n<td class=\"ltx_td ltx_align_center\">0.654</td>\n<td class=\"ltx_td ltx_align_center\">0.130</td>\n<td class=\"ltx_td ltx_align_center\">0.084</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DPO <cite class=\"ltx_cite ltx_citemacro_citep\">(Tian et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib16\" title=\"\">2025</a>)</cite>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Paired</th>\n<td class=\"ltx_td ltx_align_center\">0.706</td>\n<td class=\"ltx_td ltx_align_center\">0.120</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.076</td>\n<td class=\"ltx_td ltx_align_center\">0.693</td>\n<td class=\"ltx_td ltx_align_center\">0.130</td>\n<td class=\"ltx_td ltx_align_center\">0.082</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">KTO <cite class=\"ltx_cite ltx_citemacro_citep\">(Ethayarajh et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib3\" title=\"\">2024</a>)</cite>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Paired</th>\n<td class=\"ltx_td ltx_align_center\">0.654</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.066</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.028</span></td>\n<td class=\"ltx_td ltx_align_center\">0.651</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.074</span></td>\n<td class=\"ltx_td ltx_align_center\">0.030</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">KTO <cite class=\"ltx_cite ltx_citemacro_citep\">(Ethayarajh et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib3\" title=\"\">2024</a>)</cite>\n</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Unpaired</th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.933</span></td>\n<td class=\"ltx_td ltx_align_center\">0.079</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.030</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\">0.952</span></td>\n<td class=\"ltx_td ltx_align_center\">0.087</td>\n<td class=\"ltx_td ltx_align_center\">0.032</td>\n</tr>\n<tr class=\"ltx_tr\" style=\"--ltx-bg-color:#ECECEC;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#ECECEC;\">TKTO (ours)</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#ECECEC;\">Paired</span></th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#ECECEC;\">0.681</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"--ltx-bg-color:#ECECEC;\">0.059</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text ltx_font_bold\" style=\"--ltx-bg-color:#ECECEC;\">0.025</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#ECECEC;\">0.701</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"--ltx-bg-color:#ECECEC;\">0.066</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"--ltx-bg-color:#ECECEC;\">0.029</span></td>\n</tr>\n<tr class=\"ltx_tr\" style=\"--ltx-bg-color:#ECECEC;\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#ECECEC;\">TKTO (ours)</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#ECECEC;\">Unpaired</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\" style=\"--ltx-bg-color:#ECECEC;\">0.949</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"--ltx-bg-color:#ECECEC;\">0.075</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#ECECEC;\">0.029</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\" style=\"--ltx-bg-color:#ECECEC;\">0.958</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"--ltx-bg-color:#ECECEC;\">0.085</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\" style=\"--ltx-bg-color:#ECECEC;\">0.027</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "models",
            "gemini25propreviewtts",
            "supervised",
            "underline",
            "error",
            "rate",
            "gpt4ominitts",
            "base",
            "bad",
            "tkto",
            "character",
            "ethayarajh",
            "case",
            "accuracy",
            "ratio",
            "male",
            "across",
            "finetuning",
            "bold",
            "highlighted",
            "sft",
            "f5tts",
            "results",
            "tian",
            "paired",
            "g2p",
            "oura",
            "respectively",
            "ours",
            "secondbest",
            "desirable",
            "chen",
            "model",
            "best",
            "acc",
            "data",
            "kto",
            "cer",
            "dpo",
            "female",
            "unpaired",
            "different",
            "gemini25flashpreviewtts"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S2.T1\" title=\"Table 1 &#8227; 2 LLM-based Text-to-Speech &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> presents the objective evaluation results.\nOur TKTO model achieves the highest Japanese TTS accuracy and the lowest CER and bad case ratio.\nThe non-LLM baseline F5-TTS shows extremely low accuracy regardless of whether it uses G2P or not, highlighting the importance of LLMs to consider contextual information.\nThe use of unpaired data allows us to leverage samples that are always desirable or always undesirable, which cannot be used in paired training.\nThis leads to a significant improvement in accuracy (0.949 or 0.958), surpassing even strong industry models.\nUsing only paired data excludes samples that always produce desirable outputs, causing the model to overfit toward undesirable examples. As a result, accuracy improvement is limited, although the CER and bad case ratio become slightly lower.\nCompared with KTO, our model achieves improvements across all metrics, demonstrating the effectiveness of token-level targeted optimization.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Aligning text-to-speech (TTS) system outputs with human feedback through preference optimization has been shown to effectively improve the robustness and naturalness of language model-based TTS models.\nCurrent approaches primarily require paired desirable and undesirable samples at the utterance level. However, such pairs are often limited in TTS output data, and utterance-level formulation prevents fine-grained token-level optimization needed for accurate pronunciation alignment.\nIn this study, we propose TKTO that eliminates the need for paired data, enabling a more data-efficient training paradigm, and directly targets token-level units, automatically providing fine-grained alignment signals without token-level annotations.\nTKTO improves the challenging Japanese TTS accuracy by 39% and reduces CER by 54%, automatically assigning <math alttext=\"12.8\\times\" class=\"ltx_math_unparsed\" display=\"inline\" id=\"m1\" intent=\":literal\"><semantics><mrow><mn>12.8</mn><mo lspace=\"0.222em\">&#215;</mo></mrow><annotation encoding=\"application/x-tex\">12.8\\times</annotation></semantics></math> stronger reward to targeted tokens.</p>\n\n",
                "matched_terms": [
                    "models",
                    "desirable",
                    "tkto",
                    "data",
                    "cer",
                    "accuracy",
                    "paired"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent advances in neural network technology have enabled high-fidelity text-to-speech (TTS) synthesis models <cite class=\"ltx_cite ltx_citemacro_cite\">Chen et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib1\" title=\"\">2025</a>); Meng et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib7\" title=\"\">2025</a>); Li et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib5\" title=\"\">2024</a>)</cite>. They typically convert input text into a phoneme sequence using a grapheme-to-phoneme (G2P) converter <cite class=\"ltx_cite ltx_citemacro_cite\">Oura et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib12\" title=\"\">2010</a>)</cite>, followed by generative models from the phoneme sequence <cite class=\"ltx_cite ltx_citemacro_cite\">Wang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib18\" title=\"\">2025b</a>); <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib8\" title=\"\">Nishimura et&#160;al. </a></cite>.\nHowever, G2P is generally based on morphological analysis, and thus may fail to generate correct pronunciations in ambiguous languages like Japanese, where the reading and meaning of words can change depending on context (Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).</p>\n\n",
                "matched_terms": [
                    "models",
                    "oura",
                    "chen",
                    "g2p"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">G2P-free large language model (LLM)-based TTS methods <cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib17\" title=\"\">2025a</a>; Du et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib2\" title=\"\">2024</a>)</cite> have shown great promise to generate context-aware pronunciations directly from raw text without G2P by leveraging large-scale natural language pretraining.\nRecent work <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib20\" title=\"\">2025</a>; Tian et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib16\" title=\"\">2025</a>; Zhang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib19\" title=\"\">2024</a>)</cite> has further applied Direct Preference Optimization (DPO) <cite class=\"ltx_cite ltx_citemacro_cite\">Rafailov et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib15\" title=\"\">2023</a>)</cite> to improve intelligibility, speaker similarity, and overall naturalness by enlarging the preference gap between pairwise samples.</p>\n\n",
                "matched_terms": [
                    "model",
                    "tian",
                    "dpo",
                    "g2p"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Despite these advances, two fundamental challenges remain.\n<span class=\"ltx_text ltx_font_bold\">(i) Necessity of paired data:</span> DPO-based methods require paired desirable and undesirable outputs for the same utterance, but TTS systems often produce one-sided results, where many samples are consistently desirable or undesirable. This causes significant data inefficiency and wastes costly human feedback, limiting the scalability of DPO-based preference alignment.\n<span class=\"ltx_text ltx_font_bold\">(ii) Sample-level optimization:</span> Pronunciation generation is essentially a character- or token-level task, while preference alignment is conducted with utterance-level labels. This mismatch forces the model to optimize at the data-sample level rather than directly at the pronunciation unit level, leading to suboptimal learning signals and limiting the effectiveness of alignment.</p>\n\n",
                "matched_terms": [
                    "desirable",
                    "model",
                    "character",
                    "data",
                    "results",
                    "paired"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address these challenges, we propose a novel preference optimization framework, <span class=\"ltx_text ltx_font_bold\">Token-level Kahneman-Tversky Optimization (TKTO)</span> that constructs contrastive LLMs to estimate token-level weights and optimizes token-level preferences grounded in Kahneman-Tversky&#8217;s prospect theory <cite class=\"ltx_cite ltx_citemacro_cite\">Ethayarajh et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib3\" title=\"\">2024</a>)</cite>.\nOur contributions are summarized in three key dimensions:</p>\n\n",
                "matched_terms": [
                    "tkto",
                    "ethayarajh"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Novel methodology:</span> we propose TKTO that (i) eliminates the need for paired data, enabling a more data-efficient training paradigm, and (ii) directly targets token-level units, automatically providing fine-grained alignment signals.</p>\n\n",
                "matched_terms": [
                    "tkto",
                    "paired",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Wide evaluation:</span> we demonstrate that TKTO not only reduces character error rate (CER) by 54% but also improves the accuracy of Japanese pronunciation by 39 %, surpassing industry models. It selectively increases the generation probability of desirable tokens and assigns 12.8&#215; stronger rewards to targeted tokens.</p>\n\n",
                "matched_terms": [
                    "models",
                    "desirable",
                    "rate",
                    "tkto",
                    "character",
                    "cer",
                    "accuracy",
                    "error"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose a two-step approach to optimize token-level preferences from unpaired data (Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S1.F2\" title=\"Figure 2 &#8227; 1 Introduction &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>).\nFirst,\nwe quantify how informative each token is for preference learning.\nThese weights are then used to guide our TKTO objective.</p>\n\n",
                "matched_terms": [
                    "tkto",
                    "unpaired",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose a KTO-based approach to construct contrastive LLMs.\nKTO <cite class=\"ltx_cite ltx_citemacro_cite\">Ethayarajh et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib3\" title=\"\">2024</a>)</cite> uses unpaired data, enabling more flexible training.\nWe build two contrastive LLMs, <math alttext=\"\\pi^{+}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS0.Px1.p1.m1\" intent=\":literal\"><semantics><msup><mi>&#960;</mi><mo>+</mo></msup><annotation encoding=\"application/x-tex\">\\pi^{+}</annotation></semantics></math> and <math alttext=\"\\pi^{-}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS0.Px1.p1.m2\" intent=\":literal\"><semantics><msup><mi>&#960;</mi><mo>&#8722;</mo></msup><annotation encoding=\"application/x-tex\">\\pi^{-}</annotation></semantics></math>, where <math alttext=\"\\pi^{+}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS0.Px1.p1.m3\" intent=\":literal\"><semantics><msup><mi>&#960;</mi><mo>+</mo></msup><annotation encoding=\"application/x-tex\">\\pi^{+}</annotation></semantics></math> favors high- and <math alttext=\"\\pi^{-}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS0.Px1.p1.m4\" intent=\":literal\"><semantics><msup><mi>&#960;</mi><mo>&#8722;</mo></msup><annotation encoding=\"application/x-tex\">\\pi^{-}</annotation></semantics></math> favors low-reward tokens.\nWe train <math alttext=\"\\pi^{+}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS0.Px1.p1.m5\" intent=\":literal\"><semantics><msup><mi>&#960;</mi><mo>+</mo></msup><annotation encoding=\"application/x-tex\">\\pi^{+}</annotation></semantics></math> with normal labels and obtain <math alttext=\"\\pi^{-}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS0.Px1.p1.m6\" intent=\":literal\"><semantics><msup><mi>&#960;</mi><mo>&#8722;</mo></msup><annotation encoding=\"application/x-tex\">\\pi^{-}</annotation></semantics></math> by simply flipping the labels, treating desirable as undesirable and vice versa.</p>\n\n",
                "matched_terms": [
                    "desirable",
                    "data",
                    "kto",
                    "ethayarajh",
                    "unpaired"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We extend KTO <cite class=\"ltx_cite ltx_citemacro_cite\">Ethayarajh et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib3\" title=\"\">2024</a>)</cite> to the <em class=\"ltx_emph ltx_font_italic\">token level</em>, proposing Token-level KTO (TKTO) to learn finer-grained token-level signals.</p>\n\n",
                "matched_terms": [
                    "tkto",
                    "kto",
                    "ethayarajh"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The total TKTO loss is defined by summing token-level values across the sequence and weighting them by an importance weight <math alttext=\"w_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.SSS0.Px3.p1.m1\" intent=\":literal\"><semantics><msub><mi>w</mi><mi>t</mi></msub><annotation encoding=\"application/x-tex\">w_{t}</annotation></semantics></math>:</p>\n\n",
                "matched_terms": [
                    "tkto",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For each text sentence, we generate five speech samples for both female and male Japanese speakers <cite class=\"ltx_cite ltx_citemacro_cite\">Okamoto et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib9\" title=\"\">2023</a>)</cite> using a TTS model, with training data containing 23 hours of speech for each speaker. Among them, the sample with the correct pronunciation and the lowest CER is selected as a desirable sample. Conversely, the sample with the incorrect pronunciation and the highest CER is selected as an undesirable sample.\nThe CER is computed using the whisper-v3-large <cite class=\"ltx_cite ltx_citemacro_cite\">Radford et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib13\" title=\"\">2023</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "desirable",
                    "model",
                    "data",
                    "cer",
                    "female",
                    "male"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use CosyVoice2 (0.5B) <cite class=\"ltx_cite ltx_citemacro_cite\">Du et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib2\" title=\"\">2024</a>)</cite> fine-tuned on 20K hours of Japanese speech data as our base model and apply our TKTO.\nThe following baselines are considered:</p>\n\n",
                "matched_terms": [
                    "base",
                    "tkto",
                    "data",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><em class=\"ltx_emph ltx_font_italic\">Preference Optimization (PO) methods:</em>\nDPO uses 1.5K paired desirable&#8211;undesirable samples;\nKTO uses 9K unpaired desirable or undesirable samples;\nSFT uses 6K desirable samples.</p>\n\n",
                "matched_terms": [
                    "desirable",
                    "paired",
                    "kto",
                    "sft",
                    "dpo",
                    "unpaired"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><em class=\"ltx_emph ltx_font_italic\">TTS models:</em>\nFlow matching-based F5-TTS &#160;<cite class=\"ltx_cite ltx_citemacro_cite\">Chen et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib1\" title=\"\">2025</a>)</cite> trained on the 20K hours, w/ and w/o Japanese G2P <cite class=\"ltx_cite ltx_citemacro_cite\">Oura et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib12\" title=\"\">2010</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "models",
                    "chen",
                    "oura",
                    "f5tts",
                    "g2p"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><em class=\"ltx_emph ltx_font_italic\">Reference industry models:</em>\ngpt-4o-mini-tts <cite class=\"ltx_cite ltx_citemacro_cite\">OpenAI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib10\" title=\"\">2025a</a>)</cite> (<span class=\"ltx_text ltx_font_italic\">Coral</span>: female, <span class=\"ltx_text ltx_font_italic\">Ash</span>: male) and gemini-2.5-tts-preview&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">Google (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib4\" title=\"\">2025</a>)</cite> (<span class=\"ltx_text ltx_font_italic\">Zephyr</span>: female, <span class=\"ltx_text ltx_font_italic\">Puck</span>: male).</p>\n\n",
                "matched_terms": [
                    "gpt4ominitts",
                    "models",
                    "male",
                    "female"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use CER to evaluate overall robustness\nand the bad case ratio (Bad), where samples with CER exceed 0.3.</p>\n\n",
                "matched_terms": [
                    "case",
                    "bad",
                    "ratio",
                    "cer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S4.F3\" title=\"Figure 3 &#8227; 4 Experiments &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> illustrates the changes in the average log-likelihood of desirable and undesirable tokens.\nAs training progresses, TKTO (left) effectively increases only that of desirable tokens, whereas SFT (right) tends to increase the log-likelihood of undesirable tokens.</p>\n\n",
                "matched_terms": [
                    "tkto",
                    "sft",
                    "desirable"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S4.F4\" title=\"Figure 4 &#8227; 4.2 Objective Evaluation Results &#8227; 4 Experiments &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> illustrates the token rewards <math alttext=\"\\log\\frac{\\pi^{+}(y_{t}\\mid x,y^{&lt;t})}{\\pi^{-}(y_{t}\\mid x,y^{&lt;t})}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.SSS0.Px3.p1.m1\" intent=\":literal\"><semantics><mrow><mi>log</mi><mo lspace=\"0.167em\">&#8289;</mo><mfrac><mrow><msup><mi>&#960;</mi><mo>+</mo></msup><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>&#8739;</mo><mrow><mi>x</mi><mo>,</mo><msup><mi>y</mi><mrow><mi/><mo>&lt;</mo><mi>t</mi></mrow></msup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msup><mi>&#960;</mi><mo>&#8722;</mo></msup><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>&#8739;</mo><mrow><mi>x</mi><mo>,</mo><msup><mi>y</mi><mrow><mi/><mo>&lt;</mo><mi>t</mi></mrow></msup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\log\\frac{\\pi^{+}(y_{t}\\mid x,y^{&lt;t})}{\\pi^{-}(y_{t}\\mid x,y^{&lt;t})}</annotation></semantics></math> for desirable and undesirable tokens for the target character\n \"&#36763;\" \nand the overall average.\nThe desirable tokens have a higher reward (0.22) compared to the overall mean (0.12), while the undesirable tokens show a much lower value (-1.54), indicating that targeted tokens are automatically assigned larger weights.\nFor undesirable samples, two peaks are observed when a clear difference between <math alttext=\"\\pi^{+}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.SSS0.Px3.p1.m2\" intent=\":literal\"><semantics><msup><mi>&#960;</mi><mo>+</mo></msup><annotation encoding=\"application/x-tex\">\\pi^{+}</annotation></semantics></math> and <math alttext=\"\\pi^{-}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.SSS0.Px3.p1.m3\" intent=\":literal\"><semantics><msup><mi>&#960;</mi><mo>&#8722;</mo></msup><annotation encoding=\"application/x-tex\">\\pi^{-}</annotation></semantics></math> emerges; the reward drops sharply, whereas when no significant difference exists.\nFigure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S4.F5\" title=\"Figure 5 &#8227; 4.2 Objective Evaluation Results &#8227; 4 Experiments &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> also presents a case study showing that the tokens corresponding to the target characters receive notably higher weights.</p>\n\n",
                "matched_terms": [
                    "case",
                    "desirable",
                    "character"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S4.T2\" title=\"Table 2 &#8227; 4.2 Objective Evaluation Results &#8227; 4 Experiments &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> presents the NMOS subjective evaluation scores. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S4.F6\" title=\"Figure 6 &#8227; 4.2 Objective Evaluation Results &#8227; 4 Experiments &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> shows the results of the ABX test.\nIn the subjective evaluations, TKTO also outperforms the base model and the standard KTO.</p>\n\n",
                "matched_terms": [
                    "base",
                    "tkto",
                    "model",
                    "kto",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose TKTO that eliminates the need for paired data, enabling a more data-efficient training paradigm, and directly targets token-level units, automatically providing fine-grained alignment signals without token-level annotations.\nTKTO serves as an off-policy approach compatible with human feedback, while extending it to an on-policy setting remains a promising direction for future work.</p>\n\n",
                "matched_terms": [
                    "tkto",
                    "paired",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The evaluations are conducted on only challenging Japanese data.\nAlthough multiple preference optimization methods and configurations were tested, the base model was limited to CosyVoice2 0.5B model due to the computational resources.\nWhile this work only focuses on preference optimization for TTS, the proposed TKTO framework can potentially be applied to other text generation tasks where specific tokens play a crucial role.</p>\n\n",
                "matched_terms": [
                    "base",
                    "tkto",
                    "data",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The instructions for the subjective evaluation are as follows.\nA Japanese native human annotator listened to the speech samples and rated their naturalness as NMOS on a 5-point scale, where 1 indicates very unnatural and 5 indicates completely natural. In addition, we conducted an ABX test in which the participant listened to two generated speech samples from different models but based on the same input and then chose the one that sounds more natural; if the samples are too similar to distinguish, they are instructed to indicate a tie.\nThe annotator was recruited via a crowdsourcing platform and received appropriate compensation for their work.</p>\n\n",
                "matched_terms": [
                    "models",
                    "different"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our implementation was based on the publicly available codes of prior work <cite class=\"ltx_cite ltx_citemacro_cite\">Chen et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib1\" title=\"\">2025</a>); Du et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib2\" title=\"\">2024</a>)</cite>, which are released under research-permissive licenses, and hyperparameters and libraries used followed those studies.\nBase model and baseline F5-TTS were initialized from the pretrained checkpoints and fine-tuned once.\nTraining took a few minutes on 8<math alttext=\"\\times\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p1.m1\" intent=\":literal\"><semantics><mo>&#215;</mo><annotation encoding=\"application/x-tex\">\\times</annotation></semantics></math>A100 GPUs.\nAll preference optimization experiments were conducted on 1 epoch with 1e-6 learning rate.\nWe set <math alttext=\"\\lambda_{D}=\\lambda_{U}=1\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p1.m2\" intent=\":literal\"><semantics><mrow><msub><mi>&#955;</mi><mi>D</mi></msub><mo>=</mo><msub><mi>&#955;</mi><mi>U</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda_{D}=\\lambda_{U}=1</annotation></semantics></math>, <math alttext=\"\\beta=0.10\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p1.m3\" intent=\":literal\"><semantics><mrow><mi>&#946;</mi><mo>=</mo><mn>0.10</mn></mrow><annotation encoding=\"application/x-tex\">\\beta=0.10</annotation></semantics></math>, we set <math alttext=\"\\mu=1\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p1.m4\" intent=\":literal\"><semantics><mrow><mi>&#956;</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\mu=1</annotation></semantics></math> for desirable tokens, <math alttext=\"\\mu=-1\" class=\"ltx_Math\" display=\"inline\" id=\"A2.p1.m5\" intent=\":literal\"><semantics><mrow><mi>&#956;</mi><mo>=</mo><mrow><mo>&#8722;</mo><mn>1</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\mu=-1</annotation></semantics></math> for undesirable ones, following <cite class=\"ltx_cite ltx_citemacro_citet\">Ethayarajh et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib3\" title=\"\">2024</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "desirable",
                    "rate",
                    "base",
                    "chen",
                    "model",
                    "f5tts",
                    "ethayarajh"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Since the clamping range controls the scaling of the reward weights, it plays an important role in balancing learning stability and sensitivity.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#A2.T3\" title=\"Table 3 &#8227; Appendix B Implementation Details &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> presents the clamping range (L,U) sensitivity analysis results.\nWhile performance remains stable for moderate clamping ranges, wide bounds (e.g., (-3, 3)) can slightly lead to accuracy degradation.\nThis suggests that imposing reasonable constraints on the reward range is beneficial for achieving optimal results.\nWe select <math alttext=\"(-2,2)\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p1.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><mrow><mo>&#8722;</mo><mn>2</mn></mrow><mo>,</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(-2,2)</annotation></semantics></math> as the optimal range for experiments.</p>\n\n",
                "matched_terms": [
                    "accuracy",
                    "results"
                ]
            }
        ]
    },
    "S4.T2": {
        "caption": "Table 2: NMOS comparison (higher is better).",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">Base</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">KTO</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">TKTO (ours)</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">NMOS &#8593;</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">4.15</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">4.21</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">4.26</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "ours",
            "base",
            "tkto",
            "better",
            "higher",
            "kto",
            "nmos",
            "comparison"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S4.T2\" title=\"Table 2 &#8227; 4.2 Objective Evaluation Results &#8227; 4 Experiments &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> presents the NMOS subjective evaluation scores. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S4.F6\" title=\"Figure 6 &#8227; 4.2 Objective Evaluation Results &#8227; 4 Experiments &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> shows the results of the ABX test.\nIn the subjective evaluations, TKTO also outperforms the base model and the standard KTO.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">We extend KTO <cite class=\"ltx_cite ltx_citemacro_cite\">Ethayarajh et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib3\" title=\"\">2024</a>)</cite> to the <em class=\"ltx_emph ltx_font_italic\">token level</em>, proposing Token-level KTO (TKTO) to learn finer-grained token-level signals.</p>\n\n",
                "matched_terms": [
                    "tkto",
                    "kto"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use CosyVoice2 (0.5B) <cite class=\"ltx_cite ltx_citemacro_cite\">Du et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib2\" title=\"\">2024</a>)</cite> fine-tuned on 20K hours of Japanese speech data as our base model and apply our TKTO.\nThe following baselines are considered:</p>\n\n",
                "matched_terms": [
                    "base",
                    "tkto"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S2.T1\" title=\"Table 1 &#8227; 2 LLM-based Text-to-Speech &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> presents the objective evaluation results.\nOur TKTO model achieves the highest Japanese TTS accuracy and the lowest CER and bad case ratio.\nThe non-LLM baseline F5-TTS shows extremely low accuracy regardless of whether it uses G2P or not, highlighting the importance of LLMs to consider contextual information.\nThe use of unpaired data allows us to leverage samples that are always desirable or always undesirable, which cannot be used in paired training.\nThis leads to a significant improvement in accuracy (0.949 or 0.958), surpassing even strong industry models.\nUsing only paired data excludes samples that always produce desirable outputs, causing the model to overfit toward undesirable examples. As a result, accuracy improvement is limited, although the CER and bad case ratio become slightly lower.\nCompared with KTO, our model achieves improvements across all metrics, demonstrating the effectiveness of token-level targeted optimization.</p>\n\n",
                "matched_terms": [
                    "tkto",
                    "kto"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The evaluations are conducted on only challenging Japanese data.\nAlthough multiple preference optimization methods and configurations were tested, the base model was limited to CosyVoice2 0.5B model due to the computational resources.\nWhile this work only focuses on preference optimization for TTS, the proposed TKTO framework can potentially be applied to other text generation tasks where specific tokens play a crucial role.</p>\n\n",
                "matched_terms": [
                    "base",
                    "tkto"
                ]
            }
        ]
    },
    "A2.T3": {
        "caption": "Table 3: Parameter sensitivity analysis.",
        "body": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">Parameter</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"3\">Female</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">Male</th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r\">L, U</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Acc &#8593;</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">CER &#8595;</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">Bad &#8595;</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Acc &#8593;</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">CER &#8595;</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Bad &#8595;</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">-1, 1</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.937</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.076</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.028</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.951</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.088</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.031</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">-2, 2</th>\n<td class=\"ltx_td ltx_align_center\">0.949</td>\n<td class=\"ltx_td ltx_align_center\">0.075</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\">0.029</td>\n<td class=\"ltx_td ltx_align_center\">0.958</td>\n<td class=\"ltx_td ltx_align_center\">0.085</td>\n<td class=\"ltx_td ltx_align_center\">0.027</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">-3, 3</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.956</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.072</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">0.027</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.948</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.088</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.028</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "analysis",
            "bad",
            "acc",
            "sensitivity",
            "cer",
            "female",
            "male",
            "parameter"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Since the clamping range controls the scaling of the reward weights, it plays an important role in balancing learning stability and sensitivity.\nTable&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#A2.T3\" title=\"Table 3 &#8227; Appendix B Implementation Details &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> presents the clamping range (L,U) sensitivity analysis results.\nWhile performance remains stable for moderate clamping ranges, wide bounds (e.g., (-3, 3)) can slightly lead to accuracy degradation.\nThis suggests that imposing reasonable constraints on the reward range is beneficial for achieving optimal results.\nWe select <math alttext=\"(-2,2)\" class=\"ltx_Math\" display=\"inline\" id=\"A3.p1.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">(</mo><mrow><mo>&#8722;</mo><mn>2</mn></mrow><mo>,</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(-2,2)</annotation></semantics></math> as the optimal range for experiments.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">For each text sentence, we generate five speech samples for both female and male Japanese speakers <cite class=\"ltx_cite ltx_citemacro_cite\">Okamoto et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib9\" title=\"\">2023</a>)</cite> using a TTS model, with training data containing 23 hours of speech for each speaker. Among them, the sample with the correct pronunciation and the lowest CER is selected as a desirable sample. Conversely, the sample with the incorrect pronunciation and the highest CER is selected as an undesirable sample.\nThe CER is computed using the whisper-v3-large <cite class=\"ltx_cite ltx_citemacro_cite\">Radford et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib13\" title=\"\">2023</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "female",
                    "male",
                    "cer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><em class=\"ltx_emph ltx_font_italic\">Reference industry models:</em>\ngpt-4o-mini-tts <cite class=\"ltx_cite ltx_citemacro_cite\">OpenAI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib10\" title=\"\">2025a</a>)</cite> (<span class=\"ltx_text ltx_font_italic\">Coral</span>: female, <span class=\"ltx_text ltx_font_italic\">Ash</span>: male) and gemini-2.5-tts-preview&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">Google (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#bib.bib4\" title=\"\">2025</a>)</cite> (<span class=\"ltx_text ltx_font_italic\">Zephyr</span>: female, <span class=\"ltx_text ltx_font_italic\">Puck</span>: male).</p>\n\n",
                "matched_terms": [
                    "female",
                    "male"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use CER to evaluate overall robustness\nand the bad case ratio (Bad), where samples with CER exceed 0.3.</p>\n\n",
                "matched_terms": [
                    "bad",
                    "cer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.05799v1#S2.T1\" title=\"Table 1 &#8227; 2 LLM-based Text-to-Speech &#8227; Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> presents the objective evaluation results.\nOur TKTO model achieves the highest Japanese TTS accuracy and the lowest CER and bad case ratio.\nThe non-LLM baseline F5-TTS shows extremely low accuracy regardless of whether it uses G2P or not, highlighting the importance of LLMs to consider contextual information.\nThe use of unpaired data allows us to leverage samples that are always desirable or always undesirable, which cannot be used in paired training.\nThis leads to a significant improvement in accuracy (0.949 or 0.958), surpassing even strong industry models.\nUsing only paired data excludes samples that always produce desirable outputs, causing the model to overfit toward undesirable examples. As a result, accuracy improvement is limited, although the CER and bad case ratio become slightly lower.\nCompared with KTO, our model achieves improvements across all metrics, demonstrating the effectiveness of token-level targeted optimization.</p>\n\n",
                "matched_terms": [
                    "bad",
                    "cer"
                ]
            }
        ]
    }
}