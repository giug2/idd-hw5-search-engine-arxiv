{
    "Sx5.T1": {
        "source_file": "SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise",
        "caption": "Table 1: Training attack effectiveness. Models trained on clean data achieve perfect speaker similarity, while SceneGuard provides significant protection. Statistical significance: p<0.01p<0.01, p<0.001p<0.001.",
        "body": "Training Data\nSIM ↓\\downarrow\n\nWER (%)\nPESQ\nSTOI\n\npp-value\nCohen’s dd\n\n\n\n\n\nClean\n1.000\n0.00\n4.64\n1.00\n–\n–\n\n\nRandom Noise\n0.965\n5.82\n1.85\n0.97\n0.0030.003\n1.42\n\n\nGaussian Noise\n0.968\n5.28\n1.92\n0.98\n0.0020.002\n1.51\n\n\nSceneGuard (Ours)\n0.945\n2.77\n2.22\n0.99\n<10−15<10^{-15}\n2.18",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Training Data</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">SIM <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T1.m5\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WER (%)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">PESQ</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">STOI</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">\n<math alttext=\"p\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T1.m6\" intent=\":literal\"><semantics><mi>p</mi><annotation encoding=\"application/x-tex\">p</annotation></semantics></math>-value</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Cohen&#8217;s <math alttext=\"d\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T1.m7\" intent=\":literal\"><semantics><mi>d</mi><annotation encoding=\"application/x-tex\">d</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">Clean</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">1.000</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">4.64</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">1.00</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">&#8211;</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">&#8211;</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Random Noise</td>\n<td class=\"ltx_td ltx_align_center\">0.965</td>\n<td class=\"ltx_td ltx_align_center\">5.82</td>\n<td class=\"ltx_td ltx_align_center\">1.85</td>\n<td class=\"ltx_td ltx_align_center\">0.97</td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.003\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T1.m8\" intent=\":literal\"><semantics><mn>0.003</mn><annotation encoding=\"application/x-tex\">0.003</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\">1.42</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Gaussian Noise</td>\n<td class=\"ltx_td ltx_align_center\">0.968</td>\n<td class=\"ltx_td ltx_align_center\">5.28</td>\n<td class=\"ltx_td ltx_align_center\">1.92</td>\n<td class=\"ltx_td ltx_align_center\">0.98</td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"0.002\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T1.m9\" intent=\":literal\"><semantics><mn>0.002</mn><annotation encoding=\"application/x-tex\">0.002</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\">1.51</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">SceneGuard (Ours)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\">0.945</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\">2.77</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">2.22</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\">0.99</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><math alttext=\"&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T1.m10\" intent=\":literal\"><semantics><mrow><mi/><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">&lt;10^{-15}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\">2.18</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "training",
            "stoi",
            "↓downarrow",
            "ours",
            "sim",
            "protection",
            "significance",
            "random",
            "statistical",
            "p001p001",
            "gaussian",
            "10−151015",
            "ppvalue",
            "wer",
            "speaker",
            "attack",
            "sceneguard",
            "effectiveness",
            "noise",
            "trained",
            "p0001p0001",
            "pesq",
            "similarity",
            "significant",
            "clean",
            "perfect",
            "models",
            "while",
            "cohen’s",
            "data",
            "provides",
            "achieve"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">We evaluate SceneGuard&#8217;s effectiveness against training attacks where an adversary uses protected recordings to fine-tune TTS models. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.T1\" title=\"Table 1 &#8227; Training Attack Protection &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> summarizes the results across different defense strategies.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Voice cloning technology poses significant privacy threats by enabling unauthorized speech synthesis from limited audio samples. Existing defenses based on imperceptible adversarial perturbations are vulnerable to common audio preprocessing such as denoising and compression. We propose SceneGuard, a training-time voice protection method that applies scene-consistent audible background noise to speech recordings. Unlike imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes (e.g., airport, street, park) to create protective noise that is contextually appropriate and robust to countermeasures. We evaluate SceneGuard on text-to-speech training attacks, demonstrating 5.5% speaker similarity degradation with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>) while preserving 98.6% speech intelligibility (STOI = 0.986). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures including MP3 compression, spectral subtraction, lowpass filtering, and downsampling. Our results suggest that audible, scene-consistent noise provides a more robust alternative to imperceptible perturbations for training-time voice protection. The source code are available at: <span class=\"ltx_ref ltx_nolink ltx_url ltx_ref_self\">https://github.com/richael-sang/SceneGuard</span>.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "statistical",
                    "training",
                    "stoi",
                    "sceneguard",
                    "provides",
                    "similarity",
                    "significant",
                    "while",
                    "cohen’s",
                    "speaker",
                    "protection",
                    "significance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Deep learning has enabled high-fidelity voice cloning systems capable of synthesizing speech that closely mimics a target speaker&#8217;s voice&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">gao2025black</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">fanantifake</span>)</cite>. While these technologies have legitimate applications in accessibility and entertainment, they also pose serious threats to privacy and security. Attackers can use unauthorized voice recordings to train text-to-speech (TTS) or voice conversion (VC) models, enabling impersonation attacks, voice-based authentication breaches, and creation of misleading audio content&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">wang2025one</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "models",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent work has explored proactive defense mechanisms that protect voice recordings from being exploited for cloning. A prominent approach adds imperceptible adversarial perturbations to audio recordings, degrading the quality of models trained on protected data&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite>. However, these defenses face a fundamental challenge: imperceptible perturbations are fragile. Standard audio preprocessing operations such as denoising, compression, and filtering can remove or significantly reduce these perturbations, rendering the protection ineffective&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">fei2025vocalcrypt</span>)</cite>. Moreover, the field lacks a unified, human&#8211;perception&#8211;aligned metric for speech perturbations, so imperceptibility is enforced via proxies (e.g., <math alttext=\"L_{p}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p2.m1\" intent=\":literal\"><semantics><msub><mi>L</mi><mi>p</mi></msub><annotation encoding=\"application/x-tex\">L_{p}</annotation></semantics></math> bounds or heuristic masking) that guarantee neither true inaudibility nor robustness&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">li2025cloneshield</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">feng2025enkidu</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "models",
                    "trained",
                    "protection",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We observe that the requirement for imperceptibility may be unnecessarily restrictive. In many real-world scenarios, background noise is expected and acceptable. For instance, recordings made in cafes, streets, or offices naturally contain ambient noise. This insight leads to a key question: can we design voice protection mechanisms that leverage audible but contextually appropriate noise?</p>\n\n",
                "matched_terms": [
                    "noise",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SceneGuard, a training-time defense that applies scene-consistent audible background noise to speech recordings through gradient-based optimization. SceneGuard first classifies the acoustic scene of input speech, then jointly optimizes a temporal mask <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m1\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while maintaining usability. For example, speech recorded in an airport is mixed with optimized airport background noise, creating a protective layer that appears natural and contextually plausible. This design offers three advantages: (1) optimization automatically finds the protection-usability trade-off, (2) the protection is harder to remove because scene-consistent noise cannot be easily separated from speech without degrading speech quality, and (3) the defense is robust to common audio preprocessing operations.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "similarity",
                    "while",
                    "speaker",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate SceneGuard on training attack scenarios where an attacker uses protected recordings to fine-tune TTS models. Our experiments on 100 training samples and 40 test samples demonstrate 5.5% speaker similarity degradation (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>), indicating strong statistical evidence of protection effectiveness. Importantly, SceneGuard preserves 98.6% speech intelligibility (STOI = 0.986) and achieves low word error rate (WER = 3.6%), demonstrating that protected speech remains highly usable. Robustness evaluation shows that SceneGuard maintains protection under MP3 compression and even exhibits enhanced protection under denoising, lowpass filtering, and downsampling operations.</p>\n\n",
                "matched_terms": [
                    "statistical",
                    "training",
                    "stoi",
                    "effectiveness",
                    "models",
                    "similarity",
                    "attack",
                    "cohen’s",
                    "wer",
                    "speaker",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose a novel training-time voice protection method based on scene-consistent audible background noise with joint optimization of temporal mask and noise strength, departing from the conventional imperceptibility requirement.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We design a gradient-based optimization framework that automatically balances speaker protection and speech usability under SNR constraints.</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We demonstrate strong protection against training attacks with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.I1.i3.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.I1.i3.p1.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>) while preserving speech usability (STOI = 0.986, WER = 3.6%).</p>\n\n",
                "matched_terms": [
                    "statistical",
                    "training",
                    "stoi",
                    "while",
                    "cohen’s",
                    "wer",
                    "protection",
                    "significance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We provide comprehensive robustness evaluation showing that SceneGuard maintains or enhances protection under five common audio countermeasures.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent work has explored adversarial perturbations as a proactive defense against voice cloning. VoiceBlock&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>)</cite> is a real-time de-identification approach that learns a time-varying FIR filter to apply perceptually inconspicuous, streaming-friendly perturbations for evading speaker recognition. Building on proactive protection but shifting the threat model to training-time cloning, SafeSpeech&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite> embeds imperceptible, universal perturbations via its SPEC objective to degrade generative TTS across models while emphasizing transferability and robustness. Contemporary work&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">gao2025black</span>)</cite> proposes a black-box defense for voice conversion that adds imperceptible perturbations and optimizes them in latent space with evolution-based search to adapt against unknown VC systems. While these methods demonstrate effectiveness in controlled settings, they face a fundamental limitation: imperceptible perturbations are inherently fragile to common audio processing operations.</p>\n\n",
                "matched_terms": [
                    "models",
                    "while",
                    "speaker",
                    "protection",
                    "effectiveness"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent voice protection methods&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>)</cite> embed imperceptible adversarial perturbations by minimizing <math alttext=\"\\ell_{p}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m1\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#8467;</mi><mi>p</mi></msub><annotation encoding=\"application/x-tex\">\\ell_{p}</annotation></semantics></math> norms (typically <math alttext=\"\\|\\delta\\|_{\\infty}\\leq\\epsilon\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mrow><mo stretchy=\"false\">&#8214;</mo><mi>&#948;</mi><mo stretchy=\"false\">&#8214;</mo></mrow><mi mathvariant=\"normal\">&#8734;</mi></msub><mo>&#8804;</mo><mi>&#1013;</mi></mrow><annotation encoding=\"application/x-tex\">\\|\\delta\\|_{\\infty}\\leq\\epsilon</annotation></semantics></math> with <math alttext=\"\\epsilon\\approx 8/255\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>&#1013;</mi><mo>&#8776;</mo><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\epsilon\\approx 8/255</annotation></semantics></math>). While these perturbations are inaudible, they are <span class=\"ltx_text ltx_font_italic\">fragile</span>: standard audio processing operations such as lossy compression (MP3, AAC), speech enhancement, or denoising can significantly attenuate protection effectiveness. For instance, SafeSpeech&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite> shows that DeepMucs&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">demucs</span>)</cite> denoising reduces protection by up to 42% (SIM increases from 0.204 to 0.284). This fragility arises because imperceptible perturbations occupy high-frequency or low-energy regions that are specifically targeted by perceptual codecs and noise reduction algorithms.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "sim",
                    "while",
                    "protection",
                    "effectiveness"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Acoustic scene classification (ASC) aims to identify the environmental context of audio recordings&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">tau_dataset</span>)</cite>. State-of-the-art ASC systems use deep convolutional networks trained on large-scale datasets such as TAU Urban Acoustic Scenes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">ASC1</span>)</cite>. SceneGuard leverages ASC to ensure that protective noise matches the acoustic context of input speech, creating a more natural and robust defense compared to context-agnostic perturbations.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "trained",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We consider a training-time attack scenario where an adversary aims to clone a target speaker&#8217;s voice by fine-tuning a pre-trained TTS or VC model on unauthorized audio recordings. The attacker operates in a black-box setting, having no knowledge of the protection mechanism applied to the training data. Formally, given a dataset <math alttext=\"\\mathcal{D}=\\{(x_{i},y_{i})\\}_{i=1}^{N}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119967;</mi><mo>=</mo><msubsup><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\mathcal{D}=\\{(x_{i},y_{i})\\}_{i=1}^{N}</annotation></semantics></math> of protected speech samples <math alttext=\"x^{\\prime}_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m2\" intent=\":literal\"><semantics><msubsup><mi>x</mi><mi>i</mi><mo>&#8242;</mo></msubsup><annotation encoding=\"application/x-tex\">x^{\\prime}_{i}</annotation></semantics></math> and corresponding text labels <math alttext=\"y_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m3\" intent=\":literal\"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">y_{i}</annotation></semantics></math>, the attacker solves:</p>\n\n",
                "matched_terms": [
                    "data",
                    "attack",
                    "protection",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The defender&#8217;s objective is to apply a transformation <math alttext=\"\\mathcal{T}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><annotation encoding=\"application/x-tex\">\\mathcal{T}</annotation></semantics></math> to speech <math alttext=\"x\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m2\" intent=\":literal\"><semantics><mi>x</mi><annotation encoding=\"application/x-tex\">x</annotation></semantics></math> that produces protected audio <math alttext=\"x^{\\prime}=\\mathcal{T}(x,s)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m3\" intent=\":literal\"><semantics><mrow><msup><mi>x</mi><mo>&#8242;</mo></msup><mo>=</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">x^{\\prime}=\\mathcal{T}(x,s)</annotation></semantics></math> (where <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m4\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math> denotes acoustic scene context) satisfying two criteria: (1) <span class=\"ltx_text ltx_font_italic\">Protection</span>: degraded speaker identity prevents successful cloning, formally:</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"e(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m5\" intent=\":literal\"><semantics><mrow><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">e(\\cdot)</annotation></semantics></math> is a speaker verification encoder and <math alttext=\"\\tau_{\\text{sim}},\\tau_{\\text{eer}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m6\" intent=\":literal\"><semantics><mrow><msub><mi>&#964;</mi><mtext>sim</mtext></msub><mo>,</mo><msub><mi>&#964;</mi><mtext>eer</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\tau_{\\text{sim}},\\tau_{\\text{eer}}</annotation></semantics></math> are protection thresholds; and (2) <span class=\"ltx_text ltx_font_italic\">Usability</span>: preserved intelligibility for legitimate communication:</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Unlike random noise addition, we require that the protective transformation preserves acoustic scene consistency. Specifically, for a speech recording <math alttext=\"x\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m1\" intent=\":literal\"><semantics><mi>x</mi><annotation encoding=\"application/x-tex\">x</annotation></semantics></math> that an acoustic scene classification (ASC) model recognizes as scene <math alttext=\"s\\in\\mathcal{S}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m2\" intent=\":literal\"><semantics><mrow><mi>s</mi><mo>&#8712;</mo><mi class=\"ltx_font_mathcaligraphic\">&#119982;</mi></mrow><annotation encoding=\"application/x-tex\">s\\in\\mathcal{S}</annotation></semantics></math> (e.g., &#8220;park&#8221;, &#8220;street_traffic&#8221;), the protected audio <math alttext=\"x^{\\prime}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m3\" intent=\":literal\"><semantics><msup><mi>x</mi><mo>&#8242;</mo></msup><annotation encoding=\"application/x-tex\">x^{\\prime}</annotation></semantics></math> should remain plausibly associated with the same scene <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m4\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math>:</p>\n\n",
                "matched_terms": [
                    "random",
                    "noise"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Naive mixing of speech with scene noise at a fixed signal-to-noise ratio (SNR) and uniform temporal weighting faces two risks: (1) insufficient protection if SNR is too high or noise placement is suboptimal, resulting in speaker embeddings that remain similar (<math alttext=\"\\text{SIM}&gt;\\tau_{\\text{sim}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m1\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>&gt;</mo><msub><mi>&#964;</mi><mtext>sim</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}&gt;\\tau_{\\text{sim}}</annotation></semantics></math>); (2) excessive degradation if SNR is too low or noise overwhelms speech regions, causing unacceptable WER increases. To navigate this trade-off, we formulate protection as an <span class=\"ltx_text ltx_font_italic\">optimization problem</span>: jointly optimize the temporal mask <math alttext=\"m(t)\\in[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m2\" intent=\":literal\"><semantics><mrow><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)\\in[0,1]</annotation></semantics></math> controlling when noise is applied, and the noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m3\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> controlling overall SNR, to minimize speaker similarity while maintaining usability. This optimization ensures that the noise is strategically placed (e.g., emphasizing pauses or non-critical phonemes) and calibrated to the specific speech sample.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "similarity",
                    "while",
                    "wer",
                    "speaker",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Overview.</span> Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.F1\" title=\"Figure 1 &#8227; Need for Optimization. &#8227; Scene-Consistent Audible Noise Defense &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> summarizes SceneGuard:\n(1) we obtain a scene label <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m1\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math> via ASC (or user-specified) and sample noise <math alttext=\"n_{k}\\!\\in\\!\\mathcal{N}_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub><mo lspace=\"0.108em\" rspace=\"0.108em\">&#8712;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119977;</mi><mi>s</mi></msub></mrow><annotation encoding=\"application/x-tex\">n_{k}\\!\\in\\!\\mathcal{N}_{s}</annotation></semantics></math>;\n(2) protected audio is produced by the mixer <math alttext=\"x^{\\prime}(t)=x(t)+\\gamma\\,m(t)\\odot n_{k}(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m3\" intent=\":literal\"><semantics><mrow><mrow><msup><mi>x</mi><mo>&#8242;</mo></msup><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>x</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mrow><mi>&#947;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo rspace=\"0.055em\" stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"0.222em\">&#8857;</mo><msub><mi>n</mi><mi>k</mi></msub></mrow><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">x^{\\prime}(t)=x(t)+\\gamma\\,m(t)\\odot n_{k}(t)</annotation></semantics></math> (Sec.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.E5\" title=\"In Mixing Model. &#8227; Optimization Objective &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>);\n(3) an optimization loop updates <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m4\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m5\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> using an ECAPA-based similarity loss with SNR/regularization\nconstraints (Sec.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.E6\" title=\"In Objective Function. &#8227; Optimization Objective &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>). The defended data are then used against training-time and zero-shot attacks.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "similarity",
                    "data",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Given clean speech <math alttext=\"x(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><mi>x</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">x(t)</annotation></semantics></math> and a scene-consistent noise signal <math alttext=\"n_{k}(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx1.p1.m2\" intent=\":literal\"><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">n_{k}(t)</annotation></semantics></math> sampled from a scene-specific library <math alttext=\"\\mathcal{N}_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx1.p1.m3\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#119977;</mi><mi>s</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{N}_{s}</annotation></semantics></math>, we define the protected speech as:</p>\n\n",
                "matched_terms": [
                    "noise",
                    "clean"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We jointly optimize <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx2.p1.m1\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> and <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx2.p1.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while regularizing for usability and smoothness. The total loss is:</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "similarity",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Speaker Similarity Loss</span> <math alttext=\"\\mathcal{L}_{\\text{SIM}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.I2.i1.p1.m1\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8466;</mi><mtext>SIM</mtext></msub><annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\text{SIM}}</annotation></semantics></math>: Minimizes cosine similarity between speaker embeddings of protected and clean audio:</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "similarity",
                    "clean"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"e(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.I2.i1.p1.m2\" intent=\":literal\"><semantics><mrow><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">e(\\cdot)</annotation></semantics></math> is a pre-trained speaker verification encoder (ECAPA-TDNN&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">ecapa</span>)</cite>). This is the primary protection objective.</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">: We use LibriTTS&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">libritts</span>)</cite>, a multi-speaker English corpus derived from audiobooks. We split the data into 100 training samples and 40 test samples for training attack evaluation, with additional subsets for zero-shot and robustness experiments.</p>\n\n",
                "matched_terms": [
                    "data",
                    "attack",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">: We use the TAU Urban Acoustic Scenes 2022 Mobile Development dataset&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">tau_dataset</span>)</cite>, which contains authentic recordings from 10 urban scenes captured with mobile devices. The dataset provides diverse acoustic contexts including transportation hubs (airport, bus, metro), public spaces (park, square, mall), and street environments. We extract 50,000 three-second clips (5,000 per scene) for our noise library.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "provides"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use ECAPA-TDNN&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">ecapa</span>)</cite>, a state-of-the-art speaker verification model from the SpeechBrain toolkit. The model extracts 192-dimensional speaker embeddings, which we use to compute speaker similarity via cosine distance. ECAPA-TDNN achieves strong performance on VoxCeleb and is widely used for speaker verification tasks.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We employ Whisper Base&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">whisper</span>)</cite>, an encoder-decoder transformer trained on 680,000 hours of multilingual speech data. Whisper provides robust transcription for measuring speech intelligibility via word error rate (WER). We use the base model (74M parameters) for computational efficiency.</p>\n\n",
                "matched_terms": [
                    "trained",
                    "data",
                    "provides",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For training attack experiments, we reference BERT-VITS2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">bertvits2</span>)</cite>, a recent TTS architecture that combines BERT-based text encoding with VITS neural vocoder. While we do not perform full TTS training due to computational constraints, we use speaker embedding degradation as a proxy for TTS quality, following established evaluation protocols&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "while",
                    "speaker",
                    "attack",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SceneGuard employs gradient-based optimization to jointly learn the temporal mask <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.p1.m1\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.p1.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math>. We describe the key hyperparameters and design choices:</p>\n\n",
                "matched_terms": [
                    "noise",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We minimize speaker similarity while maintaining usability constraints. The primary loss term is speaker embedding cosine similarity computed using ECAPA-TDNN. We add a regularization term (<math alttext=\"\\lambda_{\\text{REG}}=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><msub><mi>&#955;</mi><mtext>REG</mtext></msub><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}=0.01</annotation></semantics></math>) that penalizes mask roughness and excessive noise strength to promote smooth, stable solutions.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "speaker",
                    "similarity",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use the Adam optimizer&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">adam</span>)</cite> with learning rate <math alttext=\"\\text{lr}=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx2.p1.m1\" intent=\":literal\"><semantics><mrow><mtext>lr</mtext><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\text{lr}=0.01</annotation></semantics></math> and default momentum parameters (<math alttext=\"\\beta_{1}=0.9\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx2.p1.m2\" intent=\":literal\"><semantics><mrow><msub><mi>&#946;</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn></mrow><annotation encoding=\"application/x-tex\">\\beta_{1}=0.9</annotation></semantics></math>, <math alttext=\"\\beta_{2}=0.999\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx2.p1.m3\" intent=\":literal\"><semantics><mrow><msub><mi>&#946;</mi><mn>2</mn></msub><mo>=</mo><mn>0.999</mn></mrow><annotation encoding=\"application/x-tex\">\\beta_{2}=0.999</annotation></semantics></math>). We run optimization for 50 epochs per sample, which empirically provides good convergence. To ensure training stability, we apply gradient clipping with maximum norm 1.0.</p>\n\n",
                "matched_terms": [
                    "training",
                    "provides"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We simulate an attacker who fine-tunes a TTS model on protected recordings. To evaluate protection effectiveness, we measure speaker embedding quality and consistency on training data, then assess the similarity between embeddings extracted from clean and defended audio on held-out test samples. Lower test similarity indicates successful protection.</p>\n\n",
                "matched_terms": [
                    "training",
                    "similarity",
                    "clean",
                    "data",
                    "speaker",
                    "protection",
                    "effectiveness"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate protection against zero-shot voice cloning, where an attacker uses protected recordings as reference audio for inference-time cloning. We generate synthetic speech using a pre-trained model with clean versus defended reference, measuring speaker similarity to the original speaker.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "protection",
                    "clean"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We test whether protection persists under five common audio preprocessing operations: MP3 compression (128 kbps and 64 kbps), spectral subtraction denoising, lowpass filtering (3400 Hz cutoff), and downsampling to 8 kHz. For each countermeasure, we re-compute speaker similarity and WER to assess protection retention.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "protection",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We compute cosine similarity between speaker embeddings extracted from clean and defended (or synthesized) audio. Higher similarity indicates stronger speaker identity preservation. Protection effectiveness is measured as similarity degradation.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "clean",
                    "speaker",
                    "protection",
                    "effectiveness"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We employ PESQ&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">pesq</span>)</cite> (Perceptual Evaluation of Speech Quality) and STOI&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">stoi</span>)</cite> (Short-Time Objective Intelligibility) as objective quality metrics. PESQ ranges from -0.5 to 4.5 (higher is better), with scores above 3.0 considered good quality. STOI ranges from 0 to 1 (higher is better), with scores above 0.85 indicating high intelligibility.</p>\n\n",
                "matched_terms": [
                    "pesq",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We compute MCD between clean and defended speech to quantify spectral distortion. Lower MCD indicates closer acoustic similarity.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "clean"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To demonstrate the advantage of scene-consistent noise, we compare SceneGuard against two baselines:</p>\n\n",
                "matched_terms": [
                    "noise",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Uniform random noise sampled from <math alttext=\"[-1,1]\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx6.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mrow><mo>&#8722;</mo><mn>1</mn></mrow><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[-1,1]</annotation></semantics></math> and mixed at the same SNR range as SceneGuard. This baseline lacks scene consistency.</p>\n\n",
                "matched_terms": [
                    "random",
                    "noise",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Zero-mean Gaussian noise with unit variance, scaled to match SceneGuard&#8217;s SNR range. This represents a simple additive noise baseline commonly used in audio processing.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "gaussian"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use permutation tests with <math alttext=\"n=10,000\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx7.SSSx2.p1.m1\" intent=\":literal\"><semantics><mrow><mi>n</mi><mo>=</mo><mrow><mn>10</mn><mo>,</mo><mn>000</mn></mrow></mrow><annotation encoding=\"application/x-tex\">n=10,000</annotation></semantics></math> iterations to assess statistical significance of protection effects. We report p-values and Cohen&#8217;s <math alttext=\"d\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx7.SSSx2.p1.m2\" intent=\":literal\"><semantics><mi>d</mi><annotation encoding=\"application/x-tex\">d</annotation></semantics></math> effect sizes for key comparisons.</p>\n\n",
                "matched_terms": [
                    "statistical",
                    "protection",
                    "cohen’s",
                    "significance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SceneGuard achieves 5.5% speaker similarity degradation (<math alttext=\"\\text{SIM}=0.945\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m1\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>=</mo><mn>0.945</mn></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}=0.945</annotation></semantics></math>) compared to clean training (<math alttext=\"\\text{SIM}=1.000\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m2\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>=</mo><mn>1.000</mn></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}=1.000</annotation></semantics></math>). This protection effect is statistically significant with <math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math> (permutation test, <math alttext=\"n=10,000\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m4\" intent=\":literal\"><semantics><mrow><mi>n</mi><mo>=</mo><mrow><mn>10</mn><mo>,</mo><mn>000</mn></mrow></mrow><annotation encoding=\"application/x-tex\">n=10,000</annotation></semantics></math> iterations) and demonstrates a large effect size (Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m5\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>). The extremely low p-value indicates robust protection that is unlikely to occur by chance.</p>\n\n",
                "matched_terms": [
                    "training",
                    "similarity",
                    "significant",
                    "clean",
                    "cohen’s",
                    "speaker",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Importantly, SceneGuard maintains high usability. Protected speech achieves WER of 2.77%, indicating near-perfect transcription accuracy. The STOI score of 0.99 confirms that intelligibility is essentially preserved. While PESQ (2.22) is below the ideal threshold of 3.0, it remains in an acceptable range for many applications.</p>\n\n",
                "matched_terms": [
                    "stoi",
                    "pesq",
                    "while",
                    "wer",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.F2\" title=\"Figure 2 &#8227; Training Attack Protection &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> visualizes the training attack results, comparing speaker similarity degradation across defense methods. SceneGuard demonstrates stronger protection than random or Gaussian noise baselines while maintaining comparable usability.</p>\n\n",
                "matched_terms": [
                    "random",
                    "noise",
                    "training",
                    "gaussian",
                    "similarity",
                    "attack",
                    "while",
                    "speaker",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The STOI score of 0.986 significantly exceeds the intelligibility threshold of 0.85, indicating that protected speech remains highly comprehensible. WER of 3.60% with a narrow confidence interval [1.40%, 6.43%] demonstrates robust transcription accuracy across samples. While PESQ falls slightly below the ideal 3.0 threshold, the value of 2.034 is acceptable for many practical applications and represents a deliberate trade-off for robustness.</p>\n\n",
                "matched_terms": [
                    "while",
                    "wer",
                    "pesq",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SceneGuard demonstrates remarkable robustness. MP3 compression at both 128 kbps and 64 kbps slightly reduces similarity but maintains protection (SIM &#161; 0.91). More aggressive operations such as spectral subtraction, lowpass filtering, and downsampling actually enhance protection, reducing similarity to 0.745, 0.704, and 0.688 respectively.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "protection",
                    "sceneguard",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This counterintuitive enhancement occurs because these operations preferentially damage the clean speech components relative to the protective noise. Spectral subtraction removes stationary components but preserves scene-consistent temporal variations. Lowpass filtering and downsampling reduce high-frequency detail critical for speaker identity while preserving protective noise structure. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.F3\" title=\"Figure 3 &#8227; Robustness to Countermeasures &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> visualizes the robustness results as a heatmap, showing speaker similarity and WER under different countermeasures.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "similarity",
                    "clean",
                    "while",
                    "wer",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Using defended reference audio reduces mean speaker similarity from 0.618 to 0.588, representing a 5.0% degradation. More importantly, the attack success rate (similarity <math alttext=\"&gt;0.7\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx4.p2.m1\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>0.7</mn></mrow><annotation encoding=\"application/x-tex\">&gt;0.7</annotation></semantics></math>) drops from 20.0% to 13.3%, a 33.5% relative reduction. This demonstrates that SceneGuard provides meaningful protection even in zero-shot scenarios where the attacker does not perform training. Using defended reference audio reduces mean speaker similarity from 0.618 to 0.588 (-5.0%) and lowers the attack success rate from 20.0% to 13.3% (-6.7 pp, 33.5% relative), indicating meaningful zero-shot protection.</p>\n\n",
                "matched_terms": [
                    "training",
                    "provides",
                    "similarity",
                    "attack",
                    "speaker",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.T5\" title=\"Table 5 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents the quantitative results. Lower SNR (stronger noise) provides better protection but degrades usability, while higher SNR (weaker noise) improves usability but reduces protection. The [10, 20] dB range achieves an effective balance, providing 5.5% similarity degradation while maintaining STOI above 0.98 and WER below 4%.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "stoi",
                    "similarity",
                    "while",
                    "wer",
                    "protection",
                    "provides"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.F4\" title=\"Figure 4 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> visualizes this trade-off using a dual-axis plot showing protection strength (speaker similarity degradation) and usability (STOI) as functions of SNR range.</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "similarity",
                    "protection",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The ablation study validates our choice of SNR range and demonstrates that SceneGuard&#8217;s protection can be tuned based on application requirements. Users prioritizing strong protection can select lower SNR, while those prioritizing quality can use higher SNR, with the [10, 20] dB range serving as a reasonable default.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization nearly doubles the protection strength, achieving 5.5% degradation compared to 2.8% for direct mixing. This 2.7 percentage point improvement comes at minimal usability cost: STOI decreases by only 0.003 (from 0.989 to 0.986) and WER increases by 0.4 percentage points (from 3.2% to 3.6%), both negligible changes.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "wer",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The key advantage of optimization is its ability to identify optimal mask patterns. Direct mixing applies a uniform stochastic mask, which may unnecessarily distort speech regions while under-protecting others. In contrast, gradient-based optimization adaptively concentrates protection in regions that most effectively reduce speaker similarity while avoiding critical speech segments.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "protection",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The regularization weight <math alttext=\"\\lambda_{\\text{REG}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m1\" intent=\":literal\"><semantics><msub><mi>&#955;</mi><mtext>REG</mtext></msub><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}</annotation></semantics></math> controls the smoothness of the temporal mask. Higher values (<math alttext=\"\\lambda=0.1\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m2\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.1</annotation></semantics></math>) produce smoother masks but slightly reduce protection strength (SIM = 0.958). Lower values (<math alttext=\"\\lambda=0.001\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m3\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.001</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.001</annotation></semantics></math>) allow rougher masks with marginally better protection (SIM = 0.939) but risk overfitting. Our default <math alttext=\"\\lambda=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m4\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.01</annotation></semantics></math> strikes a good balance.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The number of epochs shows diminishing returns beyond 50 iterations. While 100 epochs achieve slightly better protection (SIM = 0.943), the improvement is minimal (0.2 percentage points) and doubles computation time. 20 epochs provide fast computation but do not fully converge. We therefore recommend 50 epochs as the default, offering good convergence without excessive cost.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "achieve",
                    "while",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The key insight behind SceneGuard is that scene-consistent noise is fundamentally different from random or imperceptible perturbations. When background noise matches the acoustic context of speech, it creates a perceptually natural mixture that is difficult to separate. Speech enhancement algorithms are designed to preserve speech while removing noise, but this separation becomes ambiguous when noise and speech share similar spectro-temporal characteristics typical of a scene.</p>\n\n",
                "matched_terms": [
                    "random",
                    "noise",
                    "while",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Psychoacoustic masking further explains SceneGuard&#8217;s effectiveness. Auditory masking occurs when one sound makes another sound less audible. Scene-consistent noise can mask subtle speaker-specific characteristics while preserving overall speech intelligibility. This selective masking degrades speaker embeddings without proportionally affecting transcription accuracy, as evidenced by our results (5.5% similarity degradation vs. 2.77% WER).</p>\n\n",
                "matched_terms": [
                    "noise",
                    "similarity",
                    "while",
                    "wer",
                    "speaker",
                    "effectiveness"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The robustness of SceneGuard to audio preprocessing is a critical advantage over imperceptible perturbations. Our results show that certain countermeasures paradoxically enhance protection rather than removing it. This phenomenon has several explanations:</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Spectral Subtraction</span>: This denoising technique assumes stationary noise and removes spectral components with consistent energy. However, scene-consistent noise contains non-stationary elements (e.g., footsteps, vehicle sounds) that are not fully removed. Meanwhile, spectral subtraction introduces musical noise artifacts that further degrade speaker embeddings.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Lowpass Filtering and Downsampling</span>: Speaker identity relies significantly on high-frequency spectral details and prosodic variations. Lowpass filtering and downsampling preferentially remove these high-frequency components while preserving lower-frequency protective noise. This asymmetric degradation enhances protection.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "speaker",
                    "protection",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">MP3 Compression</span>: Lossy compression preserves perceptually important components. Because SceneGuard uses audible noise, it is treated as salient content rather than irrelevant information to be discarded. This contrasts with imperceptible perturbations that fall below perceptual thresholds and are aggressively quantized.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Audible Protection</span>: SceneGuard deliberately uses audible noise, which may be undesirable in scenarios requiring pristine audio quality. Applications such as studio recordings or professional voice work may prefer imperceptible protections despite their fragility. SceneGuard is best suited for everyday voice recordings where some background noise is acceptable.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Quality Metrics</span>: Our PESQ scores (2.03) fall below the ideal threshold of 3.0, indicating room for improvement in perceptual quality. This reflects the fundamental trade-off between protection and quality. Future work could explore perceptually optimized noise mixing strategies that maximize protection while minimizing quality degradation.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "protection",
                    "while",
                    "pesq"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Adaptive Attacks</span>: We evaluate SceneGuard against standard audio preprocessing countermeasures, but a sophisticated attacker might develop adaptive attacks specifically designed to remove scene-consistent noise. Potential adaptive strategies include scene-aware source separation or adversarial training. However, such attacks would require significant additional effort and may introduce other artifacts.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "significant",
                    "training",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We presented SceneGuard, a training-time voice protection method based on scene-consistent audible background noise. Unlike existing defenses that rely on imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes to create protective noise that is contextually appropriate and robust to common audio preprocessing operations.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our experimental evaluation demonstrates that SceneGuard achieves strong protection against training attacks, degrading speaker similarity by 5.5% with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>). Critically, SceneGuard preserves speech usability, maintaining 98.6% intelligibility (STOI = 0.986) and achieving low word error rate (3.6%). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures, including MP3 compression, denoising, filtering, and downsampling.</p>\n\n",
                "matched_terms": [
                    "statistical",
                    "training",
                    "stoi",
                    "sceneguard",
                    "similarity",
                    "cohen’s",
                    "speaker",
                    "protection",
                    "significance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">These results suggest that audible, scene-consistent noise provides a practical alternative to imperceptible perturbations for voice protection. By deliberately using audible but natural noise, SceneGuard achieves robustness properties that imperceptible methods cannot match, addressing a fundamental limitation of existing approaches.</p>\n\n",
                "matched_terms": [
                    "noise",
                    "provides",
                    "protection",
                    "sceneguard"
                ]
            }
        ]
    },
    "Sx5.T2": {
        "source_file": "SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise",
        "caption": "Table 2: Protected speech quality metrics. All metrics meet or exceed usability thresholds, indicating that SceneGuard preserves practical utility while providing protection.",
        "body": "Metric\nValue\n95% CI\nThreshold\nStatus\n\n\n\n\nSTOI\n0.986\n[0.980, 0.992]\n≥0.85\\geq 0.85\n✓Excellent\n\n\nWER (%)\n3.60\n[1.40, 6.43]\n<15%<15\\%\n✓Excellent\n\n\nPESQ\n2.034\n[1.840, 2.233]\n≥3.0\\geq 3.0\nAcceptable",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Metric</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Value</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">95% CI</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Threshold</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Status</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">STOI</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.986</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">[0.980, 0.992]</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"\\geq 0.85\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T2.m1\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8805;</mo><mn>0.85</mn></mrow><annotation encoding=\"application/x-tex\">\\geq 0.85</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">&#10003;Excellent</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">WER (%)</td>\n<td class=\"ltx_td ltx_align_center\">3.60</td>\n<td class=\"ltx_td ltx_align_center\">[1.40, 6.43]</td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"&lt;15\\%\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T2.m2\" intent=\":literal\"><semantics><mrow><mi/><mo>&lt;</mo><mrow><mn>15</mn><mo>%</mo></mrow></mrow><annotation encoding=\"application/x-tex\">&lt;15\\%</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\">&#10003;Excellent</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">PESQ</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">2.034</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">[1.840, 2.233]</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><math alttext=\"\\geq 3.0\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T2.m3\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8805;</mo><mn>3.0</mn></mrow><annotation encoding=\"application/x-tex\">\\geq 3.0</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">Acceptable</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "quality",
            "≥30geq",
            "stoi",
            "threshold",
            "indicating",
            "protection",
            "speech",
            "usability",
            "utility",
            "preserves",
            "providing",
            "all",
            "metrics",
            "status",
            "wer",
            "sceneguard",
            "protected",
            "meet",
            "exceed",
            "practical",
            "pesq",
            "✓excellent",
            "acceptable",
            "metric",
            "≥085geq",
            "value",
            "thresholds",
            "while"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.T2\" title=\"Table 2 &#8227; Usability Preservation &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> presents detailed usability metrics for SceneGuard-protected speech, demonstrating that protection does not significantly compromise speech quality for legitimate use cases.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Voice cloning technology poses significant privacy threats by enabling unauthorized speech synthesis from limited audio samples. Existing defenses based on imperceptible adversarial perturbations are vulnerable to common audio preprocessing such as denoising and compression. We propose SceneGuard, a training-time voice protection method that applies scene-consistent audible background noise to speech recordings. Unlike imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes (e.g., airport, street, park) to create protective noise that is contextually appropriate and robust to countermeasures. We evaluate SceneGuard on text-to-speech training attacks, demonstrating 5.5% speaker similarity degradation with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>) while preserving 98.6% speech intelligibility (STOI = 0.986). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures including MP3 compression, spectral subtraction, lowpass filtering, and downsampling. Our results suggest that audible, scene-consistent noise provides a more robust alternative to imperceptible perturbations for training-time voice protection. The source code are available at: <span class=\"ltx_ref ltx_nolink ltx_url ltx_ref_self\">https://github.com/richael-sang/SceneGuard</span>.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "stoi",
                    "while",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Deep learning has enabled high-fidelity voice cloning systems capable of synthesizing speech that closely mimics a target speaker&#8217;s voice&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">gao2025black</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">fanantifake</span>)</cite>. While these technologies have legitimate applications in accessibility and entertainment, they also pose serious threats to privacy and security. Attackers can use unauthorized voice recordings to train text-to-speech (TTS) or voice conversion (VC) models, enabling impersonation attacks, voice-based authentication breaches, and creation of misleading audio content&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">wang2025one</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent work has explored proactive defense mechanisms that protect voice recordings from being exploited for cloning. A prominent approach adds imperceptible adversarial perturbations to audio recordings, degrading the quality of models trained on protected data&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite>. However, these defenses face a fundamental challenge: imperceptible perturbations are fragile. Standard audio preprocessing operations such as denoising, compression, and filtering can remove or significantly reduce these perturbations, rendering the protection ineffective&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">fei2025vocalcrypt</span>)</cite>. Moreover, the field lacks a unified, human&#8211;perception&#8211;aligned metric for speech perturbations, so imperceptibility is enforced via proxies (e.g., <math alttext=\"L_{p}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p2.m1\" intent=\":literal\"><semantics><msub><mi>L</mi><mi>p</mi></msub><annotation encoding=\"application/x-tex\">L_{p}</annotation></semantics></math> bounds or heuristic masking) that guarantee neither true inaudibility nor robustness&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">li2025cloneshield</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">feng2025enkidu</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "protected",
                    "quality",
                    "metric",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We observe that the requirement for imperceptibility may be unnecessarily restrictive. In many real-world scenarios, background noise is expected and acceptable. For instance, recordings made in cafes, streets, or offices naturally contain ambient noise. This insight leads to a key question: can we design voice protection mechanisms that leverage audible but contextually appropriate noise?</p>\n\n",
                "matched_terms": [
                    "protection",
                    "acceptable"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SceneGuard, a training-time defense that applies scene-consistent audible background noise to speech recordings through gradient-based optimization. SceneGuard first classifies the acoustic scene of input speech, then jointly optimizes a temporal mask <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m1\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while maintaining usability. For example, speech recorded in an airport is mixed with optimized airport background noise, creating a protective layer that appears natural and contextually plausible. This design offers three advantages: (1) optimization automatically finds the protection-usability trade-off, (2) the protection is harder to remove because scene-consistent noise cannot be easily separated from speech without degrading speech quality, and (3) the defense is robust to common audio preprocessing operations.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "usability",
                    "quality",
                    "while",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate SceneGuard on training attack scenarios where an attacker uses protected recordings to fine-tune TTS models. Our experiments on 100 training samples and 40 test samples demonstrate 5.5% speaker similarity degradation (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>), indicating strong statistical evidence of protection effectiveness. Importantly, SceneGuard preserves 98.6% speech intelligibility (STOI = 0.986) and achieves low word error rate (WER = 3.6%), demonstrating that protected speech remains highly usable. Robustness evaluation shows that SceneGuard maintains protection under MP3 compression and even exhibits enhanced protection under denoising, lowpass filtering, and downsampling operations.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "protected",
                    "stoi",
                    "preserves",
                    "indicating",
                    "wer",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We design a gradient-based optimization framework that automatically balances speaker protection and speech usability under SNR constraints.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "usability",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We demonstrate strong protection against training attacks with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.I1.i3.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.I1.i3.p1.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>) while preserving speech usability (STOI = 0.986, WER = 3.6%).</p>\n\n",
                "matched_terms": [
                    "speech",
                    "usability",
                    "stoi",
                    "while",
                    "wer",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We provide comprehensive robustness evaluation showing that SceneGuard maintains or enhances protection under five common audio countermeasures.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent work has explored adversarial perturbations as a proactive defense against voice cloning. VoiceBlock&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>)</cite> is a real-time de-identification approach that learns a time-varying FIR filter to apply perceptually inconspicuous, streaming-friendly perturbations for evading speaker recognition. Building on proactive protection but shifting the threat model to training-time cloning, SafeSpeech&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite> embeds imperceptible, universal perturbations via its SPEC objective to degrade generative TTS across models while emphasizing transferability and robustness. Contemporary work&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">gao2025black</span>)</cite> proposes a black-box defense for voice conversion that adds imperceptible perturbations and optimizes them in latent space with evolution-based search to adapt against unknown VC systems. While these methods demonstrate effectiveness in controlled settings, they face a fundamental limitation: imperceptible perturbations are inherently fragile to common audio processing operations.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent voice protection methods&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>)</cite> embed imperceptible adversarial perturbations by minimizing <math alttext=\"\\ell_{p}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m1\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#8467;</mi><mi>p</mi></msub><annotation encoding=\"application/x-tex\">\\ell_{p}</annotation></semantics></math> norms (typically <math alttext=\"\\|\\delta\\|_{\\infty}\\leq\\epsilon\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mrow><mo stretchy=\"false\">&#8214;</mo><mi>&#948;</mi><mo stretchy=\"false\">&#8214;</mo></mrow><mi mathvariant=\"normal\">&#8734;</mi></msub><mo>&#8804;</mo><mi>&#1013;</mi></mrow><annotation encoding=\"application/x-tex\">\\|\\delta\\|_{\\infty}\\leq\\epsilon</annotation></semantics></math> with <math alttext=\"\\epsilon\\approx 8/255\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>&#1013;</mi><mo>&#8776;</mo><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\epsilon\\approx 8/255</annotation></semantics></math>). While these perturbations are inaudible, they are <span class=\"ltx_text ltx_font_italic\">fragile</span>: standard audio processing operations such as lossy compression (MP3, AAC), speech enhancement, or denoising can significantly attenuate protection effectiveness. For instance, SafeSpeech&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite> shows that DeepMucs&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">demucs</span>)</cite> denoising reduces protection by up to 42% (SIM increases from 0.204 to 0.284). This fragility arises because imperceptible perturbations occupy high-frequency or low-energy regions that are specifically targeted by perceptual codecs and noise reduction algorithms.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "protection",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our work departs from the imperceptibility paradigm by deliberately using audible but contextually natural noise. We hypothesize that scene-consistent background noise, being perceptually meaningful and semantically coherent with the speech content, is fundamentally harder to separate without degrading speech quality. This trade-off between imperceptibility and robustness represents a key design choice that distinguishes our approach from prior work.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Acoustic scene classification (ASC) aims to identify the environmental context of audio recordings&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">tau_dataset</span>)</cite>. State-of-the-art ASC systems use deep convolutional networks trained on large-scale datasets such as TAU Urban Acoustic Scenes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">ASC1</span>)</cite>. SceneGuard leverages ASC to ensure that protective noise matches the acoustic context of input speech, creating a more natural and robust defense compared to context-agnostic perturbations.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We consider a training-time attack scenario where an adversary aims to clone a target speaker&#8217;s voice by fine-tuning a pre-trained TTS or VC model on unauthorized audio recordings. The attacker operates in a black-box setting, having no knowledge of the protection mechanism applied to the training data. Formally, given a dataset <math alttext=\"\\mathcal{D}=\\{(x_{i},y_{i})\\}_{i=1}^{N}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119967;</mi><mo>=</mo><msubsup><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\mathcal{D}=\\{(x_{i},y_{i})\\}_{i=1}^{N}</annotation></semantics></math> of protected speech samples <math alttext=\"x^{\\prime}_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m2\" intent=\":literal\"><semantics><msubsup><mi>x</mi><mi>i</mi><mo>&#8242;</mo></msubsup><annotation encoding=\"application/x-tex\">x^{\\prime}_{i}</annotation></semantics></math> and corresponding text labels <math alttext=\"y_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m3\" intent=\":literal\"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">y_{i}</annotation></semantics></math>, the attacker solves:</p>\n\n",
                "matched_terms": [
                    "speech",
                    "protection",
                    "protected"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The defender&#8217;s objective is to apply a transformation <math alttext=\"\\mathcal{T}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><annotation encoding=\"application/x-tex\">\\mathcal{T}</annotation></semantics></math> to speech <math alttext=\"x\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m2\" intent=\":literal\"><semantics><mi>x</mi><annotation encoding=\"application/x-tex\">x</annotation></semantics></math> that produces protected audio <math alttext=\"x^{\\prime}=\\mathcal{T}(x,s)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m3\" intent=\":literal\"><semantics><mrow><msup><mi>x</mi><mo>&#8242;</mo></msup><mo>=</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">x^{\\prime}=\\mathcal{T}(x,s)</annotation></semantics></math> (where <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m4\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math> denotes acoustic scene context) satisfying two criteria: (1) <span class=\"ltx_text ltx_font_italic\">Protection</span>: degraded speaker identity prevents successful cloning, formally:</p>\n\n",
                "matched_terms": [
                    "speech",
                    "protection",
                    "protected"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"e(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m5\" intent=\":literal\"><semantics><mrow><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">e(\\cdot)</annotation></semantics></math> is a speaker verification encoder and <math alttext=\"\\tau_{\\text{sim}},\\tau_{\\text{eer}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m6\" intent=\":literal\"><semantics><mrow><msub><mi>&#964;</mi><mtext>sim</mtext></msub><mo>,</mo><msub><mi>&#964;</mi><mtext>eer</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\tau_{\\text{sim}},\\tau_{\\text{eer}}</annotation></semantics></math> are protection thresholds; and (2) <span class=\"ltx_text ltx_font_italic\">Usability</span>: preserved intelligibility for legitimate communication:</p>\n\n",
                "matched_terms": [
                    "thresholds",
                    "usability",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"\\epsilon_{\\text{wer}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m7\" intent=\":literal\"><semantics><msub><mi>&#1013;</mi><mtext>wer</mtext></msub><annotation encoding=\"application/x-tex\">\\epsilon_{\\text{wer}}</annotation></semantics></math> is the maximum acceptable word error rate increase and <math alttext=\"\\tau_{\\text{stoi}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m8\" intent=\":literal\"><semantics><msub><mi>&#964;</mi><mtext>stoi</mtext></msub><annotation encoding=\"application/x-tex\">\\tau_{\\text{stoi}}</annotation></semantics></math> is the minimum intelligibility threshold.</p>\n\n",
                "matched_terms": [
                    "threshold",
                    "acceptable"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Unlike random noise addition, we require that the protective transformation preserves acoustic scene consistency. Specifically, for a speech recording <math alttext=\"x\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m1\" intent=\":literal\"><semantics><mi>x</mi><annotation encoding=\"application/x-tex\">x</annotation></semantics></math> that an acoustic scene classification (ASC) model recognizes as scene <math alttext=\"s\\in\\mathcal{S}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m2\" intent=\":literal\"><semantics><mrow><mi>s</mi><mo>&#8712;</mo><mi class=\"ltx_font_mathcaligraphic\">&#119982;</mi></mrow><annotation encoding=\"application/x-tex\">s\\in\\mathcal{S}</annotation></semantics></math> (e.g., &#8220;park&#8221;, &#8220;street_traffic&#8221;), the protected audio <math alttext=\"x^{\\prime}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m3\" intent=\":literal\"><semantics><msup><mi>x</mi><mo>&#8242;</mo></msup><annotation encoding=\"application/x-tex\">x^{\\prime}</annotation></semantics></math> should remain plausibly associated with the same scene <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m4\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math>:</p>\n\n",
                "matched_terms": [
                    "speech",
                    "protected",
                    "preserves"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"P_{\\text{ASC}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m5\" intent=\":literal\"><semantics><msub><mi>P</mi><mtext>ASC</mtext></msub><annotation encoding=\"application/x-tex\">P_{\\text{ASC}}</annotation></semantics></math> is an acoustic scene classifier and <math alttext=\"\\tau_{\\text{scene}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m6\" intent=\":literal\"><semantics><msub><mi>&#964;</mi><mtext>scene</mtext></msub><annotation encoding=\"application/x-tex\">\\tau_{\\text{scene}}</annotation></semantics></math> is a scene confidence threshold. This constraint ensures natural-sounding protection that is less likely to be removed by preprocessing.</p>\n\n",
                "matched_terms": [
                    "threshold",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Naive mixing of speech with scene noise at a fixed signal-to-noise ratio (SNR) and uniform temporal weighting faces two risks: (1) insufficient protection if SNR is too high or noise placement is suboptimal, resulting in speaker embeddings that remain similar (<math alttext=\"\\text{SIM}&gt;\\tau_{\\text{sim}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m1\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>&gt;</mo><msub><mi>&#964;</mi><mtext>sim</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}&gt;\\tau_{\\text{sim}}</annotation></semantics></math>); (2) excessive degradation if SNR is too low or noise overwhelms speech regions, causing unacceptable WER increases. To navigate this trade-off, we formulate protection as an <span class=\"ltx_text ltx_font_italic\">optimization problem</span>: jointly optimize the temporal mask <math alttext=\"m(t)\\in[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m2\" intent=\":literal\"><semantics><mrow><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)\\in[0,1]</annotation></semantics></math> controlling when noise is applied, and the noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m3\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> controlling overall SNR, to minimize speaker similarity while maintaining usability. This optimization ensures that the noise is strategically placed (e.g., emphasizing pauses or non-critical phonemes) and calibrated to the specific speech sample.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "usability",
                    "while",
                    "wer",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Overview.</span> Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.F1\" title=\"Figure 1 &#8227; Need for Optimization. &#8227; Scene-Consistent Audible Noise Defense &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> summarizes SceneGuard:\n(1) we obtain a scene label <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m1\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math> via ASC (or user-specified) and sample noise <math alttext=\"n_{k}\\!\\in\\!\\mathcal{N}_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub><mo lspace=\"0.108em\" rspace=\"0.108em\">&#8712;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119977;</mi><mi>s</mi></msub></mrow><annotation encoding=\"application/x-tex\">n_{k}\\!\\in\\!\\mathcal{N}_{s}</annotation></semantics></math>;\n(2) protected audio is produced by the mixer <math alttext=\"x^{\\prime}(t)=x(t)+\\gamma\\,m(t)\\odot n_{k}(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m3\" intent=\":literal\"><semantics><mrow><mrow><msup><mi>x</mi><mo>&#8242;</mo></msup><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>x</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mrow><mi>&#947;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo rspace=\"0.055em\" stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"0.222em\">&#8857;</mo><msub><mi>n</mi><mi>k</mi></msub></mrow><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">x^{\\prime}(t)=x(t)+\\gamma\\,m(t)\\odot n_{k}(t)</annotation></semantics></math> (Sec.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.E5\" title=\"In Mixing Model. &#8227; Optimization Objective &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>);\n(3) an optimization loop updates <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m4\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m5\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> using an ECAPA-based similarity loss with SNR/regularization\nconstraints (Sec.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.E6\" title=\"In Objective Function. &#8227; Optimization Objective &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>). The defended data are then used against training-time and zero-shot attacks.</p>\n\n",
                "matched_terms": [
                    "protected",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Given clean speech <math alttext=\"x(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><mi>x</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">x(t)</annotation></semantics></math> and a scene-consistent noise signal <math alttext=\"n_{k}(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx1.p1.m2\" intent=\":literal\"><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">n_{k}(t)</annotation></semantics></math> sampled from a scene-specific library <math alttext=\"\\mathcal{N}_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx1.p1.m3\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#119977;</mi><mi>s</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{N}_{s}</annotation></semantics></math>, we define the protected speech as:</p>\n\n",
                "matched_terms": [
                    "speech",
                    "protected"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We jointly optimize <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx2.p1.m1\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> and <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx2.p1.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while regularizing for usability and smoothness. The total loss is:</p>\n\n",
                "matched_terms": [
                    "usability",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We employ Whisper Base&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">whisper</span>)</cite>, an encoder-decoder transformer trained on 680,000 hours of multilingual speech data. Whisper provides robust transcription for measuring speech intelligibility via word error rate (WER). We use the base model (74M parameters) for computational efficiency.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For training attack experiments, we reference BERT-VITS2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">bertvits2</span>)</cite>, a recent TTS architecture that combines BERT-based text encoding with VITS neural vocoder. While we do not perform full TTS training due to computational constraints, we use speaker embedding degradation as a proxy for TTS quality, following established evaluation protocols&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "while",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We minimize speaker similarity while maintaining usability constraints. The primary loss term is speaker embedding cosine similarity computed using ECAPA-TDNN. We add a regularization term (<math alttext=\"\\lambda_{\\text{REG}}=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><msub><mi>&#955;</mi><mtext>REG</mtext></msub><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}=0.01</annotation></semantics></math>) that penalizes mask roughness and excessive noise strength to promote smooth, stable solutions.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We simulate an attacker who fine-tunes a TTS model on protected recordings. To evaluate protection effectiveness, we measure speaker embedding quality and consistency on training data, then assess the similarity between embeddings extracted from clean and defended audio on held-out test samples. Lower test similarity indicates successful protection.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "protected",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate protection against zero-shot voice cloning, where an attacker uses protected recordings as reference audio for inference-time cloning. We generate synthetic speech using a pre-trained model with clean versus defended reference, measuring speaker similarity to the original speaker.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "protection",
                    "protected"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We test whether protection persists under five common audio preprocessing operations: MP3 compression (128 kbps and 64 kbps), spectral subtraction denoising, lowpass filtering (3400 Hz cutoff), and downsampling to 8 kHz. For each countermeasure, we re-compute speaker similarity and WER to assess protection retention.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We measure the percentage of word-level errors (insertions, deletions, substitutions) between reference transcripts and ASR outputs. Lower WER indicates better intelligibility. We use WER to ensure protected speech remains usable.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "protected",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We employ PESQ&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">pesq</span>)</cite> (Perceptual Evaluation of Speech Quality) and STOI&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">stoi</span>)</cite> (Short-Time Objective Intelligibility) as objective quality metrics. PESQ ranges from -0.5 to 4.5 (higher is better), with scores above 3.0 considered good quality. STOI ranges from 0 to 1 (higher is better), with scores above 0.85 indicating high intelligibility.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "quality",
                    "stoi",
                    "metrics",
                    "pesq",
                    "indicating"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Unprotected speech serves as an upper bound on cloning quality and a baseline for usability metrics.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "usability",
                    "metrics",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We compute 95% confidence intervals for all metrics using bootstrap resampling with <math alttext=\"n=10,000\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx7.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><mi>n</mi><mo>=</mo><mrow><mn>10</mn><mo>,</mo><mn>000</mn></mrow></mrow><annotation encoding=\"application/x-tex\">n=10,000</annotation></semantics></math> iterations. This provides robust uncertainty estimates without parametric assumptions.</p>\n\n",
                "matched_terms": [
                    "all",
                    "metrics"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SceneGuard achieves 5.5% speaker similarity degradation (<math alttext=\"\\text{SIM}=0.945\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m1\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>=</mo><mn>0.945</mn></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}=0.945</annotation></semantics></math>) compared to clean training (<math alttext=\"\\text{SIM}=1.000\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m2\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>=</mo><mn>1.000</mn></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}=1.000</annotation></semantics></math>). This protection effect is statistically significant with <math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math> (permutation test, <math alttext=\"n=10,000\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m4\" intent=\":literal\"><semantics><mrow><mi>n</mi><mo>=</mo><mrow><mn>10</mn><mo>,</mo><mn>000</mn></mrow></mrow><annotation encoding=\"application/x-tex\">n=10,000</annotation></semantics></math> iterations) and demonstrates a large effect size (Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m5\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>). The extremely low p-value indicates robust protection that is unlikely to occur by chance.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Importantly, SceneGuard maintains high usability. Protected speech achieves WER of 2.77%, indicating near-perfect transcription accuracy. The STOI score of 0.99 confirms that intelligibility is essentially preserved. While PESQ (2.22) is below the ideal threshold of 3.0, it remains in an acceptable range for many applications.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "usability",
                    "protected",
                    "acceptable",
                    "stoi",
                    "threshold",
                    "pesq",
                    "indicating",
                    "while",
                    "wer",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.F2\" title=\"Figure 2 &#8227; Training Attack Protection &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> visualizes the training attack results, comparing speaker similarity degradation across defense methods. SceneGuard demonstrates stronger protection than random or Gaussian noise baselines while maintaining comparable usability.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection",
                    "while",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The STOI score of 0.986 significantly exceeds the intelligibility threshold of 0.85, indicating that protected speech remains highly comprehensible. WER of 3.60% with a narrow confidence interval [1.40%, 6.43%] demonstrates robust transcription accuracy across samples. While PESQ falls slightly below the ideal 3.0 threshold, the value of 2.034 is acceptable for many practical applications and represents a deliberate trade-off for robustness.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "protected",
                    "acceptable",
                    "stoi",
                    "threshold",
                    "practical",
                    "value",
                    "pesq",
                    "indicating",
                    "while",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SceneGuard demonstrates remarkable robustness. MP3 compression at both 128 kbps and 64 kbps slightly reduces similarity but maintains protection (SIM &#161; 0.91). More aggressive operations such as spectral subtraction, lowpass filtering, and downsampling actually enhance protection, reducing similarity to 0.745, 0.704, and 0.688 respectively.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This counterintuitive enhancement occurs because these operations preferentially damage the clean speech components relative to the protective noise. Spectral subtraction removes stationary components but preserves scene-consistent temporal variations. Lowpass filtering and downsampling reduce high-frequency detail critical for speaker identity while preserving protective noise structure. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.F3\" title=\"Figure 3 &#8227; Robustness to Countermeasures &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> visualizes the robustness results as a heatmap, showing speaker similarity and WER under different countermeasures.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "while",
                    "preserves",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate protection against zero-shot voice cloning attacks where an attacker uses protected recordings as reference audio for inference-time synthesis. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.T4\" title=\"Table 4 &#8227; Zero-Shot Attack Results &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> summarizes the results.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "protected"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Using defended reference audio reduces mean speaker similarity from 0.618 to 0.588, representing a 5.0% degradation. More importantly, the attack success rate (similarity <math alttext=\"&gt;0.7\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx4.p2.m1\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>0.7</mn></mrow><annotation encoding=\"application/x-tex\">&gt;0.7</annotation></semantics></math>) drops from 20.0% to 13.3%, a 33.5% relative reduction. This demonstrates that SceneGuard provides meaningful protection even in zero-shot scenarios where the attacker does not perform training. Using defended reference audio reduces mean speaker similarity from 0.618 to 0.588 (-5.0%) and lowers the attack success rate from 20.0% to 13.3% (-6.7 pp, 33.5% relative), indicating meaningful zero-shot protection.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "indicating",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To understand the trade-off between protection strength and usability, we conduct an ablation study on the signal-to-noise ratio (SNR) parameter. We evaluate four SNR ranges: [5, 10] dB (strong protection), [10, 20] dB (balanced, our default), [15, 25] dB (moderate protection), and [20, 30] dB (weak protection).</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.T5\" title=\"Table 5 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents the quantitative results. Lower SNR (stronger noise) provides better protection but degrades usability, while higher SNR (weaker noise) improves usability but reduces protection. The [10, 20] dB range achieves an effective balance, providing 5.5% similarity degradation while maintaining STOI above 0.98 and WER below 4%.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "stoi",
                    "providing",
                    "while",
                    "wer",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.F4\" title=\"Figure 4 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> visualizes this trade-off using a dual-axis plot showing protection strength (speaker similarity degradation) and usability (STOI) as functions of SNR range.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The ablation study validates our choice of SNR range and demonstrates that SceneGuard&#8217;s protection can be tuned based on application requirements. Users prioritizing strong protection can select lower SNR, while those prioritizing quality can use higher SNR, with the [10, 20] dB range serving as a reasonable default.</p>\n\n",
                "matched_terms": [
                    "while",
                    "protection",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization nearly doubles the protection strength, achieving 5.5% degradation compared to 2.8% for direct mixing. This 2.7 percentage point improvement comes at minimal usability cost: STOI decreases by only 0.003 (from 0.989 to 0.986) and WER increases by 0.4 percentage points (from 3.2% to 3.6%), both negligible changes.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection",
                    "wer",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The key advantage of optimization is its ability to identify optimal mask patterns. Direct mixing applies a uniform stochastic mask, which may unnecessarily distort speech regions while under-protecting others. In contrast, gradient-based optimization adaptively concentrates protection in regions that most effectively reduce speaker similarity while avoiding critical speech segments.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "protection",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The number of epochs shows diminishing returns beyond 50 iterations. While 100 epochs achieve slightly better protection (SIM = 0.943), the improvement is minimal (0.2 percentage points) and doubles computation time. 20 epochs provide fast computation but do not fully converge. We therefore recommend 50 epochs as the default, offering good convergence without excessive cost.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The key insight behind SceneGuard is that scene-consistent noise is fundamentally different from random or imperceptible perturbations. When background noise matches the acoustic context of speech, it creates a perceptually natural mixture that is difficult to separate. Speech enhancement algorithms are designed to preserve speech while removing noise, but this separation becomes ambiguous when noise and speech share similar spectro-temporal characteristics typical of a scene.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "while",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Psychoacoustic masking further explains SceneGuard&#8217;s effectiveness. Auditory masking occurs when one sound makes another sound less audible. Scene-consistent noise can mask subtle speaker-specific characteristics while preserving overall speech intelligibility. This selective masking degrades speaker embeddings without proportionally affecting transcription accuracy, as evidenced by our results (5.5% similarity degradation vs. 2.77% WER).</p>\n\n",
                "matched_terms": [
                    "speech",
                    "while",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The robustness of SceneGuard to audio preprocessing is a critical advantage over imperceptible perturbations. Our results show that certain countermeasures paradoxically enhance protection rather than removing it. This phenomenon has several explanations:</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Lowpass Filtering and Downsampling</span>: Speaker identity relies significantly on high-frequency spectral details and prosodic variations. Lowpass filtering and downsampling preferentially remove these high-frequency components while preserving lower-frequency protective noise. This asymmetric degradation enhances protection.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">MP3 Compression</span>: Lossy compression preserves perceptually important components. Because SceneGuard uses audible noise, it is treated as salient content rather than irrelevant information to be discarded. This contrasts with imperceptible perturbations that fall below perceptual thresholds and are aggressively quantized.</p>\n\n",
                "matched_terms": [
                    "preserves",
                    "thresholds",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Audible Protection</span>: SceneGuard deliberately uses audible noise, which may be undesirable in scenarios requiring pristine audio quality. Applications such as studio recordings or professional voice work may prefer imperceptible protections despite their fragility. SceneGuard is best suited for everyday voice recordings where some background noise is acceptable.</p>\n\n",
                "matched_terms": [
                    "acceptable",
                    "protection",
                    "quality",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Quality Metrics</span>: Our PESQ scores (2.03) fall below the ideal threshold of 3.0, indicating room for improvement in perceptual quality. This reflects the fundamental trade-off between protection and quality. Future work could explore perceptually optimized noise mixing strategies that maximize protection while minimizing quality degradation.</p>\n\n",
                "matched_terms": [
                    "quality",
                    "threshold",
                    "metrics",
                    "pesq",
                    "indicating",
                    "while",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We presented SceneGuard, a training-time voice protection method based on scene-consistent audible background noise. Unlike existing defenses that rely on imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes to create protective noise that is contextually appropriate and robust to common audio preprocessing operations.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our experimental evaluation demonstrates that SceneGuard achieves strong protection against training attacks, degrading speaker similarity by 5.5% with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>). Critically, SceneGuard preserves speech usability, maintaining 98.6% intelligibility (STOI = 0.986) and achieving low word error rate (3.6%). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures, including MP3 compression, denoising, filtering, and downsampling.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "usability",
                    "stoi",
                    "preserves",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">These results suggest that audible, scene-consistent noise provides a practical alternative to imperceptible perturbations for voice protection. By deliberately using audible but natural noise, SceneGuard achieves robustness properties that imperceptible methods cannot match, addressing a fundamental limitation of existing approaches.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "practical",
                    "sceneguard"
                ]
            }
        ]
    },
    "Sx5.T3": {
        "source_file": "SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise",
        "caption": "Table 3: Robustness evaluation under audio preprocessing countermeasures. SceneGuard maintains or enhances protection across all operations. Δ\\Delta indicates change in speaker similarity relative to baseline.",
        "body": "Countermeasure\nSIM\n\nΔ\\Delta vs Baseline\nProtection\n\n\n\n\nNone (baseline)\n0.937\n–\n✓\n\n\nMP3 128 kbps\n0.901\n−0.036-0.036\n✓Maintained\n\n\nMP3 64 kbps\n0.899\n−0.038-0.038\n✓Maintained\n\n\nSpectral Subtraction\n0.745\n−0.192-0.192\n✓Enhanced\n\n\nLowpass 3400 Hz\n0.704\n−0.232-0.232\n✓Enhanced\n\n\nDownsample 8 kHz\n0.688\n−0.249-0.249\n✓Enhanced",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Countermeasure</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">SIM</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">\n<math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T3.m3\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#916;</mi><annotation encoding=\"application/x-tex\">\\Delta</annotation></semantics></math> vs Baseline</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Protection</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">None (baseline)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.937</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">&#8211;</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">&#10003;</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">MP3 128 kbps</td>\n<td class=\"ltx_td ltx_align_center\">0.901</td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"-0.036\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T3.m4\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>0.036</mn></mrow><annotation encoding=\"application/x-tex\">-0.036</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\">&#10003;Maintained</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">MP3 64 kbps</td>\n<td class=\"ltx_td ltx_align_center\">0.899</td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"-0.038\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T3.m5\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>0.038</mn></mrow><annotation encoding=\"application/x-tex\">-0.038</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\">&#10003;Maintained</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Spectral Subtraction</td>\n<td class=\"ltx_td ltx_align_center\">0.745</td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"-0.192\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T3.m6\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>0.192</mn></mrow><annotation encoding=\"application/x-tex\">-0.192</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\">&#10003;Enhanced</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Lowpass 3400 Hz</td>\n<td class=\"ltx_td ltx_align_center\">0.704</td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"-0.232\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T3.m7\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>0.232</mn></mrow><annotation encoding=\"application/x-tex\">-0.232</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\">&#10003;Enhanced</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">Downsample 8 kHz</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.688</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><math alttext=\"-0.249\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.T3.m8\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>0.249</mn></mrow><annotation encoding=\"application/x-tex\">-0.249</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">&#10003;Enhanced</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "relative",
            "lowpass",
            "sim",
            "robustness",
            "−01920192",
            "enhances",
            "protection",
            "kbps",
            "audio",
            "across",
            "−02490249",
            "operations",
            "all",
            "−00360036",
            "downsample",
            "baseline",
            "subtraction",
            "preprocessing",
            "khz",
            "speaker",
            "none",
            "sceneguard",
            "evaluation",
            "maintains",
            "similarity",
            "countermeasure",
            "✓enhanced",
            "mp3",
            "indicates",
            "change",
            "✓maintained",
            "−02320232",
            "−00380038",
            "under",
            "countermeasures",
            "spectral",
            "δdelta"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">A key advantage of SceneGuard is its robustness to audio preprocessing operations that typically neutralize imperceptible perturbations. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.T3\" title=\"Table 3 &#8227; Robustness to Countermeasures &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> presents results under five common countermeasures.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Voice cloning technology poses significant privacy threats by enabling unauthorized speech synthesis from limited audio samples. Existing defenses based on imperceptible adversarial perturbations are vulnerable to common audio preprocessing such as denoising and compression. We propose SceneGuard, a training-time voice protection method that applies scene-consistent audible background noise to speech recordings. Unlike imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes (e.g., airport, street, park) to create protective noise that is contextually appropriate and robust to countermeasures. We evaluate SceneGuard on text-to-speech training attacks, demonstrating 5.5% speaker similarity degradation with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>) while preserving 98.6% speech intelligibility (STOI = 0.986). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures including MP3 compression, spectral subtraction, lowpass filtering, and downsampling. Our results suggest that audible, scene-consistent noise provides a more robust alternative to imperceptible perturbations for training-time voice protection. The source code are available at: <span class=\"ltx_ref ltx_nolink ltx_url ltx_ref_self\">https://github.com/richael-sang/SceneGuard</span>.</p>\n\n",
                "matched_terms": [
                    "lowpass",
                    "under",
                    "evaluation",
                    "robustness",
                    "maintains",
                    "similarity",
                    "countermeasures",
                    "subtraction",
                    "enhances",
                    "spectral",
                    "mp3",
                    "preprocessing",
                    "speaker",
                    "protection",
                    "audio",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent work has explored proactive defense mechanisms that protect voice recordings from being exploited for cloning. A prominent approach adds imperceptible adversarial perturbations to audio recordings, degrading the quality of models trained on protected data&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite>. However, these defenses face a fundamental challenge: imperceptible perturbations are fragile. Standard audio preprocessing operations such as denoising, compression, and filtering can remove or significantly reduce these perturbations, rendering the protection ineffective&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">fei2025vocalcrypt</span>)</cite>. Moreover, the field lacks a unified, human&#8211;perception&#8211;aligned metric for speech perturbations, so imperceptibility is enforced via proxies (e.g., <math alttext=\"L_{p}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p2.m1\" intent=\":literal\"><semantics><msub><mi>L</mi><mi>p</mi></msub><annotation encoding=\"application/x-tex\">L_{p}</annotation></semantics></math> bounds or heuristic masking) that guarantee neither true inaudibility nor robustness&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">li2025cloneshield</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">feng2025enkidu</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "operations",
                    "robustness",
                    "preprocessing",
                    "protection",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SceneGuard, a training-time defense that applies scene-consistent audible background noise to speech recordings through gradient-based optimization. SceneGuard first classifies the acoustic scene of input speech, then jointly optimizes a temporal mask <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m1\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while maintaining usability. For example, speech recorded in an airport is mixed with optimized airport background noise, creating a protective layer that appears natural and contextually plausible. This design offers three advantages: (1) optimization automatically finds the protection-usability trade-off, (2) the protection is harder to remove because scene-consistent noise cannot be easily separated from speech without degrading speech quality, and (3) the defense is robust to common audio preprocessing operations.</p>\n\n",
                "matched_terms": [
                    "operations",
                    "similarity",
                    "preprocessing",
                    "speaker",
                    "protection",
                    "audio",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate SceneGuard on training attack scenarios where an attacker uses protected recordings to fine-tune TTS models. Our experiments on 100 training samples and 40 test samples demonstrate 5.5% speaker similarity degradation (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>), indicating strong statistical evidence of protection effectiveness. Importantly, SceneGuard preserves 98.6% speech intelligibility (STOI = 0.986) and achieves low word error rate (WER = 3.6%), demonstrating that protected speech remains highly usable. Robustness evaluation shows that SceneGuard maintains protection under MP3 compression and even exhibits enhanced protection under denoising, lowpass filtering, and downsampling operations.</p>\n\n",
                "matched_terms": [
                    "lowpass",
                    "operations",
                    "under",
                    "evaluation",
                    "robustness",
                    "maintains",
                    "similarity",
                    "mp3",
                    "speaker",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We design a gradient-based optimization framework that automatically balances speaker protection and speech usability under SNR constraints.</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "under",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We provide comprehensive robustness evaluation showing that SceneGuard maintains or enhances protection under five common audio countermeasures.</p>\n\n",
                "matched_terms": [
                    "under",
                    "evaluation",
                    "robustness",
                    "maintains",
                    "countermeasures",
                    "enhances",
                    "protection",
                    "audio",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent work has explored adversarial perturbations as a proactive defense against voice cloning. VoiceBlock&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>)</cite> is a real-time de-identification approach that learns a time-varying FIR filter to apply perceptually inconspicuous, streaming-friendly perturbations for evading speaker recognition. Building on proactive protection but shifting the threat model to training-time cloning, SafeSpeech&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite> embeds imperceptible, universal perturbations via its SPEC objective to degrade generative TTS across models while emphasizing transferability and robustness. Contemporary work&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">gao2025black</span>)</cite> proposes a black-box defense for voice conversion that adds imperceptible perturbations and optimizes them in latent space with evolution-based search to adapt against unknown VC systems. While these methods demonstrate effectiveness in controlled settings, they face a fundamental limitation: imperceptible perturbations are inherently fragile to common audio processing operations.</p>\n\n",
                "matched_terms": [
                    "across",
                    "operations",
                    "robustness",
                    "speaker",
                    "protection",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent voice protection methods&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>)</cite> embed imperceptible adversarial perturbations by minimizing <math alttext=\"\\ell_{p}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m1\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#8467;</mi><mi>p</mi></msub><annotation encoding=\"application/x-tex\">\\ell_{p}</annotation></semantics></math> norms (typically <math alttext=\"\\|\\delta\\|_{\\infty}\\leq\\epsilon\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mrow><mo stretchy=\"false\">&#8214;</mo><mi>&#948;</mi><mo stretchy=\"false\">&#8214;</mo></mrow><mi mathvariant=\"normal\">&#8734;</mi></msub><mo>&#8804;</mo><mi>&#1013;</mi></mrow><annotation encoding=\"application/x-tex\">\\|\\delta\\|_{\\infty}\\leq\\epsilon</annotation></semantics></math> with <math alttext=\"\\epsilon\\approx 8/255\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>&#1013;</mi><mo>&#8776;</mo><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\epsilon\\approx 8/255</annotation></semantics></math>). While these perturbations are inaudible, they are <span class=\"ltx_text ltx_font_italic\">fragile</span>: standard audio processing operations such as lossy compression (MP3, AAC), speech enhancement, or denoising can significantly attenuate protection effectiveness. For instance, SafeSpeech&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite> shows that DeepMucs&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">demucs</span>)</cite> denoising reduces protection by up to 42% (SIM increases from 0.204 to 0.284). This fragility arises because imperceptible perturbations occupy high-frequency or low-energy regions that are specifically targeted by perceptual codecs and noise reduction algorithms.</p>\n\n",
                "matched_terms": [
                    "operations",
                    "sim",
                    "mp3",
                    "protection",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Acoustic scene classification (ASC) aims to identify the environmental context of audio recordings&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">tau_dataset</span>)</cite>. State-of-the-art ASC systems use deep convolutional networks trained on large-scale datasets such as TAU Urban Acoustic Scenes&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">ASC1</span>)</cite>. SceneGuard leverages ASC to ensure that protective noise matches the acoustic context of input speech, creating a more natural and robust defense compared to context-agnostic perturbations.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We consider a training-time attack scenario where an adversary aims to clone a target speaker&#8217;s voice by fine-tuning a pre-trained TTS or VC model on unauthorized audio recordings. The attacker operates in a black-box setting, having no knowledge of the protection mechanism applied to the training data. Formally, given a dataset <math alttext=\"\\mathcal{D}=\\{(x_{i},y_{i})\\}_{i=1}^{N}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119967;</mi><mo>=</mo><msubsup><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\mathcal{D}=\\{(x_{i},y_{i})\\}_{i=1}^{N}</annotation></semantics></math> of protected speech samples <math alttext=\"x^{\\prime}_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m2\" intent=\":literal\"><semantics><msubsup><mi>x</mi><mi>i</mi><mo>&#8242;</mo></msubsup><annotation encoding=\"application/x-tex\">x^{\\prime}_{i}</annotation></semantics></math> and corresponding text labels <math alttext=\"y_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m3\" intent=\":literal\"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">y_{i}</annotation></semantics></math>, the attacker solves:</p>\n\n",
                "matched_terms": [
                    "protection",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The defender&#8217;s objective is to apply a transformation <math alttext=\"\\mathcal{T}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><annotation encoding=\"application/x-tex\">\\mathcal{T}</annotation></semantics></math> to speech <math alttext=\"x\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m2\" intent=\":literal\"><semantics><mi>x</mi><annotation encoding=\"application/x-tex\">x</annotation></semantics></math> that produces protected audio <math alttext=\"x^{\\prime}=\\mathcal{T}(x,s)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m3\" intent=\":literal\"><semantics><mrow><msup><mi>x</mi><mo>&#8242;</mo></msup><mo>=</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">x^{\\prime}=\\mathcal{T}(x,s)</annotation></semantics></math> (where <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m4\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math> denotes acoustic scene context) satisfying two criteria: (1) <span class=\"ltx_text ltx_font_italic\">Protection</span>: degraded speaker identity prevents successful cloning, formally:</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "protection",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"e(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m5\" intent=\":literal\"><semantics><mrow><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">e(\\cdot)</annotation></semantics></math> is a speaker verification encoder and <math alttext=\"\\tau_{\\text{sim}},\\tau_{\\text{eer}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m6\" intent=\":literal\"><semantics><mrow><msub><mi>&#964;</mi><mtext>sim</mtext></msub><mo>,</mo><msub><mi>&#964;</mi><mtext>eer</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\tau_{\\text{sim}},\\tau_{\\text{eer}}</annotation></semantics></math> are protection thresholds; and (2) <span class=\"ltx_text ltx_font_italic\">Usability</span>: preserved intelligibility for legitimate communication:</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"P_{\\text{ASC}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m5\" intent=\":literal\"><semantics><msub><mi>P</mi><mtext>ASC</mtext></msub><annotation encoding=\"application/x-tex\">P_{\\text{ASC}}</annotation></semantics></math> is an acoustic scene classifier and <math alttext=\"\\tau_{\\text{scene}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx3.p1.m6\" intent=\":literal\"><semantics><msub><mi>&#964;</mi><mtext>scene</mtext></msub><annotation encoding=\"application/x-tex\">\\tau_{\\text{scene}}</annotation></semantics></math> is a scene confidence threshold. This constraint ensures natural-sounding protection that is less likely to be removed by preprocessing.</p>\n\n",
                "matched_terms": [
                    "preprocessing",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Naive mixing of speech with scene noise at a fixed signal-to-noise ratio (SNR) and uniform temporal weighting faces two risks: (1) insufficient protection if SNR is too high or noise placement is suboptimal, resulting in speaker embeddings that remain similar (<math alttext=\"\\text{SIM}&gt;\\tau_{\\text{sim}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m1\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>&gt;</mo><msub><mi>&#964;</mi><mtext>sim</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}&gt;\\tau_{\\text{sim}}</annotation></semantics></math>); (2) excessive degradation if SNR is too low or noise overwhelms speech regions, causing unacceptable WER increases. To navigate this trade-off, we formulate protection as an <span class=\"ltx_text ltx_font_italic\">optimization problem</span>: jointly optimize the temporal mask <math alttext=\"m(t)\\in[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m2\" intent=\":literal\"><semantics><mrow><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)\\in[0,1]</annotation></semantics></math> controlling when noise is applied, and the noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m3\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> controlling overall SNR, to minimize speaker similarity while maintaining usability. This optimization ensures that the noise is strategically placed (e.g., emphasizing pauses or non-critical phonemes) and calibrated to the specific speech sample.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Overview.</span> Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.F1\" title=\"Figure 1 &#8227; Need for Optimization. &#8227; Scene-Consistent Audible Noise Defense &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> summarizes SceneGuard:\n(1) we obtain a scene label <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m1\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math> via ASC (or user-specified) and sample noise <math alttext=\"n_{k}\\!\\in\\!\\mathcal{N}_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub><mo lspace=\"0.108em\" rspace=\"0.108em\">&#8712;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119977;</mi><mi>s</mi></msub></mrow><annotation encoding=\"application/x-tex\">n_{k}\\!\\in\\!\\mathcal{N}_{s}</annotation></semantics></math>;\n(2) protected audio is produced by the mixer <math alttext=\"x^{\\prime}(t)=x(t)+\\gamma\\,m(t)\\odot n_{k}(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m3\" intent=\":literal\"><semantics><mrow><mrow><msup><mi>x</mi><mo>&#8242;</mo></msup><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>x</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mrow><mi>&#947;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo rspace=\"0.055em\" stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"0.222em\">&#8857;</mo><msub><mi>n</mi><mi>k</mi></msub></mrow><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">x^{\\prime}(t)=x(t)+\\gamma\\,m(t)\\odot n_{k}(t)</annotation></semantics></math> (Sec.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.E5\" title=\"In Mixing Model. &#8227; Optimization Objective &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>);\n(3) an optimization loop updates <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m4\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m5\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> using an ECAPA-based similarity loss with SNR/regularization\nconstraints (Sec.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.E6\" title=\"In Objective Function. &#8227; Optimization Objective &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>). The defended data are then used against training-time and zero-shot attacks.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "audio",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We jointly optimize <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx2.p1.m1\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> and <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx2.p1.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while regularizing for usability and smoothness. The total loss is:</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "similarity"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Speaker Similarity Loss</span> <math alttext=\"\\mathcal{L}_{\\text{SIM}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.I2.i1.p1.m1\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8466;</mi><mtext>SIM</mtext></msub><annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\text{SIM}}</annotation></semantics></math>: Minimizes cosine similarity between speaker embeddings of protected and clean audio:</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "similarity",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"e(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.I2.i1.p1.m2\" intent=\":literal\"><semantics><mrow><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">e(\\cdot)</annotation></semantics></math> is a pre-trained speaker verification encoder (ECAPA-TDNN&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">ecapa</span>)</cite>). This is the primary protection objective.</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">: We use LibriTTS&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">libritts</span>)</cite>, a multi-speaker English corpus derived from audiobooks. We split the data into 100 training samples and 40 test samples for training attack evaluation, with additional subsets for zero-shot and robustness experiments.</p>\n\n",
                "matched_terms": [
                    "robustness",
                    "evaluation"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use ECAPA-TDNN&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">ecapa</span>)</cite>, a state-of-the-art speaker verification model from the SpeechBrain toolkit. The model extracts 192-dimensional speaker embeddings, which we use to compute speaker similarity via cosine distance. ECAPA-TDNN achieves strong performance on VoxCeleb and is widely used for speaker verification tasks.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For training attack experiments, we reference BERT-VITS2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">bertvits2</span>)</cite>, a recent TTS architecture that combines BERT-based text encoding with VITS neural vocoder. While we do not perform full TTS training due to computational constraints, we use speaker embedding degradation as a proxy for TTS quality, following established evaluation protocols&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "evaluation"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We minimize speaker similarity while maintaining usability constraints. The primary loss term is speaker embedding cosine similarity computed using ECAPA-TDNN. We add a regularization term (<math alttext=\"\\lambda_{\\text{REG}}=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><msub><mi>&#955;</mi><mtext>REG</mtext></msub><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}=0.01</annotation></semantics></math>) that penalizes mask roughness and excessive noise strength to promote smooth, stable solutions.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We simulate an attacker who fine-tunes a TTS model on protected recordings. To evaluate protection effectiveness, we measure speaker embedding quality and consistency on training data, then assess the similarity between embeddings extracted from clean and defended audio on held-out test samples. Lower test similarity indicates successful protection.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "similarity",
                    "speaker",
                    "protection",
                    "indicates"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate protection against zero-shot voice cloning, where an attacker uses protected recordings as reference audio for inference-time cloning. We generate synthetic speech using a pre-trained model with clean versus defended reference, measuring speaker similarity to the original speaker.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "protection",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We test whether protection persists under five common audio preprocessing operations: MP3 compression (128 kbps and 64 kbps), spectral subtraction denoising, lowpass filtering (3400 Hz cutoff), and downsampling to 8 kHz. For each countermeasure, we re-compute speaker similarity and WER to assess protection retention.</p>\n\n",
                "matched_terms": [
                    "lowpass",
                    "operations",
                    "under",
                    "similarity",
                    "spectral",
                    "subtraction",
                    "countermeasure",
                    "mp3",
                    "preprocessing",
                    "khz",
                    "speaker",
                    "kbps",
                    "protection",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We compute cosine similarity between speaker embeddings extracted from clean and defended (or synthesized) audio. Higher similarity indicates stronger speaker identity preservation. Protection effectiveness is measured as similarity degradation.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "similarity",
                    "speaker",
                    "protection",
                    "indicates"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We compute MCD between clean and defended speech to quantify spectral distortion. Lower MCD indicates closer acoustic similarity.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "spectral",
                    "indicates"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Uniform random noise sampled from <math alttext=\"[-1,1]\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx6.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mrow><mo>&#8722;</mo><mn>1</mn></mrow><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[-1,1]</annotation></semantics></math> and mixed at the same SNR range as SceneGuard. This baseline lacks scene consistency.</p>\n\n",
                "matched_terms": [
                    "baseline",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Zero-mean Gaussian noise with unit variance, scaled to match SceneGuard&#8217;s SNR range. This represents a simple additive noise baseline commonly used in audio processing.</p>\n\n",
                "matched_terms": [
                    "baseline",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SceneGuard achieves 5.5% speaker similarity degradation (<math alttext=\"\\text{SIM}=0.945\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m1\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>=</mo><mn>0.945</mn></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}=0.945</annotation></semantics></math>) compared to clean training (<math alttext=\"\\text{SIM}=1.000\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m2\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>=</mo><mn>1.000</mn></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}=1.000</annotation></semantics></math>). This protection effect is statistically significant with <math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math> (permutation test, <math alttext=\"n=10,000\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m4\" intent=\":literal\"><semantics><mrow><mi>n</mi><mo>=</mo><mrow><mn>10</mn><mo>,</mo><mn>000</mn></mrow></mrow><annotation encoding=\"application/x-tex\">n=10,000</annotation></semantics></math> iterations) and demonstrates a large effect size (Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m5\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>). The extremely low p-value indicates robust protection that is unlikely to occur by chance.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "protection",
                    "indicates",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Importantly, SceneGuard maintains high usability. Protected speech achieves WER of 2.77%, indicating near-perfect transcription accuracy. The STOI score of 0.99 confirms that intelligibility is essentially preserved. While PESQ (2.22) is below the ideal threshold of 3.0, it remains in an acceptable range for many applications.</p>\n\n",
                "matched_terms": [
                    "maintains",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.F2\" title=\"Figure 2 &#8227; Training Attack Protection &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> visualizes the training attack results, comparing speaker similarity degradation across defense methods. SceneGuard demonstrates stronger protection than random or Gaussian noise baselines while maintaining comparable usability.</p>\n\n",
                "matched_terms": [
                    "across",
                    "similarity",
                    "speaker",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The STOI score of 0.986 significantly exceeds the intelligibility threshold of 0.85, indicating that protected speech remains highly comprehensible. WER of 3.60% with a narrow confidence interval [1.40%, 6.43%] demonstrates robust transcription accuracy across samples. While PESQ falls slightly below the ideal 3.0 threshold, the value of 2.034 is acceptable for many practical applications and represents a deliberate trade-off for robustness.</p>\n\n",
                "matched_terms": [
                    "robustness",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SceneGuard demonstrates remarkable robustness. MP3 compression at both 128 kbps and 64 kbps slightly reduces similarity but maintains protection (SIM &#161; 0.91). More aggressive operations such as spectral subtraction, lowpass filtering, and downsampling actually enhance protection, reducing similarity to 0.745, 0.704, and 0.688 respectively.</p>\n\n",
                "matched_terms": [
                    "lowpass",
                    "operations",
                    "sim",
                    "robustness",
                    "maintains",
                    "similarity",
                    "spectral",
                    "kbps",
                    "subtraction",
                    "mp3",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This counterintuitive enhancement occurs because these operations preferentially damage the clean speech components relative to the protective noise. Spectral subtraction removes stationary components but preserves scene-consistent temporal variations. Lowpass filtering and downsampling reduce high-frequency detail critical for speaker identity while preserving protective noise structure. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.F3\" title=\"Figure 3 &#8227; Robustness to Countermeasures &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> visualizes the robustness results as a heatmap, showing speaker similarity and WER under different countermeasures.</p>\n\n",
                "matched_terms": [
                    "relative",
                    "lowpass",
                    "operations",
                    "under",
                    "robustness",
                    "similarity",
                    "countermeasures",
                    "subtraction",
                    "spectral",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate protection against zero-shot voice cloning attacks where an attacker uses protected recordings as reference audio for inference-time synthesis. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.T4\" title=\"Table 4 &#8227; Zero-Shot Attack Results &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> summarizes the results.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Using defended reference audio reduces mean speaker similarity from 0.618 to 0.588, representing a 5.0% degradation. More importantly, the attack success rate (similarity <math alttext=\"&gt;0.7\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx4.p2.m1\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>0.7</mn></mrow><annotation encoding=\"application/x-tex\">&gt;0.7</annotation></semantics></math>) drops from 20.0% to 13.3%, a 33.5% relative reduction. This demonstrates that SceneGuard provides meaningful protection even in zero-shot scenarios where the attacker does not perform training. Using defended reference audio reduces mean speaker similarity from 0.618 to 0.588 (-5.0%) and lowers the attack success rate from 20.0% to 13.3% (-6.7 pp, 33.5% relative), indicating meaningful zero-shot protection.</p>\n\n",
                "matched_terms": [
                    "relative",
                    "similarity",
                    "speaker",
                    "protection",
                    "audio",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.T5\" title=\"Table 5 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents the quantitative results. Lower SNR (stronger noise) provides better protection but degrades usability, while higher SNR (weaker noise) improves usability but reduces protection. The [10, 20] dB range achieves an effective balance, providing 5.5% similarity degradation while maintaining STOI above 0.98 and WER below 4%.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.F4\" title=\"Figure 4 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> visualizes this trade-off using a dual-axis plot showing protection strength (speaker similarity degradation) and usability (STOI) as functions of SNR range.</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "similarity",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The key advantage of optimization is its ability to identify optimal mask patterns. Direct mixing applies a uniform stochastic mask, which may unnecessarily distort speech regions while under-protecting others. In contrast, gradient-based optimization adaptively concentrates protection in regions that most effectively reduce speaker similarity while avoiding critical speech segments.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The regularization weight <math alttext=\"\\lambda_{\\text{REG}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m1\" intent=\":literal\"><semantics><msub><mi>&#955;</mi><mtext>REG</mtext></msub><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}</annotation></semantics></math> controls the smoothness of the temporal mask. Higher values (<math alttext=\"\\lambda=0.1\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m2\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.1</annotation></semantics></math>) produce smoother masks but slightly reduce protection strength (SIM = 0.958). Lower values (<math alttext=\"\\lambda=0.001\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m3\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.001</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.001</annotation></semantics></math>) allow rougher masks with marginally better protection (SIM = 0.939) but risk overfitting. Our default <math alttext=\"\\lambda=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m4\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.01</annotation></semantics></math> strikes a good balance.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The number of epochs shows diminishing returns beyond 50 iterations. While 100 epochs achieve slightly better protection (SIM = 0.943), the improvement is minimal (0.2 percentage points) and doubles computation time. 20 epochs provide fast computation but do not fully converge. We therefore recommend 50 epochs as the default, offering good convergence without excessive cost.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Psychoacoustic masking further explains SceneGuard&#8217;s effectiveness. Auditory masking occurs when one sound makes another sound less audible. Scene-consistent noise can mask subtle speaker-specific characteristics while preserving overall speech intelligibility. This selective masking degrades speaker embeddings without proportionally affecting transcription accuracy, as evidenced by our results (5.5% similarity degradation vs. 2.77% WER).</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The robustness of SceneGuard to audio preprocessing is a critical advantage over imperceptible perturbations. Our results show that certain countermeasures paradoxically enhance protection rather than removing it. This phenomenon has several explanations:</p>\n\n",
                "matched_terms": [
                    "robustness",
                    "countermeasures",
                    "preprocessing",
                    "protection",
                    "audio",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Spectral Subtraction</span>: This denoising technique assumes stationary noise and removes spectral components with consistent energy. However, scene-consistent noise contains non-stationary elements (e.g., footsteps, vehicle sounds) that are not fully removed. Meanwhile, spectral subtraction introduces musical noise artifacts that further degrade speaker embeddings.</p>\n\n",
                "matched_terms": [
                    "spectral",
                    "speaker",
                    "subtraction"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Lowpass Filtering and Downsampling</span>: Speaker identity relies significantly on high-frequency spectral details and prosodic variations. Lowpass filtering and downsampling preferentially remove these high-frequency components while preserving lower-frequency protective noise. This asymmetric degradation enhances protection.</p>\n\n",
                "matched_terms": [
                    "lowpass",
                    "spectral",
                    "enhances",
                    "speaker",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">MP3 Compression</span>: Lossy compression preserves perceptually important components. Because SceneGuard uses audible noise, it is treated as salient content rather than irrelevant information to be discarded. This contrasts with imperceptible perturbations that fall below perceptual thresholds and are aggressively quantized.</p>\n\n",
                "matched_terms": [
                    "mp3",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Audible Protection</span>: SceneGuard deliberately uses audible noise, which may be undesirable in scenarios requiring pristine audio quality. Applications such as studio recordings or professional voice work may prefer imperceptible protections despite their fragility. SceneGuard is best suited for everyday voice recordings where some background noise is acceptable.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "audio",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Adaptive Attacks</span>: We evaluate SceneGuard against standard audio preprocessing countermeasures, but a sophisticated attacker might develop adaptive attacks specifically designed to remove scene-consistent noise. Potential adaptive strategies include scene-aware source separation or adversarial training. However, such attacks would require significant additional effort and may introduce other artifacts.</p>\n\n",
                "matched_terms": [
                    "preprocessing",
                    "countermeasures",
                    "audio",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We presented SceneGuard, a training-time voice protection method based on scene-consistent audible background noise. Unlike existing defenses that rely on imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes to create protective noise that is contextually appropriate and robust to common audio preprocessing operations.</p>\n\n",
                "matched_terms": [
                    "operations",
                    "preprocessing",
                    "protection",
                    "audio",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our experimental evaluation demonstrates that SceneGuard achieves strong protection against training attacks, degrading speaker similarity by 5.5% with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>). Critically, SceneGuard preserves speech usability, maintaining 98.6% intelligibility (STOI = 0.986) and achieving low word error rate (3.6%). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures, including MP3 compression, denoising, filtering, and downsampling.</p>\n\n",
                "matched_terms": [
                    "under",
                    "evaluation",
                    "robustness",
                    "maintains",
                    "similarity",
                    "countermeasures",
                    "enhances",
                    "mp3",
                    "speaker",
                    "protection",
                    "sceneguard"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">These results suggest that audible, scene-consistent noise provides a practical alternative to imperceptible perturbations for voice protection. By deliberately using audible but natural noise, SceneGuard achieves robustness properties that imperceptible methods cannot match, addressing a fundamental limitation of existing approaches.</p>\n\n",
                "matched_terms": [
                    "robustness",
                    "protection",
                    "sceneguard"
                ]
            }
        ]
    },
    "Sx5.T4": {
        "source_file": "SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise",
        "caption": "Table 4: Zero-shot attack results using clean versus defended reference audio. Attack success rate is measured as the percentage of synthesis attempts achieving similarity >> 0.7 to the target speaker.",
        "body": "Reference Type\nMean Similarity\nAttack Success Rate (%)\n\n\n\n\nClean\n0.618\n20.0\n\n\nDefended\n0.588\n13.3\n\n\nReduction\n0.031\n6.7 pp",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Reference Type</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Mean Similarity</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Attack Success Rate (%)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Clean</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.618</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">20.0</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Defended</th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.588</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">13.3</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Reduction</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.031</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">6.7 pp</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "type",
            "percentage",
            "rate",
            "target",
            "success",
            "zeroshot",
            "mean",
            "reference",
            "speaker",
            "attack",
            "results",
            "synthesis",
            "measured",
            "achieving",
            "similarity",
            "clean",
            "versus",
            "defended",
            "attempts",
            "reduction",
            "audio"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">We evaluate protection against zero-shot voice cloning attacks where an attacker uses protected recordings as reference audio for inference-time synthesis. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.T4\" title=\"Table 4 &#8227; Zero-Shot Attack Results &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> summarizes the results.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Voice cloning technology poses significant privacy threats by enabling unauthorized speech synthesis from limited audio samples. Existing defenses based on imperceptible adversarial perturbations are vulnerable to common audio preprocessing such as denoising and compression. We propose SceneGuard, a training-time voice protection method that applies scene-consistent audible background noise to speech recordings. Unlike imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes (e.g., airport, street, park) to create protective noise that is contextually appropriate and robust to countermeasures. We evaluate SceneGuard on text-to-speech training attacks, demonstrating 5.5% speaker similarity degradation with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>) while preserving 98.6% speech intelligibility (STOI = 0.986). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures including MP3 compression, spectral subtraction, lowpass filtering, and downsampling. Our results suggest that audible, scene-consistent noise provides a more robust alternative to imperceptible perturbations for training-time voice protection. The source code are available at: <span class=\"ltx_ref ltx_nolink ltx_url ltx_ref_self\">https://github.com/richael-sang/SceneGuard</span>.</p>\n\n",
                "matched_terms": [
                    "synthesis",
                    "similarity",
                    "speaker",
                    "results",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Deep learning has enabled high-fidelity voice cloning systems capable of synthesizing speech that closely mimics a target speaker&#8217;s voice&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">gao2025black</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">fanantifake</span>)</cite>. While these technologies have legitimate applications in accessibility and entertainment, they also pose serious threats to privacy and security. Attackers can use unauthorized voice recordings to train text-to-speech (TTS) or voice conversion (VC) models, enabling impersonation attacks, voice-based authentication breaches, and creation of misleading audio content&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">wang2025one</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "audio",
                    "target"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SceneGuard, a training-time defense that applies scene-consistent audible background noise to speech recordings through gradient-based optimization. SceneGuard first classifies the acoustic scene of input speech, then jointly optimizes a temporal mask <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m1\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while maintaining usability. For example, speech recorded in an airport is mixed with optimized airport background noise, creating a protective layer that appears natural and contextually plausible. This design offers three advantages: (1) optimization automatically finds the protection-usability trade-off, (2) the protection is harder to remove because scene-consistent noise cannot be easily separated from speech without degrading speech quality, and (3) the defense is robust to common audio preprocessing operations.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate SceneGuard on training attack scenarios where an attacker uses protected recordings to fine-tune TTS models. Our experiments on 100 training samples and 40 test samples demonstrate 5.5% speaker similarity degradation (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>), indicating strong statistical evidence of protection effectiveness. Importantly, SceneGuard preserves 98.6% speech intelligibility (STOI = 0.986) and achieves low word error rate (WER = 3.6%), demonstrating that protected speech remains highly usable. Robustness evaluation shows that SceneGuard maintains protection under MP3 compression and even exhibits enhanced protection under denoising, lowpass filtering, and downsampling operations.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "attack",
                    "rate"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent work has explored adversarial perturbations as a proactive defense against voice cloning. VoiceBlock&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>)</cite> is a real-time de-identification approach that learns a time-varying FIR filter to apply perceptually inconspicuous, streaming-friendly perturbations for evading speaker recognition. Building on proactive protection but shifting the threat model to training-time cloning, SafeSpeech&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite> embeds imperceptible, universal perturbations via its SPEC objective to degrade generative TTS across models while emphasizing transferability and robustness. Contemporary work&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">gao2025black</span>)</cite> proposes a black-box defense for voice conversion that adds imperceptible perturbations and optimizes them in latent space with evolution-based search to adapt against unknown VC systems. While these methods demonstrate effectiveness in controlled settings, they face a fundamental limitation: imperceptible perturbations are inherently fragile to common audio processing operations.</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent voice protection methods&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>)</cite> embed imperceptible adversarial perturbations by minimizing <math alttext=\"\\ell_{p}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m1\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#8467;</mi><mi>p</mi></msub><annotation encoding=\"application/x-tex\">\\ell_{p}</annotation></semantics></math> norms (typically <math alttext=\"\\|\\delta\\|_{\\infty}\\leq\\epsilon\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mrow><mo stretchy=\"false\">&#8214;</mo><mi>&#948;</mi><mo stretchy=\"false\">&#8214;</mo></mrow><mi mathvariant=\"normal\">&#8734;</mi></msub><mo>&#8804;</mo><mi>&#1013;</mi></mrow><annotation encoding=\"application/x-tex\">\\|\\delta\\|_{\\infty}\\leq\\epsilon</annotation></semantics></math> with <math alttext=\"\\epsilon\\approx 8/255\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>&#1013;</mi><mo>&#8776;</mo><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\epsilon\\approx 8/255</annotation></semantics></math>). While these perturbations are inaudible, they are <span class=\"ltx_text ltx_font_italic\">fragile</span>: standard audio processing operations such as lossy compression (MP3, AAC), speech enhancement, or denoising can significantly attenuate protection effectiveness. For instance, SafeSpeech&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite> shows that DeepMucs&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">demucs</span>)</cite> denoising reduces protection by up to 42% (SIM increases from 0.204 to 0.284). This fragility arises because imperceptible perturbations occupy high-frequency or low-energy regions that are specifically targeted by perceptual codecs and noise reduction algorithms.</p>\n\n",
                "matched_terms": [
                    "reduction",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We consider a training-time attack scenario where an adversary aims to clone a target speaker&#8217;s voice by fine-tuning a pre-trained TTS or VC model on unauthorized audio recordings. The attacker operates in a black-box setting, having no knowledge of the protection mechanism applied to the training data. Formally, given a dataset <math alttext=\"\\mathcal{D}=\\{(x_{i},y_{i})\\}_{i=1}^{N}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119967;</mi><mo>=</mo><msubsup><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\mathcal{D}=\\{(x_{i},y_{i})\\}_{i=1}^{N}</annotation></semantics></math> of protected speech samples <math alttext=\"x^{\\prime}_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m2\" intent=\":literal\"><semantics><msubsup><mi>x</mi><mi>i</mi><mo>&#8242;</mo></msubsup><annotation encoding=\"application/x-tex\">x^{\\prime}_{i}</annotation></semantics></math> and corresponding text labels <math alttext=\"y_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx1.p1.m3\" intent=\":literal\"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">y_{i}</annotation></semantics></math>, the attacker solves:</p>\n\n",
                "matched_terms": [
                    "audio",
                    "attack",
                    "target"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The defender&#8217;s objective is to apply a transformation <math alttext=\"\\mathcal{T}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><annotation encoding=\"application/x-tex\">\\mathcal{T}</annotation></semantics></math> to speech <math alttext=\"x\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m2\" intent=\":literal\"><semantics><mi>x</mi><annotation encoding=\"application/x-tex\">x</annotation></semantics></math> that produces protected audio <math alttext=\"x^{\\prime}=\\mathcal{T}(x,s)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m3\" intent=\":literal\"><semantics><mrow><msup><mi>x</mi><mo>&#8242;</mo></msup><mo>=</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">x^{\\prime}=\\mathcal{T}(x,s)</annotation></semantics></math> (where <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m4\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math> denotes acoustic scene context) satisfying two criteria: (1) <span class=\"ltx_text ltx_font_italic\">Protection</span>: degraded speaker identity prevents successful cloning, formally:</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Naive mixing of speech with scene noise at a fixed signal-to-noise ratio (SNR) and uniform temporal weighting faces two risks: (1) insufficient protection if SNR is too high or noise placement is suboptimal, resulting in speaker embeddings that remain similar (<math alttext=\"\\text{SIM}&gt;\\tau_{\\text{sim}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m1\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>&gt;</mo><msub><mi>&#964;</mi><mtext>sim</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}&gt;\\tau_{\\text{sim}}</annotation></semantics></math>); (2) excessive degradation if SNR is too low or noise overwhelms speech regions, causing unacceptable WER increases. To navigate this trade-off, we formulate protection as an <span class=\"ltx_text ltx_font_italic\">optimization problem</span>: jointly optimize the temporal mask <math alttext=\"m(t)\\in[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m2\" intent=\":literal\"><semantics><mrow><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)\\in[0,1]</annotation></semantics></math> controlling when noise is applied, and the noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m3\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> controlling overall SNR, to minimize speaker similarity while maintaining usability. This optimization ensures that the noise is strategically placed (e.g., emphasizing pauses or non-critical phonemes) and calibrated to the specific speech sample.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Overview.</span> Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.F1\" title=\"Figure 1 &#8227; Need for Optimization. &#8227; Scene-Consistent Audible Noise Defense &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> summarizes SceneGuard:\n(1) we obtain a scene label <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m1\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math> via ASC (or user-specified) and sample noise <math alttext=\"n_{k}\\!\\in\\!\\mathcal{N}_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mi>n</mi><mi>k</mi></msub><mo lspace=\"0.108em\" rspace=\"0.108em\">&#8712;</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119977;</mi><mi>s</mi></msub></mrow><annotation encoding=\"application/x-tex\">n_{k}\\!\\in\\!\\mathcal{N}_{s}</annotation></semantics></math>;\n(2) protected audio is produced by the mixer <math alttext=\"x^{\\prime}(t)=x(t)+\\gamma\\,m(t)\\odot n_{k}(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m3\" intent=\":literal\"><semantics><mrow><mrow><msup><mi>x</mi><mo>&#8242;</mo></msup><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>x</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mrow><mi>&#947;</mi><mo lspace=\"0.170em\" rspace=\"0em\">&#8203;</mo><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo rspace=\"0.055em\" stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"0.222em\">&#8857;</mo><msub><mi>n</mi><mi>k</mi></msub></mrow><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">x^{\\prime}(t)=x(t)+\\gamma\\,m(t)\\odot n_{k}(t)</annotation></semantics></math> (Sec.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.E5\" title=\"In Mixing Model. &#8227; Optimization Objective &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>);\n(3) an optimization loop updates <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m4\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p2.m5\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> using an ECAPA-based similarity loss with SNR/regularization\nconstraints (Sec.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.E6\" title=\"In Objective Function. &#8227; Optimization Objective &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>). The defended data are then used against training-time and zero-shot attacks.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "defended",
                    "audio",
                    "zeroshot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We jointly optimize <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx2.p1.m1\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> and <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx2.p1.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while regularizing for usability and smoothness. The total loss is:</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "similarity"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Speaker Similarity Loss</span> <math alttext=\"\\mathcal{L}_{\\text{SIM}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.I2.i1.p1.m1\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8466;</mi><mtext>SIM</mtext></msub><annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\text{SIM}}</annotation></semantics></math>: Minimizes cosine similarity between speaker embeddings of protected and clean audio:</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "audio",
                    "similarity",
                    "clean"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">: We use LibriTTS&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">libritts</span>)</cite>, a multi-speaker English corpus derived from audiobooks. We split the data into 100 training samples and 40 test samples for training attack evaluation, with additional subsets for zero-shot and robustness experiments.</p>\n\n",
                "matched_terms": [
                    "attack",
                    "zeroshot"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use ECAPA-TDNN&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">ecapa</span>)</cite>, a state-of-the-art speaker verification model from the SpeechBrain toolkit. The model extracts 192-dimensional speaker embeddings, which we use to compute speaker similarity via cosine distance. ECAPA-TDNN achieves strong performance on VoxCeleb and is widely used for speaker verification tasks.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For training attack experiments, we reference BERT-VITS2&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">bertvits2</span>)</cite>, a recent TTS architecture that combines BERT-based text encoding with VITS neural vocoder. While we do not perform full TTS training due to computational constraints, we use speaker embedding degradation as a proxy for TTS quality, following established evaluation protocols&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "reference",
                    "attack"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We minimize speaker similarity while maintaining usability constraints. The primary loss term is speaker embedding cosine similarity computed using ECAPA-TDNN. We add a regularization term (<math alttext=\"\\lambda_{\\text{REG}}=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><msub><mi>&#955;</mi><mtext>REG</mtext></msub><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}=0.01</annotation></semantics></math>) that penalizes mask roughness and excessive noise strength to promote smooth, stable solutions.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We simulate an attacker who fine-tunes a TTS model on protected recordings. To evaluate protection effectiveness, we measure speaker embedding quality and consistency on training data, then assess the similarity between embeddings extracted from clean and defended audio on held-out test samples. Lower test similarity indicates successful protection.</p>\n\n",
                "matched_terms": [
                    "defended",
                    "similarity",
                    "clean",
                    "speaker",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate protection against zero-shot voice cloning, where an attacker uses protected recordings as reference audio for inference-time cloning. We generate synthetic speech using a pre-trained model with clean versus defended reference, measuring speaker similarity to the original speaker.</p>\n\n",
                "matched_terms": [
                    "versus",
                    "defended",
                    "zeroshot",
                    "similarity",
                    "reference",
                    "clean",
                    "speaker",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We test whether protection persists under five common audio preprocessing operations: MP3 compression (128 kbps and 64 kbps), spectral subtraction denoising, lowpass filtering (3400 Hz cutoff), and downsampling to 8 kHz. For each countermeasure, we re-compute speaker similarity and WER to assess protection retention.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We compute cosine similarity between speaker embeddings extracted from clean and defended (or synthesized) audio. Higher similarity indicates stronger speaker identity preservation. Protection effectiveness is measured as similarity degradation.</p>\n\n",
                "matched_terms": [
                    "measured",
                    "defended",
                    "similarity",
                    "clean",
                    "speaker",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We measure the percentage of word-level errors (insertions, deletions, substitutions) between reference transcripts and ASR outputs. Lower WER indicates better intelligibility. We use WER to ensure protected speech remains usable.</p>\n\n",
                "matched_terms": [
                    "reference",
                    "percentage"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We compute MCD between clean and defended speech to quantify spectral distortion. Lower MCD indicates closer acoustic similarity.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "clean",
                    "defended"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SceneGuard achieves 5.5% speaker similarity degradation (<math alttext=\"\\text{SIM}=0.945\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m1\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>=</mo><mn>0.945</mn></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}=0.945</annotation></semantics></math>) compared to clean training (<math alttext=\"\\text{SIM}=1.000\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m2\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>=</mo><mn>1.000</mn></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}=1.000</annotation></semantics></math>). This protection effect is statistically significant with <math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math> (permutation test, <math alttext=\"n=10,000\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m4\" intent=\":literal\"><semantics><mrow><mi>n</mi><mo>=</mo><mrow><mn>10</mn><mo>,</mo><mn>000</mn></mrow></mrow><annotation encoding=\"application/x-tex\">n=10,000</annotation></semantics></math> iterations) and demonstrates a large effect size (Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx1.p2.m5\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>). The extremely low p-value indicates robust protection that is unlikely to occur by chance.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "clean"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.F2\" title=\"Figure 2 &#8227; Training Attack Protection &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> visualizes the training attack results, comparing speaker similarity degradation across defense methods. SceneGuard demonstrates stronger protection than random or Gaussian noise baselines while maintaining comparable usability.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "attack",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">A key advantage of SceneGuard is its robustness to audio preprocessing operations that typically neutralize imperceptible perturbations. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.T3\" title=\"Table 3 &#8227; Robustness to Countermeasures &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> presents results under five common countermeasures.</p>\n\n",
                "matched_terms": [
                    "results",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This counterintuitive enhancement occurs because these operations preferentially damage the clean speech components relative to the protective noise. Spectral subtraction removes stationary components but preserves scene-consistent temporal variations. Lowpass filtering and downsampling reduce high-frequency detail critical for speaker identity while preserving protective noise structure. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.F3\" title=\"Figure 3 &#8227; Robustness to Countermeasures &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> visualizes the robustness results as a heatmap, showing speaker similarity and WER under different countermeasures.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "results",
                    "clean"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Using defended reference audio reduces mean speaker similarity from 0.618 to 0.588, representing a 5.0% degradation. More importantly, the attack success rate (similarity <math alttext=\"&gt;0.7\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx4.p2.m1\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>0.7</mn></mrow><annotation encoding=\"application/x-tex\">&gt;0.7</annotation></semantics></math>) drops from 20.0% to 13.3%, a 33.5% relative reduction. This demonstrates that SceneGuard provides meaningful protection even in zero-shot scenarios where the attacker does not perform training. Using defended reference audio reduces mean speaker similarity from 0.618 to 0.588 (-5.0%) and lowers the attack success rate from 20.0% to 13.3% (-6.7 pp, 33.5% relative), indicating meaningful zero-shot protection.</p>\n\n",
                "matched_terms": [
                    "success",
                    "defended",
                    "reduction",
                    "rate",
                    "zeroshot",
                    "mean",
                    "similarity",
                    "reference",
                    "attack",
                    "speaker",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.T5\" title=\"Table 5 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents the quantitative results. Lower SNR (stronger noise) provides better protection but degrades usability, while higher SNR (weaker noise) improves usability but reduces protection. The [10, 20] dB range achieves an effective balance, providing 5.5% similarity degradation while maintaining STOI above 0.98 and WER below 4%.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.F4\" title=\"Figure 4 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> visualizes this trade-off using a dual-axis plot showing protection strength (speaker similarity degradation) and usability (STOI) as functions of SNR range.</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "similarity"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization nearly doubles the protection strength, achieving 5.5% degradation compared to 2.8% for direct mixing. This 2.7 percentage point improvement comes at minimal usability cost: STOI decreases by only 0.003 (from 0.989 to 0.986) and WER increases by 0.4 percentage points (from 3.2% to 3.6%), both negligible changes.</p>\n\n",
                "matched_terms": [
                    "percentage",
                    "achieving"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The key advantage of optimization is its ability to identify optimal mask patterns. Direct mixing applies a uniform stochastic mask, which may unnecessarily distort speech regions while under-protecting others. In contrast, gradient-based optimization adaptively concentrates protection in regions that most effectively reduce speaker similarity while avoiding critical speech segments.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Psychoacoustic masking further explains SceneGuard&#8217;s effectiveness. Auditory masking occurs when one sound makes another sound less audible. Scene-consistent noise can mask subtle speaker-specific characteristics while preserving overall speech intelligibility. This selective masking degrades speaker embeddings without proportionally affecting transcription accuracy, as evidenced by our results (5.5% similarity degradation vs. 2.77% WER).</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The robustness of SceneGuard to audio preprocessing is a critical advantage over imperceptible perturbations. Our results show that certain countermeasures paradoxically enhance protection rather than removing it. This phenomenon has several explanations:</p>\n\n",
                "matched_terms": [
                    "results",
                    "audio"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our experimental evaluation demonstrates that SceneGuard achieves strong protection against training attacks, degrading speaker similarity by 5.5% with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>). Critically, SceneGuard preserves speech usability, maintaining 98.6% intelligibility (STOI = 0.986) and achieving low word error rate (3.6%). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures, including MP3 compression, denoising, filtering, and downsampling.</p>\n\n",
                "matched_terms": [
                    "similarity",
                    "speaker",
                    "rate",
                    "achieving"
                ]
            }
        ]
    },
    "Sx6.T5": {
        "source_file": "SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise",
        "caption": "Table 5: SNR range ablation study. The default [10, 20] dB range provides the best balance between protection and usability.",
        "body": "SNR (dB)\nSIM ↓\\downarrow\n\nProtection (%)\nSTOI ↑\\uparrow\n\nWER (%) ↓\\downarrow\n\n\n\n\n\n[5, 10]\n0.921\n7.9\n0.942\n8.2\n\n\n[10, 20]\n0.945\n5.5\n0.986\n3.6\n\n\n[15, 25]\n0.968\n3.2\n0.993\n1.8\n\n\n[20, 30]\n0.982\n1.8\n0.997\n0.9",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">SNR (dB)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">SIM <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T5.m1\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Protection (%)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">STOI <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T5.m2\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">WER (%) <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T5.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">[5, 10]</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.921</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">7.9</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.942</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">8.2</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text ltx_font_bold\">[10, 20]</span></th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.945</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">5.5</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.986</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">3.6</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">[15, 25]</th>\n<td class=\"ltx_td ltx_align_center\">0.968</td>\n<td class=\"ltx_td ltx_align_center\">3.2</td>\n<td class=\"ltx_td ltx_align_center\">0.993</td>\n<td class=\"ltx_td ltx_align_center\">1.8</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">[20, 30]</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.982</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">1.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.997</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.9</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "usability",
            "snr",
            "balance",
            "range",
            "study",
            "default",
            "ablation",
            "stoi",
            "↓downarrow",
            "sim",
            "best",
            "between",
            "wer",
            "↑uparrow",
            "protection",
            "provides"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.T5\" title=\"Table 5 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents the quantitative results. Lower SNR (stronger noise) provides better protection but degrades usability, while higher SNR (weaker noise) improves usability but reduces protection. The [10, 20] dB range achieves an effective balance, providing 5.5% similarity degradation while maintaining STOI above 0.98 and WER below 4%.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Voice cloning technology poses significant privacy threats by enabling unauthorized speech synthesis from limited audio samples. Existing defenses based on imperceptible adversarial perturbations are vulnerable to common audio preprocessing such as denoising and compression. We propose SceneGuard, a training-time voice protection method that applies scene-consistent audible background noise to speech recordings. Unlike imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes (e.g., airport, street, park) to create protective noise that is contextually appropriate and robust to countermeasures. We evaluate SceneGuard on text-to-speech training attacks, demonstrating 5.5% speaker similarity degradation with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>) while preserving 98.6% speech intelligibility (STOI = 0.986). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures including MP3 compression, spectral subtraction, lowpass filtering, and downsampling. Our results suggest that audible, scene-consistent noise provides a more robust alternative to imperceptible perturbations for training-time voice protection. The source code are available at: <span class=\"ltx_ref ltx_nolink ltx_url ltx_ref_self\">https://github.com/richael-sang/SceneGuard</span>.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "provides",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SceneGuard, a training-time defense that applies scene-consistent audible background noise to speech recordings through gradient-based optimization. SceneGuard first classifies the acoustic scene of input speech, then jointly optimizes a temporal mask <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m1\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while maintaining usability. For example, speech recorded in an airport is mixed with optimized airport background noise, creating a protective layer that appears natural and contextually plausible. This design offers three advantages: (1) optimization automatically finds the protection-usability trade-off, (2) the protection is harder to remove because scene-consistent noise cannot be easily separated from speech without degrading speech quality, and (3) the defense is robust to common audio preprocessing operations.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate SceneGuard on training attack scenarios where an attacker uses protected recordings to fine-tune TTS models. Our experiments on 100 training samples and 40 test samples demonstrate 5.5% speaker similarity degradation (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>), indicating strong statistical evidence of protection effectiveness. Importantly, SceneGuard preserves 98.6% speech intelligibility (STOI = 0.986) and achieves low word error rate (WER = 3.6%), demonstrating that protected speech remains highly usable. Robustness evaluation shows that SceneGuard maintains protection under MP3 compression and even exhibits enhanced protection under denoising, lowpass filtering, and downsampling operations.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "wer",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We design a gradient-based optimization framework that automatically balances speaker protection and speech usability under SNR constraints.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "snr",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We demonstrate strong protection against training attacks with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.I1.i3.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.I1.i3.p1.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>) while preserving speech usability (STOI = 0.986, WER = 3.6%).</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection",
                    "wer",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent voice protection methods&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>)</cite> embed imperceptible adversarial perturbations by minimizing <math alttext=\"\\ell_{p}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m1\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#8467;</mi><mi>p</mi></msub><annotation encoding=\"application/x-tex\">\\ell_{p}</annotation></semantics></math> norms (typically <math alttext=\"\\|\\delta\\|_{\\infty}\\leq\\epsilon\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mrow><mo stretchy=\"false\">&#8214;</mo><mi>&#948;</mi><mo stretchy=\"false\">&#8214;</mo></mrow><mi mathvariant=\"normal\">&#8734;</mi></msub><mo>&#8804;</mo><mi>&#1013;</mi></mrow><annotation encoding=\"application/x-tex\">\\|\\delta\\|_{\\infty}\\leq\\epsilon</annotation></semantics></math> with <math alttext=\"\\epsilon\\approx 8/255\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>&#1013;</mi><mo>&#8776;</mo><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\epsilon\\approx 8/255</annotation></semantics></math>). While these perturbations are inaudible, they are <span class=\"ltx_text ltx_font_italic\">fragile</span>: standard audio processing operations such as lossy compression (MP3, AAC), speech enhancement, or denoising can significantly attenuate protection effectiveness. For instance, SafeSpeech&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite> shows that DeepMucs&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">demucs</span>)</cite> denoising reduces protection by up to 42% (SIM increases from 0.204 to 0.284). This fragility arises because imperceptible perturbations occupy high-frequency or low-energy regions that are specifically targeted by perceptual codecs and noise reduction algorithms.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"e(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m5\" intent=\":literal\"><semantics><mrow><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">e(\\cdot)</annotation></semantics></math> is a speaker verification encoder and <math alttext=\"\\tau_{\\text{sim}},\\tau_{\\text{eer}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m6\" intent=\":literal\"><semantics><mrow><msub><mi>&#964;</mi><mtext>sim</mtext></msub><mo>,</mo><msub><mi>&#964;</mi><mtext>eer</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\tau_{\\text{sim}},\\tau_{\\text{eer}}</annotation></semantics></math> are protection thresholds; and (2) <span class=\"ltx_text ltx_font_italic\">Usability</span>: preserved intelligibility for legitimate communication:</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Naive mixing of speech with scene noise at a fixed signal-to-noise ratio (SNR) and uniform temporal weighting faces two risks: (1) insufficient protection if SNR is too high or noise placement is suboptimal, resulting in speaker embeddings that remain similar (<math alttext=\"\\text{SIM}&gt;\\tau_{\\text{sim}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m1\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>&gt;</mo><msub><mi>&#964;</mi><mtext>sim</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}&gt;\\tau_{\\text{sim}}</annotation></semantics></math>); (2) excessive degradation if SNR is too low or noise overwhelms speech regions, causing unacceptable WER increases. To navigate this trade-off, we formulate protection as an <span class=\"ltx_text ltx_font_italic\">optimization problem</span>: jointly optimize the temporal mask <math alttext=\"m(t)\\in[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m2\" intent=\":literal\"><semantics><mrow><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)\\in[0,1]</annotation></semantics></math> controlling when noise is applied, and the noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m3\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> controlling overall SNR, to minimize speaker similarity while maintaining usability. This optimization ensures that the noise is strategically placed (e.g., emphasizing pauses or non-critical phonemes) and calibrated to the specific speech sample.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "snr",
                    "protection",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">ASR Loss</span> <math alttext=\"\\mathcal{L}_{\\text{ASR}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.I2.i3.p1.m1\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8466;</mi><mtext>ASR</mtext></msub><annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\text{ASR}}</annotation></semantics></math> (optional): Penalizes transcription errors to maintain intelligibility. In practice, this is disabled (<math alttext=\"\\lambda_{\\text{ASR}}=0\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.I2.i3.p1.m2\" intent=\":literal\"><semantics><mrow><msub><mi>&#955;</mi><mtext>ASR</mtext></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda_{\\text{ASR}}=0</annotation></semantics></math>) due to computational cost; usability is enforced via the SNR constraint instead.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "snr"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We employ Whisper Base&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">whisper</span>)</cite>, an encoder-decoder transformer trained on 680,000 hours of multilingual speech data. Whisper provides robust transcription for measuring speech intelligibility via word error rate (WER). We use the base model (74M parameters) for computational efficiency.</p>\n\n",
                "matched_terms": [
                    "provides",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use the Adam optimizer&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">adam</span>)</cite> with learning rate <math alttext=\"\\text{lr}=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx2.p1.m1\" intent=\":literal\"><semantics><mrow><mtext>lr</mtext><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\text{lr}=0.01</annotation></semantics></math> and default momentum parameters (<math alttext=\"\\beta_{1}=0.9\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx2.p1.m2\" intent=\":literal\"><semantics><mrow><msub><mi>&#946;</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn></mrow><annotation encoding=\"application/x-tex\">\\beta_{1}=0.9</annotation></semantics></math>, <math alttext=\"\\beta_{2}=0.999\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx2.p1.m3\" intent=\":literal\"><semantics><mrow><msub><mi>&#946;</mi><mn>2</mn></msub><mo>=</mo><mn>0.999</mn></mrow><annotation encoding=\"application/x-tex\">\\beta_{2}=0.999</annotation></semantics></math>). We run optimization for 50 epochs per sample, which empirically provides good convergence. To ensure training stability, we apply gradient clipping with maximum norm 1.0.</p>\n\n",
                "matched_terms": [
                    "default",
                    "provides"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The temporal mask logits are initialized from a standard normal distribution, corresponding to a uniform mask (<math alttext=\"m(t)\\approx 0.5\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx3.p1.m1\" intent=\":literal\"><semantics><mrow><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8776;</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">m(t)\\approx 0.5</annotation></semantics></math>) after sigmoid activation. The noise strength is initialized to produce SNR near the middle of the allowed range (approximately 15 dB).</p>\n\n",
                "matched_terms": [
                    "snr",
                    "range"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We simulate an attacker who fine-tunes a TTS model on protected recordings. To evaluate protection effectiveness, we measure speaker embedding quality and consistency on training data, then assess the similarity between embeddings extracted from clean and defended audio on held-out test samples. Lower test similarity indicates successful protection.</p>\n\n",
                "matched_terms": [
                    "between",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We test whether protection persists under five common audio preprocessing operations: MP3 compression (128 kbps and 64 kbps), spectral subtraction denoising, lowpass filtering (3400 Hz cutoff), and downsampling to 8 kHz. For each countermeasure, we re-compute speaker similarity and WER to assess protection retention.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We compute cosine similarity between speaker embeddings extracted from clean and defended (or synthesized) audio. Higher similarity indicates stronger speaker identity preservation. Protection effectiveness is measured as similarity degradation.</p>\n\n",
                "matched_terms": [
                    "between",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We measure the percentage of word-level errors (insertions, deletions, substitutions) between reference transcripts and ASR outputs. Lower WER indicates better intelligibility. We use WER to ensure protected speech remains usable.</p>\n\n",
                "matched_terms": [
                    "between",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Uniform random noise sampled from <math alttext=\"[-1,1]\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx6.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><mo stretchy=\"false\">[</mo><mrow><mo>&#8722;</mo><mn>1</mn></mrow><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[-1,1]</annotation></semantics></math> and mixed at the same SNR range as SceneGuard. This baseline lacks scene consistency.</p>\n\n",
                "matched_terms": [
                    "snr",
                    "range"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Zero-mean Gaussian noise with unit variance, scaled to match SceneGuard&#8217;s SNR range. This represents a simple additive noise baseline commonly used in audio processing.</p>\n\n",
                "matched_terms": [
                    "snr",
                    "range"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Importantly, SceneGuard maintains high usability. Protected speech achieves WER of 2.77%, indicating near-perfect transcription accuracy. The STOI score of 0.99 confirms that intelligibility is essentially preserved. While PESQ (2.22) is below the ideal threshold of 3.0, it remains in an acceptable range for many applications.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "wer",
                    "range",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.F2\" title=\"Figure 2 &#8227; Training Attack Protection &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> visualizes the training attack results, comparing speaker similarity degradation across defense methods. SceneGuard demonstrates stronger protection than random or Gaussian noise baselines while maintaining comparable usability.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.T2\" title=\"Table 2 &#8227; Usability Preservation &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> presents detailed usability metrics for SceneGuard-protected speech, demonstrating that protection does not significantly compromise speech quality for legitimate use cases.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The STOI score of 0.986 significantly exceeds the intelligibility threshold of 0.85, indicating that protected speech remains highly comprehensible. WER of 3.60% with a narrow confidence interval [1.40%, 6.43%] demonstrates robust transcription accuracy across samples. While PESQ falls slightly below the ideal 3.0 threshold, the value of 2.034 is acceptable for many practical applications and represents a deliberate trade-off for robustness.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SceneGuard demonstrates remarkable robustness. MP3 compression at both 128 kbps and 64 kbps slightly reduces similarity but maintains protection (SIM &#161; 0.91). More aggressive operations such as spectral subtraction, lowpass filtering, and downsampling actually enhance protection, reducing similarity to 0.745, 0.704, and 0.688 respectively.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Using defended reference audio reduces mean speaker similarity from 0.618 to 0.588, representing a 5.0% degradation. More importantly, the attack success rate (similarity <math alttext=\"&gt;0.7\" class=\"ltx_Math\" display=\"inline\" id=\"Sx5.SSx4.p2.m1\" intent=\":literal\"><semantics><mrow><mi/><mo>&gt;</mo><mn>0.7</mn></mrow><annotation encoding=\"application/x-tex\">&gt;0.7</annotation></semantics></math>) drops from 20.0% to 13.3%, a 33.5% relative reduction. This demonstrates that SceneGuard provides meaningful protection even in zero-shot scenarios where the attacker does not perform training. Using defended reference audio reduces mean speaker similarity from 0.618 to 0.588 (-5.0%) and lowers the attack success rate from 20.0% to 13.3% (-6.7 pp, 33.5% relative), indicating meaningful zero-shot protection.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "provides"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To understand the trade-off between protection strength and usability, we conduct an ablation study on the signal-to-noise ratio (SNR) parameter. We evaluate four SNR ranges: [5, 10] dB (strong protection), [10, 20] dB (balanced, our default), [15, 25] dB (moderate protection), and [20, 30] dB (weak protection).</p>\n\n",
                "matched_terms": [
                    "usability",
                    "snr",
                    "ablation",
                    "default",
                    "study",
                    "between",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.F4\" title=\"Figure 4 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> visualizes this trade-off using a dual-axis plot showing protection strength (speaker similarity degradation) and usability (STOI) as functions of SNR range.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "snr",
                    "range",
                    "stoi",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The ablation study validates our choice of SNR range and demonstrates that SceneGuard&#8217;s protection can be tuned based on application requirements. Users prioritizing strong protection can select lower SNR, while those prioritizing quality can use higher SNR, with the [10, 20] dB range serving as a reasonable default.</p>\n\n",
                "matched_terms": [
                    "snr",
                    "range",
                    "ablation",
                    "default",
                    "study",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization nearly doubles the protection strength, achieving 5.5% degradation compared to 2.8% for direct mixing. This 2.7 percentage point improvement comes at minimal usability cost: STOI decreases by only 0.003 (from 0.989 to 0.986) and WER increases by 0.4 percentage points (from 3.2% to 3.6%), both negligible changes.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection",
                    "wer",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The regularization weight <math alttext=\"\\lambda_{\\text{REG}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m1\" intent=\":literal\"><semantics><msub><mi>&#955;</mi><mtext>REG</mtext></msub><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}</annotation></semantics></math> controls the smoothness of the temporal mask. Higher values (<math alttext=\"\\lambda=0.1\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m2\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.1</annotation></semantics></math>) produce smoother masks but slightly reduce protection strength (SIM = 0.958). Lower values (<math alttext=\"\\lambda=0.001\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m3\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.001</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.001</annotation></semantics></math>) allow rougher masks with marginally better protection (SIM = 0.939) but risk overfitting. Our default <math alttext=\"\\lambda=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m4\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.01</annotation></semantics></math> strikes a good balance.</p>\n\n",
                "matched_terms": [
                    "default",
                    "protection",
                    "balance",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The number of epochs shows diminishing returns beyond 50 iterations. While 100 epochs achieve slightly better protection (SIM = 0.943), the improvement is minimal (0.2 percentage points) and doubles computation time. 20 epochs provide fast computation but do not fully converge. We therefore recommend 50 epochs as the default, offering good convergence without excessive cost.</p>\n\n",
                "matched_terms": [
                    "default",
                    "protection",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Audible Protection</span>: SceneGuard deliberately uses audible noise, which may be undesirable in scenarios requiring pristine audio quality. Applications such as studio recordings or professional voice work may prefer imperceptible protections despite their fragility. SceneGuard is best suited for everyday voice recordings where some background noise is acceptable.</p>\n\n",
                "matched_terms": [
                    "best",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Quality Metrics</span>: Our PESQ scores (2.03) fall below the ideal threshold of 3.0, indicating room for improvement in perceptual quality. This reflects the fundamental trade-off between protection and quality. Future work could explore perceptually optimized noise mixing strategies that maximize protection while minimizing quality degradation.</p>\n\n",
                "matched_terms": [
                    "between",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our experimental evaluation demonstrates that SceneGuard achieves strong protection against training attacks, degrading speaker similarity by 5.5% with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>). Critically, SceneGuard preserves speech usability, maintaining 98.6% intelligibility (STOI = 0.986) and achieving low word error rate (3.6%). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures, including MP3 compression, denoising, filtering, and downsampling.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">These results suggest that audible, scene-consistent noise provides a practical alternative to imperceptible perturbations for voice protection. By deliberately using audible but natural noise, SceneGuard achieves robustness properties that imperceptible methods cannot match, addressing a fundamental limitation of existing approaches.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "provides"
                ]
            }
        ]
    },
    "Sx6.T6": {
        "source_file": "SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise",
        "caption": "Table 6: Comparison of direct mixing versus optimized mixing. Optimization significantly improves protection while maintaining comparable usability.",
        "body": "Method\nSIM ↓\\downarrow\n\nProt. (%)\nSTOI ↑\\uparrow\n\nWER (%) ↓\\downarrow\n\n\n\nDirect Mixing\n0.972\n2.8\n0.989\n3.2\n\n\nOptimized (Ours)\n0.945\n5.5\n0.986\n3.6\n\n\n\nΔ\\Delta vs. Direct\n\n−0.027-0.027\n+2.7+2.7\n−0.003-0.003\n+0.4+0.4",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">Method</th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">SIM <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T6.m1\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">Prot. (%)</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">STOI <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T6.m2\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_tt\">WER (%) <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T6.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Direct Mixing</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.972</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">2.8</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">0.989</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">3.2</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Optimized (Ours)</th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">0.945</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">5.5</span></td>\n<td class=\"ltx_td ltx_align_center\">0.986</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\">3.6</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\">\n<math alttext=\"\\Delta\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T6.m4\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#916;</mi><annotation encoding=\"application/x-tex\">\\Delta</annotation></semantics></math><span class=\"ltx_text ltx_font_italic\"> vs. Direct</span>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><math alttext=\"-0.027\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T6.m5\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>0.027</mn></mrow><annotation encoding=\"application/x-tex\">-0.027</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><math alttext=\"+2.7\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T6.m6\" intent=\":literal\"><semantics><mrow><mo>+</mo><mn>2.7</mn></mrow><annotation encoding=\"application/x-tex\">+2.7</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><math alttext=\"-0.003\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T6.m7\" intent=\":literal\"><semantics><mrow><mo>&#8722;</mo><mn>0.003</mn></mrow><annotation encoding=\"application/x-tex\">-0.003</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\"><math alttext=\"+0.4\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T6.m8\" intent=\":literal\"><semantics><mrow><mo>+</mo><mn>0.4</mn></mrow><annotation encoding=\"application/x-tex\">+0.4</annotation></semantics></math></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "stoi",
            "↓downarrow",
            "ours",
            "sim",
            "prot",
            "protection",
            "usability",
            "−00270027",
            "maintaining",
            "wer",
            "optimization",
            "significantly",
            "↑uparrow",
            "−00030003",
            "optimized",
            "versus",
            "mixing",
            "improves",
            "comparable",
            "method",
            "while",
            "direct",
            "comparison",
            "δdelta"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">To quantify the benefit of gradient-based optimization, we compare SceneGuard&#8217;s optimized mixing approach against direct mixing without optimization. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.T6\" title=\"Table 6 &#8227; Optimization Ablation &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> presents results for both methods under identical SNR constraints.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Voice cloning technology poses significant privacy threats by enabling unauthorized speech synthesis from limited audio samples. Existing defenses based on imperceptible adversarial perturbations are vulnerable to common audio preprocessing such as denoising and compression. We propose SceneGuard, a training-time voice protection method that applies scene-consistent audible background noise to speech recordings. Unlike imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes (e.g., airport, street, park) to create protective noise that is contextually appropriate and robust to countermeasures. We evaluate SceneGuard on text-to-speech training attacks, demonstrating 5.5% speaker similarity degradation with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>) while preserving 98.6% speech intelligibility (STOI = 0.986). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures including MP3 compression, spectral subtraction, lowpass filtering, and downsampling. Our results suggest that audible, scene-consistent noise provides a more robust alternative to imperceptible perturbations for training-time voice protection. The source code are available at: <span class=\"ltx_ref ltx_nolink ltx_url ltx_ref_self\">https://github.com/richael-sang/SceneGuard</span>.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "method",
                    "while",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent work has explored proactive defense mechanisms that protect voice recordings from being exploited for cloning. A prominent approach adds imperceptible adversarial perturbations to audio recordings, degrading the quality of models trained on protected data&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite>. However, these defenses face a fundamental challenge: imperceptible perturbations are fragile. Standard audio preprocessing operations such as denoising, compression, and filtering can remove or significantly reduce these perturbations, rendering the protection ineffective&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">fei2025vocalcrypt</span>)</cite>. Moreover, the field lacks a unified, human&#8211;perception&#8211;aligned metric for speech perturbations, so imperceptibility is enforced via proxies (e.g., <math alttext=\"L_{p}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p2.m1\" intent=\":literal\"><semantics><msub><mi>L</mi><mi>p</mi></msub><annotation encoding=\"application/x-tex\">L_{p}</annotation></semantics></math> bounds or heuristic masking) that guarantee neither true inaudibility nor robustness&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">li2025cloneshield</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">feng2025enkidu</span>)</cite>.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "significantly"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose SceneGuard, a training-time defense that applies scene-consistent audible background noise to speech recordings through gradient-based optimization. SceneGuard first classifies the acoustic scene of input speech, then jointly optimizes a temporal mask <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m1\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while maintaining usability. For example, speech recorded in an airport is mixed with optimized airport background noise, creating a protective layer that appears natural and contextually plausible. This design offers three advantages: (1) optimization automatically finds the protection-usability trade-off, (2) the protection is harder to remove because scene-consistent noise cannot be easily separated from speech without degrading speech quality, and (3) the defense is robust to common audio preprocessing operations.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "optimized",
                    "optimization",
                    "maintaining",
                    "while",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate SceneGuard on training attack scenarios where an attacker uses protected recordings to fine-tune TTS models. Our experiments on 100 training samples and 40 test samples demonstrate 5.5% speaker similarity degradation (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p5.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>), indicating strong statistical evidence of protection effectiveness. Importantly, SceneGuard preserves 98.6% speech intelligibility (STOI = 0.986) and achieves low word error rate (WER = 3.6%), demonstrating that protected speech remains highly usable. Robustness evaluation shows that SceneGuard maintains protection under MP3 compression and even exhibits enhanced protection under denoising, lowpass filtering, and downsampling operations.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "wer",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose a novel training-time voice protection method based on scene-consistent audible background noise with joint optimization of temporal mask and noise strength, departing from the conventional imperceptibility requirement.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "method",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We design a gradient-based optimization framework that automatically balances speaker protection and speech usability under SNR constraints.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We demonstrate strong protection against training attacks with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.I1.i3.p1.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.I1.i3.p1.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>) while preserving speech usability (STOI = 0.986, WER = 3.6%).</p>\n\n",
                "matched_terms": [
                    "usability",
                    "stoi",
                    "while",
                    "wer",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent work has explored adversarial perturbations as a proactive defense against voice cloning. VoiceBlock&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>)</cite> is a real-time de-identification approach that learns a time-varying FIR filter to apply perceptually inconspicuous, streaming-friendly perturbations for evading speaker recognition. Building on proactive protection but shifting the threat model to training-time cloning, SafeSpeech&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite> embeds imperceptible, universal perturbations via its SPEC objective to degrade generative TTS across models while emphasizing transferability and robustness. Contemporary work&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">gao2025black</span>)</cite> proposes a black-box defense for voice conversion that adds imperceptible perturbations and optimizes them in latent space with evolution-based search to adapt against unknown VC systems. While these methods demonstrate effectiveness in controlled settings, they face a fundamental limitation: imperceptible perturbations are inherently fragile to common audio processing operations.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Recent voice protection methods&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>; <span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">voiceblock</span>)</cite> embed imperceptible adversarial perturbations by minimizing <math alttext=\"\\ell_{p}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m1\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#8467;</mi><mi>p</mi></msub><annotation encoding=\"application/x-tex\">\\ell_{p}</annotation></semantics></math> norms (typically <math alttext=\"\\|\\delta\\|_{\\infty}\\leq\\epsilon\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m2\" intent=\":literal\"><semantics><mrow><msub><mrow><mo stretchy=\"false\">&#8214;</mo><mi>&#948;</mi><mo stretchy=\"false\">&#8214;</mo></mrow><mi mathvariant=\"normal\">&#8734;</mi></msub><mo>&#8804;</mo><mi>&#1013;</mi></mrow><annotation encoding=\"application/x-tex\">\\|\\delta\\|_{\\infty}\\leq\\epsilon</annotation></semantics></math> with <math alttext=\"\\epsilon\\approx 8/255\" class=\"ltx_Math\" display=\"inline\" id=\"Sx2.SSx1.p2.m3\" intent=\":literal\"><semantics><mrow><mi>&#1013;</mi><mo>&#8776;</mo><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding=\"application/x-tex\">\\epsilon\\approx 8/255</annotation></semantics></math>). While these perturbations are inaudible, they are <span class=\"ltx_text ltx_font_italic\">fragile</span>: standard audio processing operations such as lossy compression (MP3, AAC), speech enhancement, or denoising can significantly attenuate protection effectiveness. For instance, SafeSpeech&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">safespeech</span>)</cite> shows that DeepMucs&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">demucs</span>)</cite> denoising reduces protection by up to 42% (SIM increases from 0.204 to 0.284). This fragility arises because imperceptible perturbations occupy high-frequency or low-energy regions that are specifically targeted by perceptual codecs and noise reduction algorithms.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "while",
                    "significantly",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"e(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m5\" intent=\":literal\"><semantics><mrow><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">e(\\cdot)</annotation></semantics></math> is a speaker verification encoder and <math alttext=\"\\tau_{\\text{sim}},\\tau_{\\text{eer}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx1.SSSx2.p1.m6\" intent=\":literal\"><semantics><mrow><msub><mi>&#964;</mi><mtext>sim</mtext></msub><mo>,</mo><msub><mi>&#964;</mi><mtext>eer</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\tau_{\\text{sim}},\\tau_{\\text{eer}}</annotation></semantics></math> are protection thresholds; and (2) <span class=\"ltx_text ltx_font_italic\">Usability</span>: preserved intelligibility for legitimate communication:</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Naive mixing of speech with scene noise at a fixed signal-to-noise ratio (SNR) and uniform temporal weighting faces two risks: (1) insufficient protection if SNR is too high or noise placement is suboptimal, resulting in speaker embeddings that remain similar (<math alttext=\"\\text{SIM}&gt;\\tau_{\\text{sim}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m1\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>&gt;</mo><msub><mi>&#964;</mi><mtext>sim</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}&gt;\\tau_{\\text{sim}}</annotation></semantics></math>); (2) excessive degradation if SNR is too low or noise overwhelms speech regions, causing unacceptable WER increases. To navigate this trade-off, we formulate protection as an <span class=\"ltx_text ltx_font_italic\">optimization problem</span>: jointly optimize the temporal mask <math alttext=\"m(t)\\in[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m2\" intent=\":literal\"><semantics><mrow><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)\\in[0,1]</annotation></semantics></math> controlling when noise is applied, and the noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m3\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> controlling overall SNR, to minimize speaker similarity while maintaining usability. This optimization ensures that the noise is strategically placed (e.g., emphasizing pauses or non-critical phonemes) and calibrated to the specific speech sample.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "mixing",
                    "optimization",
                    "maintaining",
                    "while",
                    "wer",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We jointly optimize <math alttext=\"m\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx2.p1.m1\" intent=\":literal\"><semantics><mi>m</mi><annotation encoding=\"application/x-tex\">m</annotation></semantics></math> and <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx3.SSSx2.p1.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while regularizing for usability and smoothness. The total loss is:</p>\n\n",
                "matched_terms": [
                    "usability",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#algorithm1\" title=\"In Temporal Mask Optimization Algorithm &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> presents the complete optimization procedure. We initialize <math alttext=\"\\tilde{m}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.p1.m1\" intent=\":literal\"><semantics><mover accent=\"true\"><mi>m</mi><mo>~</mo></mover><annotation encoding=\"application/x-tex\">\\tilde{m}</annotation></semantics></math> and <math alttext=\"\\tilde{\\gamma}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.p1.m2\" intent=\":literal\"><semantics><mover accent=\"true\"><mi>&#947;</mi><mo>~</mo></mover><annotation encoding=\"application/x-tex\">\\tilde{\\gamma}</annotation></semantics></math> randomly and optimize them via Adam with gradient clipping for stability. At each iteration, we project parameters to their constrained forms (<math alttext=\"m\\in[0,1]^{T}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.p1.m3\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo>&#8712;</mo><msup><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">m\\in[0,1]^{T}</annotation></semantics></math>, <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.p1.m4\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> via SNR bounds), apply the mixing model (Eq.&#160;(<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.E5\" title=\"In Mixing Model. &#8227; Optimization Objective &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>)), compute losses, and perform a gradient step. The optimization converges in 50-100 epochs (approximately 10-30 seconds per sample on RTX A6000).</p>\n\n",
                "matched_terms": [
                    "mixing",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We minimize speaker similarity while maintaining usability constraints. The primary loss term is speaker embedding cosine similarity computed using ECAPA-TDNN. We add a regularization term (<math alttext=\"\\lambda_{\\text{REG}}=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><msub><mi>&#955;</mi><mtext>REG</mtext></msub><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}=0.01</annotation></semantics></math>) that penalizes mask roughness and excessive noise strength to promote smooth, stable solutions.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "maintaining",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization takes approximately 10-15 seconds per sample on a single NVIDIA RTX A6000 GPU. The total defense generation time for 168 samples is under 45 minutes, making the method practical for real-world deployment.</p>\n\n",
                "matched_terms": [
                    "method",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate protection against zero-shot voice cloning, where an attacker uses protected recordings as reference audio for inference-time cloning. We generate synthetic speech using a pre-trained model with clean versus defended reference, measuring speaker similarity to the original speaker.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "versus"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We test whether protection persists under five common audio preprocessing operations: MP3 compression (128 kbps and 64 kbps), spectral subtraction denoising, lowpass filtering (3400 Hz cutoff), and downsampling to 8 kHz. For each countermeasure, we re-compute speaker similarity and WER to assess protection retention.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Importantly, SceneGuard maintains high usability. Protected speech achieves WER of 2.77%, indicating near-perfect transcription accuracy. The STOI score of 0.99 confirms that intelligibility is essentially preserved. While PESQ (2.22) is below the ideal threshold of 3.0, it remains in an acceptable range for many applications.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "while",
                    "wer",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.F2\" title=\"Figure 2 &#8227; Training Attack Protection &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> visualizes the training attack results, comparing speaker similarity degradation across defense methods. SceneGuard demonstrates stronger protection than random or Gaussian noise baselines while maintaining comparable usability.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "maintaining",
                    "comparable",
                    "while",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.T2\" title=\"Table 2 &#8227; Usability Preservation &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> presents detailed usability metrics for SceneGuard-protected speech, demonstrating that protection does not significantly compromise speech quality for legitimate use cases.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection",
                    "significantly"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The STOI score of 0.986 significantly exceeds the intelligibility threshold of 0.85, indicating that protected speech remains highly comprehensible. WER of 3.60% with a narrow confidence interval [1.40%, 6.43%] demonstrates robust transcription accuracy across samples. While PESQ falls slightly below the ideal 3.0 threshold, the value of 2.034 is acceptable for many practical applications and represents a deliberate trade-off for robustness.</p>\n\n",
                "matched_terms": [
                    "while",
                    "wer",
                    "significantly",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SceneGuard demonstrates remarkable robustness. MP3 compression at both 128 kbps and 64 kbps slightly reduces similarity but maintains protection (SIM &#161; 0.91). More aggressive operations such as spectral subtraction, lowpass filtering, and downsampling actually enhance protection, reducing similarity to 0.745, 0.704, and 0.688 respectively.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This counterintuitive enhancement occurs because these operations preferentially damage the clean speech components relative to the protective noise. Spectral subtraction removes stationary components but preserves scene-consistent temporal variations. Lowpass filtering and downsampling reduce high-frequency detail critical for speaker identity while preserving protective noise structure. Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx5.F3\" title=\"Figure 3 &#8227; Robustness to Countermeasures &#8227; Results &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> visualizes the robustness results as a heatmap, showing speaker similarity and WER under different countermeasures.</p>\n\n",
                "matched_terms": [
                    "while",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To understand the trade-off between protection strength and usability, we conduct an ablation study on the signal-to-noise ratio (SNR) parameter. We evaluate four SNR ranges: [5, 10] dB (strong protection), [10, 20] dB (balanced, our default), [15, 25] dB (moderate protection), and [20, 30] dB (weak protection).</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.T5\" title=\"Table 5 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> presents the quantitative results. Lower SNR (stronger noise) provides better protection but degrades usability, while higher SNR (weaker noise) improves usability but reduces protection. The [10, 20] dB range achieves an effective balance, providing 5.5% similarity degradation while maintaining STOI above 0.98 and WER below 4%.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "stoi",
                    "improves",
                    "maintaining",
                    "while",
                    "wer",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.F4\" title=\"Figure 4 &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> visualizes this trade-off using a dual-axis plot showing protection strength (speaker similarity degradation) and usability (STOI) as functions of SNR range.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "protection",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The ablation study validates our choice of SNR range and demonstrates that SceneGuard&#8217;s protection can be tuned based on application requirements. Users prioritizing strong protection can select lower SNR, while those prioritizing quality can use higher SNR, with the [10, 20] dB range serving as a reasonable default.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization nearly doubles the protection strength, achieving 5.5% degradation compared to 2.8% for direct mixing. This 2.7 percentage point improvement comes at minimal usability cost: STOI decreases by only 0.003 (from 0.989 to 0.986) and WER increases by 0.4 percentage points (from 3.2% to 3.6%), both negligible changes.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "mixing",
                    "optimization",
                    "stoi",
                    "direct",
                    "wer",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The key advantage of optimization is its ability to identify optimal mask patterns. Direct mixing applies a uniform stochastic mask, which may unnecessarily distort speech regions while under-protecting others. In contrast, gradient-based optimization adaptively concentrates protection in regions that most effectively reduce speaker similarity while avoiding critical speech segments.</p>\n\n",
                "matched_terms": [
                    "mixing",
                    "optimization",
                    "while",
                    "direct",
                    "protection"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The regularization weight <math alttext=\"\\lambda_{\\text{REG}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m1\" intent=\":literal\"><semantics><msub><mi>&#955;</mi><mtext>REG</mtext></msub><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}</annotation></semantics></math> controls the smoothness of the temporal mask. Higher values (<math alttext=\"\\lambda=0.1\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m2\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.1</annotation></semantics></math>) produce smoother masks but slightly reduce protection strength (SIM = 0.958). Lower values (<math alttext=\"\\lambda=0.001\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m3\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.001</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.001</annotation></semantics></math>) allow rougher masks with marginally better protection (SIM = 0.939) but risk overfitting. Our default <math alttext=\"\\lambda=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m4\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.01</annotation></semantics></math> strikes a good balance.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The number of epochs shows diminishing returns beyond 50 iterations. While 100 epochs achieve slightly better protection (SIM = 0.943), the improvement is minimal (0.2 percentage points) and doubles computation time. 20 epochs provide fast computation but do not fully converge. We therefore recommend 50 epochs as the default, offering good convergence without excessive cost.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "while",
                    "sim"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Psychoacoustic masking further explains SceneGuard&#8217;s effectiveness. Auditory masking occurs when one sound makes another sound less audible. Scene-consistent noise can mask subtle speaker-specific characteristics while preserving overall speech intelligibility. This selective masking degrades speaker embeddings without proportionally affecting transcription accuracy, as evidenced by our results (5.5% similarity degradation vs. 2.77% WER).</p>\n\n",
                "matched_terms": [
                    "while",
                    "wer"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Lowpass Filtering and Downsampling</span>: Speaker identity relies significantly on high-frequency spectral details and prosodic variations. Lowpass filtering and downsampling preferentially remove these high-frequency components while preserving lower-frequency protective noise. This asymmetric degradation enhances protection.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "while",
                    "significantly"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Quality Metrics</span>: Our PESQ scores (2.03) fall below the ideal threshold of 3.0, indicating room for improvement in perceptual quality. This reflects the fundamental trade-off between protection and quality. Future work could explore perceptually optimized noise mixing strategies that maximize protection while minimizing quality degradation.</p>\n\n",
                "matched_terms": [
                    "optimized",
                    "protection",
                    "mixing",
                    "while"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We presented SceneGuard, a training-time voice protection method based on scene-consistent audible background noise. Unlike existing defenses that rely on imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes to create protective noise that is contextually appropriate and robust to common audio preprocessing operations.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "method"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our experimental evaluation demonstrates that SceneGuard achieves strong protection against training attacks, degrading speaker similarity by 5.5% with extremely high statistical significance (<math alttext=\"p&lt;10^{-15}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m1\" intent=\":literal\"><semantics><mrow><mi>p</mi><mo>&lt;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>15</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">p&lt;10^{-15}</annotation></semantics></math>, Cohen&#8217;s <math alttext=\"d=2.18\" class=\"ltx_Math\" display=\"inline\" id=\"Sx8.p2.m2\" intent=\":literal\"><semantics><mrow><mi>d</mi><mo>=</mo><mn>2.18</mn></mrow><annotation encoding=\"application/x-tex\">d=2.18</annotation></semantics></math>). Critically, SceneGuard preserves speech usability, maintaining 98.6% intelligibility (STOI = 0.986) and achieving low word error rate (3.6%). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures, including MP3 compression, denoising, filtering, and downsampling.</p>\n\n",
                "matched_terms": [
                    "usability",
                    "maintaining",
                    "protection",
                    "stoi"
                ]
            }
        ]
    },
    "Sx6.T7": {
        "source_file": "SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise",
        "caption": "Table 7: Hyperparameter sensitivity. Default (λREG=0.01\\lambda_{\\text{REG}}{=}0.01, 50 epochs) performs well with stable convergence.",
        "body": "Configuration\nSIM ↓\\downarrow\n\nSTOI ↑\\uparrow\n\nMask Smooth.\nTime (s)\n\n\nRegularization weight λREG\\lambda_{\\text{REG}}:\n\n\nλ=0.001\\lambda=0.001\n0.939\n0.983\n0.062\n15\n\n\n\nλ=0.01\\lambda=0.01 (default)\n0.945\n0.986\n0.041\n15\n\n\nλ=0.1\\lambda=0.1\n0.958\n0.989\n0.028\n15\n\n\nOptimization epochs:\n\n\n20 epochs\n0.952\n0.987\n0.045\n6\n\n\n50 epochs (default)\n0.945\n0.986\n0.041\n15\n\n\n100 epochs\n0.943\n0.985\n0.040\n30",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Configuration</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">SIM <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T7.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">STOI <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T7.m4\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Mask Smooth.</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Time (s)</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_italic\">Regularization weight <math alttext=\"\\lambda_{\\text{REG}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T7.m5\" intent=\":literal\"><semantics><msub><mi>&#955;</mi><mtext class=\"ltx_mathvariant_italic\">REG</mtext></msub><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}</annotation></semantics></math>:</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math alttext=\"\\lambda=0.001\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T7.m6\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.001</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.001</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.939</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.983</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.062</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">15</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<math alttext=\"\\lambda=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T7.m7\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.01</annotation></semantics></math> (default)</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\">0.945</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\">0.986</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\">0.041</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">15</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math alttext=\"\\lambda=0.1\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.T7.m8\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.1</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.958</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.989</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.028</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">15</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"5\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_italic\">Optimization epochs:</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">20 epochs</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.952</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.987</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.045</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">6</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">50 epochs (default)</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\">0.945</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\">0.986</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\">0.041</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">15</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">100 epochs</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.943</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.985</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">0.040</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">30</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "λ01lambda01",
            "stoi",
            "hyperparameter",
            "↓downarrow",
            "sim",
            "well",
            "performs",
            "mask",
            "λ0001lambda0001",
            "smooth",
            "convergence",
            "λreg001lambdatextreg001",
            "λ001lambda001",
            "sensitivity",
            "stable",
            "weight",
            "optimization",
            "default",
            "configuration",
            "λreglambdatextreg",
            "↑uparrow",
            "epochs",
            "regularization",
            "time"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">We examine the sensitivity of SceneGuard to two key hyperparameters: the regularization weight <math alttext=\"\\lambda_{\\text{REG}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p1.m1\" intent=\":literal\"><semantics><msub><mi>&#955;</mi><mtext>REG</mtext></msub><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}</annotation></semantics></math> and the number of optimization epochs. Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx6.T7\" title=\"Table 7 &#8227; Hyperparameter Sensitivity &#8227; Ablation Study &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">7</span></a> summarizes the results.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">We propose SceneGuard, a training-time defense that applies scene-consistent audible background noise to speech recordings through gradient-based optimization. SceneGuard first classifies the acoustic scene of input speech, then jointly optimizes a temporal mask <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m1\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx1.p4.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> to minimize speaker similarity while maintaining usability. For example, speech recorded in an airport is mixed with optimized airport background noise, creating a protective layer that appears natural and contextually plausible. This design offers three advantages: (1) optimization automatically finds the protection-usability trade-off, (2) the protection is harder to remove because scene-consistent noise cannot be easily separated from speech without degrading speech quality, and (3) the defense is robust to common audio preprocessing operations.</p>\n\n",
                "matched_terms": [
                    "mask",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose a novel training-time voice protection method based on scene-consistent audible background noise with joint optimization of temporal mask and noise strength, departing from the conventional imperceptibility requirement.</p>\n\n",
                "matched_terms": [
                    "mask",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Naive mixing of speech with scene noise at a fixed signal-to-noise ratio (SNR) and uniform temporal weighting faces two risks: (1) insufficient protection if SNR is too high or noise placement is suboptimal, resulting in speaker embeddings that remain similar (<math alttext=\"\\text{SIM}&gt;\\tau_{\\text{sim}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m1\" intent=\":literal\"><semantics><mrow><mtext>SIM</mtext><mo>&gt;</mo><msub><mi>&#964;</mi><mtext>sim</mtext></msub></mrow><annotation encoding=\"application/x-tex\">\\text{SIM}&gt;\\tau_{\\text{sim}}</annotation></semantics></math>); (2) excessive degradation if SNR is too low or noise overwhelms speech regions, causing unacceptable WER increases. To navigate this trade-off, we formulate protection as an <span class=\"ltx_text ltx_font_italic\">optimization problem</span>: jointly optimize the temporal mask <math alttext=\"m(t)\\in[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m2\" intent=\":literal\"><semantics><mrow><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)\\in[0,1]</annotation></semantics></math> controlling when noise is applied, and the noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx2.SSSx2.p1.m3\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> controlling overall SNR, to minimize speaker similarity while maintaining usability. This optimization ensures that the noise is strategically placed (e.g., emphasizing pauses or non-critical phonemes) and calibrated to the specific speech sample.</p>\n\n",
                "matched_terms": [
                    "mask",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Regularization Loss</span> <math alttext=\"\\mathcal{L}_{\\text{REG}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.I2.i2.p1.m1\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8466;</mi><mtext>REG</mtext></msub><annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\text{REG}}</annotation></semantics></math>: Encourages smooth masks and bounded noise strength to prevent extreme solutions:</p>\n\n",
                "matched_terms": [
                    "regularization",
                    "smooth"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Algorithm&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#algorithm1\" title=\"In Temporal Mask Optimization Algorithm &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">1</span></a> presents the complete optimization procedure. We initialize <math alttext=\"\\tilde{m}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.p1.m1\" intent=\":literal\"><semantics><mover accent=\"true\"><mi>m</mi><mo>~</mo></mover><annotation encoding=\"application/x-tex\">\\tilde{m}</annotation></semantics></math> and <math alttext=\"\\tilde{\\gamma}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.p1.m2\" intent=\":literal\"><semantics><mover accent=\"true\"><mi>&#947;</mi><mo>~</mo></mover><annotation encoding=\"application/x-tex\">\\tilde{\\gamma}</annotation></semantics></math> randomly and optimize them via Adam with gradient clipping for stability. At each iteration, we project parameters to their constrained forms (<math alttext=\"m\\in[0,1]^{T}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.p1.m3\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo>&#8712;</mo><msup><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">m\\in[0,1]^{T}</annotation></semantics></math>, <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.p1.m4\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> via SNR bounds), apply the mixing model (Eq.&#160;(<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.16114v1#Sx3.E5\" title=\"In Mixing Model. &#8227; Optimization Objective &#8227; Method &#8227; SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>)), compute losses, and perform a gradient step. The optimization converges in 50-100 epochs (approximately 10-30 seconds per sample on RTX A6000).</p>\n\n",
                "matched_terms": [
                    "epochs",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We employ three techniques for stable optimization: (1) <span class=\"ltx_text ltx_font_italic\">Gradient clipping</span> with <math alttext=\"\\ell_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.SSSx1.p1.m1\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#8467;</mi><mn>2</mn></msub><annotation encoding=\"application/x-tex\">\\ell_{2}</annotation></semantics></math> norm <math alttext=\"\\leq 1.0\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.SSSx1.p1.m2\" intent=\":literal\"><semantics><mrow><mi/><mo>&#8804;</mo><mn>1.0</mn></mrow><annotation encoding=\"application/x-tex\">\\leq 1.0</annotation></semantics></math> prevents exploding gradients, especially in early epochs when <math alttext=\"\\mathcal{L}_{\\text{SIM}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.SSSx1.p1.m3\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8466;</mi><mtext>SIM</mtext></msub><annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\text{SIM}}</annotation></semantics></math> changes rapidly. (2) <span class=\"ltx_text ltx_font_italic\">Smoothness regularization</span> via the total variation term <math alttext=\"\\|\\nabla m\\|_{2}^{2}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.SSSx1.p1.m4\" intent=\":literal\"><semantics><msubsup><mrow><mo stretchy=\"false\">&#8214;</mo><mrow><mo rspace=\"0.167em\">&#8711;</mo><mi>m</mi></mrow><mo stretchy=\"false\">&#8214;</mo></mrow><mn>2</mn><mn>2</mn></msubsup><annotation encoding=\"application/x-tex\">\\|\\nabla m\\|_{2}^{2}</annotation></semantics></math> discourages abrupt mask transitions that could create audible artifacts. (3) <span class=\"ltx_text ltx_font_italic\">Energy regularization</span> <math alttext=\"\\gamma^{2}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.SSSx1.p1.m5\" intent=\":literal\"><semantics><msup><mi>&#947;</mi><mn>2</mn></msup><annotation encoding=\"application/x-tex\">\\gamma^{2}</annotation></semantics></math> prevents the optimizer from converging to excessively large <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx3.SSx4.SSSx1.p1.m6\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> values that would violate the SNR constraint.</p>\n\n",
                "matched_terms": [
                    "stable",
                    "regularization",
                    "optimization",
                    "mask",
                    "epochs"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SceneGuard employs gradient-based optimization to jointly learn the temporal mask <math alttext=\"m(t)\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.p1.m1\" intent=\":literal\"><semantics><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">m(t)</annotation></semantics></math> and noise strength <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.p1.m2\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math>. We describe the key hyperparameters and design choices:</p>\n\n",
                "matched_terms": [
                    "mask",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We minimize speaker similarity while maintaining usability constraints. The primary loss term is speaker embedding cosine similarity computed using ECAPA-TDNN. We add a regularization term (<math alttext=\"\\lambda_{\\text{REG}}=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx1.p1.m1\" intent=\":literal\"><semantics><mrow><msub><mi>&#955;</mi><mtext>REG</mtext></msub><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}=0.01</annotation></semantics></math>) that penalizes mask roughness and excessive noise strength to promote smooth, stable solutions.</p>\n\n",
                "matched_terms": [
                    "stable",
                    "regularization",
                    "mask",
                    "smooth",
                    "λreg001lambdatextreg001"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We use the Adam optimizer&#160;<cite class=\"ltx_cite ltx_citemacro_citep\">(<span class=\"ltx_ref ltx_missing_citation ltx_ref_self\">adam</span>)</cite> with learning rate <math alttext=\"\\text{lr}=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx2.p1.m1\" intent=\":literal\"><semantics><mrow><mtext>lr</mtext><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\text{lr}=0.01</annotation></semantics></math> and default momentum parameters (<math alttext=\"\\beta_{1}=0.9\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx2.p1.m2\" intent=\":literal\"><semantics><mrow><msub><mi>&#946;</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn></mrow><annotation encoding=\"application/x-tex\">\\beta_{1}=0.9</annotation></semantics></math>, <math alttext=\"\\beta_{2}=0.999\" class=\"ltx_Math\" display=\"inline\" id=\"Sx4.SSx3.SSSx2.p1.m3\" intent=\":literal\"><semantics><mrow><msub><mi>&#946;</mi><mn>2</mn></msub><mo>=</mo><mn>0.999</mn></mrow><annotation encoding=\"application/x-tex\">\\beta_{2}=0.999</annotation></semantics></math>). We run optimization for 50 epochs per sample, which empirically provides good convergence. To ensure training stability, we apply gradient clipping with maximum norm 1.0.</p>\n\n",
                "matched_terms": [
                    "default",
                    "epochs",
                    "convergence",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization takes approximately 10-15 seconds per sample on a single NVIDIA RTX A6000 GPU. The total defense generation time for 168 samples is under 45 minutes, making the method practical for real-world deployment.</p>\n\n",
                "matched_terms": [
                    "time",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Optimization nearly doubles the protection strength, achieving 5.5% degradation compared to 2.8% for direct mixing. This 2.7 percentage point improvement comes at minimal usability cost: STOI decreases by only 0.003 (from 0.989 to 0.986) and WER increases by 0.4 percentage points (from 3.2% to 3.6%), both negligible changes.</p>\n\n",
                "matched_terms": [
                    "optimization",
                    "stoi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The key advantage of optimization is its ability to identify optimal mask patterns. Direct mixing applies a uniform stochastic mask, which may unnecessarily distort speech regions while under-protecting others. In contrast, gradient-based optimization adaptively concentrates protection in regions that most effectively reduce speaker similarity while avoiding critical speech segments.</p>\n\n",
                "matched_terms": [
                    "mask",
                    "optimization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The regularization weight <math alttext=\"\\lambda_{\\text{REG}}\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m1\" intent=\":literal\"><semantics><msub><mi>&#955;</mi><mtext>REG</mtext></msub><annotation encoding=\"application/x-tex\">\\lambda_{\\text{REG}}</annotation></semantics></math> controls the smoothness of the temporal mask. Higher values (<math alttext=\"\\lambda=0.1\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m2\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.1</annotation></semantics></math>) produce smoother masks but slightly reduce protection strength (SIM = 0.958). Lower values (<math alttext=\"\\lambda=0.001\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m3\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.001</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.001</annotation></semantics></math>) allow rougher masks with marginally better protection (SIM = 0.939) but risk overfitting. Our default <math alttext=\"\\lambda=0.01\" class=\"ltx_Math\" display=\"inline\" id=\"Sx6.SSx2.p2.m4\" intent=\":literal\"><semantics><mrow><mi>&#955;</mi><mo>=</mo><mn>0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda=0.01</annotation></semantics></math> strikes a good balance.</p>\n\n",
                "matched_terms": [
                    "regularization",
                    "λ01lambda01",
                    "weight",
                    "mask",
                    "default",
                    "λ0001lambda0001",
                    "sim",
                    "λreglambdatextreg",
                    "λ001lambda001"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The number of epochs shows diminishing returns beyond 50 iterations. While 100 epochs achieve slightly better protection (SIM = 0.943), the improvement is minimal (0.2 percentage points) and doubles computation time. 20 epochs provide fast computation but do not fully converge. We therefore recommend 50 epochs as the default, offering good convergence without excessive cost.</p>\n\n",
                "matched_terms": [
                    "time",
                    "default",
                    "convergence",
                    "sim",
                    "epochs"
                ]
            }
        ]
    }
}