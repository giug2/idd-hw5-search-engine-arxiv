{
    "p3": {
        "source_file": "CantoNLU: A benchmark for Cantonese natural language understanding",
        "caption": "",
        "body": "Junghyun Min†\\dagger   York Hay Ng‡\\ddagger   Sophia Chan§\\S\n\nHelena Shunhua Zhao‡\\ddagger   En-Shiun Annie Lee‡⁣&\\ddagger\\&\n\n\n\n\n†\\daggerGeorgetown University   ‡\\ddaggerUniversity of Toronto\n\n\n\n&\\&Ontario Tech University   §\\SIndependent Researcher\n\n\njm3743@georgetown.edu",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_align_top\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">\n<span class=\"ltx_tabular ltx_align_middle\">\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\">Junghyun Min<sup class=\"ltx_sup\"><math alttext=\"\\dagger\" class=\"ltx_Math\" display=\"inline\" id=\"m1\" intent=\":literal\"><semantics><mo>&#8224;</mo><annotation encoding=\"application/x-tex\">\\dagger</annotation></semantics></math></sup> &#8195;&#8196;York Hay Ng<sup class=\"ltx_sup\"><math alttext=\"\\ddagger\" class=\"ltx_Math\" display=\"inline\" id=\"m2\" intent=\":literal\"><semantics><mo>&#8225;</mo><annotation encoding=\"application/x-tex\">\\ddagger</annotation></semantics></math></sup> &#8195;&#8196;Sophia Chan<sup class=\"ltx_sup\"><math alttext=\"\\S\" class=\"ltx_Math\" display=\"inline\" id=\"m3\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#167;</mi><annotation encoding=\"application/x-tex\">\\S</annotation></semantics></math></sup></span></span>\n<span class=\"ltx_tr\">\n<span class=\"ltx_td ltx_nopad_r ltx_align_center\">Helena Shunhua Zhao<sup class=\"ltx_sup\"><math alttext=\"\\ddagger\" class=\"ltx_Math\" display=\"inline\" id=\"m4\" intent=\":literal\"><semantics><mo>&#8225;</mo><annotation encoding=\"application/x-tex\">\\ddagger</annotation></semantics></math></sup> &#8195;&#8196;En-Shiun Annie Lee<sup class=\"ltx_sup\"><math alttext=\"\\ddagger\\&amp;\" class=\"ltx_Math\" display=\"inline\" id=\"m5\" intent=\":literal\"><semantics><mrow><mo>&#8225;</mo><mo lspace=\"0em\">&#8291;</mo><mo>&amp;</mo></mrow><annotation encoding=\"application/x-tex\">\\ddagger\\&amp;</annotation></semantics></math></sup></span></span>\n</span></span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\">\n<sup class=\"ltx_sup\"><math alttext=\"\\dagger\" class=\"ltx_Math\" display=\"inline\" id=\"m6\" intent=\":literal\"><semantics><mo>&#8224;</mo><annotation encoding=\"application/x-tex\">\\dagger</annotation></semantics></math></sup>Georgetown University &#8195;&#8195;<sup class=\"ltx_sup\"><math alttext=\"\\ddagger\" class=\"ltx_Math\" display=\"inline\" id=\"m7\" intent=\":literal\"><semantics><mo>&#8225;</mo><annotation encoding=\"application/x-tex\">\\ddagger</annotation></semantics></math></sup>University of Toronto</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\">\n<sup class=\"ltx_sup\"><math alttext=\"\\&amp;\" class=\"ltx_Math\" display=\"inline\" id=\"m8\" intent=\":literal\"><semantics><mo>&amp;</mo><annotation encoding=\"application/x-tex\">\\&amp;</annotation></semantics></math></sup>Ontario Tech University &#8195;&#8195;<sup class=\"ltx_sup\"><math alttext=\"\\S\" class=\"ltx_Math\" display=\"inline\" id=\"m9\" intent=\":literal\"><semantics><mi mathvariant=\"normal\">&#167;</mi><annotation encoding=\"application/x-tex\">\\S</annotation></semantics></math></sup>Independent Researcher</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\">jm3743@georgetown.edu</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "jm3743georgetownedu",
            "lee‡⁣ddagger",
            "hay",
            "shunhua",
            "enshiun",
            "junghyun",
            "tech",
            "helena",
            "§sindependent",
            "‡ddaggeruniversity",
            "min†dagger",
            "researcher",
            "†daggergeorgetown",
            "ontario",
            "chan§s",
            "york",
            "ng‡ddagger",
            "university",
            "annie",
            "toronto",
            "zhao‡ddagger",
            "sophia"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": []
    },
    "S1.T1": {
        "source_file": "CantoNLU: A benchmark for Cantonese natural language understanding",
        "caption": "Table 1: An overview of the 7 NLU tasks that make up CantoNLU, what the task requires, their size and source. L, F, M stand for lexicon, form (syntax), and meaning (semantics), respectively.",
        "body": "Task\nRequires\nSize\nSource\n\n\nSentence-level tasks\n\n\n\nAcceptability\nL, F, M\n1.6k\nMT error dataset (Liu et al., 2025) adapted\n\n\nLang Detection\nL, F\n47k\nParallel corpus (Dai et al., 2025) aligned and purturbed\n\n\nNLI\nM\n570k\nMachine-translated English NLI (Chung Shing, 2025)\n\n\n\nSentiment\nM\n12k\nHong Kong restaurant reviews (Zhang et al., 2011)\n\n\n\nWord-level tasks\n\n\n\nWSD\nL, M\n109\nManual compilation\n\n\nPOS, Dep parsing\nF\n14k\nUniversal Dependencies dataset Wong et al. (2017)",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\">Task</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\">Requires</td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\">Size</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\">Source</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"3\"><span class=\"ltx_text ltx_font_bold\">Sentence-level tasks</span></td>\n<td class=\"ltx_td ltx_border_t\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Acceptability</td>\n<td class=\"ltx_td ltx_align_left\">L, F, M</td>\n<td class=\"ltx_td ltx_align_right\">1.6k</td>\n<td class=\"ltx_td ltx_align_left\">MT error dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib35\" title=\"\">2025</a>)</cite> adapted</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Lang Detection</td>\n<td class=\"ltx_td ltx_align_left\">L, F</td>\n<td class=\"ltx_td ltx_align_right\">47k</td>\n<td class=\"ltx_td ltx_align_left\">Parallel corpus <cite class=\"ltx_cite ltx_citemacro_citep\">(Dai et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib11\" title=\"\">2025</a>)</cite> aligned and purturbed</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">NLI</td>\n<td class=\"ltx_td ltx_align_left\">M</td>\n<td class=\"ltx_td ltx_align_right\">570k</td>\n<td class=\"ltx_td ltx_align_left\">Machine-translated English NLI <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Sentiment</td>\n<td class=\"ltx_td ltx_align_left\">M</td>\n<td class=\"ltx_td ltx_align_right\">12k</td>\n<td class=\"ltx_td ltx_align_left\">Hong Kong restaurant reviews <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib68\" title=\"\">2011</a>)</cite>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"3\"><span class=\"ltx_text ltx_font_bold\">Word-level tasks</span></td>\n<td class=\"ltx_td ltx_border_t\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">WSD</td>\n<td class=\"ltx_td ltx_align_left\">L, M</td>\n<td class=\"ltx_td ltx_align_right\">109</td>\n<td class=\"ltx_td ltx_align_left\">Manual compilation</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">POS, Dep parsing</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">F</td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\">14k</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">Universal Dependencies dataset <cite class=\"ltx_cite ltx_citemacro_citet\">Wong et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>)</cite>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "sentencelevel",
            "570k",
            "respectively",
            "corpus",
            "sentiment",
            "wsd",
            "kong",
            "meaning",
            "purturbed",
            "parsing",
            "aligned",
            "adapted",
            "nlu",
            "make",
            "source",
            "overview",
            "error",
            "47k",
            "lang",
            "dai",
            "form",
            "what",
            "restaurant",
            "lexicon",
            "compilation",
            "dep",
            "cantonlu",
            "syntax",
            "universal",
            "detection",
            "14k",
            "their",
            "nli",
            "dependencies",
            "chung",
            "zhang",
            "parallel",
            "hong",
            "reviews",
            "dataset",
            "16k",
            "english",
            "manual",
            "stand",
            "wordlevel",
            "task",
            "size",
            "pos",
            "wong",
            "shing",
            "tasks",
            "requires",
            "machinetranslated",
            "liu",
            "acceptability",
            "12k",
            "semantics"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">In this paper, we introduce <span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\">CantoNLU</span>, a GLUE-like <cite class=\"ltx_cite ltx_citemacro_citep\">(General Language Understanding Evaluation;  Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib55\" title=\"\">2018</a>)</cite> natural language understanding benchmark in Cantonese.\n<span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\">CantoNLU</span> provides an in-depth evaluation of syntax, lexicon and semantic understanding, comprising 7 tasks: word sense disambiguation (WSD), linguistic acceptability judgment (LAJ), language detection (LD), natural language inference (NLI), sentiment analysis (SA), part-of-speech tagging (POS), and dependency parsing (DEPS).\nIn particular, the WSD dataset is entirely novel, providing the first resource for sense-level lexical understanding in Cantonese.\nLAJ and LD represent novel adaptations of existing datasets, while NLI, SA, POS, and DEPS datasets are direct adoptions of existing datasets <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>; Zhang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib68\" title=\"\">2011</a>; Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>, respectively)</cite>.\nWe describe each task and underlying datasets in Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S4\" title=\"4. Building CantoNLU &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, whose overview is outlined in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S1.T1\" title=\"Table 1 &#8227; 1. Introduction &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Cantonese, although spoken by millions, remains under-resourced due to policy and diglossia. To address this scarcity of evaluation frameworks for Cantonese, we introduce <span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\">CantoNLU</span>, a benchmark for Cantonese natural language understanding (NLU).\nThis novel benchmark spans seven tasks covering syntax and semantics, including word sense disambiguation, linguistic acceptability judgment, language detection, natural language inference, sentiment analysis, part-of-speech tagging, and dependency parsing. In addition to the benchmark, we provide model baseline performance across a set of models: a Mandarin model without Cantonese training, two Cantonese-adapted models obtained by continual pre-training a Mandarin model on Cantonese text, and a monolingual Cantonese model trained from scratch. Results show that Cantonese-adapted models perform best overall, while monolingual models perform better on syntactic tasks. Mandarin models remain competitive in certain settings, indicating that direct transfer may be sufficient when Cantonese domain data is scarce. We release all datasets, code, and model weights to facilitate future research in Cantonese NLP.\n\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>\n<span class=\"ltx_text ltx_font_bold\">Keywords:&#8201;</span>Cantonese, natural language understanding, transfer learning, benchmark</p>\n\n",
                "matched_terms": [
                    "cantonlu",
                    "syntax",
                    "sentiment",
                    "detection",
                    "parsing",
                    "tasks",
                    "nlu",
                    "acceptability",
                    "semantics"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Such lack of written standardization, prestige, and official status results in a shortage of language resources in Cantonese. It is frequently described as a low-resource language <cite class=\"ltx_cite ltx_citemacro_citep\">(e.g.  Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib34\" title=\"\">2022</a>; Xiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib62\" title=\"\">2022</a>; Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite> despite having millions of speakers <cite class=\"ltx_cite ltx_citemacro_citep\">(Eberhard et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib14\" title=\"\">2023</a>)</cite>. As a result, Cantonese language processing systems often rely on datasets, models, and corpora adapted from Mandarin <cite class=\"ltx_cite ltx_citemacro_cite\">Xiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib61\" title=\"\">2024</a>)</cite>, despite a lack of mutual intelligibility between the two languages <cite class=\"ltx_cite ltx_citemacro_citep\">(Norman, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib44\" title=\"\">1988</a>; Tang and van Heuven, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib53\" title=\"\">2007</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "liu",
                    "adapted"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Cross-lingual transfer from Mandarin for Cantonese language processing has proven effective, with empirical success across a range of tasks, including language modeling and reading comprehension <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>, translation <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib34\" title=\"\">2022</a>; Suen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib52\" title=\"\">2024</a>)</cite>, and speech recognition <cite class=\"ltx_cite ltx_citemacro_citep\">(Li et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib29\" title=\"\">2019</a>; Luo et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib38\" title=\"\">2021</a>)</cite>. However, despite empirical success, there remains a gap in formal investigations into the best practices for Cantonese natural language understanding (NLU). This is attributable to a lack of a centralized evaluation framework for Cantonese language processing or understanding.</p>\n\n",
                "matched_terms": [
                    "liu",
                    "tasks",
                    "nlu"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Using <span class=\"ltx_text ltx_font_smallcaps\">CantoNLU</span>, we evaluate three types of models &#8211; a Mandarin model<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span><span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span></span></span></span> without explicit training on Cantonese, Cantonese-adapted transfer models with additional Cantonese training on a Mandarin model, and a monolingual Cantonese model, as outlined in Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5\" title=\"5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>.\nIn Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S6\" title=\"6. Results and Discussion &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>, we discuss how monolingual Cantonese, Cantonese-adapted, and Mandarin models compare across various aspects in Cantonese NLU.</p>\n\n",
                "matched_terms": [
                    "cantonlu",
                    "nlu"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In spite of limited training data in Cantonese, we demonstrate that our monolingual Cantonese model excels in syntactic tasks such as POS and DEPS.\nOn the other hand, Cantonese-adapted models excel in semantic tasks such as NLI, LD, WSD, and SA.\nSimultaneously, mandarin models offer a competitive alternative to additional or monolingual training on Cantonese data, excelling in NLI and LAJ.</p>\n\n",
                "matched_terms": [
                    "wsd",
                    "nli",
                    "tasks",
                    "pos"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Cantonese, also known as Yue <cite class=\"ltx_cite ltx_citemacro_citep\">(Eberhard et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib14\" title=\"\">2023</a>)</cite>, is the second most widely used Sinitic language after Mandarin, spoken by an estimated 85 million people worldwide.\nHowever, it remains primarily a spoken language <cite class=\"ltx_cite ltx_citemacro_citep\">(Norman, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib44\" title=\"\">1988</a>)</cite>, with most speakers defaulting to written Standard Chinese <cite class=\"ltx_cite ltx_citemacro_citep\">(Xiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib61\" title=\"\">2024</a>)</cite>.\nThis diglossic situation and its short history as a written language <cite class=\"ltx_cite ltx_citemacro_citep\">(Snow, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib51\" title=\"\">2004</a>)</cite> has contributed to the scarcity of high-quality textual resources for Cantonese NLP, in stark contrast to Mandarin Chinese, a related language rich in resource across corpora, models <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>; Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib36\" title=\"\">2020</a>; Conneau et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib10\" title=\"\">2020</a>; Bai et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib3\" title=\"\">2023</a>; Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib33\" title=\"\">2024</a>)</cite>, and evaluation resources <cite class=\"ltx_cite ltx_citemacro_citep\">(e.g.  Xu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib63\" title=\"\">2020</a>; Xiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib60\" title=\"\">2021</a>)</cite>.\nThus, as highlighted in Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S1\" title=\"1. Introduction &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, prior work have used varying degrees of transfer from models with Mandarin knowledge to perform downstream tasks in Cantonese <cite class=\"ltx_cite ltx_citemacro_citep\">(Li et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib29\" title=\"\">2019</a>; Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>; Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "liu",
                    "shing",
                    "tasks",
                    "chung"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Transfer learning is a common strategy in deep learning (DL) to address data sparsity, where features or signal learned from a resource-rich domain is used to augment a low-resource domain, task, or dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Bengio, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib4\" title=\"\">2012</a>)</cite>.\nIn the context of NLP, a common application of transfer learning is in cross-lingual transfer for low-resource languages <cite class=\"ltx_cite ltx_citemacro_cite\">Ruder et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib48\" title=\"\">2019</a>); Conneau et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib10\" title=\"\">2020</a>)</cite>.\nTwo types of cross-lingual transfer exists: model transfer and data transfer, as described in <cite class=\"ltx_cite ltx_citemacro_citet\">Garc&#237;a-Ferrero et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib16\" title=\"\">2022</a>)</cite>.\nData transfer involves translating a dataset or corpus from a high-resource language to a lesser-resourced target language, as performed in <span class=\"ltx_text ltx_font_typewriter\">yue-all-nli</span> <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite>, the MMLU <cite class=\"ltx_cite ltx_citemacro_citep\">(Hendrycks et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib18\" title=\"\">2021</a>)</cite> portion of the HKCanto-Eval benchmark <cite class=\"ltx_cite ltx_citemacro_citep\">(Cheng et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>)</cite>, and Yue benchmarks from <cite class=\"ltx_cite ltx_citemacro_citet\">Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "corpus",
                    "task",
                    "chung",
                    "shing",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">On the other hand, model transfer involves adapting models trained on a high-resource source language to a lesser-resourced target language, such as Mandarin to Cantonese and Danish to Faroese <cite class=\"ltx_cite ltx_citemacro_citep\">(Sn&#230;bjarnarson et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib50\" title=\"\">2023</a>)</cite>.\nModel transfer relies on the lexical or typological similarity between the two languages, thereby enabling the transfer of linguistic knowledge <cite class=\"ltx_cite ltx_citemacro_cite\">Khan et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib22\" title=\"\">2025</a>)</cite>.\nWhile some implementations of cross-lingual transfer explicitly designate a source language for cross-lingual transfer <cite class=\"ltx_cite ltx_citemacro_citep\">(Sn&#230;bjarnarson et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib50\" title=\"\">2023</a>; Thangaraj et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib54\" title=\"\">2024</a>)</cite>, others rely on multilingual models.\nRather than transferring from a specific source language, such models are thought to capture general cross-linguistic patterns that extend beyond typological or lexical similarity, allowing them to perform reasonably well even on unseen or low-resource languages <cite class=\"ltx_cite ltx_citemacro_citep\">(Conneau et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib10\" title=\"\">2020</a>; Scivetti et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib49\" title=\"\">2025</a>)</cite>.\nHybrid approaches combine both paradigms: they begin with a multilingual model, then continue pre-training or fine-tuning on a specific target language before applying the resulting model to downstream tasks <cite class=\"ltx_cite ltx_citemacro_citep\">(Protasov et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib47\" title=\"\">2024</a>; Manafi and Krishnaswamy, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib40\" title=\"\">2024</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "tasks",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Due to the richness of Mandarin language resources and the strong performance of Mandarin PLMs and LLMs, most cross-lingual transfer to Cantonese use Mandarin as the source language <cite class=\"ltx_cite ltx_citemacro_citep\">(Li et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib29\" title=\"\">2019</a>; Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib34\" title=\"\">2022</a>; Luo et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib38\" title=\"\">2021</a>; Suen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib52\" title=\"\">2024</a>; Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>)</cite>, with exceptions using a multilingual model <cite class=\"ltx_cite ltx_citemacro_citep\">(e.g. Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "liu",
                    "shing",
                    "chung",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">However, there is emerging work suggesting limitations in models&#8217; ability to capture Cantonese idiosyncrasies.\nFactors previously identified include substantial dissimilarities in lexicon, syntax and writing systems <cite class=\"ltx_cite ltx_citemacro_cite\">Suen et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib52\" title=\"\">2024</a>)</cite>, along with the prevalence of colloquial phrases and code-switching in more recent Cantonese corpora <cite class=\"ltx_cite ltx_citemacro_cite\">Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite>.\nThese issues hinder the ability of Mandarin-trained models in Cantonese <cite class=\"ltx_cite ltx_citemacro_cite\">Xiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib61\" title=\"\">2024</a>)</cite> due to over-reliance on Mandarin linguistic knowledge <cite class=\"ltx_cite ltx_citemacro_cite\">Cheng et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "syntax",
                    "lexicon"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Cantonese diverges from Mandarin in word order, particle and grammatical word inventory, and morphology, as highlighted in theoretical linguistics work <cite class=\"ltx_cite ltx_citemacro_citep\">(Matthews, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib41\" title=\"\">2006</a>; Yap and Chor, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib64\" title=\"\">2011</a>; Matthews and Yip, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib42\" title=\"\">2011</a>)</cite> as well as prior work in Cantonese-Mandarin machine translation and corpus linguistics <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib67\" title=\"\">1998</a>; Lam, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib24\" title=\"\">2020</a>; Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib35\" title=\"\">2025</a>)</cite>.\nFor example, in double object constructions, Mandarin takes the direct-indirect order as seen in (1), while Cantonese takes the indirect-direct order as seen in (2) <cite class=\"ltx_cite ltx_citemacro_citep\">(Matthews and Yip, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib42\" title=\"\">2011</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "liu",
                    "zhang",
                    "corpus"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Although widely considered low-resource, recent efforts have begun to address scarcity in Cantonese language resources.\nMachine-translations of non-Cantonese resources may offer potential utility as data transfer, as provided by <cite class=\"ltx_cite ltx_citemacro_citet\">Chung&#160;Shing (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite> for Cantonese natural language inference (NLI) and <cite class=\"ltx_cite ltx_citemacro_citet\">Cheng et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>); Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite> for LLM knowledge evaluation.\nFoundational tools such as PyCantonese <cite class=\"ltx_cite ltx_citemacro_citep\">(Lee et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib26\" title=\"\">2022</a>)</cite> provide <span class=\"ltx_text ltx_font_typewriter\">NLTK</span>-like <cite class=\"ltx_cite ltx_citemacro_citep\">(Bird and Loper, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib5\" title=\"\">2004</a>)</cite> essential language processing utilities, while a Cantonese Universal Dependencies dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>)</cite> offers a small yet significant syntactically annotated treebank.\nMultilingual resources such as Wikipedia <cite class=\"ltx_cite ltx_citemacro_citep\">(Foundation, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib15\" title=\"\">2023</a>)</cite>, SIB-200 <cite class=\"ltx_cite ltx_citemacro_citep\">(Adelani et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib1\" title=\"\">2024</a>)</cite>, and NLLB <cite class=\"ltx_cite ltx_citemacro_citep\">(NLLB Team et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib43\" title=\"\">2024</a>)</cite> include Cantonese portions, which may be useful for representation learning or evaluation in topic classification and multilingual translation.\nLarger-scale corpora such as YueData <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite> have also emerged, though they often contain substantial portions of non-Cantonese text.</p>\n\n",
                "matched_terms": [
                    "universal",
                    "nli",
                    "dependencies",
                    "chung",
                    "wong",
                    "shing",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Beyond corpora, work has extended to specific applications, including sentiment analysis <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib68\" title=\"\">2011</a>)</cite>, automatic speech recognition <cite class=\"ltx_cite ltx_citemacro_citep\">(Li et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib29\" title=\"\">2019</a>)</cite>, machine translation <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib34\" title=\"\">2022</a>; Suen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib52\" title=\"\">2024</a>; Dai et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib11\" title=\"\">2025</a>; Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib35\" title=\"\">2025</a>)</cite>.\nMost recently, <cite class=\"ltx_cite ltx_citemacro_citet\">Cheng et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>)</cite> introduced HKCanto-Eval, a comprehensive benchmark for evaluating linguistic and cultural understanding in Cantonese.\n<cite class=\"ltx_cite ltx_citemacro_citet\">Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite> presents another benchmark for evaluating LLM reasoning, knowledge, and logic in Cantonese.</p>\n\n",
                "matched_terms": [
                    "zhang",
                    "dai",
                    "liu",
                    "sentiment"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">On the modeling side, prior work has explored both general-purpose and Cantonese-specific pretrained models.\nWhile commercial multilingual models such as Qwen <cite class=\"ltx_cite ltx_citemacro_citep\">(Bai et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib3\" title=\"\">2023</a>)</cite> and DeepSeek <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib33\" title=\"\">2024</a>)</cite> provide Cantonese support, their Cantonese proficiency lags behind that in English or Mandarin <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite>.\n<cite class=\"ltx_cite ltx_citemacro_citet\">Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite> use their <span class=\"ltx_text ltx_font_typewriter\">YueData</span> corpus to train <span class=\"ltx_text ltx_font_typewriter\">YueTung-7b</span>, a continually pre-trained model based on a Qwen-7B model <cite class=\"ltx_cite ltx_citemacro_citep\">(Bai et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib3\" title=\"\">2023</a>)</cite>, which exhibit improved Cantonese performance compared to other open-source and commercial LLMs.\nOn the smaller end in terms of the number of parameters, <cite class=\"ltx_cite ltx_citemacro_citet\">Chung&#160;Shing (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>)</cite> represents the only encoder-only Cantonese model to our knowledge.\nIt is continually pre-trained <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> on Cantonese news articles, social media posts, and web pages on.\nImplementation details, training recipes, and corpora selection for <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> and <span class=\"ltx_text ltx_font_typewriter\">bert-base-cantonese</span> are both obscure as neither model provides a description paper or technical report. In particular, <cite class=\"ltx_cite ltx_citemacro_citet\">Devlin et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite> describes the BERT architecture in general but not the Chinese model.</p>\n\n",
                "matched_terms": [
                    "english",
                    "corpus",
                    "their",
                    "chung",
                    "shing",
                    "liu"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Although we have described Cantonese benchmarks HKCanto-Eval <cite class=\"ltx_cite ltx_citemacro_citep\">(Cheng et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>)</cite> and Yue-Benchmark <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite> as related work, we wish to clarify our contributions to Cantonese benchmarking in comparison to these two benchmarks.\nWhile HKCanto-Eval includes OpenRice <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib68\" title=\"\">2011</a>)</cite> as a SA dataset, which overlaps with our <span class=\"ltx_text ltx_font_smallcaps\">CantoNLU</span>, along with minor datasets in Cantonese phonology and orthography, HKCanto-Eval and Yue-Benchmark primarily target generative LLMs on general world knowledge and reasoning, in a comparable way to MMLU <cite class=\"ltx_cite ltx_citemacro_citep\">(Hendrycks et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib18\" title=\"\">2021</a>)</cite>.\nWe highlight <span class=\"ltx_text ltx_font_smallcaps\">CantoNLU</span>&#8217;s focus on discriminative NLU tasks, explicitly evaluating a model&#8217;s ability to understand the Cantonese lexicon (WSD), syntax (POS, DEPS), semantics (NLI, SA), and overall well-formedness with respect to both syntax and semantics (LAJ).\nThe focus is similar to those of GLUE <cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib55\" title=\"\">2018</a>)</cite> and its derivatives&#8211;in Korean <cite class=\"ltx_cite ltx_citemacro_citep\">(Park et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib46\" title=\"\">2021</a>)</cite>, Chinese <cite class=\"ltx_cite ltx_citemacro_citep\">(Xu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib63\" title=\"\">2020</a>)</cite>, Vietnamese <cite class=\"ltx_cite ltx_citemacro_citep\">(Do et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib13\" title=\"\">2024</a>)</cite>, and Indonesian <cite class=\"ltx_cite ltx_citemacro_citep\">(Wilie et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib57\" title=\"\">2020</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "cantonlu",
                    "syntax",
                    "wsd",
                    "nli",
                    "pos",
                    "zhang",
                    "tasks",
                    "nlu",
                    "lexicon",
                    "dataset",
                    "semantics"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We introduce a benchmark of seven Cantonese NLU tasks, encompassing word sense disambiguation (WSD), linguistic acceptability judgment (LAJ), language detection (LD), natural language inference (NLI), sentiment analysis (SA), part-of-speech tagging (POS), and dependency parsing (DEPS).\nWhile all tasks require Cantonese proficiency, tasks such as LD may reward Mandarin knowledge, whereas tasks such as DEPS and WSD may penalize Mandarin knowledge.\nWSD, LAJ, and LD datasets are novel contributions to Cantonese NLU.</p>\n\n",
                "matched_terms": [
                    "detection",
                    "sentiment",
                    "wsd",
                    "nli",
                    "pos",
                    "parsing",
                    "tasks",
                    "nlu",
                    "acceptability"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, we manually compile Cantonese words with more than one attested meaning to create the first Cantonese word sense disambiguation dataset.\nWe collect the words&#8217; multiples senses and two example sentences for each sense, resulting in 41 multi-sense words with a total of 109 senses.\nFor each sense, there are least 2 example sentences containing the word.\nThe dataset does not require fine-tuning for evaluation&#8212;model predictions are obtained by masking the target word in each sentence and comparing cosine similarities between the hidden representations at the mask position.\nFor each target word <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS0.SSS0.Px1.p1.m1\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> with two contexts <math alttext=\"s_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS0.SSS0.Px1.p1.m2\" intent=\":literal\"><semantics><msub><mi>s</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">s_{i}</annotation></semantics></math> and <math alttext=\"s_{j}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS0.SSS0.Px1.p1.m3\" intent=\":literal\"><semantics><msub><mi>s</mi><mi>j</mi></msub><annotation encoding=\"application/x-tex\">s_{j}</annotation></semantics></math>, we obtain hidden representations\nfor each at the masked position from the model <math alttext=\"\\mathbf{h}_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS0.SSS0.Px1.p1.m4\" intent=\":literal\"><semantics><msub><mi>&#119841;</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">\\mathbf{h}_{i}</annotation></semantics></math> and <math alttext=\"\\mathbf{h}_{j}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS0.SSS0.Px1.p1.m5\" intent=\":literal\"><semantics><msub><mi>&#119841;</mi><mi>j</mi></msub><annotation encoding=\"application/x-tex\">\\mathbf{h}_{j}</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "meaning",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LAJ is a classification task, where the model predicts whether the given sequence is linguistically acceptable.\nThis often aligns with grammatical judgment acceptability, but may also include judgment on semantic plausibility or pragmatic felicity.\nWe compile the first Cantonese LAJ dataset by adapting the Cantonese portion of <span class=\"ltx_text ltx_font_smallcaps\">SiniticMTError</span> <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib35\" title=\"\">2025</a>)</cite>, a dataset of Sinitic translation error span annotations, where each datapoint consists of a well-formed reference sentence <span class=\"ltx_text ltx_font_typewriter\">ref</span>, a machine translated sentence <span class=\"ltx_text ltx_font_typewriter\">mt</span>, and annotations of errors in the <span class=\"ltx_text ltx_font_typewriter\">mt</span> sentence.\nWe consider error-free <span class=\"ltx_text ltx_font_typewriter\">ref</span> as acceptable, <span class=\"ltx_text ltx_font_typewriter\">mt</span> with error annotations not acceptable, to create pairs with one acceptable and one not acceptable versions of the same sentence.\nUnlike previous LAJ datasets such as CoLA <cite class=\"ltx_cite ltx_citemacro_citep\">(Warstadt et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib56\" title=\"\">2019</a>)</cite>, which asks for a binary acceptable-not acceptable judgment, we implement a more robust setup of providing two versions of the same sentence and asking for a more acceptable version as is preferred in psycholinguistics and cognitive science <cite class=\"ltx_cite ltx_citemacro_citep\">(Mahowald et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib39\" title=\"\">2016</a>; Linzen and Oseki, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib32\" title=\"\">2018</a>)</cite>.\nThe dataset consists of 1.6k pairs.</p>\n\n",
                "matched_terms": [
                    "error",
                    "task",
                    "liu",
                    "acceptability",
                    "dataset",
                    "16k"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Language Detection (LD) is a three-label classification task that identifies whether a given sentence is written in Cantonese, Mandarin, or mixed.\nWe construct the novel dataset from the parallel translation corpus of <cite class=\"ltx_cite ltx_citemacro_citet\">Dai et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib11\" title=\"\">2025</a>)</cite>, selecting the first 10,000 sentence pairs.\nTo create mixed-language examples, we randomly replace tokens in Cantonese and Mandarin sentences with their counterparts from the other language with a set probability.\nIn a given mixed sentence, 15%, 33%, 50% of the sentence may be from the other language, thus producing up to 6 mixed sentences for each pair.\nWord-level alignments are obtained using SimAlign <cite class=\"ltx_cite ltx_citemacro_citep\">(Jalili&#160;Sabet et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib19\" title=\"\">2020</a>)</cite>, and all text is converted to traditional orthography using HanziConv <cite class=\"ltx_cite ltx_citemacro_citep\">(Yue and Gallant, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib66\" title=\"\">2014</a>)</cite> to prevent script-based shallow heuristics.\nThe resulting dataset contains 47,578 sentences, of which 27,578 are mixed.\nWe reserve 5% each for the validation and testing splits.\nWe note that this task requires proficiency in both Mandarin and Cantonese to perform well.\n</p>\n\n",
                "matched_terms": [
                    "detection",
                    "corpus",
                    "wordlevel",
                    "their",
                    "task",
                    "dai",
                    "parallel",
                    "requires",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">NLI is a classification task where the model is asked to predict whether the premise entails, or implies the truth of, the hypothesis.\nThe NLI portion of our benchmark is the <span class=\"ltx_text ltx_font_typewriter\">yue-nli-all</span> dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite>, which is a machine translation of English NLI datasets SNLI <cite class=\"ltx_cite ltx_citemacro_citep\">(Bowman et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib6\" title=\"\">2015</a>)</cite> and MNLI <cite class=\"ltx_cite ltx_citemacro_citep\">(Williams et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib58\" title=\"\">2018</a>)</cite> into Cantonese.\nThe dataset comprises of 557k train examples, 6.6k development examples, and 6.6k test examples.\nEach example includes a reference premise and two hypotheses, one entailing and one contradicting, from which we create two examples with each label.\nThis results in a balanced, two-label classification dataset.</p>\n\n",
                "matched_terms": [
                    "english",
                    "task",
                    "nli",
                    "chung",
                    "shing",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Sentiment analysis is a sentence-level classification task of predicting the sentiment of a given sentence.\nWe use the OpenRice dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib68\" title=\"\">2011</a>)</cite> compiled from restaurant reviews in Hong Kong, with the 3-way label space of positive, neutral, and negative.\nThe dataset is balanced, with 10k datapoints in its train split, 1k in its development split, and 1k in its test split.</p>\n\n",
                "matched_terms": [
                    "sentencelevel",
                    "sentiment",
                    "kong",
                    "task",
                    "zhang",
                    "restaurant",
                    "hong",
                    "reviews",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Finally, POS and DEPS are both token-level classification tasks.\nA POS model predicts the part-of-speech tag (e.g. noun, verb, etc.) of a given word, while a DEPS model predicts the dependency head (answering, which word is the syntactic head of this word?) and dependency type (answering, what is the relationship between this word and its head?) of the given word.\nFor POS and DEPS, we use the Cantonese-HK Universal Dependency dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>)</cite>, which comprises of 1k sentences and 14k tokens.\nWe split the dataset 9:1 for training and testing, respectively.\nThe dataset contains 15 POS tags and 48 dependency relations, of which 17 are specific to Cantonese.\nWe report both unlabeled (UAS) and labeled attachment scores (LAS) to measure DEPS performance.\n</p>\n\n",
                "matched_terms": [
                    "universal",
                    "respectively",
                    "14k",
                    "pos",
                    "wong",
                    "what",
                    "tasks",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Cantonese-adapted model represents the most common text processing effort in Cantonese, taking an existing model with Mandarin support and performing continued pre-training on Cantonese before applying the adapted text or speech model to downstream tasks <cite class=\"ltx_cite ltx_citemacro_citep\">(Luo et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib38\" title=\"\">2021</a>; Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>; Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>.\nIn our implementation, we take the off-the-shelf <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> model <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite><span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_tag ltx_tag_note\">3</span>The citation is attributable to the <span class=\"ltx_text ltx_font_typewriter\">bert</span> language model as a whole; it does not include implementation details on <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span>.</span></span></span> and continually pre-train on Cantonese text described above.\nWe do not make any changes to the model&#8217;s tokenizer.</p>\n\n",
                "matched_terms": [
                    "chung",
                    "shing",
                    "tasks",
                    "adapted",
                    "make"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In addition, we offer a comparison to a concurrent BERT-based Cantonese work in <span class=\"ltx_text ltx_font_typewriter\">bert-base-cantonese</span> <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>)</cite>, also a continually pre-trained model, but on a close-source corpus of news articles, social media posts, and web content.</p>\n\n",
                "matched_terms": [
                    "shing",
                    "chung",
                    "corpus"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Direct transfer from Mandarin without conditioning on Cantonese also represents a small subset of Cantonese NLP efforts <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib34\" title=\"\">2022</a>; Li, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib31\" title=\"\">2024</a>)</cite>, including evaluating non-Cantonese trained multi-lingual LLMs such as Llama models on Cantonese knowledge benchmarks <cite class=\"ltx_cite ltx_citemacro_citep\">(Cheng et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>)</cite>.\nWe employ <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite> as a model representing direct transfer from Mandarin, and fine-tune the model on the downstream tasks without additional conditioning on Cantonese text.\nWe do not make any changes to the model&#8217;s tokenizer.</p>\n\n",
                "matched_terms": [
                    "liu",
                    "make",
                    "tasks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We train a monolingual Cantonese model from scratch using the BERT architecture <cite class=\"ltx_cite ltx_citemacro_cite\">Devlin et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite>.\nWhile previous work in Cantonese language modeling have incorporated additional datasets <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>, many of them are proprietary, may include non-Cantonese text, or may not be freely used as pointed out by <cite class=\"ltx_cite ltx_citemacro_citet\">Xiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib61\" title=\"\">2024</a>)</cite>.\nThus, similar to the Cantonese-adapted model, we train a monolingual Cantonese model using the publicly available Cantonese Wikipedia dump <cite class=\"ltx_cite ltx_citemacro_citep\">(Foundation, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib15\" title=\"\">2023</a>)</cite> and the <span class=\"ltx_text ltx_font_typewriter\">cantonese-sentences</span> corpus <cite class=\"ltx_cite ltx_citemacro_citep\">(Kwok, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib23\" title=\"\">2024</a>)</cite>.\nThe amount of data, totaling 700M characters, is an order of magnitude smaller than what was used to train <span class=\"ltx_text ltx_font_typewriter\">bert-base-uncased</span> at 3.3B words <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite>.\nWe are unable to make an exact comparison to <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> as training details of the model are not publicly available, although we suspect the Mandarin Wikipedia dump was used for a part of its training, which consists of around 1 million articles (cf. 137k articles for Cantonese) at the time of <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> training.</p>\n\n",
                "matched_terms": [
                    "make",
                    "what",
                    "corpus"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For the monolingual model, we train a sentencepiece byte-pair encoding tokenizer on the same data to obtain a Cantonese-only tokenizer.\nUnlike the tokenizer from <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> which only includes 8k tokens of character length 1, the Cantonese tokenizer captures subword structure by including around 32k tokens, of which 27k are multi-character tokens. Moreover, a high overlap in lexicons is maintained, with 4.8k characters being represented in both <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> and our Cantonese tokenizer.\nWhile we expected greater coverage of Cantonese-only characters from Hong Kong Supplementary Character Set (HKSCS), this is not the case as <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span>&#8217;s tokenizer boasts a greater coverage with 603 characters, while our tokenizer covers only 233 characters in HKSCS.\nThis result reflects the relative scarcity of Cantonese-specific data compared to the abundant Mandarin data available.</p>\n\n",
                "matched_terms": [
                    "kong",
                    "hong"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Each model is fine-tuned on the training split of the downstream NLU task, then evaluated on the test split of the same task with the exception of LAJ and WSD which use model surprisal without fine-tuning.\nWe report accuracy metrics for NLI, LAJ, WSD; F1 metrics for POS, LD and SA; and UAS and LAS for DEPS.\nFollowing NLU convention <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite>, we do not freeze model weights and allow them to be updated during fine-tuning.\nWe report task-specific hyperparameter choice during fine-tuning in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5.T2\" title=\"Table 2 &#8227; Monolingual Cantonese model. &#8227; 5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>.</p>\n\n",
                "matched_terms": [
                    "wsd",
                    "nli",
                    "task",
                    "pos",
                    "nlu"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our results across the 7 Cantonese NLU tasks are shown in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5.T3\" title=\"Table 3 &#8227; Monolingual Cantonese model. &#8227; 5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, where our Cantonese monolingual model demonstrates the highest performance for POS and DEPS; Cantonese-adapted for NLI, LD, and WSD; Mandarin model without Cantonese adaptation for NLI and LAJ.\nOur transfer model&#8217;s performances slightly tail that of <span class=\"ltx_text ltx_font_typewriter\">bert-base-cantonese</span>.\nWe highlight three main findings.\nFirst, Cantonese monolingual models excel in syntactic tasks, while Cantonese-adapted Mandarin models are currently the most effective approach for Cantonese semantic tasks.\nSecond, Mandarin-only models can still perform competitively on some tasks.\nFinally, despite the relative success of monolingual and transfer models, there remains substantial room for improvement in representing Cantonese lexicon, syntax, and semantics.</p>\n\n",
                "matched_terms": [
                    "syntax",
                    "wsd",
                    "nli",
                    "pos",
                    "tasks",
                    "nlu",
                    "lexicon",
                    "semantics"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Supporting the empirical success of Mandarin-to-Cantonese transfer seen in contemporary Cantonese NLP, Cantonese-adapted Mandarin models offer the strongest performance with a task-averaged score of 69.4 (<span class=\"ltx_text ltx_font_typewriter\">bert-base-cantonese</span>) and 68.0 (our open-source transfer model).\nWhile the monolingual model excels in syntactic tasks POS and DEPS, its average score of 65.1 lags behind those the Cantonese-adapted and Mandarin models.\nWe attribute this primarily to the small size of our Cantonese pretraining corpus (roughly 700M characters).\nAs discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5\" title=\"5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, this is an order of magnitude smaller than the datasets used to train comparable English or Mandarin models, and therefore insufficient for learning robust linguistic representations from scratch.</p>\n\n",
                "matched_terms": [
                    "english",
                    "corpus",
                    "size",
                    "pos",
                    "tasks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Interestingly, <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> achieves comparable, or in some cases, superior performance to its Cantonese-adapted and Cantonese-monolingual counterparts with an average score of 68.1.\nWhen scholars discuss mutual intelligibility among Sinitic languages, they typically refer to the spoken form <cite class=\"ltx_cite ltx_citemacro_citep\">(Tang and van Heuven, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib53\" title=\"\">2007</a>; Gooskens and Van&#160;Heuven, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib17\" title=\"\">2021</a>)</cite>.\nHowever, written Sinitic languages are far more mutually intelligible, given the historical influence of Mandarin as the dominant language of education and literacy across Chinese-speaking regions <cite class=\"ltx_cite ltx_citemacro_citep\">(Snow, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib51\" title=\"\">2004</a>; Xiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib61\" title=\"\">2024</a>)</cite>.\nThis suggests that effective written Cantonese understanding can emerge from training on Mandarin text without explicit exposure to Cantonese text, as also observed in <cite class=\"ltx_cite ltx_citemacro_citet\">Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>, where LLMs without explicit Cantonese support perform relatively well on Cantonese and Hong Kong-related knowledge benchmarks.</p>\n\n",
                "matched_terms": [
                    "form",
                    "hong"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While models achieve respectable performance on NLI, POS tagging, and lexical disambiguation, dependency parsing remains notably weak&#8212;likely due to both the small fine-tuning dataset of around 1k sentences and the inherent difficulty of the task.\nNonetheless, dependency parsing for other low-resource languages such as Buryat <cite class=\"ltx_cite ltx_citemacro_citep\">(Badmaeva and Tyers, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib2\" title=\"\">2017</a>)</cite> and Old English <cite class=\"ltx_cite ltx_citemacro_citep\">(Levine et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib28\" title=\"\">2025</a>)</cite> has reached higher performance with smaller datasets, suggesting that current Cantonese representations still lack sufficient syntactic and semantic grounding.</p>\n\n",
                "matched_terms": [
                    "english",
                    "nli",
                    "task",
                    "pos",
                    "parsing",
                    "dataset"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While we proposes a novel evaluation framework and recommend insights into Cantonese representation learning, several limitations remain.\nFirst, the size and coverage of available Cantonese corpora significantly constrain our results.\nOur monolingual Cantonese model was trained on roughly 700M characters, an order of magnitude smaller than corpora typically used to pre-train large language models in other major languages <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite>.\nThis data sparsity likely limits the model&#8217;s ability to capture the full lexical and semantic diversity of written Cantonese, and may explain the comparatively weaker performance of the monolingual model in semantic tasks. Future work would benefit from expanding and diversifying Cantonese text resources, especially in informal and user-generated domains that reflect contemporary usage.</p>\n\n",
                "matched_terms": [
                    "size",
                    "tasks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, our evaluation benchmark, though designed to cover multiple aspects of Cantonese NLU, is itself constrained by data availability. Some tasks, such as dependency parsing (DEPS), rely on small fine-tuning datasets <cite class=\"ltx_cite ltx_citemacro_citep\">(Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>)</cite>, making the results more susceptible to statistical noise and limiting generalization. In addition, the benchmark focuses on written Cantonese and does not address spoken or colloquial aspects of the language such as code-switching <cite class=\"ltx_cite ltx_citemacro_citep\">(Yim and Bialystok, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib65\" title=\"\">2012</a>)</cite> or informal register in-depth; these aspects are integral to Cantonese as it is a primarily spoken language <cite class=\"ltx_cite ltx_citemacro_citep\">(Snow, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib51\" title=\"\">2004</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "wong",
                    "parsing",
                    "tasks",
                    "nlu"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we describe a benchmark of Cantonese NLU tasks, and evaluate a monolingual Cantonese model, two transfer models from Mandarin, and a Mandarin model on said Cantonese benchmark to investigate contexts where each type of model is most effective.\nOur results indicate that both Cantonese monolingual models and Cantonese-adapted models with cross-lingual transfer from Mandarin both have merit for Cantonese NLP in today&#8217;s landscape of language resources.\nIn addition, direct transfer from a Mandarin model without Cantonese representation learning may suffice for some tasks.\nOur findings also suggest that the existing open-source Cantonese corpora are insufficient to train a reliable representation of Cantonese lexicon, syntax, and semantics.</p>\n\n",
                "matched_terms": [
                    "syntax",
                    "tasks",
                    "nlu",
                    "lexicon",
                    "semantics"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While we do not collect human annotations for our work, we acknowledge that we make use of datasets that were annotated by humans or otherwise adapted from a human source.</p>\n\n",
                "matched_terms": [
                    "make",
                    "adapted",
                    "source"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We make use of a variety of Cantonese NLP and language resources.\nIn addition to our discussion of them in Sections <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S3\" title=\"3. Related Work &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S4\" title=\"4. Building CantoNLU &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, and <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5\" title=\"5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>,\nwe acknowledge their use and organize them below.</p>\n\n",
                "matched_terms": [
                    "make",
                    "their"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_typewriter\">Cantonese-HK UD Corpus</span>\n<a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"github.com/UniversalDependencies/UD_Cantonese-HK\" title=\"\">github.com/UniversalDependencies/UD_Cantonese-HK</a>\n<cite class=\"ltx_cite ltx_citemacro_citep\">(Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>)</cite></p>\n\n",
                "matched_terms": [
                    "wong",
                    "corpus"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_typewriter\">Yue-All-NLI</span>\n<a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"huggingface.co/datasets/hon9kon9ize/yue-all-nli\" title=\"\">huggingface.co/datasets/hon9kon9ize/yue-all-nli</a>\n<cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite></p>\n\n",
                "matched_terms": [
                    "shing",
                    "chung"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Parallel corpus from\n<cite class=\"ltx_cite ltx_citemacro_citet\">Dai et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib11\" title=\"\">2025</a>)</cite></p>\n\n",
                "matched_terms": [
                    "dai",
                    "parallel",
                    "corpus"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_typewriter\">Hong Kong Cantonese Corpus</span>\n<a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"github.com/fcbond/hkcancor\" title=\"\">github.com/fcbond/hkcancor</a>\n<cite class=\"ltx_cite ltx_citemacro_citep\">(Luke and Wong, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib37\" title=\"\">2015</a>)</cite></p>\n\n",
                "matched_terms": [
                    "wong",
                    "kong",
                    "hong",
                    "corpus"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Hong Kong Supplementary Character Set (HKLSCS) <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"www.ccli.gov.hk/en/hkscs/what_is_hkscs.html\" title=\"\">www.ccli.gov.hk/en/hkscs/what_is_hkscs.html</a></p>\n\n",
                "matched_terms": [
                    "kong",
                    "hong"
                ]
            }
        ]
    },
    "S5.T2": {
        "source_file": "CantoNLU: A benchmark for Cantonese natural language understanding",
        "caption": "Table 2: Hyperparameters used for fine-tuning across tasks. LR = learning rate. Patience refers to the number of epochs before early stopping.",
        "body": "Task\nLR\nBatch\nEpochs\n\n\n\n\nNLI\n2e-5\n16\n3\n\n\nPOS\n2e-5\n32\n3\n\n\nDEP\n3e-5\n16\n20\n\n\nLD\n2e-6\n16\n3\n\n\nSA\n2e-5\n16\n3\n\n\n\n\nLAJ\nNo fine-tuning performed\n\n\nWSD\nNo fine-tuning performed",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Task</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">LR</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Batch</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Epochs</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">NLI</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">2e-5</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">16</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\">3</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">POS</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">2e-5</th>\n<td class=\"ltx_td ltx_align_center\">32</td>\n<td class=\"ltx_td ltx_align_center\">3</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">DEP</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">3e-5</th>\n<td class=\"ltx_td ltx_align_center\">16</td>\n<td class=\"ltx_td ltx_align_center\">20</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">LD</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">2e-6</th>\n<td class=\"ltx_td ltx_align_center\">16</td>\n<td class=\"ltx_td ltx_align_center\">3</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">SA</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">2e-5</th>\n<td class=\"ltx_td ltx_align_center\">16</td>\n<td class=\"ltx_td ltx_align_center\">3</td>\n</tr>\n</tbody>\n<tfoot class=\"ltx_tfoot\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">LAJ</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\" colspan=\"3\">No fine-tuning performed</th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">WSD</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\" colspan=\"3\">No fine-tuning performed</th>\n</tr>\n</tfoot>\n</table>\n\n",
        "informative_terms_identified": [
            "early",
            "wsd",
            "used",
            "rate",
            "hyperparameters",
            "2e6",
            "batch",
            "dep",
            "learning",
            "performed",
            "3e5",
            "patience",
            "number",
            "stopping",
            "nli",
            "2e5",
            "refers",
            "across",
            "laj",
            "finetuning",
            "task",
            "before",
            "pos",
            "tasks",
            "epochs"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Each model is fine-tuned on the training split of the downstream NLU task, then evaluated on the test split of the same task with the exception of LAJ and WSD which use model surprisal without fine-tuning.\nWe report accuracy metrics for NLI, LAJ, WSD; F1 metrics for POS, LD and SA; and UAS and LAS for DEPS.\nFollowing NLU convention <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite>, we do not freeze model weights and allow them to be updated during fine-tuning.\nWe report task-specific hyperparameter choice during fine-tuning in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5.T2\" title=\"Table 2 &#8227; Monolingual Cantonese model. &#8227; 5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Cantonese, although spoken by millions, remains under-resourced due to policy and diglossia. To address this scarcity of evaluation frameworks for Cantonese, we introduce <span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\">CantoNLU</span>, a benchmark for Cantonese natural language understanding (NLU).\nThis novel benchmark spans seven tasks covering syntax and semantics, including word sense disambiguation, linguistic acceptability judgment, language detection, natural language inference, sentiment analysis, part-of-speech tagging, and dependency parsing. In addition to the benchmark, we provide model baseline performance across a set of models: a Mandarin model without Cantonese training, two Cantonese-adapted models obtained by continual pre-training a Mandarin model on Cantonese text, and a monolingual Cantonese model trained from scratch. Results show that Cantonese-adapted models perform best overall, while monolingual models perform better on syntactic tasks. Mandarin models remain competitive in certain settings, indicating that direct transfer may be sufficient when Cantonese domain data is scarce. We release all datasets, code, and model weights to facilitate future research in Cantonese NLP.\n\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>\n<span class=\"ltx_text ltx_font_bold\">Keywords:&#8201;</span>Cantonese, natural language understanding, transfer learning, benchmark</p>\n\n",
                "matched_terms": [
                    "tasks",
                    "learning",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Cross-lingual transfer from Mandarin for Cantonese language processing has proven effective, with empirical success across a range of tasks, including language modeling and reading comprehension <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>, translation <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib34\" title=\"\">2022</a>; Suen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib52\" title=\"\">2024</a>)</cite>, and speech recognition <cite class=\"ltx_cite ltx_citemacro_citep\">(Li et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib29\" title=\"\">2019</a>; Luo et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib38\" title=\"\">2021</a>)</cite>. However, despite empirical success, there remains a gap in formal investigations into the best practices for Cantonese natural language understanding (NLU). This is attributable to a lack of a centralized evaluation framework for Cantonese language processing or understanding.</p>\n\n",
                "matched_terms": [
                    "tasks",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we introduce <span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\">CantoNLU</span>, a GLUE-like <cite class=\"ltx_cite ltx_citemacro_citep\">(General Language Understanding Evaluation;  Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib55\" title=\"\">2018</a>)</cite> natural language understanding benchmark in Cantonese.\n<span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\">CantoNLU</span> provides an in-depth evaluation of syntax, lexicon and semantic understanding, comprising 7 tasks: word sense disambiguation (WSD), linguistic acceptability judgment (LAJ), language detection (LD), natural language inference (NLI), sentiment analysis (SA), part-of-speech tagging (POS), and dependency parsing (DEPS).\nIn particular, the WSD dataset is entirely novel, providing the first resource for sense-level lexical understanding in Cantonese.\nLAJ and LD represent novel adaptations of existing datasets, while NLI, SA, POS, and DEPS datasets are direct adoptions of existing datasets <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>; Zhang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib68\" title=\"\">2011</a>; Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>, respectively)</cite>.\nWe describe each task and underlying datasets in Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S4\" title=\"4. Building CantoNLU &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, whose overview is outlined in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S1.T1\" title=\"Table 1 &#8227; 1. Introduction &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>.</p>\n\n",
                "matched_terms": [
                    "laj",
                    "wsd",
                    "nli",
                    "task",
                    "pos",
                    "tasks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In spite of limited training data in Cantonese, we demonstrate that our monolingual Cantonese model excels in syntactic tasks such as POS and DEPS.\nOn the other hand, Cantonese-adapted models excel in semantic tasks such as NLI, LD, WSD, and SA.\nSimultaneously, mandarin models offer a competitive alternative to additional or monolingual training on Cantonese data, excelling in NLI and LAJ.</p>\n\n",
                "matched_terms": [
                    "laj",
                    "wsd",
                    "nli",
                    "pos",
                    "tasks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Cantonese, also known as Yue <cite class=\"ltx_cite ltx_citemacro_citep\">(Eberhard et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib14\" title=\"\">2023</a>)</cite>, is the second most widely used Sinitic language after Mandarin, spoken by an estimated 85 million people worldwide.\nHowever, it remains primarily a spoken language <cite class=\"ltx_cite ltx_citemacro_citep\">(Norman, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib44\" title=\"\">1988</a>)</cite>, with most speakers defaulting to written Standard Chinese <cite class=\"ltx_cite ltx_citemacro_citep\">(Xiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib61\" title=\"\">2024</a>)</cite>.\nThis diglossic situation and its short history as a written language <cite class=\"ltx_cite ltx_citemacro_citep\">(Snow, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib51\" title=\"\">2004</a>)</cite> has contributed to the scarcity of high-quality textual resources for Cantonese NLP, in stark contrast to Mandarin Chinese, a related language rich in resource across corpora, models <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>; Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib36\" title=\"\">2020</a>; Conneau et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib10\" title=\"\">2020</a>; Bai et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib3\" title=\"\">2023</a>; Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib33\" title=\"\">2024</a>)</cite>, and evaluation resources <cite class=\"ltx_cite ltx_citemacro_citep\">(e.g.  Xu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib63\" title=\"\">2020</a>; Xiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib60\" title=\"\">2021</a>)</cite>.\nThus, as highlighted in Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S1\" title=\"1. Introduction &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, prior work have used varying degrees of transfer from models with Mandarin knowledge to perform downstream tasks in Cantonese <cite class=\"ltx_cite ltx_citemacro_citep\">(Li et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib29\" title=\"\">2019</a>; Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>; Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "tasks",
                    "used",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Transfer learning is a common strategy in deep learning (DL) to address data sparsity, where features or signal learned from a resource-rich domain is used to augment a low-resource domain, task, or dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Bengio, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib4\" title=\"\">2012</a>)</cite>.\nIn the context of NLP, a common application of transfer learning is in cross-lingual transfer for low-resource languages <cite class=\"ltx_cite ltx_citemacro_cite\">Ruder et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib48\" title=\"\">2019</a>); Conneau et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib10\" title=\"\">2020</a>)</cite>.\nTwo types of cross-lingual transfer exists: model transfer and data transfer, as described in <cite class=\"ltx_cite ltx_citemacro_citet\">Garc&#237;a-Ferrero et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib16\" title=\"\">2022</a>)</cite>.\nData transfer involves translating a dataset or corpus from a high-resource language to a lesser-resourced target language, as performed in <span class=\"ltx_text ltx_font_typewriter\">yue-all-nli</span> <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite>, the MMLU <cite class=\"ltx_cite ltx_citemacro_citep\">(Hendrycks et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib18\" title=\"\">2021</a>)</cite> portion of the HKCanto-Eval benchmark <cite class=\"ltx_cite ltx_citemacro_citep\">(Cheng et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>)</cite>, and Yue benchmarks from <cite class=\"ltx_cite ltx_citemacro_citet\">Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "performed",
                    "used",
                    "task",
                    "learning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">On the other hand, model transfer involves adapting models trained on a high-resource source language to a lesser-resourced target language, such as Mandarin to Cantonese and Danish to Faroese <cite class=\"ltx_cite ltx_citemacro_citep\">(Sn&#230;bjarnarson et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib50\" title=\"\">2023</a>)</cite>.\nModel transfer relies on the lexical or typological similarity between the two languages, thereby enabling the transfer of linguistic knowledge <cite class=\"ltx_cite ltx_citemacro_cite\">Khan et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib22\" title=\"\">2025</a>)</cite>.\nWhile some implementations of cross-lingual transfer explicitly designate a source language for cross-lingual transfer <cite class=\"ltx_cite ltx_citemacro_citep\">(Sn&#230;bjarnarson et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib50\" title=\"\">2023</a>; Thangaraj et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib54\" title=\"\">2024</a>)</cite>, others rely on multilingual models.\nRather than transferring from a specific source language, such models are thought to capture general cross-linguistic patterns that extend beyond typological or lexical similarity, allowing them to perform reasonably well even on unseen or low-resource languages <cite class=\"ltx_cite ltx_citemacro_citep\">(Conneau et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib10\" title=\"\">2020</a>; Scivetti et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib49\" title=\"\">2025</a>)</cite>.\nHybrid approaches combine both paradigms: they begin with a multilingual model, then continue pre-training or fine-tuning on a specific target language before applying the resulting model to downstream tasks <cite class=\"ltx_cite ltx_citemacro_citep\">(Protasov et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib47\" title=\"\">2024</a>; Manafi and Krishnaswamy, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib40\" title=\"\">2024</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "finetuning",
                    "tasks",
                    "before"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Although widely considered low-resource, recent efforts have begun to address scarcity in Cantonese language resources.\nMachine-translations of non-Cantonese resources may offer potential utility as data transfer, as provided by <cite class=\"ltx_cite ltx_citemacro_citet\">Chung&#160;Shing (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite> for Cantonese natural language inference (NLI) and <cite class=\"ltx_cite ltx_citemacro_citet\">Cheng et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>); Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite> for LLM knowledge evaluation.\nFoundational tools such as PyCantonese <cite class=\"ltx_cite ltx_citemacro_citep\">(Lee et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib26\" title=\"\">2022</a>)</cite> provide <span class=\"ltx_text ltx_font_typewriter\">NLTK</span>-like <cite class=\"ltx_cite ltx_citemacro_citep\">(Bird and Loper, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib5\" title=\"\">2004</a>)</cite> essential language processing utilities, while a Cantonese Universal Dependencies dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>)</cite> offers a small yet significant syntactically annotated treebank.\nMultilingual resources such as Wikipedia <cite class=\"ltx_cite ltx_citemacro_citep\">(Foundation, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib15\" title=\"\">2023</a>)</cite>, SIB-200 <cite class=\"ltx_cite ltx_citemacro_citep\">(Adelani et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib1\" title=\"\">2024</a>)</cite>, and NLLB <cite class=\"ltx_cite ltx_citemacro_citep\">(NLLB Team et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib43\" title=\"\">2024</a>)</cite> include Cantonese portions, which may be useful for representation learning or evaluation in topic classification and multilingual translation.\nLarger-scale corpora such as YueData <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite> have also emerged, though they often contain substantial portions of non-Cantonese text.</p>\n\n",
                "matched_terms": [
                    "learning",
                    "nli"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Although we have described Cantonese benchmarks HKCanto-Eval <cite class=\"ltx_cite ltx_citemacro_citep\">(Cheng et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>)</cite> and Yue-Benchmark <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite> as related work, we wish to clarify our contributions to Cantonese benchmarking in comparison to these two benchmarks.\nWhile HKCanto-Eval includes OpenRice <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib68\" title=\"\">2011</a>)</cite> as a SA dataset, which overlaps with our <span class=\"ltx_text ltx_font_smallcaps\">CantoNLU</span>, along with minor datasets in Cantonese phonology and orthography, HKCanto-Eval and Yue-Benchmark primarily target generative LLMs on general world knowledge and reasoning, in a comparable way to MMLU <cite class=\"ltx_cite ltx_citemacro_citep\">(Hendrycks et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib18\" title=\"\">2021</a>)</cite>.\nWe highlight <span class=\"ltx_text ltx_font_smallcaps\">CantoNLU</span>&#8217;s focus on discriminative NLU tasks, explicitly evaluating a model&#8217;s ability to understand the Cantonese lexicon (WSD), syntax (POS, DEPS), semantics (NLI, SA), and overall well-formedness with respect to both syntax and semantics (LAJ).\nThe focus is similar to those of GLUE <cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib55\" title=\"\">2018</a>)</cite> and its derivatives&#8211;in Korean <cite class=\"ltx_cite ltx_citemacro_citep\">(Park et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib46\" title=\"\">2021</a>)</cite>, Chinese <cite class=\"ltx_cite ltx_citemacro_citep\">(Xu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib63\" title=\"\">2020</a>)</cite>, Vietnamese <cite class=\"ltx_cite ltx_citemacro_citep\">(Do et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib13\" title=\"\">2024</a>)</cite>, and Indonesian <cite class=\"ltx_cite ltx_citemacro_citep\">(Wilie et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib57\" title=\"\">2020</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "laj",
                    "wsd",
                    "nli",
                    "pos",
                    "tasks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We introduce a benchmark of seven Cantonese NLU tasks, encompassing word sense disambiguation (WSD), linguistic acceptability judgment (LAJ), language detection (LD), natural language inference (NLI), sentiment analysis (SA), part-of-speech tagging (POS), and dependency parsing (DEPS).\nWhile all tasks require Cantonese proficiency, tasks such as LD may reward Mandarin knowledge, whereas tasks such as DEPS and WSD may penalize Mandarin knowledge.\nWSD, LAJ, and LD datasets are novel contributions to Cantonese NLU.</p>\n\n",
                "matched_terms": [
                    "laj",
                    "wsd",
                    "nli",
                    "pos",
                    "tasks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LAJ is a classification task, where the model predicts whether the given sequence is linguistically acceptable.\nThis often aligns with grammatical judgment acceptability, but may also include judgment on semantic plausibility or pragmatic felicity.\nWe compile the first Cantonese LAJ dataset by adapting the Cantonese portion of <span class=\"ltx_text ltx_font_smallcaps\">SiniticMTError</span> <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib35\" title=\"\">2025</a>)</cite>, a dataset of Sinitic translation error span annotations, where each datapoint consists of a well-formed reference sentence <span class=\"ltx_text ltx_font_typewriter\">ref</span>, a machine translated sentence <span class=\"ltx_text ltx_font_typewriter\">mt</span>, and annotations of errors in the <span class=\"ltx_text ltx_font_typewriter\">mt</span> sentence.\nWe consider error-free <span class=\"ltx_text ltx_font_typewriter\">ref</span> as acceptable, <span class=\"ltx_text ltx_font_typewriter\">mt</span> with error annotations not acceptable, to create pairs with one acceptable and one not acceptable versions of the same sentence.\nUnlike previous LAJ datasets such as CoLA <cite class=\"ltx_cite ltx_citemacro_citep\">(Warstadt et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib56\" title=\"\">2019</a>)</cite>, which asks for a binary acceptable-not acceptable judgment, we implement a more robust setup of providing two versions of the same sentence and asking for a more acceptable version as is preferred in psycholinguistics and cognitive science <cite class=\"ltx_cite ltx_citemacro_citep\">(Mahowald et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib39\" title=\"\">2016</a>; Linzen and Oseki, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib32\" title=\"\">2018</a>)</cite>.\nThe dataset consists of 1.6k pairs.</p>\n\n",
                "matched_terms": [
                    "task",
                    "laj"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">NLI is a classification task where the model is asked to predict whether the premise entails, or implies the truth of, the hypothesis.\nThe NLI portion of our benchmark is the <span class=\"ltx_text ltx_font_typewriter\">yue-nli-all</span> dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite>, which is a machine translation of English NLI datasets SNLI <cite class=\"ltx_cite ltx_citemacro_citep\">(Bowman et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib6\" title=\"\">2015</a>)</cite> and MNLI <cite class=\"ltx_cite ltx_citemacro_citep\">(Williams et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib58\" title=\"\">2018</a>)</cite> into Cantonese.\nThe dataset comprises of 557k train examples, 6.6k development examples, and 6.6k test examples.\nEach example includes a reference premise and two hypotheses, one entailing and one contradicting, from which we create two examples with each label.\nThis results in a balanced, two-label classification dataset.</p>\n\n",
                "matched_terms": [
                    "nli",
                    "task"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Finally, POS and DEPS are both token-level classification tasks.\nA POS model predicts the part-of-speech tag (e.g. noun, verb, etc.) of a given word, while a DEPS model predicts the dependency head (answering, which word is the syntactic head of this word?) and dependency type (answering, what is the relationship between this word and its head?) of the given word.\nFor POS and DEPS, we use the Cantonese-HK Universal Dependency dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>)</cite>, which comprises of 1k sentences and 14k tokens.\nWe split the dataset 9:1 for training and testing, respectively.\nThe dataset contains 15 POS tags and 48 dependency relations, of which 17 are specific to Cantonese.\nWe report both unlabeled (UAS) and labeled attachment scores (LAS) to measure DEPS performance.\n</p>\n\n",
                "matched_terms": [
                    "tasks",
                    "pos"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Cantonese-adapted model represents the most common text processing effort in Cantonese, taking an existing model with Mandarin support and performing continued pre-training on Cantonese before applying the adapted text or speech model to downstream tasks <cite class=\"ltx_cite ltx_citemacro_citep\">(Luo et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib38\" title=\"\">2021</a>; Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>; Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>.\nIn our implementation, we take the off-the-shelf <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> model <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite><span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_tag ltx_tag_note\">3</span>The citation is attributable to the <span class=\"ltx_text ltx_font_typewriter\">bert</span> language model as a whole; it does not include implementation details on <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span>.</span></span></span> and continually pre-train on Cantonese text described above.\nWe do not make any changes to the model&#8217;s tokenizer.</p>\n\n",
                "matched_terms": [
                    "tasks",
                    "before"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our results across the 7 Cantonese NLU tasks are shown in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5.T3\" title=\"Table 3 &#8227; Monolingual Cantonese model. &#8227; 5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, where our Cantonese monolingual model demonstrates the highest performance for POS and DEPS; Cantonese-adapted for NLI, LD, and WSD; Mandarin model without Cantonese adaptation for NLI and LAJ.\nOur transfer model&#8217;s performances slightly tail that of <span class=\"ltx_text ltx_font_typewriter\">bert-base-cantonese</span>.\nWe highlight three main findings.\nFirst, Cantonese monolingual models excel in syntactic tasks, while Cantonese-adapted Mandarin models are currently the most effective approach for Cantonese semantic tasks.\nSecond, Mandarin-only models can still perform competitively on some tasks.\nFinally, despite the relative success of monolingual and transfer models, there remains substantial room for improvement in representing Cantonese lexicon, syntax, and semantics.</p>\n\n",
                "matched_terms": [
                    "across",
                    "laj",
                    "wsd",
                    "nli",
                    "pos",
                    "tasks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Supporting the empirical success of Mandarin-to-Cantonese transfer seen in contemporary Cantonese NLP, Cantonese-adapted Mandarin models offer the strongest performance with a task-averaged score of 69.4 (<span class=\"ltx_text ltx_font_typewriter\">bert-base-cantonese</span>) and 68.0 (our open-source transfer model).\nWhile the monolingual model excels in syntactic tasks POS and DEPS, its average score of 65.1 lags behind those the Cantonese-adapted and Mandarin models.\nWe attribute this primarily to the small size of our Cantonese pretraining corpus (roughly 700M characters).\nAs discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5\" title=\"5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, this is an order of magnitude smaller than the datasets used to train comparable English or Mandarin models, and therefore insufficient for learning robust linguistic representations from scratch.</p>\n\n",
                "matched_terms": [
                    "used",
                    "tasks",
                    "learning",
                    "pos"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While models achieve respectable performance on NLI, POS tagging, and lexical disambiguation, dependency parsing remains notably weak&#8212;likely due to both the small fine-tuning dataset of around 1k sentences and the inherent difficulty of the task.\nNonetheless, dependency parsing for other low-resource languages such as Buryat <cite class=\"ltx_cite ltx_citemacro_citep\">(Badmaeva and Tyers, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib2\" title=\"\">2017</a>)</cite> and Old English <cite class=\"ltx_cite ltx_citemacro_citep\">(Levine et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib28\" title=\"\">2025</a>)</cite> has reached higher performance with smaller datasets, suggesting that current Cantonese representations still lack sufficient syntactic and semantic grounding.</p>\n\n",
                "matched_terms": [
                    "nli",
                    "pos",
                    "task",
                    "finetuning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While we proposes a novel evaluation framework and recommend insights into Cantonese representation learning, several limitations remain.\nFirst, the size and coverage of available Cantonese corpora significantly constrain our results.\nOur monolingual Cantonese model was trained on roughly 700M characters, an order of magnitude smaller than corpora typically used to pre-train large language models in other major languages <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite>.\nThis data sparsity likely limits the model&#8217;s ability to capture the full lexical and semantic diversity of written Cantonese, and may explain the comparatively weaker performance of the monolingual model in semantic tasks. Future work would benefit from expanding and diversifying Cantonese text resources, especially in informal and user-generated domains that reflect contemporary usage.</p>\n\n",
                "matched_terms": [
                    "used",
                    "tasks",
                    "learning"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, our evaluation benchmark, though designed to cover multiple aspects of Cantonese NLU, is itself constrained by data availability. Some tasks, such as dependency parsing (DEPS), rely on small fine-tuning datasets <cite class=\"ltx_cite ltx_citemacro_citep\">(Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>)</cite>, making the results more susceptible to statistical noise and limiting generalization. In addition, the benchmark focuses on written Cantonese and does not address spoken or colloquial aspects of the language such as code-switching <cite class=\"ltx_cite ltx_citemacro_citep\">(Yim and Bialystok, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib65\" title=\"\">2012</a>)</cite> or informal register in-depth; these aspects are integral to Cantonese as it is a primarily spoken language <cite class=\"ltx_cite ltx_citemacro_citep\">(Snow, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib51\" title=\"\">2004</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "finetuning",
                    "tasks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we describe a benchmark of Cantonese NLU tasks, and evaluate a monolingual Cantonese model, two transfer models from Mandarin, and a Mandarin model on said Cantonese benchmark to investigate contexts where each type of model is most effective.\nOur results indicate that both Cantonese monolingual models and Cantonese-adapted models with cross-lingual transfer from Mandarin both have merit for Cantonese NLP in today&#8217;s landscape of language resources.\nIn addition, direct transfer from a Mandarin model without Cantonese representation learning may suffice for some tasks.\nOur findings also suggest that the existing open-source Cantonese corpora are insufficient to train a reliable representation of Cantonese lexicon, syntax, and semantics.</p>\n\n",
                "matched_terms": [
                    "learning",
                    "tasks"
                ]
            }
        ]
    },
    "S5.T3": {
        "source_file": "CantoNLU: A benchmark for Cantonese natural language understanding",
        "caption": "Table 3: Performance of Mandarin, Cantonese-adapted, and monolingual models across Cantonese NLU tasks. We offer performances of open-weight but closed-source models bert-base-chinese (Devlin et al., 2019) and bert-base-cantonese Chung Shing (2024) as comparison.",
        "body": "WSD\nLAJ\nLD\nNLI\nSA\nPOS\nDEPS\nAvg.\n\n\nModel\nAcc.\nF1\nF1\nAcc.\nF1\nF1\nUAS\nLAS\n\n\n\nNo Cantonese adaptation\n\n\n\n\n\n\n\n\n\n\n\nbert-base-chinese\n78.9\n91.7\n76.4\n93.2\n70.2\n74.6\n29.1\n25.9\n67.5\n\n\nCantonese-adapted\n\n\n\n\n\n\n\n\n\n\n\nbert-base-cantonese\n92.7\n89.2\n78.7\n93.2\n71.9\n72.2\n30.2\n26.8\n69.4\n\n\nOur transfer model\n85.3\n89.6\n78.4\n87.5\n71.3\n74.8\n30.0\n26.8\n68.0\n\n\nMonolingual Cantonese\n\n\n\n\n\n\n\n\n\n\n\nOur monolingual model\n70.6\n85.7\n73.3\n82.6\n70.1\n78.2\n32.4\n27.9\n65.1",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_border_r ltx_border_tt\"/>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">WSD</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">LAJ</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">LD</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">NLI</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">SA</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">POS</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">DEPS</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:90%;\">Avg.</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Model</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">Acc.</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">Acc.</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">F1</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">UAS</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">LAS</span></td>\n<td class=\"ltx_td\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">No Cantonese adaptation</span></td>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">bert-base-chinese</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.9</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">91.7</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">76.4</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">93.2</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.2</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">74.6</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">29.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">25.9</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">67.5</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Cantonese-adapted</span></td>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text ltx_font_typewriter\" style=\"font-size:90%;\">bert-base-cantonese</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">92.7</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">89.2</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">78.7</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">93.2</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">71.9</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">72.2</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">30.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">26.8</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">69.4</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_right ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Our transfer model</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.3</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">89.6</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">78.4</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">87.5</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">71.3</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">74.8</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">30.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">26.8</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">68.0</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Monolingual Cantonese</span></td>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n<td class=\"ltx_td ltx_border_t\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:90%;\">Our monolingual model</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">85.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">73.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">82.6</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">70.1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">78.2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">32.4</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">27.9</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\"><span class=\"ltx_text\" style=\"font-size:90%;\">65.1</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "cantonese",
            "wsd",
            "offer",
            "nlu",
            "avg",
            "transfer",
            "mandarin",
            "our",
            "deps",
            "adaptation",
            "openweight",
            "cantoneseadapted",
            "monolingual",
            "performance",
            "nli",
            "comparison",
            "chung",
            "acc",
            "performances",
            "devlin",
            "across",
            "laj",
            "closedsource",
            "models",
            "bertbasechinese",
            "pos",
            "las",
            "shing",
            "tasks",
            "bertbasecantonese",
            "model",
            "uas"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Our results across the 7 Cantonese NLU tasks are shown in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5.T3\" title=\"Table 3 &#8227; Monolingual Cantonese model. &#8227; 5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, where our Cantonese monolingual model demonstrates the highest performance for POS and DEPS; Cantonese-adapted for NLI, LD, and WSD; Mandarin model without Cantonese adaptation for NLI and LAJ.\nOur transfer model&#8217;s performances slightly tail that of <span class=\"ltx_text ltx_font_typewriter\">bert-base-cantonese</span>.\nWe highlight three main findings.\nFirst, Cantonese monolingual models excel in syntactic tasks, while Cantonese-adapted Mandarin models are currently the most effective approach for Cantonese semantic tasks.\nSecond, Mandarin-only models can still perform competitively on some tasks.\nFinally, despite the relative success of monolingual and transfer models, there remains substantial room for improvement in representing Cantonese lexicon, syntax, and semantics.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Cantonese, although spoken by millions, remains under-resourced due to policy and diglossia. To address this scarcity of evaluation frameworks for Cantonese, we introduce <span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\">CantoNLU</span>, a benchmark for Cantonese natural language understanding (NLU).\nThis novel benchmark spans seven tasks covering syntax and semantics, including word sense disambiguation, linguistic acceptability judgment, language detection, natural language inference, sentiment analysis, part-of-speech tagging, and dependency parsing. In addition to the benchmark, we provide model baseline performance across a set of models: a Mandarin model without Cantonese training, two Cantonese-adapted models obtained by continual pre-training a Mandarin model on Cantonese text, and a monolingual Cantonese model trained from scratch. Results show that Cantonese-adapted models perform best overall, while monolingual models perform better on syntactic tasks. Mandarin models remain competitive in certain settings, indicating that direct transfer may be sufficient when Cantonese domain data is scarce. We release all datasets, code, and model weights to facilitate future research in Cantonese NLP.\n\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>\n<span class=\"ltx_text ltx_font_bold\">Keywords:&#8201;</span>Cantonese, natural language understanding, transfer learning, benchmark</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "transfer",
                    "across",
                    "performance",
                    "models",
                    "model",
                    "tasks",
                    "nlu",
                    "cantoneseadapted",
                    "monolingual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Mandarin Chinese is considered a high-resource language, abundant with pre-trained language model (PLM) support <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>; Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib36\" title=\"\">2020</a>; Conneau et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib10\" title=\"\">2020</a>)</cite>, corpora, and evaluation benchmarks <cite class=\"ltx_cite ltx_citemacro_citep\">(Xu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib63\" title=\"\">2020</a>; Xiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib60\" title=\"\">2021</a>)</cite>, and most recently commercial large language models <cite class=\"ltx_cite ltx_citemacro_citep\">(Bai et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib3\" title=\"\">2023</a>; Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib33\" title=\"\">2024</a>)</cite>.\nHowever, the same cannot be said about other variants of the Sinitic language family, including Cantonese. Mandarin is the official state language and the prestige language in media, business, and academia. Owing to this status, Cantonese, along with other Sinitic languages, remains a primarily vernacular language without written standardization <cite class=\"ltx_cite ltx_citemacro_citep\">(Snow, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib51\" title=\"\">2004</a>; Li, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib30\" title=\"\">2006</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "models",
                    "devlin",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Such lack of written standardization, prestige, and official status results in a shortage of language resources in Cantonese. It is frequently described as a low-resource language <cite class=\"ltx_cite ltx_citemacro_citep\">(e.g.  Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib34\" title=\"\">2022</a>; Xiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib62\" title=\"\">2022</a>; Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite> despite having millions of speakers <cite class=\"ltx_cite ltx_citemacro_citep\">(Eberhard et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib14\" title=\"\">2023</a>)</cite>. As a result, Cantonese language processing systems often rely on datasets, models, and corpora adapted from Mandarin <cite class=\"ltx_cite ltx_citemacro_cite\">Xiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib61\" title=\"\">2024</a>)</cite>, despite a lack of mutual intelligibility between the two languages <cite class=\"ltx_cite ltx_citemacro_citep\">(Norman, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib44\" title=\"\">1988</a>; Tang and van Heuven, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib53\" title=\"\">2007</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "models"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Cross-lingual transfer from Mandarin for Cantonese language processing has proven effective, with empirical success across a range of tasks, including language modeling and reading comprehension <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>, translation <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib34\" title=\"\">2022</a>; Suen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib52\" title=\"\">2024</a>)</cite>, and speech recognition <cite class=\"ltx_cite ltx_citemacro_citep\">(Li et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib29\" title=\"\">2019</a>; Luo et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib38\" title=\"\">2021</a>)</cite>. However, despite empirical success, there remains a gap in formal investigations into the best practices for Cantonese natural language understanding (NLU). This is attributable to a lack of a centralized evaluation framework for Cantonese language processing or understanding.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "transfer",
                    "across",
                    "tasks",
                    "nlu"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we introduce <span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\">CantoNLU</span>, a GLUE-like <cite class=\"ltx_cite ltx_citemacro_citep\">(General Language Understanding Evaluation;  Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib55\" title=\"\">2018</a>)</cite> natural language understanding benchmark in Cantonese.\n<span class=\"ltx_text ltx_font_bold ltx_font_smallcaps\">CantoNLU</span> provides an in-depth evaluation of syntax, lexicon and semantic understanding, comprising 7 tasks: word sense disambiguation (WSD), linguistic acceptability judgment (LAJ), language detection (LD), natural language inference (NLI), sentiment analysis (SA), part-of-speech tagging (POS), and dependency parsing (DEPS).\nIn particular, the WSD dataset is entirely novel, providing the first resource for sense-level lexical understanding in Cantonese.\nLAJ and LD represent novel adaptations of existing datasets, while NLI, SA, POS, and DEPS datasets are direct adoptions of existing datasets <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>; Zhang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib68\" title=\"\">2011</a>; Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>, respectively)</cite>.\nWe describe each task and underlying datasets in Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S4\" title=\"4. Building CantoNLU &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, whose overview is outlined in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S1.T1\" title=\"Table 1 &#8227; 1. Introduction &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "laj",
                    "wsd",
                    "nli",
                    "chung",
                    "pos",
                    "deps",
                    "shing",
                    "tasks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Using <span class=\"ltx_text ltx_font_smallcaps\">CantoNLU</span>, we evaluate three types of models &#8211; a Mandarin model<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span><span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span></span></span></span> without explicit training on Cantonese, Cantonese-adapted transfer models with additional Cantonese training on a Mandarin model, and a monolingual Cantonese model, as outlined in Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5\" title=\"5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>.\nIn Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S6\" title=\"6. Results and Discussion &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">6</span></a>, we discuss how monolingual Cantonese, Cantonese-adapted, and Mandarin models compare across various aspects in Cantonese NLU.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "transfer",
                    "across",
                    "models",
                    "model",
                    "nlu",
                    "cantoneseadapted",
                    "monolingual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In spite of limited training data in Cantonese, we demonstrate that our monolingual Cantonese model excels in syntactic tasks such as POS and DEPS.\nOn the other hand, Cantonese-adapted models excel in semantic tasks such as NLI, LD, WSD, and SA.\nSimultaneously, mandarin models offer a competitive alternative to additional or monolingual training on Cantonese data, excelling in NLI and LAJ.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "laj",
                    "wsd",
                    "models",
                    "nli",
                    "model",
                    "pos",
                    "offer",
                    "deps",
                    "tasks",
                    "our",
                    "cantoneseadapted",
                    "monolingual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Based on our results, we recommend monolingual Cantonese models for syntactic tasks, and Cantonese-adapted models for semantic tasks.\nIn domains where Cantonese corpora are scarce, Mandarin models without Cantonese adaptation may be sufficient.\nIn addition to the benchmark and analysis, we publicly release our code and model weights at <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"github.com/aatlantise/sinitic-nlu\" title=\"\">github.com/aatlantise/sinitic-nlu</a>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "models",
                    "model",
                    "adaptation",
                    "tasks",
                    "our",
                    "cantoneseadapted",
                    "monolingual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Cantonese, also known as Yue <cite class=\"ltx_cite ltx_citemacro_citep\">(Eberhard et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib14\" title=\"\">2023</a>)</cite>, is the second most widely used Sinitic language after Mandarin, spoken by an estimated 85 million people worldwide.\nHowever, it remains primarily a spoken language <cite class=\"ltx_cite ltx_citemacro_citep\">(Norman, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib44\" title=\"\">1988</a>)</cite>, with most speakers defaulting to written Standard Chinese <cite class=\"ltx_cite ltx_citemacro_citep\">(Xiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib61\" title=\"\">2024</a>)</cite>.\nThis diglossic situation and its short history as a written language <cite class=\"ltx_cite ltx_citemacro_citep\">(Snow, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib51\" title=\"\">2004</a>)</cite> has contributed to the scarcity of high-quality textual resources for Cantonese NLP, in stark contrast to Mandarin Chinese, a related language rich in resource across corpora, models <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>; Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib36\" title=\"\">2020</a>; Conneau et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib10\" title=\"\">2020</a>; Bai et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib3\" title=\"\">2023</a>; Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib33\" title=\"\">2024</a>)</cite>, and evaluation resources <cite class=\"ltx_cite ltx_citemacro_citep\">(e.g.  Xu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib63\" title=\"\">2020</a>; Xiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib60\" title=\"\">2021</a>)</cite>.\nThus, as highlighted in Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S1\" title=\"1. Introduction &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, prior work have used varying degrees of transfer from models with Mandarin knowledge to perform downstream tasks in Cantonese <cite class=\"ltx_cite ltx_citemacro_citep\">(Li et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib29\" title=\"\">2019</a>; Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>; Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "transfer",
                    "across",
                    "models",
                    "chung",
                    "shing",
                    "tasks",
                    "devlin"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Transfer learning is a common strategy in deep learning (DL) to address data sparsity, where features or signal learned from a resource-rich domain is used to augment a low-resource domain, task, or dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Bengio, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib4\" title=\"\">2012</a>)</cite>.\nIn the context of NLP, a common application of transfer learning is in cross-lingual transfer for low-resource languages <cite class=\"ltx_cite ltx_citemacro_cite\">Ruder et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib48\" title=\"\">2019</a>); Conneau et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib10\" title=\"\">2020</a>)</cite>.\nTwo types of cross-lingual transfer exists: model transfer and data transfer, as described in <cite class=\"ltx_cite ltx_citemacro_citet\">Garc&#237;a-Ferrero et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib16\" title=\"\">2022</a>)</cite>.\nData transfer involves translating a dataset or corpus from a high-resource language to a lesser-resourced target language, as performed in <span class=\"ltx_text ltx_font_typewriter\">yue-all-nli</span> <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite>, the MMLU <cite class=\"ltx_cite ltx_citemacro_citep\">(Hendrycks et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib18\" title=\"\">2021</a>)</cite> portion of the HKCanto-Eval benchmark <cite class=\"ltx_cite ltx_citemacro_citep\">(Cheng et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>)</cite>, and Yue benchmarks from <cite class=\"ltx_cite ltx_citemacro_citet\">Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "transfer",
                    "shing",
                    "model",
                    "chung"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">On the other hand, model transfer involves adapting models trained on a high-resource source language to a lesser-resourced target language, such as Mandarin to Cantonese and Danish to Faroese <cite class=\"ltx_cite ltx_citemacro_citep\">(Sn&#230;bjarnarson et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib50\" title=\"\">2023</a>)</cite>.\nModel transfer relies on the lexical or typological similarity between the two languages, thereby enabling the transfer of linguistic knowledge <cite class=\"ltx_cite ltx_citemacro_cite\">Khan et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib22\" title=\"\">2025</a>)</cite>.\nWhile some implementations of cross-lingual transfer explicitly designate a source language for cross-lingual transfer <cite class=\"ltx_cite ltx_citemacro_citep\">(Sn&#230;bjarnarson et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib50\" title=\"\">2023</a>; Thangaraj et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib54\" title=\"\">2024</a>)</cite>, others rely on multilingual models.\nRather than transferring from a specific source language, such models are thought to capture general cross-linguistic patterns that extend beyond typological or lexical similarity, allowing them to perform reasonably well even on unseen or low-resource languages <cite class=\"ltx_cite ltx_citemacro_citep\">(Conneau et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib10\" title=\"\">2020</a>; Scivetti et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib49\" title=\"\">2025</a>)</cite>.\nHybrid approaches combine both paradigms: they begin with a multilingual model, then continue pre-training or fine-tuning on a specific target language before applying the resulting model to downstream tasks <cite class=\"ltx_cite ltx_citemacro_citep\">(Protasov et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib47\" title=\"\">2024</a>; Manafi and Krishnaswamy, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib40\" title=\"\">2024</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "transfer",
                    "models",
                    "tasks",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Due to the richness of Mandarin language resources and the strong performance of Mandarin PLMs and LLMs, most cross-lingual transfer to Cantonese use Mandarin as the source language <cite class=\"ltx_cite ltx_citemacro_citep\">(Li et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib29\" title=\"\">2019</a>; Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib34\" title=\"\">2022</a>; Luo et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib38\" title=\"\">2021</a>; Suen et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib52\" title=\"\">2024</a>; Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>)</cite>, with exceptions using a multilingual model <cite class=\"ltx_cite ltx_citemacro_citep\">(e.g. Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "transfer",
                    "performance",
                    "chung",
                    "shing",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">However, there is emerging work suggesting limitations in models&#8217; ability to capture Cantonese idiosyncrasies.\nFactors previously identified include substantial dissimilarities in lexicon, syntax and writing systems <cite class=\"ltx_cite ltx_citemacro_cite\">Suen et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib52\" title=\"\">2024</a>)</cite>, along with the prevalence of colloquial phrases and code-switching in more recent Cantonese corpora <cite class=\"ltx_cite ltx_citemacro_cite\">Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite>.\nThese issues hinder the ability of Mandarin-trained models in Cantonese <cite class=\"ltx_cite ltx_citemacro_cite\">Xiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib61\" title=\"\">2024</a>)</cite> due to over-reliance on Mandarin linguistic knowledge <cite class=\"ltx_cite ltx_citemacro_cite\">Cheng et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "models"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Cantonese diverges from Mandarin in word order, particle and grammatical word inventory, and morphology, as highlighted in theoretical linguistics work <cite class=\"ltx_cite ltx_citemacro_citep\">(Matthews, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib41\" title=\"\">2006</a>; Yap and Chor, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib64\" title=\"\">2011</a>; Matthews and Yip, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib42\" title=\"\">2011</a>)</cite> as well as prior work in Cantonese-Mandarin machine translation and corpus linguistics <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib67\" title=\"\">1998</a>; Lam, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib24\" title=\"\">2020</a>; Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib35\" title=\"\">2025</a>)</cite>.\nFor example, in double object constructions, Mandarin takes the direct-indirect order as seen in (1), while Cantonese takes the indirect-direct order as seen in (2) <cite class=\"ltx_cite ltx_citemacro_citep\">(Matthews and Yip, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib42\" title=\"\">2011</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Cantonese also features a substantially larger and more diverse inventory of particles and aspect markers than Mandarin, enabling speakers to encode subtle distinctions of tense, stance, and speaker attitude\n<cite class=\"ltx_cite ltx_citemacro_citep\">(Yap and Chor, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib64\" title=\"\">2011</a>; Matthews and Yip, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib42\" title=\"\">2011</a>)</cite>.\nCantonese morphology is more flexible, with more frequent verb serialization <cite class=\"ltx_cite ltx_citemacro_citep\">(Matthews, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib41\" title=\"\">2006</a>)</cite> and reduplication <cite class=\"ltx_cite ltx_citemacro_citep\">(Lee, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib27\" title=\"\">2020</a>; Lam, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib24\" title=\"\">2020</a>)</cite> than in Mandarin.\nThis allows sequences such as (3), sourced from <cite class=\"ltx_cite ltx_citemacro_citet\">O&#8217;Melia (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib45\" title=\"\">1965</a>)</cite>, where three verbs combine to describe one scene and (4), where reduplicating the classifier (counting noun) yields an <span class=\"ltx_text ltx_font_italic\">every</span> quantifier.\nGiven such unique properties of Cantonese grammar, availability of high-quality Cantonese data is critical to performing well on Cantonese linguistic tasks.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "tasks"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Although widely considered low-resource, recent efforts have begun to address scarcity in Cantonese language resources.\nMachine-translations of non-Cantonese resources may offer potential utility as data transfer, as provided by <cite class=\"ltx_cite ltx_citemacro_citet\">Chung&#160;Shing (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite> for Cantonese natural language inference (NLI) and <cite class=\"ltx_cite ltx_citemacro_citet\">Cheng et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>); Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite> for LLM knowledge evaluation.\nFoundational tools such as PyCantonese <cite class=\"ltx_cite ltx_citemacro_citep\">(Lee et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib26\" title=\"\">2022</a>)</cite> provide <span class=\"ltx_text ltx_font_typewriter\">NLTK</span>-like <cite class=\"ltx_cite ltx_citemacro_citep\">(Bird and Loper, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib5\" title=\"\">2004</a>)</cite> essential language processing utilities, while a Cantonese Universal Dependencies dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>)</cite> offers a small yet significant syntactically annotated treebank.\nMultilingual resources such as Wikipedia <cite class=\"ltx_cite ltx_citemacro_citep\">(Foundation, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib15\" title=\"\">2023</a>)</cite>, SIB-200 <cite class=\"ltx_cite ltx_citemacro_citep\">(Adelani et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib1\" title=\"\">2024</a>)</cite>, and NLLB <cite class=\"ltx_cite ltx_citemacro_citep\">(NLLB Team et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib43\" title=\"\">2024</a>)</cite> include Cantonese portions, which may be useful for representation learning or evaluation in topic classification and multilingual translation.\nLarger-scale corpora such as YueData <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite> have also emerged, though they often contain substantial portions of non-Cantonese text.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "transfer",
                    "nli",
                    "chung",
                    "offer",
                    "shing"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">On the modeling side, prior work has explored both general-purpose and Cantonese-specific pretrained models.\nWhile commercial multilingual models such as Qwen <cite class=\"ltx_cite ltx_citemacro_citep\">(Bai et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib3\" title=\"\">2023</a>)</cite> and DeepSeek <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib33\" title=\"\">2024</a>)</cite> provide Cantonese support, their Cantonese proficiency lags behind that in English or Mandarin <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite>.\n<cite class=\"ltx_cite ltx_citemacro_citet\">Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite> use their <span class=\"ltx_text ltx_font_typewriter\">YueData</span> corpus to train <span class=\"ltx_text ltx_font_typewriter\">YueTung-7b</span>, a continually pre-trained model based on a Qwen-7B model <cite class=\"ltx_cite ltx_citemacro_citep\">(Bai et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib3\" title=\"\">2023</a>)</cite>, which exhibit improved Cantonese performance compared to other open-source and commercial LLMs.\nOn the smaller end in terms of the number of parameters, <cite class=\"ltx_cite ltx_citemacro_citet\">Chung&#160;Shing (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>)</cite> represents the only encoder-only Cantonese model to our knowledge.\nIt is continually pre-trained <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> on Cantonese news articles, social media posts, and web pages on.\nImplementation details, training recipes, and corpora selection for <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> and <span class=\"ltx_text ltx_font_typewriter\">bert-base-cantonese</span> are both obscure as neither model provides a description paper or technical report. In particular, <cite class=\"ltx_cite ltx_citemacro_citet\">Devlin et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite> describes the BERT architecture in general but not the Chinese model.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "performance",
                    "bertbasecantonese",
                    "models",
                    "bertbasechinese",
                    "chung",
                    "shing",
                    "devlin",
                    "our",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Although we have described Cantonese benchmarks HKCanto-Eval <cite class=\"ltx_cite ltx_citemacro_citep\">(Cheng et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>)</cite> and Yue-Benchmark <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib20\" title=\"\">2025a</a>)</cite> as related work, we wish to clarify our contributions to Cantonese benchmarking in comparison to these two benchmarks.\nWhile HKCanto-Eval includes OpenRice <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib68\" title=\"\">2011</a>)</cite> as a SA dataset, which overlaps with our <span class=\"ltx_text ltx_font_smallcaps\">CantoNLU</span>, along with minor datasets in Cantonese phonology and orthography, HKCanto-Eval and Yue-Benchmark primarily target generative LLMs on general world knowledge and reasoning, in a comparable way to MMLU <cite class=\"ltx_cite ltx_citemacro_citep\">(Hendrycks et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib18\" title=\"\">2021</a>)</cite>.\nWe highlight <span class=\"ltx_text ltx_font_smallcaps\">CantoNLU</span>&#8217;s focus on discriminative NLU tasks, explicitly evaluating a model&#8217;s ability to understand the Cantonese lexicon (WSD), syntax (POS, DEPS), semantics (NLI, SA), and overall well-formedness with respect to both syntax and semantics (LAJ).\nThe focus is similar to those of GLUE <cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib55\" title=\"\">2018</a>)</cite> and its derivatives&#8211;in Korean <cite class=\"ltx_cite ltx_citemacro_citep\">(Park et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib46\" title=\"\">2021</a>)</cite>, Chinese <cite class=\"ltx_cite ltx_citemacro_citep\">(Xu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib63\" title=\"\">2020</a>)</cite>, Vietnamese <cite class=\"ltx_cite ltx_citemacro_citep\">(Do et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib13\" title=\"\">2024</a>)</cite>, and Indonesian <cite class=\"ltx_cite ltx_citemacro_citep\">(Wilie et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib57\" title=\"\">2020</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "laj",
                    "wsd",
                    "nli",
                    "comparison",
                    "pos",
                    "deps",
                    "tasks",
                    "nlu",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We introduce a benchmark of seven Cantonese NLU tasks, encompassing word sense disambiguation (WSD), linguistic acceptability judgment (LAJ), language detection (LD), natural language inference (NLI), sentiment analysis (SA), part-of-speech tagging (POS), and dependency parsing (DEPS).\nWhile all tasks require Cantonese proficiency, tasks such as LD may reward Mandarin knowledge, whereas tasks such as DEPS and WSD may penalize Mandarin knowledge.\nWSD, LAJ, and LD datasets are novel contributions to Cantonese NLU.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "laj",
                    "wsd",
                    "nli",
                    "pos",
                    "deps",
                    "tasks",
                    "nlu"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">First, we manually compile Cantonese words with more than one attested meaning to create the first Cantonese word sense disambiguation dataset.\nWe collect the words&#8217; multiples senses and two example sentences for each sense, resulting in 41 multi-sense words with a total of 109 senses.\nFor each sense, there are least 2 example sentences containing the word.\nThe dataset does not require fine-tuning for evaluation&#8212;model predictions are obtained by masking the target word in each sentence and comparing cosine similarities between the hidden representations at the mask position.\nFor each target word <math alttext=\"w\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS0.SSS0.Px1.p1.m1\" intent=\":literal\"><semantics><mi>w</mi><annotation encoding=\"application/x-tex\">w</annotation></semantics></math> with two contexts <math alttext=\"s_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS0.SSS0.Px1.p1.m2\" intent=\":literal\"><semantics><msub><mi>s</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">s_{i}</annotation></semantics></math> and <math alttext=\"s_{j}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS0.SSS0.Px1.p1.m3\" intent=\":literal\"><semantics><msub><mi>s</mi><mi>j</mi></msub><annotation encoding=\"application/x-tex\">s_{j}</annotation></semantics></math>, we obtain hidden representations\nfor each at the masked position from the model <math alttext=\"\\mathbf{h}_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS0.SSS0.Px1.p1.m4\" intent=\":literal\"><semantics><msub><mi>&#119841;</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">\\mathbf{h}_{i}</annotation></semantics></math> and <math alttext=\"\\mathbf{h}_{j}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS0.SSS0.Px1.p1.m5\" intent=\":literal\"><semantics><msub><mi>&#119841;</mi><mi>j</mi></msub><annotation encoding=\"application/x-tex\">\\mathbf{h}_{j}</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LAJ is a classification task, where the model predicts whether the given sequence is linguistically acceptable.\nThis often aligns with grammatical judgment acceptability, but may also include judgment on semantic plausibility or pragmatic felicity.\nWe compile the first Cantonese LAJ dataset by adapting the Cantonese portion of <span class=\"ltx_text ltx_font_smallcaps\">SiniticMTError</span> <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib35\" title=\"\">2025</a>)</cite>, a dataset of Sinitic translation error span annotations, where each datapoint consists of a well-formed reference sentence <span class=\"ltx_text ltx_font_typewriter\">ref</span>, a machine translated sentence <span class=\"ltx_text ltx_font_typewriter\">mt</span>, and annotations of errors in the <span class=\"ltx_text ltx_font_typewriter\">mt</span> sentence.\nWe consider error-free <span class=\"ltx_text ltx_font_typewriter\">ref</span> as acceptable, <span class=\"ltx_text ltx_font_typewriter\">mt</span> with error annotations not acceptable, to create pairs with one acceptable and one not acceptable versions of the same sentence.\nUnlike previous LAJ datasets such as CoLA <cite class=\"ltx_cite ltx_citemacro_citep\">(Warstadt et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib56\" title=\"\">2019</a>)</cite>, which asks for a binary acceptable-not acceptable judgment, we implement a more robust setup of providing two versions of the same sentence and asking for a more acceptable version as is preferred in psycholinguistics and cognitive science <cite class=\"ltx_cite ltx_citemacro_citep\">(Mahowald et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib39\" title=\"\">2016</a>; Linzen and Oseki, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib32\" title=\"\">2018</a>)</cite>.\nThe dataset consists of 1.6k pairs.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "model",
                    "laj"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Language Detection (LD) is a three-label classification task that identifies whether a given sentence is written in Cantonese, Mandarin, or mixed.\nWe construct the novel dataset from the parallel translation corpus of <cite class=\"ltx_cite ltx_citemacro_citet\">Dai et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib11\" title=\"\">2025</a>)</cite>, selecting the first 10,000 sentence pairs.\nTo create mixed-language examples, we randomly replace tokens in Cantonese and Mandarin sentences with their counterparts from the other language with a set probability.\nIn a given mixed sentence, 15%, 33%, 50% of the sentence may be from the other language, thus producing up to 6 mixed sentences for each pair.\nWord-level alignments are obtained using SimAlign <cite class=\"ltx_cite ltx_citemacro_citep\">(Jalili&#160;Sabet et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib19\" title=\"\">2020</a>)</cite>, and all text is converted to traditional orthography using HanziConv <cite class=\"ltx_cite ltx_citemacro_citep\">(Yue and Gallant, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib66\" title=\"\">2014</a>)</cite> to prevent script-based shallow heuristics.\nThe resulting dataset contains 47,578 sentences, of which 27,578 are mixed.\nWe reserve 5% each for the validation and testing splits.\nWe note that this task requires proficiency in both Mandarin and Cantonese to perform well.\n</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">NLI is a classification task where the model is asked to predict whether the premise entails, or implies the truth of, the hypothesis.\nThe NLI portion of our benchmark is the <span class=\"ltx_text ltx_font_typewriter\">yue-nli-all</span> dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite>, which is a machine translation of English NLI datasets SNLI <cite class=\"ltx_cite ltx_citemacro_citep\">(Bowman et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib6\" title=\"\">2015</a>)</cite> and MNLI <cite class=\"ltx_cite ltx_citemacro_citep\">(Williams et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib58\" title=\"\">2018</a>)</cite> into Cantonese.\nThe dataset comprises of 557k train examples, 6.6k development examples, and 6.6k test examples.\nEach example includes a reference premise and two hypotheses, one entailing and one contradicting, from which we create two examples with each label.\nThis results in a balanced, two-label classification dataset.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "nli",
                    "chung",
                    "shing",
                    "our",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Finally, POS and DEPS are both token-level classification tasks.\nA POS model predicts the part-of-speech tag (e.g. noun, verb, etc.) of a given word, while a DEPS model predicts the dependency head (answering, which word is the syntactic head of this word?) and dependency type (answering, what is the relationship between this word and its head?) of the given word.\nFor POS and DEPS, we use the Cantonese-HK Universal Dependency dataset <cite class=\"ltx_cite ltx_citemacro_citep\">(Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>)</cite>, which comprises of 1k sentences and 14k tokens.\nWe split the dataset 9:1 for training and testing, respectively.\nThe dataset contains 15 POS tags and 48 dependency relations, of which 17 are specific to Cantonese.\nWe report both unlabeled (UAS) and labeled attachment scores (LAS) to measure DEPS performance.\n</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "performance",
                    "las",
                    "pos",
                    "deps",
                    "tasks",
                    "model",
                    "uas"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Using the compiled Cantonese NLU benchmark, we evaluate three types of models&#8211;Cantonese monolingual, Cantonese-adapted from Mandarin, and Mandarin.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "nlu",
                    "cantoneseadapted",
                    "monolingual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For those requiring training or adaptation into Cantonese, we use two corpora: the Cantonese Wikipedia <cite class=\"ltx_cite ltx_citemacro_citep\">(Foundation, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib15\" title=\"\">2023</a>)</cite> and a list of 30 million Cantonese sentences compiled by <cite class=\"ltx_cite ltx_citemacro_citet\">Kwok (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib23\" title=\"\">2024</a>)</cite>.\nThe two corpora are the publicly available and open-source subset of YueData <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>.\nThe Wikipedia dump includes empty parentheses from their pre-processing stage that removes text in other languages.\nFor example, (5) becomes (6), whose process often yields parentheses that are either empty or only contain punctuation marks.\nWe remove them.\nThen, the corpora are divided into excerpts of maximum length 128 for pre-training.\nThe Cantonese Wikipedia contains 137k articles, totaling 40M characters, while <cite class=\"ltx_cite ltx_citemacro_citet\">Kwok (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib23\" title=\"\">2024</a>)</cite> contains 30M sentences, totaling 660M characters.\nIn total, the pre-training corpora consists of 700M characters.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "adaptation"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">&#38651;&#24433;&#65288;&#33521;&#35486;&#65306;movie/ film&#65289;&#65292;&#29305;&#28857;&#26159;&#36816;&#21160;&#65295;&#31227;&#21160;&#30340;&#30011;&#38754;&#65288;&#33521;&#35486;&#65306;motion/ moving picture)<span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>The illustrated example is from Mandarin, due to LaTeX compilers&#8217; difficulty with Cantonese text.</span></span></span>\n<br class=\"ltx_break\"/></p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Cantonese-adapted model represents the most common text processing effort in Cantonese, taking an existing model with Mandarin support and performing continued pre-training on Cantonese before applying the adapted text or speech model to downstream tasks <cite class=\"ltx_cite ltx_citemacro_citep\">(Luo et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib38\" title=\"\">2021</a>; Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>; Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>.\nIn our implementation, we take the off-the-shelf <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> model <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite><span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_tag ltx_tag_note\">3</span>The citation is attributable to the <span class=\"ltx_text ltx_font_typewriter\">bert</span> language model as a whole; it does not include implementation details on <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span>.</span></span></span> and continually pre-train on Cantonese text described above.\nWe do not make any changes to the model&#8217;s tokenizer.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "bertbasechinese",
                    "model",
                    "chung",
                    "shing",
                    "tasks",
                    "devlin",
                    "our",
                    "cantoneseadapted"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In addition, we offer a comparison to a concurrent BERT-based Cantonese work in <span class=\"ltx_text ltx_font_typewriter\">bert-base-cantonese</span> <cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib8\" title=\"\">2024</a>)</cite>, also a continually pre-trained model, but on a close-source corpus of news articles, social media posts, and web content.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "comparison",
                    "chung",
                    "offer",
                    "shing",
                    "bertbasecantonese",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Direct transfer from Mandarin without conditioning on Cantonese also represents a small subset of Cantonese NLP efforts <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib34\" title=\"\">2022</a>; Li, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib31\" title=\"\">2024</a>)</cite>, including evaluating non-Cantonese trained multi-lingual LLMs such as Llama models on Cantonese knowledge benchmarks <cite class=\"ltx_cite ltx_citemacro_citep\">(Cheng et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib7\" title=\"\">2025</a>)</cite>.\nWe employ <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite> as a model representing direct transfer from Mandarin, and fine-tune the model on the downstream tasks without additional conditioning on Cantonese text.\nWe do not make any changes to the model&#8217;s tokenizer.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "transfer",
                    "models",
                    "bertbasechinese",
                    "tasks",
                    "devlin",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We train a monolingual Cantonese model from scratch using the BERT architecture <cite class=\"ltx_cite ltx_citemacro_cite\">Devlin et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite>.\nWhile previous work in Cantonese language modeling have incorporated additional datasets <cite class=\"ltx_cite ltx_citemacro_citep\">(Jiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>, many of them are proprietary, may include non-Cantonese text, or may not be freely used as pointed out by <cite class=\"ltx_cite ltx_citemacro_citet\">Xiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib61\" title=\"\">2024</a>)</cite>.\nThus, similar to the Cantonese-adapted model, we train a monolingual Cantonese model using the publicly available Cantonese Wikipedia dump <cite class=\"ltx_cite ltx_citemacro_citep\">(Foundation, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib15\" title=\"\">2023</a>)</cite> and the <span class=\"ltx_text ltx_font_typewriter\">cantonese-sentences</span> corpus <cite class=\"ltx_cite ltx_citemacro_citep\">(Kwok, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib23\" title=\"\">2024</a>)</cite>.\nThe amount of data, totaling 700M characters, is an order of magnitude smaller than what was used to train <span class=\"ltx_text ltx_font_typewriter\">bert-base-uncased</span> at 3.3B words <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite>.\nWe are unable to make an exact comparison to <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> as training details of the model are not publicly available, although we suspect the Mandarin Wikipedia dump was used for a part of its training, which consists of around 1 million articles (cf. 137k articles for Cantonese) at the time of <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> training.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "bertbasechinese",
                    "model",
                    "comparison",
                    "devlin",
                    "cantoneseadapted",
                    "monolingual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For the monolingual model, we train a sentencepiece byte-pair encoding tokenizer on the same data to obtain a Cantonese-only tokenizer.\nUnlike the tokenizer from <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> which only includes 8k tokens of character length 1, the Cantonese tokenizer captures subword structure by including around 32k tokens, of which 27k are multi-character tokens. Moreover, a high overlap in lexicons is maintained, with 4.8k characters being represented in both <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> and our Cantonese tokenizer.\nWhile we expected greater coverage of Cantonese-only characters from Hong Kong Supplementary Character Set (HKSCS), this is not the case as <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span>&#8217;s tokenizer boasts a greater coverage with 603 characters, while our tokenizer covers only 233 characters in HKSCS.\nThis result reflects the relative scarcity of Cantonese-specific data compared to the abundant Mandarin data available.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "bertbasechinese",
                    "our",
                    "model",
                    "monolingual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Each model is fine-tuned on the training split of the downstream NLU task, then evaluated on the test split of the same task with the exception of LAJ and WSD which use model surprisal without fine-tuning.\nWe report accuracy metrics for NLI, LAJ, WSD; F1 metrics for POS, LD and SA; and UAS and LAS for DEPS.\nFollowing NLU convention <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite>, we do not freeze model weights and allow them to be updated during fine-tuning.\nWe report task-specific hyperparameter choice during fine-tuning in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5.T2\" title=\"Table 2 &#8227; Monolingual Cantonese model. &#8227; 5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>.</p>\n\n",
                "matched_terms": [
                    "laj",
                    "wsd",
                    "nli",
                    "pos",
                    "las",
                    "deps",
                    "devlin",
                    "nlu",
                    "model",
                    "uas"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Supporting the empirical success of Mandarin-to-Cantonese transfer seen in contemporary Cantonese NLP, Cantonese-adapted Mandarin models offer the strongest performance with a task-averaged score of 69.4 (<span class=\"ltx_text ltx_font_typewriter\">bert-base-cantonese</span>) and 68.0 (our open-source transfer model).\nWhile the monolingual model excels in syntactic tasks POS and DEPS, its average score of 65.1 lags behind those the Cantonese-adapted and Mandarin models.\nWe attribute this primarily to the small size of our Cantonese pretraining corpus (roughly 700M characters).\nAs discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5\" title=\"5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, this is an order of magnitude smaller than the datasets used to train comparable English or Mandarin models, and therefore insufficient for learning robust linguistic representations from scratch.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "transfer",
                    "performance",
                    "bertbasecantonese",
                    "models",
                    "model",
                    "pos",
                    "offer",
                    "deps",
                    "tasks",
                    "our",
                    "cantoneseadapted",
                    "monolingual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Interestingly, <span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> achieves comparable, or in some cases, superior performance to its Cantonese-adapted and Cantonese-monolingual counterparts with an average score of 68.1.\nWhen scholars discuss mutual intelligibility among Sinitic languages, they typically refer to the spoken form <cite class=\"ltx_cite ltx_citemacro_citep\">(Tang and van Heuven, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib53\" title=\"\">2007</a>; Gooskens and Van&#160;Heuven, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib17\" title=\"\">2021</a>)</cite>.\nHowever, written Sinitic languages are far more mutually intelligible, given the historical influence of Mandarin as the dominant language of education and literacy across Chinese-speaking regions <cite class=\"ltx_cite ltx_citemacro_citep\">(Snow, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib51\" title=\"\">2004</a>; Xiang et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib61\" title=\"\">2024</a>)</cite>.\nThis suggests that effective written Cantonese understanding can emerge from training on Mandarin text without explicit exposure to Cantonese text, as also observed in <cite class=\"ltx_cite ltx_citemacro_citet\">Jiang et&#160;al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib21\" title=\"\">2025b</a>)</cite>, where LLMs without explicit Cantonese support perform relatively well on Cantonese and Hong Kong-related knowledge benchmarks.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "across",
                    "performance",
                    "bertbasechinese",
                    "cantoneseadapted"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While models achieve respectable performance on NLI, POS tagging, and lexical disambiguation, dependency parsing remains notably weak&#8212;likely due to both the small fine-tuning dataset of around 1k sentences and the inherent difficulty of the task.\nNonetheless, dependency parsing for other low-resource languages such as Buryat <cite class=\"ltx_cite ltx_citemacro_citep\">(Badmaeva and Tyers, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib2\" title=\"\">2017</a>)</cite> and Old English <cite class=\"ltx_cite ltx_citemacro_citep\">(Levine et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib28\" title=\"\">2025</a>)</cite> has reached higher performance with smaller datasets, suggesting that current Cantonese representations still lack sufficient syntactic and semantic grounding.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "performance",
                    "models",
                    "nli",
                    "pos"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While we proposes a novel evaluation framework and recommend insights into Cantonese representation learning, several limitations remain.\nFirst, the size and coverage of available Cantonese corpora significantly constrain our results.\nOur monolingual Cantonese model was trained on roughly 700M characters, an order of magnitude smaller than corpora typically used to pre-train large language models in other major languages <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite>.\nThis data sparsity likely limits the model&#8217;s ability to capture the full lexical and semantic diversity of written Cantonese, and may explain the comparatively weaker performance of the monolingual model in semantic tasks. Future work would benefit from expanding and diversifying Cantonese text resources, especially in informal and user-generated domains that reflect contemporary usage.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "performance",
                    "models",
                    "tasks",
                    "devlin",
                    "our",
                    "model",
                    "monolingual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Second, our evaluation benchmark, though designed to cover multiple aspects of Cantonese NLU, is itself constrained by data availability. Some tasks, such as dependency parsing (DEPS), rely on small fine-tuning datasets <cite class=\"ltx_cite ltx_citemacro_citep\">(Wong et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib59\" title=\"\">2017</a>)</cite>, making the results more susceptible to statistical noise and limiting generalization. In addition, the benchmark focuses on written Cantonese and does not address spoken or colloquial aspects of the language such as code-switching <cite class=\"ltx_cite ltx_citemacro_citep\">(Yim and Bialystok, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib65\" title=\"\">2012</a>)</cite> or informal register in-depth; these aspects are integral to Cantonese as it is a primarily spoken language <cite class=\"ltx_cite ltx_citemacro_citep\">(Snow, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib51\" title=\"\">2004</a>)</cite>.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "deps",
                    "tasks",
                    "nlu",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">As a result, while our findings suggest that Mandarin-to-Cantonese transfer is effective for semantic tasks and Mandarin models perform sufficiently well, they should be interpreted as a reflection of current data and resource disparities, rather than representative features of Mandarin and Cantonese.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "transfer",
                    "models",
                    "tasks",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we describe a benchmark of Cantonese NLU tasks, and evaluate a monolingual Cantonese model, two transfer models from Mandarin, and a Mandarin model on said Cantonese benchmark to investigate contexts where each type of model is most effective.\nOur results indicate that both Cantonese monolingual models and Cantonese-adapted models with cross-lingual transfer from Mandarin both have merit for Cantonese NLP in today&#8217;s landscape of language resources.\nIn addition, direct transfer from a Mandarin model without Cantonese representation learning may suffice for some tasks.\nOur findings also suggest that the existing open-source Cantonese corpora are insufficient to train a reliable representation of Cantonese lexicon, syntax, and semantics.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "transfer",
                    "models",
                    "model",
                    "tasks",
                    "nlu",
                    "our",
                    "cantoneseadapted",
                    "monolingual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our benchmark and analyses provide the first systematic investigation into and evidence of whether and how transfer from Mandarin is effective for performing Cantonese linguistic tasks.\nBy establishing a framework and pipeline for training monolingual or transfer models and evaluating them, we hope to catalyze broader progress in the space of Cantonese NLP.</p>\n\n",
                "matched_terms": [
                    "cantonese",
                    "mandarin",
                    "transfer",
                    "models",
                    "tasks",
                    "our",
                    "monolingual"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We make use of a variety of Cantonese NLP and language resources.\nIn addition to our discussion of them in Sections <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S3\" title=\"3. Related Work &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S4\" title=\"4. Building CantoNLU &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, and <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#S5\" title=\"5. Experimental Benchmark Setup &#8227; CantoNLU: A benchmark for Cantonese natural language understanding\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>,\nwe acknowledge their use and organize them below.</p>\n\n",
                "matched_terms": [
                    "our",
                    "cantonese"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_typewriter\">bert-base-chinese</span> <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"huggingface.co/google-bert/bert-base-chinese\" title=\"\">huggingface.co/google-bert/bert-base-chinese</a>\n<cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib12\" title=\"\">2019</a>)</cite></p>\n\n",
                "matched_terms": [
                    "bertbasechinese",
                    "devlin"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_typewriter\">Yue-All-NLI</span>\n<a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"huggingface.co/datasets/hon9kon9ize/yue-all-nli\" title=\"\">huggingface.co/datasets/hon9kon9ize/yue-all-nli</a>\n<cite class=\"ltx_cite ltx_citemacro_citep\">(Chung&#160;Shing, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.20670v1#bib.bib9\" title=\"\">2025</a>)</cite></p>\n\n",
                "matched_terms": [
                    "shing",
                    "chung"
                ]
            }
        ]
    }
}