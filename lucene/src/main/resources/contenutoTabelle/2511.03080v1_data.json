{
    "S2.T1": {
        "source_file": "PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech",
        "caption": "Table 1: List of 27 text normalization categories used for multilingual data construction.",
        "body": "List of Text Normalization Categories\n\n\n\n\nCardinal\n\n\n\n\nDate\n\n\n\n\n\n\nDecimal\n\n\n\n\nOrdinal\n\n\n\n\n\n\nFraction\n\n\n\n\nTime\n\n\n\n\n\n\nCurrency\n\n\n\n\nUnit (Measure)\n\n\n\n\n\n\nAddress\n\n\n\n\nAcronym/Initialism\n\n\n\n\n\n\nISBN\n\n\n\n\nBiological Classification\n\n\n\n\n\n\nRoman Numeral\n\n\n\n\nTelephone\n\n\n\n\n\n\nSports Score\n\n\n\n\nMathematical Expression\n\n\n\n\n\n\nSymbol\n\n\n\n\nAbbreviations\n\n\n\n\n\n\nChemical Formula\n\n\n\n\nLegal Reference\n\n\n\n\n\n\nVehicle/Product Code\n\n\n\n\nGeographic Coordinates\n\n\n\n\n\n\nVersion Number\n\n\n\n\nLicense/Serial Number\n\n\n\n\n\n\nMusical Notation\n\n\n\n\nStock Ticker\n\n\n\n\n\n\nElectronic (URL/Email)",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_align_top ltx_border_tt\" colspan=\"2\"><span class=\"ltx_text ltx_font_bold\">List of Text Normalization Categories</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Cardinal</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Date</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Decimal</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Ordinal</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Fraction</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Time</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Currency</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Unit (Measure)</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Address</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Acronym/Initialism</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">ISBN</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Biological Classification</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Roman Numeral</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Telephone</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Sports Score</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Mathematical Expression</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Symbol</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Abbreviations</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Chemical Formula</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Legal Reference</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Vehicle/Product Code</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Geographic Coordinates</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Version Number</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">License/Serial Number</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Musical Notation</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Stock Ticker</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:195.1pt;\">Electronic (URL/Email)</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_top ltx_border_bb\"/>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "fraction",
            "abbreviations",
            "notation",
            "electronic",
            "roman",
            "code",
            "ticker",
            "data",
            "licenseserial",
            "multilingual",
            "classification",
            "expression",
            "categories",
            "used",
            "time",
            "cardinal",
            "reference",
            "musical",
            "text",
            "mathematical",
            "currency",
            "telephone",
            "geographic",
            "decimal",
            "legal",
            "version",
            "address",
            "urlemail",
            "ordinal",
            "normalization",
            "chemical",
            "sports",
            "score",
            "symbol",
            "coordinates",
            "number",
            "unit",
            "biological",
            "numeral",
            "measure",
            "formula",
            "stock",
            "date",
            "list",
            "vehicleproduct",
            "acronyminitialism",
            "construction",
            "isbn"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">To address these challenges, we use DeepSeek-R1 <cite class=\"ltx_cite ltx_citemacro_cite\">DeepSeek-AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib1\" title=\"\">2025</a>)</cite> to generate datasets comprising unnormalized and normalized text pairs as our new multilingual benchmark suite, <em class=\"ltx_emph ltx_font_italic\">PolyNorm-Benchmark</em><span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>https://github.com/apple/ml-speech-polynorm-bench</span></span></span>, designed to ensure consistency across languages and taxonomies. Each dataset spans 27 normalization categories (listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S2.T1\" title=\"Table 1 &#8227; 2 Data &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>) built on Kestrel categories and expanded with new classes, comprising 20 examples per category for a total of 540 high-quality data points per language. For Chinese and Japanese, we define abbreviations as truncated forms or initial-letter substitutions, since conventional definitions may not fully capture their use in conversational language.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS) systems, converting written forms into their canonical spoken equivalents. Traditional TN systems can exhibit high accuracy, but involve substantial engineering effort, are difficult to scale, and pose challenges to language coverage, particularly in low-resource settings. We propose PolyNorm, a prompt-based approach to TN using Large Language Models (LLMs), aiming to reduce the reliance on manually crafted rules and enable broader linguistic applicability with minimal human intervention. Additionally, we present a language-agnostic pipeline for automatic data curation and evaluation, designed to facilitate scalable experimentation across diverse languages. Experiments across eight languages show consistent reductions in the word error rate (WER) compared to a production-grade-based system. To support further research, we release PolyNorm-Benchmark, a multilingual data set covering a diverse range of text normalization phenomena.</p>\n\n",
                "matched_terms": [
                    "text",
                    "normalization",
                    "multilingual",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p ltx_align_center\">\n  <span class=\"ltx_text ltx_font_bold\">PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "normalization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">TN transforms written input, often dense with numbers, abbreviations, and special characters, into fluent speech-friendly text. Early TN systems relied primarily on rule-based approaches using weighted finite-state transducers (WFSTs) <cite class=\"ltx_cite ltx_citemacro_cite\">Sproat et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib7\" title=\"\">2001</a>)</cite>. Although such systems have historically achieved high accuracy, they depend heavily on manual rules and extensive human verification, making them expensive and time-consuming to develop and maintain. These challenges are even more pronounced when dealing with low-resource or morphologically rich languages, such as Arabic and Polish <cite class=\"ltx_cite ltx_citemacro_cite\">Mosquera et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib5\" title=\"\">2012</a>); Po&#347;wiata and Pere&#322;kiewicz (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib6\" title=\"\">2019</a>)</cite>, where linguistic diversity complicates the creation of rules. Beyond the scarcity of resources, TN systems must also handle contextual ambiguities that arise within or across languages. The same surface form can be normalized differently depending on both the linguistic context and the target language, as illustrated in Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a><span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>&#8220;&#200; il 17&#176; secolo.&#8221; translates to &#8220;It&#8217;s the 17<sup class=\"ltx_sup\">th</sup> century.&#8221;\n</span></span></span>.</p>\n\n",
                "matched_terms": [
                    "text",
                    "abbreviations"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Later development lead to TN systems that are based on statistical and hybrid data-driven approaches <cite class=\"ltx_cite ltx_citemacro_cite\">Grali&#324;ski et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib4\" title=\"\">2006</a>); Zhu et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib10\" title=\"\">2007</a>); Sproat and Jaitly (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib8\" title=\"\">2016</a>)</cite>. For example, <cite class=\"ltx_cite ltx_citemacro_citet\">Grali&#324;ski et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib4\" title=\"\">2006</a>)</cite> treated TN as a machine translation problem, mapping textual representations into their spoken equivalents, while <cite class=\"ltx_cite ltx_citemacro_citet\">Zhu et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib10\" title=\"\">2007</a>)</cite> introduced a unified tagging approach using Conditional Random Fields (CRF) to simultaneously handle multiple TN subtasks, emphasizing their interdependencies. Recently, large language models (LLMs) have shown great potential in addressing these limitations by leveraging their broad linguistic knowledge. <cite class=\"ltx_cite ltx_citemacro_citet\">Zhang et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib9\" title=\"\">2024</a>)</cite> used GPT models to perform text normalization in few-shot scenarios, incorporating self-consistency reasoning and linguistically informed prompt engineering, achieving error rates approximately 40% lower than those of production-level WFST systems.</p>\n\n",
                "matched_terms": [
                    "text",
                    "used",
                    "normalization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We start with a subset of the English Kestrel dataset <cite class=\"ltx_cite ltx_citemacro_cite\">Ebden and Sproat (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib2\" title=\"\">2015</a>)</cite> comprising 14 Kestrel categories extracted from the first file of the dataset, which contains approximately 880,000 lines. For English, to construct a balanced subset, we select a total of 1,400 test cases, removing all sentences that lack normalization targets and retaining the first 100 examples per category from the Kestrel dataset for benchmarking purposes. We initially experimented with translating both the original and normalized English texts into the target languages with NLLB-200 model <cite class=\"ltx_cite ltx_citemacro_cite\">Facebook AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib3\" title=\"\">2022</a>)</cite>. However, we found most translated texts unsuitable as ground truth due to inconsistent quality, translation and inadequate localization of the normalized forms. In addition, the limited categories do not fully cover the scope of normalization phenomena that we aim to evaluate. Therefore, instead of using the entire subset for benchmarking, we reserved some of the higher-quality data, reviewed and verified by language experts, as part of the prompt examples, which will be discussed in the Methodology section.</p>\n\n",
                "matched_terms": [
                    "categories",
                    "normalization",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The initial outputs of DeepSeek serve as a foundation, then each example is subsequently edited and verified by internal language experts to ensure the highest standards of linguistic precision, naturalness, and overall quality. The orthography and formatting of synthetic data follow the conventions of target languages. For example, in French, decimal separator in currency is written with a comma instead of a period, with the currency symbol after the number:</p>\n\n",
                "matched_terms": [
                    "currency",
                    "symbol",
                    "number",
                    "decimal",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We define a normalization error as any output in which the normalized text deviates from the expected conventional spoken form. For example, rendering &#8220;Dr&#8221; as &#8220;Doctor&#8221; instead of &#8220;Drive&#8221; in an address, or normalizing &#8220;12:30&#8221; as &#8220;twelve thirty AM&#8221; when the time format is ambiguous.</p>\n\n",
                "matched_terms": [
                    "text",
                    "time",
                    "normalization",
                    "address"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We adopt a few-shot prompting strategy using ICL examples to guide the LLM in performing text normalization across all languages. This approach allows the model to generalize from a small number of curated examples across various categories, from numerical expressions to acronyms, eliminating extensive fine-tuning or rule-based engineering.</p>\n\n",
                "matched_terms": [
                    "text",
                    "categories",
                    "number",
                    "normalization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our prompt design follows a structured, step-by-step and language-agnostic format composed of three components: 1) <span class=\"ltx_text ltx_font_bold\">Instruction Prompt</span>, which defines the normalization task, 2) <span class=\"ltx_text ltx_font_bold\">In-Context Learning Examples</span>, which demonstrate how different types of text should be normalized, and 3) <span class=\"ltx_text ltx_font_bold\">Target Unnormalized Input</span>, to which the model applies learned patterns. PolyNorm uses a standardized English instruction prompt with localized ICL examples tailored to each language&#8217;s linguistic and stylistic norms.</p>\n\n",
                "matched_terms": [
                    "text",
                    "normalization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Few-shot prompting with ICL offers a lightweight, scalable solution for multilingual text normalization, relying on high-quality, language-specific examples. The effectiveness of this approach depends on the quality and relevance of the ICL examples provided to the model. We use a unified prompt format across eight languages, varying only the localized examples&#8212;except for Japanese, where a supplementary prompt guides katakana output. Our curated ICL set, excluded from PolyNorm-Bench, includes 80-100 high-quality machine-translated Kestrel data and DeepSeek synthetic examples (e.g., favoring &#8220;twenty nineteen&#8221; over &#8220;two thousand nineteen&#8221; for &#8221;2019&#8221; in English), each normalized and validated by experts to ensure stylistic consistency across domains.</p>\n\n",
                "matched_terms": [
                    "text",
                    "normalization",
                    "multilingual",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We analyzed discrepancies between expert-verified development sets and LLM outputs from GPT models to identify systematic weaknesses. Common errors included incorrect numeral expansions and inconsistent handling of language-specific formats such as date and currency. To address these issues, we identified categories or patterns where the model underperformed, then revised or added ICL examples focused on these error types, improving the model&#8217;s output with each iteration. This feedback loop refined normalization via prompt tuning and better examples, reducing errors and improving cross-lingual consistency.</p>\n\n",
                "matched_terms": [
                    "date",
                    "currency",
                    "numeral",
                    "address",
                    "categories",
                    "normalization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluated GPT-4o-mini and GPT-4o as candidate systems against Apple Siri production rule-based normalization baseline system. Because it is proprietary, we cannot release code or provide external access. However, to help readers judge strength and fairness, we report baseline scores for a representative subset of seven categories across all eight languages in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A3.T4\" title=\"Table 4 &#8227; Appendix C Baseline model WER (%) by Language and Selected Categories &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> below<span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_tag ltx_tag_note\">3</span>Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2.T3\" title=\"Table 3 &#8227; Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> in Appendix <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2\" title=\"Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">B</span></a> shows side-by-side examples illustrating some incorrect baseline outputs</span></span></span>. It is important to note that the baseline predates our benchmark and was not tuned to it.</p>\n\n",
                "matched_terms": [
                    "code",
                    "normalization",
                    "categories"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All systems were tested on PolyNorm across eight languages listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. We report the overall performance with Word Error Rate (WER) and BLEU, which reflects how closely the model&#8217;s output matches the expected spoken form and relative surface similarity to the reference respectively. For non-whitespace languages (Chinese and Japanese), we report Character Error Rate instead of WER to avoid conflating tokenization errors with true normalization errors. PolyNorm demonstrates substantial advantages in terms of flexibility, coverage, and the ability to handle previously intractable normalization challenges with minimal manual human intervention. Results in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> show improvements in both WER and BLEU across the two LLM systems compared to the rule-based baseline. GPT-4o achieves a WER ranging from 4.17% to 7.88% for all languages.</p>\n\n",
                "matched_terms": [
                    "reference",
                    "normalization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We present PolyNorm, a multilingual, LLM-assisted text normalization system designed to address scalability, cost, and language-coverage limitations of rule-based systems. It achieves strong normalization performance across languages and categories, and significantly reduces WER compared to production-grade rule-based systems, demonstrating its robustness and adaptability.</p>\n\n",
                "matched_terms": [
                    "text",
                    "address",
                    "multilingual",
                    "categories",
                    "normalization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This project explores using large language models (LLMs) to automate text normalization&#8212;a key step in processing raw text such as speech transcripts, handwriting, or informal writing. Text normalization standardizes text by handling tasks from formatting dates and numbers to restoring diacritics in accented languages. Our LLM-based system offers a scalable, efficient alternative by combining raw input with tailored prompts and few-shot examples. This approach improves consistency and quality across multiple languages, making it well-suited for applications like text-to-speech, machine translation, and speech recognition.</p>\n\n",
                "matched_terms": [
                    "text",
                    "normalization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LLM-based normalization introduces ethical and safety risks. Because the model learns from large datasets, it may replicate biases in the training data. For example, in gendered languages like Arabic, ambiguous inputs such as &#8220;ant&#8221; (which could mean &#8220;you [masc.]&#8221; or &#8220;you [fem.]&#8221;) might be resolved in biased ways. If unaddressed, such biases can reinforce stereotypes or generate inappropriate outputs. Inaccurate normalization may also mislead learners, reinforce incorrect usage, and reduce trust in downstream systems. Therefore, while PolyNorm offers efficient, multilingual normalization, it must be developed with careful attention to data quality, bias mitigation, and user safety to ensure ethical deployment.</p>\n\n",
                "matched_terms": [
                    "normalization",
                    "multilingual",
                    "data"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While PolyNorm demonstrates strong potential in terms of efficiency and multilingual consistency, the model&#8217;s performance is highly dependent on the quality and representativeness of data used as in-context learning examples. Categories covered in the examples may not capture the full range of normalization needs across different languages and varieties. Furthermore, errors in normalization can propagate into downstream tasks such as translation, sentiment analysis, or educational tools. Although expert-reviewed examples were used for in-context learning, the model may still struggle with edge cases or uncommon linguistic patterns. These limitations must be addressed before considering the system for widespread or critical work.</p>\n\n",
                "matched_terms": [
                    "data",
                    "multilingual",
                    "categories",
                    "used",
                    "normalization"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section presents the instruction prompt template. Note that certain locales include supplementary prompts tailored to their linguistic or stylistic characteristics. In-context learning (ICL) examples are omitted here for brevity.\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>You are an accurate text normalizer for {locale}. Your task is to normalize unstandardized text from the following categories to truly reflects how the real speech is, based on the context:\n<br class=\"ltx_break\"/>- Cardinal \n<br class=\"ltx_break\"/>- Date\n<br class=\"ltx_break\"/>- Decimal\n<br class=\"ltx_break\"/>- Ordinal\n<br class=\"ltx_break\"/>- Fraction\n<br class=\"ltx_break\"/>- Time\n<br class=\"ltx_break\"/>- Currency\n<br class=\"ltx_break\"/>- Unit (Measure)\n<br class=\"ltx_break\"/>- Electronic Address (URL or Email)\n<br class=\"ltx_break\"/>- Initialism or Acronym\n<br class=\"ltx_break\"/>- ISBN\n<br class=\"ltx_break\"/>- Roman Numeral\n<br class=\"ltx_break\"/>- Telephone\n<br class=\"ltx_break\"/>- Sports Score\n<br class=\"ltx_break\"/>- Mathematical Expression\n<br class=\"ltx_break\"/>- Symbol\n<br class=\"ltx_break\"/>- Abbreviation\n<br class=\"ltx_break\"/>- Chemical Formula\n<br class=\"ltx_break\"/>- Legal Reference\n<br class=\"ltx_break\"/>- Vehicle or Product Code\n<br class=\"ltx_break\"/>- Geographic Coordinates\n<br class=\"ltx_break\"/>- Version Number\n<br class=\"ltx_break\"/>- License Plate or Serial Number\n<br class=\"ltx_break\"/>- Musical Notation\n<br class=\"ltx_break\"/>- Stock Ticker\n<br class=\"ltx_break\"/>- Biological Classification\n<br class=\"ltx_break\"/>- Address\n<br class=\"ltx_break\"/>- Other unnormalized text\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>Some important rules: \n<br class=\"ltx_break\"/>- When normalizing acronyms, spell out to their full forms for clarity, except when the acronym is a widely recognized and pronounceable name (e.g. &#8220;NASA&#8221; or &#8220;NASCAR&#8221;). In those cases, keep the acronym as-is and pronounce it as a word. \n<br class=\"ltx_break\"/>- If the acronym combines a letter and a word, split accordingly. \n<br class=\"ltx_break\"/>- Convert punctuation that is spoken aloud into words. For example, write &#8216;dot&#8217; instead of a period in URLs and emails. \n<br class=\"ltx_break\"/>- To ensure clarity, segment compound words, websites and file names into recognizable component words rather than keeping them as a whole word. \n<br class=\"ltx_break\"/>- Symbols in a file name should be read as is. \n<br class=\"ltx_break\"/>- Common file extensions (.jpeg, .jpg, .txt, etc) should be spoken out. Uncommon file extensions should be spelled out. \n<br class=\"ltx_break\"/></p>\n\n",
                "matched_terms": [
                    "fraction",
                    "electronic",
                    "notation",
                    "roman",
                    "code",
                    "ticker",
                    "classification",
                    "expression",
                    "categories",
                    "reference",
                    "cardinal",
                    "time",
                    "text",
                    "mathematical",
                    "currency",
                    "telephone",
                    "geographic",
                    "decimal",
                    "legal",
                    "version",
                    "address",
                    "ordinal",
                    "chemical",
                    "sports",
                    "score",
                    "symbol",
                    "coordinates",
                    "number",
                    "unit",
                    "biological",
                    "numeral",
                    "measure",
                    "formula",
                    "stock",
                    "date",
                    "musical",
                    "isbn"
                ]
            }
        ]
    },
    "S4.T2": {
        "source_file": "PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech",
        "caption": "Table 2: WER and BLEU scores across 8 languages using PolyNorm-Benchmark. Best scores per row are in bold.",
        "body": "Language\nBaseline\nGPT-4o-mini\nGPT-4o\n\n\n\n\n\nWER (%)\n\n\n\n\nBLEU (%)\n\n\n\n\nWER (%)\n\n\n\n\nBLEU (%)\n\n\n\n\nWER (%)\n\n\n\n\nBLEU (%)\n\n\n\n\nGerman\n\n\n10.74\n\n\n\n\n60.83\n\n\n\n\n7.18\n\n\n\n\n78.35\n\n\n\n\n4.17\n\n\n\n\n84.92\n\n\n\n\nAmerican English\n\n\n9.84\n\n\n\n\n70.84\n\n\n\n\n6.60\n\n\n\n\n85.02\n\n\n\n\n4.28\n\n\n\n\n89.85\n\n\n\n\nMexican Spanish\n\n\n11.92\n\n\n\n\n55.74\n\n\n\n\n11.19\n\n\n\n\n62.49\n\n\n\n\n7.69\n\n\n\n\n71.90\n\n\n\n\nFrench\n\n\n9.72\n\n\n\n\n69.02\n\n\n\n\n7.70\n\n\n\n\n79.84\n\n\n\n\n5.65\n\n\n\n\n86.18\n\n\n\n\nItalian\n\n\n15.02\n\n\n\n\n55.14\n\n\n\n\n8.33\n\n\n\n\n72.81\n\n\n\n\n4.56\n\n\n\n\n84.96\n\n\n\n\nLithuanian\n\n\n10.04\n\n\n\n\n67.12\n\n\n\n\n10.54\n\n\n\n\n64.36\n\n\n\n\n6.99\n\n\n\n\n73.96\n\n\n\n\nMandarin Chinese\n\n\n11.36\n\n\n\n\n69.63\n\n\n\n\n6.65\n\n\n\n\n79.04\n\n\n\n\n5.05\n\n\n\n\n83.11\n\n\n\n\nJapanese\n\n\n17.49\n\n\n\n\n47.76\n\n\n\n\n10.78\n\n\n\n\n68.32\n\n\n\n\n7.88\n\n\n\n\n77.89",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Language</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span class=\"ltx_text ltx_font_bold\">Baseline</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span class=\"ltx_text ltx_font_bold\">GPT-4o-mini</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span class=\"ltx_text ltx_font_bold\">GPT-4o</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td\"/>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">WER (%)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">BLEU (%)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">WER (%)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">BLEU (%)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">WER (%)</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">BLEU (%)</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">German</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.74</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">60.83</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.18</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">78.35</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">4.17</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">84.92</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">American English</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.84</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">70.84</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">6.60</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">85.02</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">4.28</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">89.85</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Mexican Spanish</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.92</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">55.74</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.19</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">62.49</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">7.69</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">71.90</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">French</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.72</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">69.02</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.70</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">79.84</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">5.65</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">86.18</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Italian</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">15.02</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">55.14</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">8.33</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">72.81</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">4.56</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">84.96</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Lithuanian</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.04</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">67.12</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.54</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">64.36</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">6.99</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">73.96</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Mandarin Chinese</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.36</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">69.63</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">6.65</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">79.04</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">5.05</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">83.11</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">Japanese</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">17.49</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">47.76</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.78</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">68.32</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">7.88</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">77.89</span></span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "row",
            "american",
            "wer",
            "polynormbenchmark",
            "french",
            "lithuanian",
            "chinese",
            "italian",
            "mandarin",
            "gpt4omini",
            "best",
            "japanese",
            "languages",
            "gpt4o",
            "bold",
            "scores",
            "spanish",
            "language",
            "english",
            "across",
            "baseline",
            "german",
            "bleu",
            "mexican"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">All systems were tested on PolyNorm across eight languages listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. We report the overall performance with Word Error Rate (WER) and BLEU, which reflects how closely the model&#8217;s output matches the expected spoken form and relative surface similarity to the reference respectively. For non-whitespace languages (Chinese and Japanese), we report Character Error Rate instead of WER to avoid conflating tokenization errors with true normalization errors. PolyNorm demonstrates substantial advantages in terms of flexibility, coverage, and the ability to handle previously intractable normalization challenges with minimal manual human intervention. Results in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> show improvements in both WER and BLEU across the two LLM systems compared to the rule-based baseline. GPT-4o achieves a WER ranging from 4.17% to 7.88% for all languages.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS) systems, converting written forms into their canonical spoken equivalents. Traditional TN systems can exhibit high accuracy, but involve substantial engineering effort, are difficult to scale, and pose challenges to language coverage, particularly in low-resource settings. We propose PolyNorm, a prompt-based approach to TN using Large Language Models (LLMs), aiming to reduce the reliance on manually crafted rules and enable broader linguistic applicability with minimal human intervention. Additionally, we present a language-agnostic pipeline for automatic data curation and evaluation, designed to facilitate scalable experimentation across diverse languages. Experiments across eight languages show consistent reductions in the word error rate (WER) compared to a production-grade-based system. To support further research, we release PolyNorm-Benchmark, a multilingual data set covering a diverse range of text normalization phenomena.</p>\n\n",
                "matched_terms": [
                    "language",
                    "across",
                    "wer",
                    "polynormbenchmark",
                    "languages"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">TN transforms written input, often dense with numbers, abbreviations, and special characters, into fluent speech-friendly text. Early TN systems relied primarily on rule-based approaches using weighted finite-state transducers (WFSTs) <cite class=\"ltx_cite ltx_citemacro_cite\">Sproat et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib7\" title=\"\">2001</a>)</cite>. Although such systems have historically achieved high accuracy, they depend heavily on manual rules and extensive human verification, making them expensive and time-consuming to develop and maintain. These challenges are even more pronounced when dealing with low-resource or morphologically rich languages, such as Arabic and Polish <cite class=\"ltx_cite ltx_citemacro_cite\">Mosquera et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib5\" title=\"\">2012</a>); Po&#347;wiata and Pere&#322;kiewicz (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib6\" title=\"\">2019</a>)</cite>, where linguistic diversity complicates the creation of rules. Beyond the scarcity of resources, TN systems must also handle contextual ambiguities that arise within or across languages. The same surface form can be normalized differently depending on both the linguistic context and the target language, as illustrated in Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a><span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>&#8220;&#200; il 17&#176; secolo.&#8221; translates to &#8220;It&#8217;s the 17<sup class=\"ltx_sup\">th</sup> century.&#8221;\n</span></span></span>.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "language",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Building on prior research that focused on English and GPT models, this work introduces PolyNorm, an LLM-assisted TN framework that leverages prompting and contextual learning, and compares multiple LLMs across diverse languages. Our research pursues two primary goals: (1) developing a sustainable, cost-effective TN solution with minimal human involvement, and (2) creating a reliable, language-agnostic process for automatic data curation and evaluation applicable across both high- and low-resource languages, offering a scalable and accessible TN solution for modern TTS systems.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "english",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our research focuses on American English, German, French, Mexican Spanish, Italian, Lithuanian, Japanese, and Mandarin Chinese.</p>\n\n",
                "matched_terms": [
                    "mandarin",
                    "english",
                    "american",
                    "spanish",
                    "german",
                    "french",
                    "japanese",
                    "italian",
                    "lithuanian",
                    "chinese",
                    "mexican"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We start with a subset of the English Kestrel dataset <cite class=\"ltx_cite ltx_citemacro_cite\">Ebden and Sproat (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib2\" title=\"\">2015</a>)</cite> comprising 14 Kestrel categories extracted from the first file of the dataset, which contains approximately 880,000 lines. For English, to construct a balanced subset, we select a total of 1,400 test cases, removing all sentences that lack normalization targets and retaining the first 100 examples per category from the Kestrel dataset for benchmarking purposes. We initially experimented with translating both the original and normalized English texts into the target languages with NLLB-200 model <cite class=\"ltx_cite ltx_citemacro_cite\">Facebook AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib3\" title=\"\">2022</a>)</cite>. However, we found most translated texts unsuitable as ground truth due to inconsistent quality, translation and inadequate localization of the normalized forms. In addition, the limited categories do not fully cover the scope of normalization phenomena that we aim to evaluate. Therefore, instead of using the entire subset for benchmarking, we reserved some of the higher-quality data, reviewed and verified by language experts, as part of the prompt examples, which will be discussed in the Methodology section.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "language",
                    "english"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address these challenges, we use DeepSeek-R1 <cite class=\"ltx_cite ltx_citemacro_cite\">DeepSeek-AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib1\" title=\"\">2025</a>)</cite> to generate datasets comprising unnormalized and normalized text pairs as our new multilingual benchmark suite, <em class=\"ltx_emph ltx_font_italic\">PolyNorm-Benchmark</em><span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>https://github.com/apple/ml-speech-polynorm-bench</span></span></span>, designed to ensure consistency across languages and taxonomies. Each dataset spans 27 normalization categories (listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S2.T1\" title=\"Table 1 &#8227; 2 Data &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>) built on Kestrel categories and expanded with new classes, comprising 20 examples per category for a total of 540 high-quality data points per language. For Chinese and Japanese, we define abbreviations as truncated forms or initial-letter substitutions, since conventional definitions may not fully capture their use in conversational language.</p>\n\n",
                "matched_terms": [
                    "language",
                    "across",
                    "japanese",
                    "languages",
                    "chinese"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The initial outputs of DeepSeek serve as a foundation, then each example is subsequently edited and verified by internal language experts to ensure the highest standards of linguistic precision, naturalness, and overall quality. The orthography and formatting of synthetic data follow the conventions of target languages. For example, in French, decimal separator in currency is written with a comma instead of a period, with the currency symbol after the number:</p>\n\n",
                "matched_terms": [
                    "languages",
                    "language",
                    "french"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For clarity and consistency, we standardize normalization to common conventions across languages when applicable. For instance, in American English, we follow the month-day-year format, consistent with our TTS production system expectations. Years like &#8221;2020&#8221; are normalized as <span class=\"ltx_text ltx_font_typewriter\">twenty twenty</span>, and dates such as &#8221;4/18&#8221; are normalized as <span class=\"ltx_text ltx_font_typewriter\">april eighteenth</span>.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "english",
                    "across",
                    "american"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Certain differences are not considered errors in our evaluation, as they do not affect the semantic or phonetic realization of the text. These include casing, optional spacing (e.g., in German compound words), and orthographic variants such as &#8221;&#223;&#8221; vs. &#8221;ss&#8221; in specific German contexts, ensuring the evaluation focuses on differences affecting meaning, pronunciation, or intelligibility. To identify such issues and iteratively refine our system, we collaborate with language experts who review LLM outputs on our development sets and flag inaccuracies or inconsistencies, which inform benchmark corrections, in-context learning (ICL) examples refinements, and system iterations.</p>\n\n",
                "matched_terms": [
                    "language",
                    "german"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We adopt a few-shot prompting strategy using ICL examples to guide the LLM in performing text normalization across all languages. This approach allows the model to generalize from a small number of curated examples across various categories, from numerical expressions to acronyms, eliminating extensive fine-tuning or rule-based engineering.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Few-shot prompting with ICL offers a lightweight, scalable solution for multilingual text normalization, relying on high-quality, language-specific examples. The effectiveness of this approach depends on the quality and relevance of the ICL examples provided to the model. We use a unified prompt format across eight languages, varying only the localized examples&#8212;except for Japanese, where a supplementary prompt guides katakana output. Our curated ICL set, excluded from PolyNorm-Bench, includes 80-100 high-quality machine-translated Kestrel data and DeepSeek synthetic examples (e.g., favoring &#8220;twenty nineteen&#8221; over &#8220;two thousand nineteen&#8221; for &#8221;2019&#8221; in English), each normalized and validated by experts to ensure stylistic consistency across domains.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "english",
                    "across",
                    "japanese"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluated GPT-4o-mini and GPT-4o as candidate systems against Apple Siri production rule-based normalization baseline system. Because it is proprietary, we cannot release code or provide external access. However, to help readers judge strength and fairness, we report baseline scores for a representative subset of seven categories across all eight languages in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A3.T4\" title=\"Table 4 &#8227; Appendix C Baseline model WER (%) by Language and Selected Categories &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> below<span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_tag ltx_tag_note\">3</span>Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2.T3\" title=\"Table 3 &#8227; Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> in Appendix <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2\" title=\"Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">B</span></a> shows side-by-side examples illustrating some incorrect baseline outputs</span></span></span>. It is important to note that the baseline predates our benchmark and was not tuned to it.</p>\n\n",
                "matched_terms": [
                    "gpt4omini",
                    "across",
                    "baseline",
                    "languages",
                    "gpt4o",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Future work for PolyNorm includes enabling diacritization restoration in languages like Arabic and Hebrew, where diacritics serve critical grammatical and phonetic roles, and missing markers affect grammar and pronunciation. Targeted prompting could improve accuracy and naturalness of speech synthesis. Japanese and other non-whitespace languages could benefit from integrated tokenizers and multitask learning. While normalizing input to Katakana resolves homograph ambiguities (e.g., &#12295; read as &#8221;rei,&#8221; &#8221;zero,&#8221; or &#8221;maru&#8221;) in Japanese, it may disrupt pitch accent patterns crucial for naturalness. Future work should incorporate suprasegmental features like pitch accent and tone prediction into the normalization pipeline.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "japanese"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We present PolyNorm, a multilingual, LLM-assisted text normalization system designed to address scalability, cost, and language-coverage limitations of rule-based systems. It achieves strong normalization performance across languages and categories, and significantly reduces WER compared to production-grade rule-based systems, demonstrating its robustness and adaptability.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "languages",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Beyond performance, PolyNorm represents a paradigm shift in how normalization systems can be developed, maintained, and scaled. The use of instruct prompting and in-context learning enables rapid iteration cycles, eliminates the dependency on handcrafted rules, and lowers the entry barrier for low-resource languages and domain-specific applications. Our language-agnostic prompt design and PolyNorm-Benchmark further establish a foundation for standardized evaluation and future research in LLM-based normalization. As we look ahead, expanding our system to handle complex linguistic phenomena such as diacritization, non-whitespace tokenization, and suprasegmental features will further broaden its applicability, making high-quality TTS systems accessible across a wider range of languages and user contexts.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "across",
                    "polynormbenchmark"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This project explores using large language models (LLMs) to automate text normalization&#8212;a key step in processing raw text such as speech transcripts, handwriting, or informal writing. Text normalization standardizes text by handling tasks from formatting dates and numbers to restoring diacritics in accented languages. Our LLM-based system offers a scalable, efficient alternative by combining raw input with tailored prompts and few-shot examples. This approach improves consistency and quality across multiple languages, making it well-suited for applications like text-to-speech, machine translation, and speech recognition.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "language",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While PolyNorm demonstrates strong potential in terms of efficiency and multilingual consistency, the model&#8217;s performance is highly dependent on the quality and representativeness of data used as in-context learning examples. Categories covered in the examples may not capture the full range of normalization needs across different languages and varieties. Furthermore, errors in normalization can propagate into downstream tasks such as translation, sentiment analysis, or educational tools. Although expert-reviewed examples were used for in-context learning, the model may still struggle with edge cases or uncommon linguistic patterns. These limitations must be addressed before considering the system for widespread or critical work.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Overall column reports the average WER across all 27 categories.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Overall column reports the average WER across all 27 categories.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "across"
                ]
            }
        ]
    },
    "A2.T3": {
        "source_file": "PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech",
        "caption": "Table 3: Examples of baseline TN errors across the targeted languages and selected categories.",
        "body": "Language\n\n\n\n\nCategory\n\n\n\n\nExample\n\n\n\n\nGround Truth\n\n\n\n\nError\n\n\n\n\n\n\nGerman\n\n\n\n\nAddress\n\n\n\n\nDie Wohnung befindet sich in der Hauptstrae 45.\n\n\n\n\ndie wohnung befindet sich in der hauptstrasse fnfundvierzig.\n\n\n\n\ndie wohnung befindet sich in der hauptstrasse fnf und vierzig.\n\n\n\n\n\n\nAmerican English\n\n\n\n\nLegal References\n\n\n\n\nThe regulation is 15 CFR Part 12.\n\n\n\n\nthe regulation is fifteen c f r part twelve.\n\n\n\n\nthe regulation is fifteen cfr part twelve.\n\n\n\n\n\n\nMexican Spanish\n\n\n\n\nPhone Numbers\n\n\n\n\nMi celular es 442-789-0123.\n\n\n\n\nmi celular es cuatro cuatro dos, siete ocho nueve, cero uno dos tres.\n\n\n\n\nmi celular es cuatrocientos cuarenta y dos, setecientos ochenta y nueve, cero un veintitrs.\n\n\n\n\n\n\nFrench\n\n\n\n\nSports Scores\n\n\n\n\nLe tennis de table a fini 11-9.\n\n\n\n\nle tennis de table a fini onze  neuf.\n\n\n\n\nle tennis de table a fini onze moins neuf.\n\n\n\n\n\n\nItalian\n\n\n\n\nCurrencies\n\n\n\n\nLa tariffa  CHF 20.\n\n\n\n\nla tariffa  venti franchi svizzeri.\n\n\n\n\nla tariffa  c h f venti.\n\n\n\n\n\n\nLithuanian\n\n\n\n\nMathematical Expressions\n\n\n\n\n5  6 = 30.\n\n\n\n\npenki kart ei lygu trisdeimt.\n\n\n\n\npenki kart ei yra trisdeimt.\n\n\n\n\n\n\nMandarin Chinese\n\n\n\n\nMusical Notation\n\n\n\n\n=120\n\n\n\n\n\n\n\n\n\n  =    \n\n\n\n\n\n\nJapanese\n\n\n\n\nCurrencies\n\n\n\n\n15,000\n\n\n\n\n  \n\n\n\n\n   ",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:51.2pt;\"><span class=\"ltx_text ltx_font_bold\">Language</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:62.6pt;\"><span class=\"ltx_text ltx_font_bold\">Category</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Example</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Ground Truth</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Error</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:51.2pt;\">German</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:62.6pt;\">Address</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">Die Wohnung befindet sich in der Hauptstra&#223;e 45.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">die wohnung befindet sich in der hauptstrasse f&#252;nfundvierzig.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">die wohnung befindet sich in der hauptstrasse f&#252;nf und vierzig.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:51.2pt;\">American English</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:62.6pt;\">Legal References</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">The regulation is 15 CFR Part 12.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">the regulation is fifteen c f r part twelve.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">the regulation is fifteen cfr part twelve.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:51.2pt;\">Mexican Spanish</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:62.6pt;\">Phone Numbers</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">Mi celular es 442-789-0123.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">mi celular es cuatro cuatro dos, siete ocho nueve, cero uno dos tres.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">mi celular es cuatrocientos cuarenta y dos, setecientos ochenta y nueve, cero un veintitr&#233;s.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:51.2pt;\">French</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:62.6pt;\">Sports Scores</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">Le tennis de table a fini 11-9.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">le tennis de table a fini onze &#224; neuf.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">le tennis de table a fini onze moins neuf.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:51.2pt;\">Italian</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:62.6pt;\">Currencies</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">La tariffa &#232; CHF 20.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">la tariffa &#232; venti franchi svizzeri.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">la tariffa &#232; c h f venti.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:51.2pt;\">Lithuanian</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:62.6pt;\">Mathematical Expressions</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">5 &#215; 6 = 30.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">penki kart &#353;e&#353;i lygu trisde&#353;imt.</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">penki kart &#353;e&#353;i yra trisde&#353;imt.</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:51.2pt;\">Mandarin Chinese</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:62.6pt;\">Musical Notation</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">&#36895;&#24230;&#26631;&#35760;&#119135;=120</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">&#36895;&#24230;&#26631;&#35760;&#22235;&#20998;&#38899;&#31526;&#31561;&#20110;&#19968;&#30334;&#20108;&#21313;</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">&#36895;&#24230; &#26631;&#35760; = &#19968; &#30334; &#20108; &#21313;</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:51.2pt;\">Japanese</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\" style=\"width:62.6pt;\">Currencies</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">&#20385;&#26684;&#12399;&#8361;15,000&#12290;</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">&#12459;&#12459;&#12463;&#12527; &#12452;&#12481;&#12510;&#12531; &#12468;&#12475;&#12531;&#12527;&#12531;&#12290;</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">&#12459;&#12459;&#12463; &#12495; &#12452;&#12481;&#12510;&#12531; &#12468;&#12475;&#12531;&#12527;&#12531;&#12290;</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "befindet",
            "neuf",
            "siete",
            "currencies",
            "fini",
            "lygu",
            "",
            "trisdeimt",
            "lithuanian",
            "categories",
            "penki",
            "mathematical",
            "cuatrocientos",
            "address",
            "errors",
            "hauptstrasse",
            "hauptstrae",
            "celular",
            "tariffa",
            "fnf",
            "phone",
            "baseline",
            "dos",
            "german",
            "onze",
            "tennis",
            "svizzeri",
            "cuarenta",
            "und",
            "die",
            "kart",
            "setecientos",
            "references",
            "chf",
            "yra",
            "fifteen",
            "",
            "120",
            "category",
            "expressions",
            "spanish",
            "sich",
            "regulation",
            "across",
            "ground",
            "notation",
            "american",
            "french",
            "cfr",
            "",
            "chinese",
            "cuatro",
            "mandarin",
            "tres",
            "error",
            "legal",
            "japanese",
            "languages",
            "veintitrs",
            "truth",
            "numbers",
            "sports",
            "selected",
            "english",
            "vierzig",
            "",
            "nueve",
            "der",
            "ei",
            "cero",
            "italian",
            "15000",
            "example",
            "moins",
            "scores",
            "part",
            "franchi",
            "targeted",
            "",
            "examples",
            "venti",
            "language",
            "twelve",
            "ocho",
            "fnfundvierzig",
            "ochenta",
            "mexican",
            "musical",
            "wohnung"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">We evaluated GPT-4o-mini and GPT-4o as candidate systems against Apple Siri production rule-based normalization baseline system. Because it is proprietary, we cannot release code or provide external access. However, to help readers judge strength and fairness, we report baseline scores for a representative subset of seven categories across all eight languages in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A3.T4\" title=\"Table 4 &#8227; Appendix C Baseline model WER (%) by Language and Selected Categories &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> below<span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_tag ltx_tag_note\">3</span>Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2.T3\" title=\"Table 3 &#8227; Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> in Appendix <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2\" title=\"Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">B</span></a> shows side-by-side examples illustrating some incorrect baseline outputs</span></span></span>. It is important to note that the baseline predates our benchmark and was not tuned to it.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS) systems, converting written forms into their canonical spoken equivalents. Traditional TN systems can exhibit high accuracy, but involve substantial engineering effort, are difficult to scale, and pose challenges to language coverage, particularly in low-resource settings. We propose PolyNorm, a prompt-based approach to TN using Large Language Models (LLMs), aiming to reduce the reliance on manually crafted rules and enable broader linguistic applicability with minimal human intervention. Additionally, we present a language-agnostic pipeline for automatic data curation and evaluation, designed to facilitate scalable experimentation across diverse languages. Experiments across eight languages show consistent reductions in the word error rate (WER) compared to a production-grade-based system. To support further research, we release PolyNorm-Benchmark, a multilingual data set covering a diverse range of text normalization phenomena.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "language",
                    "across",
                    "error"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">TN transforms written input, often dense with numbers, abbreviations, and special characters, into fluent speech-friendly text. Early TN systems relied primarily on rule-based approaches using weighted finite-state transducers (WFSTs) <cite class=\"ltx_cite ltx_citemacro_cite\">Sproat et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib7\" title=\"\">2001</a>)</cite>. Although such systems have historically achieved high accuracy, they depend heavily on manual rules and extensive human verification, making them expensive and time-consuming to develop and maintain. These challenges are even more pronounced when dealing with low-resource or morphologically rich languages, such as Arabic and Polish <cite class=\"ltx_cite ltx_citemacro_cite\">Mosquera et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib5\" title=\"\">2012</a>); Po&#347;wiata and Pere&#322;kiewicz (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib6\" title=\"\">2019</a>)</cite>, where linguistic diversity complicates the creation of rules. Beyond the scarcity of resources, TN systems must also handle contextual ambiguities that arise within or across languages. The same surface form can be normalized differently depending on both the linguistic context and the target language, as illustrated in Figure <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a><span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\">1</span>&#8220;&#200; il 17&#176; secolo.&#8221; translates to &#8220;It&#8217;s the 17<sup class=\"ltx_sup\">th</sup> century.&#8221;\n</span></span></span>.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "language",
                    "across",
                    "numbers"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Later development lead to TN systems that are based on statistical and hybrid data-driven approaches <cite class=\"ltx_cite ltx_citemacro_cite\">Grali&#324;ski et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib4\" title=\"\">2006</a>); Zhu et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib10\" title=\"\">2007</a>); Sproat and Jaitly (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib8\" title=\"\">2016</a>)</cite>. For example, <cite class=\"ltx_cite ltx_citemacro_citet\">Grali&#324;ski et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib4\" title=\"\">2006</a>)</cite> treated TN as a machine translation problem, mapping textual representations into their spoken equivalents, while <cite class=\"ltx_cite ltx_citemacro_citet\">Zhu et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib10\" title=\"\">2007</a>)</cite> introduced a unified tagging approach using Conditional Random Fields (CRF) to simultaneously handle multiple TN subtasks, emphasizing their interdependencies. Recently, large language models (LLMs) have shown great potential in addressing these limitations by leveraging their broad linguistic knowledge. <cite class=\"ltx_cite ltx_citemacro_citet\">Zhang et al. (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib9\" title=\"\">2024</a>)</cite> used GPT models to perform text normalization in few-shot scenarios, incorporating self-consistency reasoning and linguistically informed prompt engineering, achieving error rates approximately 40% lower than those of production-level WFST systems.</p>\n\n",
                "matched_terms": [
                    "example",
                    "language",
                    "error"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Building on prior research that focused on English and GPT models, this work introduces PolyNorm, an LLM-assisted TN framework that leverages prompting and contextual learning, and compares multiple LLMs across diverse languages. Our research pursues two primary goals: (1) developing a sustainable, cost-effective TN solution with minimal human involvement, and (2) creating a reliable, language-agnostic process for automatic data curation and evaluation applicable across both high- and low-resource languages, offering a scalable and accessible TN solution for modern TTS systems.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "english",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our research focuses on American English, German, French, Mexican Spanish, Italian, Lithuanian, Japanese, and Mandarin Chinese.</p>\n\n",
                "matched_terms": [
                    "mandarin",
                    "english",
                    "american",
                    "spanish",
                    "german",
                    "french",
                    "japanese",
                    "italian",
                    "lithuanian",
                    "chinese",
                    "mexican"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We start with a subset of the English Kestrel dataset <cite class=\"ltx_cite ltx_citemacro_cite\">Ebden and Sproat (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib2\" title=\"\">2015</a>)</cite> comprising 14 Kestrel categories extracted from the first file of the dataset, which contains approximately 880,000 lines. For English, to construct a balanced subset, we select a total of 1,400 test cases, removing all sentences that lack normalization targets and retaining the first 100 examples per category from the Kestrel dataset for benchmarking purposes. We initially experimented with translating both the original and normalized English texts into the target languages with NLLB-200 model <cite class=\"ltx_cite ltx_citemacro_cite\">Facebook AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib3\" title=\"\">2022</a>)</cite>. However, we found most translated texts unsuitable as ground truth due to inconsistent quality, translation and inadequate localization of the normalized forms. In addition, the limited categories do not fully cover the scope of normalization phenomena that we aim to evaluate. Therefore, instead of using the entire subset for benchmarking, we reserved some of the higher-quality data, reviewed and verified by language experts, as part of the prompt examples, which will be discussed in the Methodology section.</p>\n\n",
                "matched_terms": [
                    "part",
                    "language",
                    "category",
                    "english",
                    "ground",
                    "languages",
                    "examples",
                    "truth",
                    "categories"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address these challenges, we use DeepSeek-R1 <cite class=\"ltx_cite ltx_citemacro_cite\">DeepSeek-AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib1\" title=\"\">2025</a>)</cite> to generate datasets comprising unnormalized and normalized text pairs as our new multilingual benchmark suite, <em class=\"ltx_emph ltx_font_italic\">PolyNorm-Benchmark</em><span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>https://github.com/apple/ml-speech-polynorm-bench</span></span></span>, designed to ensure consistency across languages and taxonomies. Each dataset spans 27 normalization categories (listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S2.T1\" title=\"Table 1 &#8227; 2 Data &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>) built on Kestrel categories and expanded with new classes, comprising 20 examples per category for a total of 540 high-quality data points per language. For Chinese and Japanese, we define abbreviations as truncated forms or initial-letter substitutions, since conventional definitions may not fully capture their use in conversational language.</p>\n\n",
                "matched_terms": [
                    "language",
                    "category",
                    "across",
                    "address",
                    "japanese",
                    "languages",
                    "examples",
                    "chinese",
                    "categories"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The initial outputs of DeepSeek serve as a foundation, then each example is subsequently edited and verified by internal language experts to ensure the highest standards of linguistic precision, naturalness, and overall quality. The orthography and formatting of synthetic data follow the conventions of target languages. For example, in French, decimal separator in currency is written with a comma instead of a period, with the currency symbol after the number:</p>\n\n",
                "matched_terms": [
                    "languages",
                    "language",
                    "example",
                    "french"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We define a normalization error as any output in which the normalized text deviates from the expected conventional spoken form. For example, rendering &#8220;Dr&#8221; as &#8220;Doctor&#8221; instead of &#8220;Drive&#8221; in an address, or normalizing &#8220;12:30&#8221; as &#8220;twelve thirty AM&#8221; when the time format is ambiguous.</p>\n\n",
                "matched_terms": [
                    "example",
                    "address",
                    "error"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For clarity and consistency, we standardize normalization to common conventions across languages when applicable. For instance, in American English, we follow the month-day-year format, consistent with our TTS production system expectations. Years like &#8221;2020&#8221; are normalized as <span class=\"ltx_text ltx_font_typewriter\">twenty twenty</span>, and dates such as &#8221;4/18&#8221; are normalized as <span class=\"ltx_text ltx_font_typewriter\">april eighteenth</span>.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "english",
                    "across",
                    "american"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Certain differences are not considered errors in our evaluation, as they do not affect the semantic or phonetic realization of the text. These include casing, optional spacing (e.g., in German compound words), and orthographic variants such as &#8221;&#223;&#8221; vs. &#8221;ss&#8221; in specific German contexts, ensuring the evaluation focuses on differences affecting meaning, pronunciation, or intelligibility. To identify such issues and iteratively refine our system, we collaborate with language experts who review LLM outputs on our development sets and flag inaccuracies or inconsistencies, which inform benchmark corrections, in-context learning (ICL) examples refinements, and system iterations.</p>\n\n",
                "matched_terms": [
                    "examples",
                    "language",
                    "german",
                    "errors"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We adopt a few-shot prompting strategy using ICL examples to guide the LLM in performing text normalization across all languages. This approach allows the model to generalize from a small number of curated examples across various categories, from numerical expressions to acronyms, eliminating extensive fine-tuning or rule-based engineering.</p>\n\n",
                "matched_terms": [
                    "expressions",
                    "across",
                    "languages",
                    "examples",
                    "categories"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our prompt design follows a structured, step-by-step and language-agnostic format composed of three components: 1) <span class=\"ltx_text ltx_font_bold\">Instruction Prompt</span>, which defines the normalization task, 2) <span class=\"ltx_text ltx_font_bold\">In-Context Learning Examples</span>, which demonstrate how different types of text should be normalized, and 3) <span class=\"ltx_text ltx_font_bold\">Target Unnormalized Input</span>, to which the model applies learned patterns. PolyNorm uses a standardized English instruction prompt with localized ICL examples tailored to each language&#8217;s linguistic and stylistic norms.</p>\n\n",
                "matched_terms": [
                    "examples",
                    "english"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Few-shot prompting with ICL offers a lightweight, scalable solution for multilingual text normalization, relying on high-quality, language-specific examples. The effectiveness of this approach depends on the quality and relevance of the ICL examples provided to the model. We use a unified prompt format across eight languages, varying only the localized examples&#8212;except for Japanese, where a supplementary prompt guides katakana output. Our curated ICL set, excluded from PolyNorm-Bench, includes 80-100 high-quality machine-translated Kestrel data and DeepSeek synthetic examples (e.g., favoring &#8220;twenty nineteen&#8221; over &#8220;two thousand nineteen&#8221; for &#8221;2019&#8221; in English), each normalized and validated by experts to ensure stylistic consistency across domains.</p>\n\n",
                "matched_terms": [
                    "english",
                    "across",
                    "japanese",
                    "languages",
                    "examples"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We analyzed discrepancies between expert-verified development sets and LLM outputs from GPT models to identify systematic weaknesses. Common errors included incorrect numeral expansions and inconsistent handling of language-specific formats such as date and currency. To address these issues, we identified categories or patterns where the model underperformed, then revised or added ICL examples focused on these error types, improving the model&#8217;s output with each iteration. This feedback loop refined normalization via prompt tuning and better examples, reducing errors and improving cross-lingual consistency.</p>\n\n",
                "matched_terms": [
                    "error",
                    "address",
                    "errors",
                    "examples",
                    "categories"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All systems were tested on PolyNorm across eight languages listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. We report the overall performance with Word Error Rate (WER) and BLEU, which reflects how closely the model&#8217;s output matches the expected spoken form and relative surface similarity to the reference respectively. For non-whitespace languages (Chinese and Japanese), we report Character Error Rate instead of WER to avoid conflating tokenization errors with true normalization errors. PolyNorm demonstrates substantial advantages in terms of flexibility, coverage, and the ability to handle previously intractable normalization challenges with minimal manual human intervention. Results in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> show improvements in both WER and BLEU across the two LLM systems compared to the rule-based baseline. GPT-4o achieves a WER ranging from 4.17% to 7.88% for all languages.</p>\n\n",
                "matched_terms": [
                    "across",
                    "error",
                    "baseline",
                    "japanese",
                    "errors",
                    "languages",
                    "chinese"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Another observation of PolyNorm&#8217;s context awareness over rule-based systems is its handling of dashes between numbers. In sports scores, a dash is typically verbalized as &#8221;to&#8221; (e.g., &#8221;3-2&#8221; as &#8221;three to two&#8221;), whereas in phone numbers it is ignored and the digits are read individually. A rule-based system would require an explicit and often verbose set of context-specific rules to make this distinction, while PolyNorm can infer the correct interpretation directly from context, even in novel or ambiguous formats.</p>\n\n",
                "matched_terms": [
                    "phone",
                    "sports",
                    "scores",
                    "numbers"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Training a reliable TTS system can require millions of high-quality data points. While effective in controlled environments, traditional TN pipelines, heavily rule-based, demand ongoing annotation and patching, often taking months per language and struggling to generalize or scale to noisy, ambiguous, or evolving inputs. PolyNorm replaces this manual loop with an LLM-driven framework using prompt tuning and in-context learning, cutting development overhead and accelerating iteration by refining prompts or examples.</p>\n\n",
                "matched_terms": [
                    "examples",
                    "language"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Crowdsourcing normalization can be expensive, and it takes weeks of review cycles. PolyNorm, combined with few-shot in-context learning, achieves high grapheme-to-phoneme accuracy with far fewer labeled examples, lowering the barrier for TN in low-resource languages. Beyond cost and efficiency gains, LLM-based TN offers more consistent outputs, better generalization, and language-agnostic deployment, while allowing localized examples to boost performance. By reducing manual effort and speeding iteration, PolyNorm lets developers focus on quality and localization, accelerating research and production.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "examples"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Future work for PolyNorm includes enabling diacritization restoration in languages like Arabic and Hebrew, where diacritics serve critical grammatical and phonetic roles, and missing markers affect grammar and pronunciation. Targeted prompting could improve accuracy and naturalness of speech synthesis. Japanese and other non-whitespace languages could benefit from integrated tokenizers and multitask learning. While normalizing input to Katakana resolves homograph ambiguities (e.g., &#12295; read as &#8221;rei,&#8221; &#8221;zero,&#8221; or &#8221;maru&#8221;) in Japanese, it may disrupt pitch accent patterns crucial for naturalness. Future work should incorporate suprasegmental features like pitch accent and tone prediction into the normalization pipeline.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "targeted",
                    "japanese"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We present PolyNorm, a multilingual, LLM-assisted text normalization system designed to address scalability, cost, and language-coverage limitations of rule-based systems. It achieves strong normalization performance across languages and categories, and significantly reduces WER compared to production-grade rule-based systems, demonstrating its robustness and adaptability.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "categories",
                    "across",
                    "address"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Beyond performance, PolyNorm represents a paradigm shift in how normalization systems can be developed, maintained, and scaled. The use of instruct prompting and in-context learning enables rapid iteration cycles, eliminates the dependency on handcrafted rules, and lowers the entry barrier for low-resource languages and domain-specific applications. Our language-agnostic prompt design and PolyNorm-Benchmark further establish a foundation for standardized evaluation and future research in LLM-based normalization. As we look ahead, expanding our system to handle complex linguistic phenomena such as diacritization, non-whitespace tokenization, and suprasegmental features will further broaden its applicability, making high-quality TTS systems accessible across a wider range of languages and user contexts.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This project explores using large language models (LLMs) to automate text normalization&#8212;a key step in processing raw text such as speech transcripts, handwriting, or informal writing. Text normalization standardizes text by handling tasks from formatting dates and numbers to restoring diacritics in accented languages. Our LLM-based system offers a scalable, efficient alternative by combining raw input with tailored prompts and few-shot examples. This approach improves consistency and quality across multiple languages, making it well-suited for applications like text-to-speech, machine translation, and speech recognition.</p>\n\n",
                "matched_terms": [
                    "language",
                    "across",
                    "languages",
                    "examples",
                    "numbers"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">LLM-based normalization introduces ethical and safety risks. Because the model learns from large datasets, it may replicate biases in the training data. For example, in gendered languages like Arabic, ambiguous inputs such as &#8220;ant&#8221; (which could mean &#8220;you [masc.]&#8221; or &#8220;you [fem.]&#8221;) might be resolved in biased ways. If unaddressed, such biases can reinforce stereotypes or generate inappropriate outputs. Inaccurate normalization may also mislead learners, reinforce incorrect usage, and reduce trust in downstream systems. Therefore, while PolyNorm offers efficient, multilingual normalization, it must be developed with careful attention to data quality, bias mitigation, and user safety to ensure ethical deployment.</p>\n\n",
                "matched_terms": [
                    "languages",
                    "example"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While PolyNorm demonstrates strong potential in terms of efficiency and multilingual consistency, the model&#8217;s performance is highly dependent on the quality and representativeness of data used as in-context learning examples. Categories covered in the examples may not capture the full range of normalization needs across different languages and varieties. Furthermore, errors in normalization can propagate into downstream tasks such as translation, sentiment analysis, or educational tools. Although expert-reviewed examples were used for in-context learning, the model may still struggle with edge cases or uncommon linguistic patterns. These limitations must be addressed before considering the system for widespread or critical work.</p>\n\n",
                "matched_terms": [
                    "across",
                    "errors",
                    "languages",
                    "examples",
                    "categories"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section presents the instruction prompt template. Note that certain locales include supplementary prompts tailored to their linguistic or stylistic characteristics. In-context learning (ICL) examples are omitted here for brevity.\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>You are an accurate text normalizer for {locale}. Your task is to normalize unstandardized text from the following categories to truly reflects how the real speech is, based on the context:\n<br class=\"ltx_break\"/>- Cardinal \n<br class=\"ltx_break\"/>- Date\n<br class=\"ltx_break\"/>- Decimal\n<br class=\"ltx_break\"/>- Ordinal\n<br class=\"ltx_break\"/>- Fraction\n<br class=\"ltx_break\"/>- Time\n<br class=\"ltx_break\"/>- Currency\n<br class=\"ltx_break\"/>- Unit (Measure)\n<br class=\"ltx_break\"/>- Electronic Address (URL or Email)\n<br class=\"ltx_break\"/>- Initialism or Acronym\n<br class=\"ltx_break\"/>- ISBN\n<br class=\"ltx_break\"/>- Roman Numeral\n<br class=\"ltx_break\"/>- Telephone\n<br class=\"ltx_break\"/>- Sports Score\n<br class=\"ltx_break\"/>- Mathematical Expression\n<br class=\"ltx_break\"/>- Symbol\n<br class=\"ltx_break\"/>- Abbreviation\n<br class=\"ltx_break\"/>- Chemical Formula\n<br class=\"ltx_break\"/>- Legal Reference\n<br class=\"ltx_break\"/>- Vehicle or Product Code\n<br class=\"ltx_break\"/>- Geographic Coordinates\n<br class=\"ltx_break\"/>- Version Number\n<br class=\"ltx_break\"/>- License Plate or Serial Number\n<br class=\"ltx_break\"/>- Musical Notation\n<br class=\"ltx_break\"/>- Stock Ticker\n<br class=\"ltx_break\"/>- Biological Classification\n<br class=\"ltx_break\"/>- Address\n<br class=\"ltx_break\"/>- Other unnormalized text\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>Some important rules: \n<br class=\"ltx_break\"/>- When normalizing acronyms, spell out to their full forms for clarity, except when the acronym is a widely recognized and pronounceable name (e.g. &#8220;NASA&#8221; or &#8220;NASCAR&#8221;). In those cases, keep the acronym as-is and pronounce it as a word. \n<br class=\"ltx_break\"/>- If the acronym combines a letter and a word, split accordingly. \n<br class=\"ltx_break\"/>- Convert punctuation that is spoken aloud into words. For example, write &#8216;dot&#8217; instead of a period in URLs and emails. \n<br class=\"ltx_break\"/>- To ensure clarity, segment compound words, websites and file names into recognizable component words rather than keeping them as a whole word. \n<br class=\"ltx_break\"/>- Symbols in a file name should be read as is. \n<br class=\"ltx_break\"/>- Common file extensions (.jpeg, .jpg, .txt, etc) should be spoken out. Uncommon file extensions should be spelled out. \n<br class=\"ltx_break\"/></p>\n\n",
                "matched_terms": [
                    "sports",
                    "notation",
                    "mathematical",
                    "legal",
                    "address",
                    "examples",
                    "example",
                    "categories",
                    "musical"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Overall column reports the average WER across all 27 categories.</p>\n\n",
                "matched_terms": [
                    "categories",
                    "across"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Overall column reports the average WER across all 27 categories.</p>\n\n",
                "matched_terms": [
                    "categories",
                    "across"
                ]
            }
        ]
    },
    "A3.T4": {
        "source_file": "PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech",
        "caption": "Table 4: Baseline model WER results by language and category",
        "body": "Language\n\n\nOverall\n\n\n\n\nAddress\n\n\n\n\nLegal Ref.\n\n\n\n\nCurrencies\n\n\n\n\nMath. Expr.\n\n\n\n\nMusical Not.\n\n\n\n\nPhone Num.\n\n\n\n\nSports Scores\n\n\n\n\nGerman\n\n\n10.74\n\n\n\n\n7.78\n\n\n\n\n16.03\n\n\n\n\n19.84\n\n\n\n\n24.26\n\n\n\n\n5.88\n\n\n\n\n0.89\n\n\n\n\n15.20\n\n\n\n\nAmerican English\n\n\n9.84\n\n\n\n\n8.13\n\n\n\n\n13.19\n\n\n\n\n1.94\n\n\n\n\n15.48\n\n\n\n\n10.62\n\n\n\n\n1.14\n\n\n\n\n11.11\n\n\n\n\nMexican Spanish\n\n\n11.92\n\n\n\n\n2.24\n\n\n\n\n6.43\n\n\n\n\n13.95\n\n\n\n\n24.05\n\n\n\n\n14.81\n\n\n\n\n23.11\n\n\n\n\n0.00\n\n\n\n\nFrench\n\n\n9.72\n\n\n\n\n3.19\n\n\n\n\n5.75\n\n\n\n\n7.14\n\n\n\n\n23.95\n\n\n\n\n14.63\n\n\n\n\n4.98\n\n\n\n\n11.88\n\n\n\n\nItalian\n\n\n15.02\n\n\n\n\n5.23\n\n\n\n\n13.08\n\n\n\n\n15.20\n\n\n\n\n28.57\n\n\n\n\n17.12\n\n\n\n\n22.80\n\n\n\n\n4.62\n\n\n\n\nLithuanian\n\n\n10.04\n\n\n\n\n9.63\n\n\n\n\n12.08\n\n\n\n\n7.87\n\n\n\n\n15.75\n\n\n\n\n18.63\n\n\n\n\n16.56\n\n\n\n\n6.34\n\n\n\n\nMandarin Chinese\n\n\n11.36\n\n\n\n\n0.00\n\n\n\n\n10.65\n\n\n\n\n23.48\n\n\n\n\n25.00\n\n\n\n\n4.23\n\n\n\n\n15.72\n\n\n\n\n5.92\n\n\n\n\nJapanese\n\n\n17.49\n\n\n\n\n16.19\n\n\n\n\n19.30\n\n\n\n\n18.85\n\n\n\n\n20.30\n\n\n\n\n18.06\n\n\n\n\n15.94\n\n\n\n\n21.43",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Language</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Overall</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Address</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Legal Ref.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Currencies</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Math. Expr.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Musical Not.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Phone Num.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Sports Scores</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">German</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.74</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.78</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">16.03</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">19.84</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">24.26</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.88</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.89</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">15.20</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">American English</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.84</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">8.13</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">13.19</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.94</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">15.48</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.62</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.14</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.11</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Mexican Spanish</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.92</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">2.24</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">6.43</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">13.95</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">24.05</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">14.81</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">23.11</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.00</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">French</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.72</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">3.19</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.75</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.14</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">23.95</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">14.63</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.98</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.88</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Italian</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">15.02</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.23</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">13.08</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">15.20</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">28.57</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">17.12</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">22.80</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.62</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Lithuanian</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.04</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.63</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">12.08</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.87</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">15.75</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">18.63</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">16.56</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">6.34</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Mandarin Chinese</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.36</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.00</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.65</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">23.48</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">25.00</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.23</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">15.72</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.92</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">Japanese</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">17.49</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">16.19</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">19.30</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">18.85</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">20.30</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">18.06</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">15.94</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">21.43</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "american",
            "wer",
            "currencies",
            "french",
            "num",
            "lithuanian",
            "chinese",
            "italian",
            "mandarin",
            "legal",
            "address",
            "japanese",
            "results",
            "overall",
            "scores",
            "expr",
            "category",
            "sports",
            "spanish",
            "phone",
            "language",
            "math",
            "english",
            "baseline",
            "german",
            "ref",
            "mexican",
            "musical",
            "model",
            "not"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">We evaluated GPT-4o-mini and GPT-4o as candidate systems against Apple Siri production rule-based normalization baseline system. Because it is proprietary, we cannot release code or provide external access. However, to help readers judge strength and fairness, we report baseline scores for a representative subset of seven categories across all eight languages in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A3.T4\" title=\"Table 4 &#8227; Appendix C Baseline model WER (%) by Language and Selected Categories &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> below<span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_tag ltx_tag_note\">3</span>Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2.T3\" title=\"Table 3 &#8227; Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> in Appendix <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2\" title=\"Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">B</span></a> shows side-by-side examples illustrating some incorrect baseline outputs</span></span></span>. It is important to note that the baseline predates our benchmark and was not tuned to it.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS) systems, converting written forms into their canonical spoken equivalents. Traditional TN systems can exhibit high accuracy, but involve substantial engineering effort, are difficult to scale, and pose challenges to language coverage, particularly in low-resource settings. We propose PolyNorm, a prompt-based approach to TN using Large Language Models (LLMs), aiming to reduce the reliance on manually crafted rules and enable broader linguistic applicability with minimal human intervention. Additionally, we present a language-agnostic pipeline for automatic data curation and evaluation, designed to facilitate scalable experimentation across diverse languages. Experiments across eight languages show consistent reductions in the word error rate (WER) compared to a production-grade-based system. To support further research, we release PolyNorm-Benchmark, a multilingual data set covering a diverse range of text normalization phenomena.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "language"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our research focuses on American English, German, French, Mexican Spanish, Italian, Lithuanian, Japanese, and Mandarin Chinese.</p>\n\n",
                "matched_terms": [
                    "mandarin",
                    "english",
                    "american",
                    "spanish",
                    "german",
                    "french",
                    "japanese",
                    "italian",
                    "lithuanian",
                    "chinese",
                    "mexican"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We start with a subset of the English Kestrel dataset <cite class=\"ltx_cite ltx_citemacro_cite\">Ebden and Sproat (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib2\" title=\"\">2015</a>)</cite> comprising 14 Kestrel categories extracted from the first file of the dataset, which contains approximately 880,000 lines. For English, to construct a balanced subset, we select a total of 1,400 test cases, removing all sentences that lack normalization targets and retaining the first 100 examples per category from the Kestrel dataset for benchmarking purposes. We initially experimented with translating both the original and normalized English texts into the target languages with NLLB-200 model <cite class=\"ltx_cite ltx_citemacro_cite\">Facebook AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib3\" title=\"\">2022</a>)</cite>. However, we found most translated texts unsuitable as ground truth due to inconsistent quality, translation and inadequate localization of the normalized forms. In addition, the limited categories do not fully cover the scope of normalization phenomena that we aim to evaluate. Therefore, instead of using the entire subset for benchmarking, we reserved some of the higher-quality data, reviewed and verified by language experts, as part of the prompt examples, which will be discussed in the Methodology section.</p>\n\n",
                "matched_terms": [
                    "language",
                    "category",
                    "english",
                    "model",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address these challenges, we use DeepSeek-R1 <cite class=\"ltx_cite ltx_citemacro_cite\">DeepSeek-AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib1\" title=\"\">2025</a>)</cite> to generate datasets comprising unnormalized and normalized text pairs as our new multilingual benchmark suite, <em class=\"ltx_emph ltx_font_italic\">PolyNorm-Benchmark</em><span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>https://github.com/apple/ml-speech-polynorm-bench</span></span></span>, designed to ensure consistency across languages and taxonomies. Each dataset spans 27 normalization categories (listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S2.T1\" title=\"Table 1 &#8227; 2 Data &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>) built on Kestrel categories and expanded with new classes, comprising 20 examples per category for a total of 540 high-quality data points per language. For Chinese and Japanese, we define abbreviations as truncated forms or initial-letter substitutions, since conventional definitions may not fully capture their use in conversational language.</p>\n\n",
                "matched_terms": [
                    "language",
                    "category",
                    "address",
                    "japanese",
                    "chinese",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The initial outputs of DeepSeek serve as a foundation, then each example is subsequently edited and verified by internal language experts to ensure the highest standards of linguistic precision, naturalness, and overall quality. The orthography and formatting of synthetic data follow the conventions of target languages. For example, in French, decimal separator in currency is written with a comma instead of a period, with the currency symbol after the number:</p>\n\n",
                "matched_terms": [
                    "language",
                    "overall",
                    "french"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For clarity and consistency, we standardize normalization to common conventions across languages when applicable. For instance, in American English, we follow the month-day-year format, consistent with our TTS production system expectations. Years like &#8221;2020&#8221; are normalized as <span class=\"ltx_text ltx_font_typewriter\">twenty twenty</span>, and dates such as &#8221;4/18&#8221; are normalized as <span class=\"ltx_text ltx_font_typewriter\">april eighteenth</span>.</p>\n\n",
                "matched_terms": [
                    "english",
                    "american"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Certain differences are not considered errors in our evaluation, as they do not affect the semantic or phonetic realization of the text. These include casing, optional spacing (e.g., in German compound words), and orthographic variants such as &#8221;&#223;&#8221; vs. &#8221;ss&#8221; in specific German contexts, ensuring the evaluation focuses on differences affecting meaning, pronunciation, or intelligibility. To identify such issues and iteratively refine our system, we collaborate with language experts who review LLM outputs on our development sets and flag inaccuracies or inconsistencies, which inform benchmark corrections, in-context learning (ICL) examples refinements, and system iterations.</p>\n\n",
                "matched_terms": [
                    "language",
                    "german",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our prompt design follows a structured, step-by-step and language-agnostic format composed of three components: 1) <span class=\"ltx_text ltx_font_bold\">Instruction Prompt</span>, which defines the normalization task, 2) <span class=\"ltx_text ltx_font_bold\">In-Context Learning Examples</span>, which demonstrate how different types of text should be normalized, and 3) <span class=\"ltx_text ltx_font_bold\">Target Unnormalized Input</span>, to which the model applies learned patterns. PolyNorm uses a standardized English instruction prompt with localized ICL examples tailored to each language&#8217;s linguistic and stylistic norms.</p>\n\n",
                "matched_terms": [
                    "english",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Few-shot prompting with ICL offers a lightweight, scalable solution for multilingual text normalization, relying on high-quality, language-specific examples. The effectiveness of this approach depends on the quality and relevance of the ICL examples provided to the model. We use a unified prompt format across eight languages, varying only the localized examples&#8212;except for Japanese, where a supplementary prompt guides katakana output. Our curated ICL set, excluded from PolyNorm-Bench, includes 80-100 high-quality machine-translated Kestrel data and DeepSeek synthetic examples (e.g., favoring &#8220;twenty nineteen&#8221; over &#8220;two thousand nineteen&#8221; for &#8221;2019&#8221; in English), each normalized and validated by experts to ensure stylistic consistency across domains.</p>\n\n",
                "matched_terms": [
                    "english",
                    "model",
                    "japanese"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We analyzed discrepancies between expert-verified development sets and LLM outputs from GPT models to identify systematic weaknesses. Common errors included incorrect numeral expansions and inconsistent handling of language-specific formats such as date and currency. To address these issues, we identified categories or patterns where the model underperformed, then revised or added ICL examples focused on these error types, improving the model&#8217;s output with each iteration. This feedback loop refined normalization via prompt tuning and better examples, reducing errors and improving cross-lingual consistency.</p>\n\n",
                "matched_terms": [
                    "model",
                    "address"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All systems were tested on PolyNorm across eight languages listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. We report the overall performance with Word Error Rate (WER) and BLEU, which reflects how closely the model&#8217;s output matches the expected spoken form and relative surface similarity to the reference respectively. For non-whitespace languages (Chinese and Japanese), we report Character Error Rate instead of WER to avoid conflating tokenization errors with true normalization errors. PolyNorm demonstrates substantial advantages in terms of flexibility, coverage, and the ability to handle previously intractable normalization challenges with minimal manual human intervention. Results in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> show improvements in both WER and BLEU across the two LLM systems compared to the rule-based baseline. GPT-4o achieves a WER ranging from 4.17% to 7.88% for all languages.</p>\n\n",
                "matched_terms": [
                    "baseline",
                    "wer",
                    "japanese",
                    "results",
                    "chinese",
                    "overall"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Another observation of PolyNorm&#8217;s context awareness over rule-based systems is its handling of dashes between numbers. In sports scores, a dash is typically verbalized as &#8221;to&#8221; (e.g., &#8221;3-2&#8221; as &#8221;three to two&#8221;), whereas in phone numbers it is ignored and the digits are read individually. A rule-based system would require an explicit and often verbose set of context-specific rules to make this distinction, while PolyNorm can infer the correct interpretation directly from context, even in novel or ambiguous formats.</p>\n\n",
                "matched_terms": [
                    "phone",
                    "sports",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We present PolyNorm, a multilingual, LLM-assisted text normalization system designed to address scalability, cost, and language-coverage limitations of rule-based systems. It achieves strong normalization performance across languages and categories, and significantly reduces WER compared to production-grade rule-based systems, demonstrating its robustness and adaptability.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "address"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">While PolyNorm demonstrates strong potential in terms of efficiency and multilingual consistency, the model&#8217;s performance is highly dependent on the quality and representativeness of data used as in-context learning examples. Categories covered in the examples may not capture the full range of normalization needs across different languages and varieties. Furthermore, errors in normalization can propagate into downstream tasks such as translation, sentiment analysis, or educational tools. Although expert-reviewed examples were used for in-context learning, the model may still struggle with edge cases or uncommon linguistic patterns. These limitations must be addressed before considering the system for widespread or critical work.</p>\n\n",
                "matched_terms": [
                    "model",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section presents the instruction prompt template. Note that certain locales include supplementary prompts tailored to their linguistic or stylistic characteristics. In-context learning (ICL) examples are omitted here for brevity.\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>You are an accurate text normalizer for {locale}. Your task is to normalize unstandardized text from the following categories to truly reflects how the real speech is, based on the context:\n<br class=\"ltx_break\"/>- Cardinal \n<br class=\"ltx_break\"/>- Date\n<br class=\"ltx_break\"/>- Decimal\n<br class=\"ltx_break\"/>- Ordinal\n<br class=\"ltx_break\"/>- Fraction\n<br class=\"ltx_break\"/>- Time\n<br class=\"ltx_break\"/>- Currency\n<br class=\"ltx_break\"/>- Unit (Measure)\n<br class=\"ltx_break\"/>- Electronic Address (URL or Email)\n<br class=\"ltx_break\"/>- Initialism or Acronym\n<br class=\"ltx_break\"/>- ISBN\n<br class=\"ltx_break\"/>- Roman Numeral\n<br class=\"ltx_break\"/>- Telephone\n<br class=\"ltx_break\"/>- Sports Score\n<br class=\"ltx_break\"/>- Mathematical Expression\n<br class=\"ltx_break\"/>- Symbol\n<br class=\"ltx_break\"/>- Abbreviation\n<br class=\"ltx_break\"/>- Chemical Formula\n<br class=\"ltx_break\"/>- Legal Reference\n<br class=\"ltx_break\"/>- Vehicle or Product Code\n<br class=\"ltx_break\"/>- Geographic Coordinates\n<br class=\"ltx_break\"/>- Version Number\n<br class=\"ltx_break\"/>- License Plate or Serial Number\n<br class=\"ltx_break\"/>- Musical Notation\n<br class=\"ltx_break\"/>- Stock Ticker\n<br class=\"ltx_break\"/>- Biological Classification\n<br class=\"ltx_break\"/>- Address\n<br class=\"ltx_break\"/>- Other unnormalized text\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>Some important rules: \n<br class=\"ltx_break\"/>- When normalizing acronyms, spell out to their full forms for clarity, except when the acronym is a widely recognized and pronounceable name (e.g. &#8220;NASA&#8221; or &#8220;NASCAR&#8221;). In those cases, keep the acronym as-is and pronounce it as a word. \n<br class=\"ltx_break\"/>- If the acronym combines a letter and a word, split accordingly. \n<br class=\"ltx_break\"/>- Convert punctuation that is spoken aloud into words. For example, write &#8216;dot&#8217; instead of a period in URLs and emails. \n<br class=\"ltx_break\"/>- To ensure clarity, segment compound words, websites and file names into recognizable component words rather than keeping them as a whole word. \n<br class=\"ltx_break\"/>- Symbols in a file name should be read as is. \n<br class=\"ltx_break\"/>- Common file extensions (.jpeg, .jpg, .txt, etc) should be spoken out. Uncommon file extensions should be spelled out. \n<br class=\"ltx_break\"/></p>\n\n",
                "matched_terms": [
                    "legal",
                    "sports",
                    "musical",
                    "address"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Overall column reports the average WER across all 27 categories.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "overall"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Overall column reports the average WER across all 27 categories.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "overall"
                ]
            }
        ]
    },
    "A4.T5": {
        "source_file": "PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech",
        "caption": "Table 5: GPT-4o WER results for Iteration 2",
        "body": "Language\n\n\nOverall\n\n\n\n\nAddress\n\n\n\n\nLegal Ref.\n\n\n\n\nCurrencies\n\n\n\n\nMath. Expr.\n\n\n\n\nMusical Not.\n\n\n\n\nPhone Num.\n\n\n\n\nSports Scores\n\n\n\n\nGerman\n\n\n4.24\n\n\n\n\n1.11\n\n\n\n\n22.90\n\n\n\n\n9.52\n\n\n\n\n19.12\n\n\n\n\n2.52\n\n\n\n\n2.23\n\n\n\n\n9.31\n\n\n\n\nAmerican English\n\n\n5.23\n\n\n\n\n1.44\n\n\n\n\n4.68\n\n\n\n\n1.02\n\n\n\n\n2.38\n\n\n\n\n3.54\n\n\n\n\n0.38\n\n\n\n\n1.85\n\n\n\n\nMexican Spanish\n\n\n8.45\n\n\n\n\n0.45\n\n\n\n\n7.86\n\n\n\n\n13.95\n\n\n\n\n7.59\n\n\n\n\n19.75\n\n\n\n\n5.78\n\n\n\n\n6.25\n\n\n\n\nFrench\n\n\n5.73\n\n\n\n\n0.53\n\n\n\n\n4.42\n\n\n\n\n1.95\n\n\n\n\n11.98\n\n\n\n\n6.50\n\n\n\n\n2.14\n\n\n\n\n1.88\n\n\n\n\nItalian\n\n\n5.12\n\n\n\n\n0.58\n\n\n\n\n9.23\n\n\n\n\n0.80\n\n\n\n\n20.17\n\n\n\n\n4.50\n\n\n\n\n3.20\n\n\n\n\n3.08\n\n\n\n\nLithuanian\n\n\n12.22\n\n\n\n\n9.63\n\n\n\n\n13.75\n\n\n\n\n10.67\n\n\n\n\n21.26\n\n\n\n\n33.33\n\n\n\n\n13.77\n\n\n\n\n5.41\n\n\n\n\nMandarin Chinese\n\n\n6.33\n\n\n\n\n0.57\n\n\n\n\n7.41\n\n\n\n\n18.18\n\n\n\n\n10.00\n\n\n\n\n4.23\n\n\n\n\n11.27\n\n\n\n\n5.19\n\n\n\n\nJapanese\n\n\n12.32\n\n\n\n\n13.12\n\n\n\n\n11.32\n\n\n\n\n10.45\n\n\n\n\n9.10\n\n\n\n\n15.14\n\n\n\n\n9.52\n\n\n\n\n11.73",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Language</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Overall</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Address</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Legal Ref.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Currencies</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Math. Expr.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Musical Not.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Phone Num.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Sports Scores</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">German</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.24</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.11</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">22.90</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.52</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">19.12</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">2.52</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">2.23</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.31</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">American English</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.23</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.44</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.68</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.02</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">2.38</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">3.54</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.38</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.85</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Mexican Spanish</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">8.45</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.45</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.86</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">13.95</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.59</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">19.75</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.78</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">6.25</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">French</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.73</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.53</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.42</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.95</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.98</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">6.50</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">2.14</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.88</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Italian</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.12</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.58</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.23</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.80</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">20.17</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.50</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">3.20</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">3.08</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Lithuanian</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">12.22</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.63</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">13.75</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.67</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">21.26</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">33.33</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">13.77</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.41</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Mandarin Chinese</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">6.33</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.57</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.41</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">18.18</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.00</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.23</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.27</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.19</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">Japanese</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">12.32</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">13.12</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.32</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.45</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.10</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">15.14</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.52</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.73</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "american",
            "wer",
            "currencies",
            "french",
            "num",
            "lithuanian",
            "chinese",
            "italian",
            "mandarin",
            "legal",
            "address",
            "japanese",
            "results",
            "gpt4o",
            "overall",
            "scores",
            "expr",
            "sports",
            "spanish",
            "phone",
            "language",
            "math",
            "english",
            "german",
            "iteration",
            "ref",
            "mexican",
            "musical",
            "not"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS) systems, converting written forms into their canonical spoken equivalents. Traditional TN systems can exhibit high accuracy, but involve substantial engineering effort, are difficult to scale, and pose challenges to language coverage, particularly in low-resource settings. We propose PolyNorm, a prompt-based approach to TN using Large Language Models (LLMs), aiming to reduce the reliance on manually crafted rules and enable broader linguistic applicability with minimal human intervention. Additionally, we present a language-agnostic pipeline for automatic data curation and evaluation, designed to facilitate scalable experimentation across diverse languages. Experiments across eight languages show consistent reductions in the word error rate (WER) compared to a production-grade-based system. To support further research, we release PolyNorm-Benchmark, a multilingual data set covering a diverse range of text normalization phenomena.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "language"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our research focuses on American English, German, French, Mexican Spanish, Italian, Lithuanian, Japanese, and Mandarin Chinese.</p>\n\n",
                "matched_terms": [
                    "mandarin",
                    "english",
                    "american",
                    "spanish",
                    "german",
                    "french",
                    "japanese",
                    "italian",
                    "lithuanian",
                    "chinese",
                    "mexican"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We start with a subset of the English Kestrel dataset <cite class=\"ltx_cite ltx_citemacro_cite\">Ebden and Sproat (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib2\" title=\"\">2015</a>)</cite> comprising 14 Kestrel categories extracted from the first file of the dataset, which contains approximately 880,000 lines. For English, to construct a balanced subset, we select a total of 1,400 test cases, removing all sentences that lack normalization targets and retaining the first 100 examples per category from the Kestrel dataset for benchmarking purposes. We initially experimented with translating both the original and normalized English texts into the target languages with NLLB-200 model <cite class=\"ltx_cite ltx_citemacro_cite\">Facebook AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib3\" title=\"\">2022</a>)</cite>. However, we found most translated texts unsuitable as ground truth due to inconsistent quality, translation and inadequate localization of the normalized forms. In addition, the limited categories do not fully cover the scope of normalization phenomena that we aim to evaluate. Therefore, instead of using the entire subset for benchmarking, we reserved some of the higher-quality data, reviewed and verified by language experts, as part of the prompt examples, which will be discussed in the Methodology section.</p>\n\n",
                "matched_terms": [
                    "language",
                    "english",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address these challenges, we use DeepSeek-R1 <cite class=\"ltx_cite ltx_citemacro_cite\">DeepSeek-AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib1\" title=\"\">2025</a>)</cite> to generate datasets comprising unnormalized and normalized text pairs as our new multilingual benchmark suite, <em class=\"ltx_emph ltx_font_italic\">PolyNorm-Benchmark</em><span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>https://github.com/apple/ml-speech-polynorm-bench</span></span></span>, designed to ensure consistency across languages and taxonomies. Each dataset spans 27 normalization categories (listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S2.T1\" title=\"Table 1 &#8227; 2 Data &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>) built on Kestrel categories and expanded with new classes, comprising 20 examples per category for a total of 540 high-quality data points per language. For Chinese and Japanese, we define abbreviations as truncated forms or initial-letter substitutions, since conventional definitions may not fully capture their use in conversational language.</p>\n\n",
                "matched_terms": [
                    "language",
                    "address",
                    "japanese",
                    "chinese",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The initial outputs of DeepSeek serve as a foundation, then each example is subsequently edited and verified by internal language experts to ensure the highest standards of linguistic precision, naturalness, and overall quality. The orthography and formatting of synthetic data follow the conventions of target languages. For example, in French, decimal separator in currency is written with a comma instead of a period, with the currency symbol after the number:</p>\n\n",
                "matched_terms": [
                    "language",
                    "overall",
                    "french"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For clarity and consistency, we standardize normalization to common conventions across languages when applicable. For instance, in American English, we follow the month-day-year format, consistent with our TTS production system expectations. Years like &#8221;2020&#8221; are normalized as <span class=\"ltx_text ltx_font_typewriter\">twenty twenty</span>, and dates such as &#8221;4/18&#8221; are normalized as <span class=\"ltx_text ltx_font_typewriter\">april eighteenth</span>.</p>\n\n",
                "matched_terms": [
                    "english",
                    "american"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Certain differences are not considered errors in our evaluation, as they do not affect the semantic or phonetic realization of the text. These include casing, optional spacing (e.g., in German compound words), and orthographic variants such as &#8221;&#223;&#8221; vs. &#8221;ss&#8221; in specific German contexts, ensuring the evaluation focuses on differences affecting meaning, pronunciation, or intelligibility. To identify such issues and iteratively refine our system, we collaborate with language experts who review LLM outputs on our development sets and flag inaccuracies or inconsistencies, which inform benchmark corrections, in-context learning (ICL) examples refinements, and system iterations.</p>\n\n",
                "matched_terms": [
                    "language",
                    "german",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Few-shot prompting with ICL offers a lightweight, scalable solution for multilingual text normalization, relying on high-quality, language-specific examples. The effectiveness of this approach depends on the quality and relevance of the ICL examples provided to the model. We use a unified prompt format across eight languages, varying only the localized examples&#8212;except for Japanese, where a supplementary prompt guides katakana output. Our curated ICL set, excluded from PolyNorm-Bench, includes 80-100 high-quality machine-translated Kestrel data and DeepSeek synthetic examples (e.g., favoring &#8220;twenty nineteen&#8221; over &#8220;two thousand nineteen&#8221; for &#8221;2019&#8221; in English), each normalized and validated by experts to ensure stylistic consistency across domains.</p>\n\n",
                "matched_terms": [
                    "english",
                    "japanese"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We analyzed discrepancies between expert-verified development sets and LLM outputs from GPT models to identify systematic weaknesses. Common errors included incorrect numeral expansions and inconsistent handling of language-specific formats such as date and currency. To address these issues, we identified categories or patterns where the model underperformed, then revised or added ICL examples focused on these error types, improving the model&#8217;s output with each iteration. This feedback loop refined normalization via prompt tuning and better examples, reducing errors and improving cross-lingual consistency.</p>\n\n",
                "matched_terms": [
                    "address",
                    "iteration"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluated GPT-4o-mini and GPT-4o as candidate systems against Apple Siri production rule-based normalization baseline system. Because it is proprietary, we cannot release code or provide external access. However, to help readers judge strength and fairness, we report baseline scores for a representative subset of seven categories across all eight languages in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A3.T4\" title=\"Table 4 &#8227; Appendix C Baseline model WER (%) by Language and Selected Categories &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> below<span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_tag ltx_tag_note\">3</span>Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2.T3\" title=\"Table 3 &#8227; Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> in Appendix <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2\" title=\"Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">B</span></a> shows side-by-side examples illustrating some incorrect baseline outputs</span></span></span>. It is important to note that the baseline predates our benchmark and was not tuned to it.</p>\n\n",
                "matched_terms": [
                    "gpt4o",
                    "scores",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All systems were tested on PolyNorm across eight languages listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. We report the overall performance with Word Error Rate (WER) and BLEU, which reflects how closely the model&#8217;s output matches the expected spoken form and relative surface similarity to the reference respectively. For non-whitespace languages (Chinese and Japanese), we report Character Error Rate instead of WER to avoid conflating tokenization errors with true normalization errors. PolyNorm demonstrates substantial advantages in terms of flexibility, coverage, and the ability to handle previously intractable normalization challenges with minimal manual human intervention. Results in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> show improvements in both WER and BLEU across the two LLM systems compared to the rule-based baseline. GPT-4o achieves a WER ranging from 4.17% to 7.88% for all languages.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "japanese",
                    "results",
                    "gpt4o",
                    "chinese",
                    "overall"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Another observation of PolyNorm&#8217;s context awareness over rule-based systems is its handling of dashes between numbers. In sports scores, a dash is typically verbalized as &#8221;to&#8221; (e.g., &#8221;3-2&#8221; as &#8221;three to two&#8221;), whereas in phone numbers it is ignored and the digits are read individually. A rule-based system would require an explicit and often verbose set of context-specific rules to make this distinction, while PolyNorm can infer the correct interpretation directly from context, even in novel or ambiguous formats.</p>\n\n",
                "matched_terms": [
                    "phone",
                    "sports",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Training a reliable TTS system can require millions of high-quality data points. While effective in controlled environments, traditional TN pipelines, heavily rule-based, demand ongoing annotation and patching, often taking months per language and struggling to generalize or scale to noisy, ambiguous, or evolving inputs. PolyNorm replaces this manual loop with an LLM-driven framework using prompt tuning and in-context learning, cutting development overhead and accelerating iteration by refining prompts or examples.</p>\n\n",
                "matched_terms": [
                    "language",
                    "iteration"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We present PolyNorm, a multilingual, LLM-assisted text normalization system designed to address scalability, cost, and language-coverage limitations of rule-based systems. It achieves strong normalization performance across languages and categories, and significantly reduces WER compared to production-grade rule-based systems, demonstrating its robustness and adaptability.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "address"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section presents the instruction prompt template. Note that certain locales include supplementary prompts tailored to their linguistic or stylistic characteristics. In-context learning (ICL) examples are omitted here for brevity.\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>You are an accurate text normalizer for {locale}. Your task is to normalize unstandardized text from the following categories to truly reflects how the real speech is, based on the context:\n<br class=\"ltx_break\"/>- Cardinal \n<br class=\"ltx_break\"/>- Date\n<br class=\"ltx_break\"/>- Decimal\n<br class=\"ltx_break\"/>- Ordinal\n<br class=\"ltx_break\"/>- Fraction\n<br class=\"ltx_break\"/>- Time\n<br class=\"ltx_break\"/>- Currency\n<br class=\"ltx_break\"/>- Unit (Measure)\n<br class=\"ltx_break\"/>- Electronic Address (URL or Email)\n<br class=\"ltx_break\"/>- Initialism or Acronym\n<br class=\"ltx_break\"/>- ISBN\n<br class=\"ltx_break\"/>- Roman Numeral\n<br class=\"ltx_break\"/>- Telephone\n<br class=\"ltx_break\"/>- Sports Score\n<br class=\"ltx_break\"/>- Mathematical Expression\n<br class=\"ltx_break\"/>- Symbol\n<br class=\"ltx_break\"/>- Abbreviation\n<br class=\"ltx_break\"/>- Chemical Formula\n<br class=\"ltx_break\"/>- Legal Reference\n<br class=\"ltx_break\"/>- Vehicle or Product Code\n<br class=\"ltx_break\"/>- Geographic Coordinates\n<br class=\"ltx_break\"/>- Version Number\n<br class=\"ltx_break\"/>- License Plate or Serial Number\n<br class=\"ltx_break\"/>- Musical Notation\n<br class=\"ltx_break\"/>- Stock Ticker\n<br class=\"ltx_break\"/>- Biological Classification\n<br class=\"ltx_break\"/>- Address\n<br class=\"ltx_break\"/>- Other unnormalized text\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>Some important rules: \n<br class=\"ltx_break\"/>- When normalizing acronyms, spell out to their full forms for clarity, except when the acronym is a widely recognized and pronounceable name (e.g. &#8220;NASA&#8221; or &#8220;NASCAR&#8221;). In those cases, keep the acronym as-is and pronounce it as a word. \n<br class=\"ltx_break\"/>- If the acronym combines a letter and a word, split accordingly. \n<br class=\"ltx_break\"/>- Convert punctuation that is spoken aloud into words. For example, write &#8216;dot&#8217; instead of a period in URLs and emails. \n<br class=\"ltx_break\"/>- To ensure clarity, segment compound words, websites and file names into recognizable component words rather than keeping them as a whole word. \n<br class=\"ltx_break\"/>- Symbols in a file name should be read as is. \n<br class=\"ltx_break\"/>- Common file extensions (.jpeg, .jpg, .txt, etc) should be spoken out. Uncommon file extensions should be spelled out. \n<br class=\"ltx_break\"/></p>\n\n",
                "matched_terms": [
                    "legal",
                    "sports",
                    "musical",
                    "address"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Overall column reports the average WER across all 27 categories.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "overall"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Overall column reports the average WER across all 27 categories.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "overall"
                ]
            }
        ]
    },
    "A4.T6": {
        "source_file": "PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech",
        "caption": "Table 6: GPT-4o WER results for Iteration 3",
        "body": "Language\n\n\nOverall\n\n\n\n\nAddress\n\n\n\n\nLegal Ref.\n\n\n\n\nCurrencies\n\n\n\n\nMath. Expr.\n\n\n\n\nMusical Not.\n\n\n\n\nPhone Num.\n\n\n\n\nSports Scores\n\n\n\n\nGerman\n\n\n4.17\n\n\n\n\n0.56\n\n\n\n\n19.85\n\n\n\n\n9.52\n\n\n\n\n17.65\n\n\n\n\n2.52\n\n\n\n\n1.79\n\n\n\n\n7.78\n\n\n\n\nAmerican English\n\n\n4.28\n\n\n\n\n1.91\n\n\n\n\n5.53\n\n\n\n\n1.29\n\n\n\n\n1.19\n\n\n\n\n3.54\n\n\n\n\n1.14\n\n\n\n\n1.23\n\n\n\n\nMexican Spanish\n\n\n7.69\n\n\n\n\n0.90\n\n\n\n\n7.14\n\n\n\n\n13.95\n\n\n\n\n5.70\n\n\n\n\n20.99\n\n\n\n\n4.44\n\n\n\n\n11.61\n\n\n\n\nFrench\n\n\n5.65\n\n\n\n\n2.66\n\n\n\n\n4.42\n\n\n\n\n1.30\n\n\n\n\n10.78\n\n\n\n\n4.07\n\n\n\n\n3.20\n\n\n\n\n1.88\n\n\n\n\nItalian\n\n\n4.56\n\n\n\n\n0.58\n\n\n\n\n8.46\n\n\n\n\n1.60\n\n\n\n\n17.65\n\n\n\n\n3.60\n\n\n\n\n4.40\n\n\n\n\n1.54\n\n\n\n\nLithuanian\n\n\n6.99\n\n\n\n\n5.98\n\n\n\n\n12.92\n\n\n\n\n7.30\n\n\n\n\n17.32\n\n\n\n\n16.67\n\n\n\n\n8.78\n\n\n\n\n4.13\n\n\n\n\nMandarin Chinese\n\n\n5.05\n\n\n\n\n1.06\n\n\n\n\n4.51\n\n\n\n\n17.76\n\n\n\n\n8.29\n\n\n\n\n7.04\n\n\n\n\n1.59\n\n\n\n\n2.59\n\n\n\n\nJapanese\n\n\n7.88\n\n\n\n\n3.56\n\n\n\n\n9.22\n\n\n\n\n6.58\n\n\n\n\n7.18\n\n\n\n\n8.49\n\n\n\n\n4.71\n\n\n\n\n8.31",
        "html_code": "<table class=\"ltx_tabular ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Language</span></td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Overall</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Address</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Legal Ref.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Currencies</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Math. Expr.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Musical Not.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Phone Num.</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\"><span class=\"ltx_text ltx_font_bold\">Sports Scores</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\">German</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.17</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.56</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">19.85</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.52</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">17.65</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">2.52</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.79</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.78</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">American English</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.28</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.91</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.53</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.29</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.19</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">3.54</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.14</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.23</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Mexican Spanish</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.69</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.90</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.14</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">13.95</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.70</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">20.99</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.44</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">11.61</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">French</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.65</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">2.66</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.42</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.30</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">10.78</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.07</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">3.20</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.88</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Italian</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.56</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">0.58</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">8.46</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.60</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">17.65</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">3.60</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.40</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.54</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Lithuanian</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">6.99</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.98</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">12.92</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.30</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">17.32</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">16.67</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">8.78</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.13</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\">Mandarin Chinese</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">5.05</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.06</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.51</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">17.76</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">8.29</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.04</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">1.59</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">2.59</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\">Japanese</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.88</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">3.56</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">9.22</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">6.58</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">7.18</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">8.49</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">4.71</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p ltx_align_center\">8.31</span>\n</span>\n</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "american",
            "wer",
            "currencies",
            "french",
            "num",
            "lithuanian",
            "chinese",
            "italian",
            "mandarin",
            "legal",
            "address",
            "japanese",
            "results",
            "gpt4o",
            "overall",
            "scores",
            "expr",
            "sports",
            "spanish",
            "phone",
            "language",
            "math",
            "english",
            "german",
            "iteration",
            "ref",
            "mexican",
            "musical",
            "not"
        ],
        "citing_paragraphs": [],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS) systems, converting written forms into their canonical spoken equivalents. Traditional TN systems can exhibit high accuracy, but involve substantial engineering effort, are difficult to scale, and pose challenges to language coverage, particularly in low-resource settings. We propose PolyNorm, a prompt-based approach to TN using Large Language Models (LLMs), aiming to reduce the reliance on manually crafted rules and enable broader linguistic applicability with minimal human intervention. Additionally, we present a language-agnostic pipeline for automatic data curation and evaluation, designed to facilitate scalable experimentation across diverse languages. Experiments across eight languages show consistent reductions in the word error rate (WER) compared to a production-grade-based system. To support further research, we release PolyNorm-Benchmark, a multilingual data set covering a diverse range of text normalization phenomena.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "language"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our research focuses on American English, German, French, Mexican Spanish, Italian, Lithuanian, Japanese, and Mandarin Chinese.</p>\n\n",
                "matched_terms": [
                    "mandarin",
                    "english",
                    "american",
                    "spanish",
                    "german",
                    "french",
                    "japanese",
                    "italian",
                    "lithuanian",
                    "chinese",
                    "mexican"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We start with a subset of the English Kestrel dataset <cite class=\"ltx_cite ltx_citemacro_cite\">Ebden and Sproat (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib2\" title=\"\">2015</a>)</cite> comprising 14 Kestrel categories extracted from the first file of the dataset, which contains approximately 880,000 lines. For English, to construct a balanced subset, we select a total of 1,400 test cases, removing all sentences that lack normalization targets and retaining the first 100 examples per category from the Kestrel dataset for benchmarking purposes. We initially experimented with translating both the original and normalized English texts into the target languages with NLLB-200 model <cite class=\"ltx_cite ltx_citemacro_cite\">Facebook AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib3\" title=\"\">2022</a>)</cite>. However, we found most translated texts unsuitable as ground truth due to inconsistent quality, translation and inadequate localization of the normalized forms. In addition, the limited categories do not fully cover the scope of normalization phenomena that we aim to evaluate. Therefore, instead of using the entire subset for benchmarking, we reserved some of the higher-quality data, reviewed and verified by language experts, as part of the prompt examples, which will be discussed in the Methodology section.</p>\n\n",
                "matched_terms": [
                    "language",
                    "english",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address these challenges, we use DeepSeek-R1 <cite class=\"ltx_cite ltx_citemacro_cite\">DeepSeek-AI (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#bib.bib1\" title=\"\">2025</a>)</cite> to generate datasets comprising unnormalized and normalized text pairs as our new multilingual benchmark suite, <em class=\"ltx_emph ltx_font_italic\">PolyNorm-Benchmark</em><span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">2</sup><span class=\"ltx_tag ltx_tag_note\">2</span>https://github.com/apple/ml-speech-polynorm-bench</span></span></span>, designed to ensure consistency across languages and taxonomies. Each dataset spans 27 normalization categories (listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S2.T1\" title=\"Table 1 &#8227; 2 Data &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>) built on Kestrel categories and expanded with new classes, comprising 20 examples per category for a total of 540 high-quality data points per language. For Chinese and Japanese, we define abbreviations as truncated forms or initial-letter substitutions, since conventional definitions may not fully capture their use in conversational language.</p>\n\n",
                "matched_terms": [
                    "language",
                    "address",
                    "japanese",
                    "chinese",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The initial outputs of DeepSeek serve as a foundation, then each example is subsequently edited and verified by internal language experts to ensure the highest standards of linguistic precision, naturalness, and overall quality. The orthography and formatting of synthetic data follow the conventions of target languages. For example, in French, decimal separator in currency is written with a comma instead of a period, with the currency symbol after the number:</p>\n\n",
                "matched_terms": [
                    "language",
                    "overall",
                    "french"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For clarity and consistency, we standardize normalization to common conventions across languages when applicable. For instance, in American English, we follow the month-day-year format, consistent with our TTS production system expectations. Years like &#8221;2020&#8221; are normalized as <span class=\"ltx_text ltx_font_typewriter\">twenty twenty</span>, and dates such as &#8221;4/18&#8221; are normalized as <span class=\"ltx_text ltx_font_typewriter\">april eighteenth</span>.</p>\n\n",
                "matched_terms": [
                    "english",
                    "american"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Certain differences are not considered errors in our evaluation, as they do not affect the semantic or phonetic realization of the text. These include casing, optional spacing (e.g., in German compound words), and orthographic variants such as &#8221;&#223;&#8221; vs. &#8221;ss&#8221; in specific German contexts, ensuring the evaluation focuses on differences affecting meaning, pronunciation, or intelligibility. To identify such issues and iteratively refine our system, we collaborate with language experts who review LLM outputs on our development sets and flag inaccuracies or inconsistencies, which inform benchmark corrections, in-context learning (ICL) examples refinements, and system iterations.</p>\n\n",
                "matched_terms": [
                    "language",
                    "german",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Few-shot prompting with ICL offers a lightweight, scalable solution for multilingual text normalization, relying on high-quality, language-specific examples. The effectiveness of this approach depends on the quality and relevance of the ICL examples provided to the model. We use a unified prompt format across eight languages, varying only the localized examples&#8212;except for Japanese, where a supplementary prompt guides katakana output. Our curated ICL set, excluded from PolyNorm-Bench, includes 80-100 high-quality machine-translated Kestrel data and DeepSeek synthetic examples (e.g., favoring &#8220;twenty nineteen&#8221; over &#8220;two thousand nineteen&#8221; for &#8221;2019&#8221; in English), each normalized and validated by experts to ensure stylistic consistency across domains.</p>\n\n",
                "matched_terms": [
                    "english",
                    "japanese"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We analyzed discrepancies between expert-verified development sets and LLM outputs from GPT models to identify systematic weaknesses. Common errors included incorrect numeral expansions and inconsistent handling of language-specific formats such as date and currency. To address these issues, we identified categories or patterns where the model underperformed, then revised or added ICL examples focused on these error types, improving the model&#8217;s output with each iteration. This feedback loop refined normalization via prompt tuning and better examples, reducing errors and improving cross-lingual consistency.</p>\n\n",
                "matched_terms": [
                    "address",
                    "iteration"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluated GPT-4o-mini and GPT-4o as candidate systems against Apple Siri production rule-based normalization baseline system. Because it is proprietary, we cannot release code or provide external access. However, to help readers judge strength and fairness, we report baseline scores for a representative subset of seven categories across all eight languages in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A3.T4\" title=\"Table 4 &#8227; Appendix C Baseline model WER (%) by Language and Selected Categories &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">4</span></a> below<span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">3</sup><span class=\"ltx_tag ltx_tag_note\">3</span>Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2.T3\" title=\"Table 3 &#8227; Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">3</span></a> in Appendix <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#A2\" title=\"Appendix B Baseline Normalization Examples &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">B</span></a> shows side-by-side examples illustrating some incorrect baseline outputs</span></span></span>. It is important to note that the baseline predates our benchmark and was not tuned to it.</p>\n\n",
                "matched_terms": [
                    "gpt4o",
                    "scores",
                    "not"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">All systems were tested on PolyNorm across eight languages listed in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. We report the overall performance with Word Error Rate (WER) and BLEU, which reflects how closely the model&#8217;s output matches the expected spoken form and relative surface similarity to the reference respectively. For non-whitespace languages (Chinese and Japanese), we report Character Error Rate instead of WER to avoid conflating tokenization errors with true normalization errors. PolyNorm demonstrates substantial advantages in terms of flexibility, coverage, and the ability to handle previously intractable normalization challenges with minimal manual human intervention. Results in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2511.03080v1#S4.T2\" title=\"Table 2 &#8227; 4 Results &#8227; PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> show improvements in both WER and BLEU across the two LLM systems compared to the rule-based baseline. GPT-4o achieves a WER ranging from 4.17% to 7.88% for all languages.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "japanese",
                    "results",
                    "gpt4o",
                    "chinese",
                    "overall"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Another observation of PolyNorm&#8217;s context awareness over rule-based systems is its handling of dashes between numbers. In sports scores, a dash is typically verbalized as &#8221;to&#8221; (e.g., &#8221;3-2&#8221; as &#8221;three to two&#8221;), whereas in phone numbers it is ignored and the digits are read individually. A rule-based system would require an explicit and often verbose set of context-specific rules to make this distinction, while PolyNorm can infer the correct interpretation directly from context, even in novel or ambiguous formats.</p>\n\n",
                "matched_terms": [
                    "phone",
                    "sports",
                    "scores"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Training a reliable TTS system can require millions of high-quality data points. While effective in controlled environments, traditional TN pipelines, heavily rule-based, demand ongoing annotation and patching, often taking months per language and struggling to generalize or scale to noisy, ambiguous, or evolving inputs. PolyNorm replaces this manual loop with an LLM-driven framework using prompt tuning and in-context learning, cutting development overhead and accelerating iteration by refining prompts or examples.</p>\n\n",
                "matched_terms": [
                    "language",
                    "iteration"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We present PolyNorm, a multilingual, LLM-assisted text normalization system designed to address scalability, cost, and language-coverage limitations of rule-based systems. It achieves strong normalization performance across languages and categories, and significantly reduces WER compared to production-grade rule-based systems, demonstrating its robustness and adaptability.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "address"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This section presents the instruction prompt template. Note that certain locales include supplementary prompts tailored to their linguistic or stylistic characteristics. In-context learning (ICL) examples are omitted here for brevity.\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>You are an accurate text normalizer for {locale}. Your task is to normalize unstandardized text from the following categories to truly reflects how the real speech is, based on the context:\n<br class=\"ltx_break\"/>- Cardinal \n<br class=\"ltx_break\"/>- Date\n<br class=\"ltx_break\"/>- Decimal\n<br class=\"ltx_break\"/>- Ordinal\n<br class=\"ltx_break\"/>- Fraction\n<br class=\"ltx_break\"/>- Time\n<br class=\"ltx_break\"/>- Currency\n<br class=\"ltx_break\"/>- Unit (Measure)\n<br class=\"ltx_break\"/>- Electronic Address (URL or Email)\n<br class=\"ltx_break\"/>- Initialism or Acronym\n<br class=\"ltx_break\"/>- ISBN\n<br class=\"ltx_break\"/>- Roman Numeral\n<br class=\"ltx_break\"/>- Telephone\n<br class=\"ltx_break\"/>- Sports Score\n<br class=\"ltx_break\"/>- Mathematical Expression\n<br class=\"ltx_break\"/>- Symbol\n<br class=\"ltx_break\"/>- Abbreviation\n<br class=\"ltx_break\"/>- Chemical Formula\n<br class=\"ltx_break\"/>- Legal Reference\n<br class=\"ltx_break\"/>- Vehicle or Product Code\n<br class=\"ltx_break\"/>- Geographic Coordinates\n<br class=\"ltx_break\"/>- Version Number\n<br class=\"ltx_break\"/>- License Plate or Serial Number\n<br class=\"ltx_break\"/>- Musical Notation\n<br class=\"ltx_break\"/>- Stock Ticker\n<br class=\"ltx_break\"/>- Biological Classification\n<br class=\"ltx_break\"/>- Address\n<br class=\"ltx_break\"/>- Other unnormalized text\n<br class=\"ltx_break\"/>\n<br class=\"ltx_break\"/>Some important rules: \n<br class=\"ltx_break\"/>- When normalizing acronyms, spell out to their full forms for clarity, except when the acronym is a widely recognized and pronounceable name (e.g. &#8220;NASA&#8221; or &#8220;NASCAR&#8221;). In those cases, keep the acronym as-is and pronounce it as a word. \n<br class=\"ltx_break\"/>- If the acronym combines a letter and a word, split accordingly. \n<br class=\"ltx_break\"/>- Convert punctuation that is spoken aloud into words. For example, write &#8216;dot&#8217; instead of a period in URLs and emails. \n<br class=\"ltx_break\"/>- To ensure clarity, segment compound words, websites and file names into recognizable component words rather than keeping them as a whole word. \n<br class=\"ltx_break\"/>- Symbols in a file name should be read as is. \n<br class=\"ltx_break\"/>- Common file extensions (.jpeg, .jpg, .txt, etc) should be spoken out. Uncommon file extensions should be spelled out. \n<br class=\"ltx_break\"/></p>\n\n",
                "matched_terms": [
                    "legal",
                    "sports",
                    "musical",
                    "address"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Overall column reports the average WER across all 27 categories.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "overall"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The Overall column reports the average WER across all 27 categories.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "overall"
                ]
            }
        ]
    }
}