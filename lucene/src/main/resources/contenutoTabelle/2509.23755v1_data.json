{
    "S2.T1": {
        "source_file": "Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis",
        "caption": "Table 1: Model perplexity (PPL) after deactivating 3% parameters based on parameter importance scores.",
        "body": "Size\nInput\nBase\n3% Removal\n\n\nTop\nBottom\nRandom\n\n\n\n\n1B\nSpeech\n2.08\n1.14×1051.14\\text{\\times}{10}^{5}\n2.18\n3.85\n\n\nText\n3.65\n2.68×1052.68\\text{\\times}{10}^{5}\n3.81\n6.39\n\n\n8B\nSpeech\n1.75\n2.72×1052.72\\text{\\times}{10}^{5}\n1.76\n3.54\n\n\nText\n3.12\n2.60×1052.60\\text{\\times}{10}^{5}\n3.19\n5.47",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">Size</span></th>\n<th class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">Input</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">Base</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"3\"><span class=\"ltx_text\" style=\"font-size:90%;\">3% Removal</span></th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Top</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Bottom</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Random</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">1B</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Speech</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.08</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"1.14\\text{\\times}{10}^{5}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m1\" intent=\":literal\"><semantics><mrow><mn mathsize=\"0.900em\">1.14</mn><mtext mathsize=\"0.900em\">&#215;</mtext><msup><mn mathsize=\"0.900em\">10</mn><mn mathsize=\"0.900em\">5</mn></msup></mrow><annotation encoding=\"application/x-tex\">1.14\\text{\\times}{10}^{5}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">2.18</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.85</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_l ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">Text</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.65</span></td>\n<td class=\"ltx_td ltx_align_center\"><math alttext=\"2.68\\text{\\times}{10}^{5}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m2\" intent=\":literal\"><semantics><mrow><mn mathsize=\"0.900em\">2.68</mn><mtext mathsize=\"0.900em\">&#215;</mtext><msup><mn mathsize=\"0.900em\">10</mn><mn mathsize=\"0.900em\">5</mn></msup></mrow><annotation encoding=\"application/x-tex\">2.68\\text{\\times}{10}^{5}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.81</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">6.39</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">8B</span></td>\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Speech</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.75</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><math alttext=\"2.72\\text{\\times}{10}^{5}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m3\" intent=\":literal\"><semantics><mrow><mn mathsize=\"0.900em\">2.72</mn><mtext mathsize=\"0.900em\">&#215;</mtext><msup><mn mathsize=\"0.900em\">10</mn><mn mathsize=\"0.900em\">5</mn></msup></mrow><annotation encoding=\"application/x-tex\">2.72\\text{\\times}{10}^{5}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">1.76</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.54</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">Text</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.12</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><math alttext=\"2.60\\text{\\times}{10}^{5}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m4\" intent=\":literal\"><semantics><mrow><mn mathsize=\"0.900em\">2.60</mn><mtext mathsize=\"0.900em\">&#215;</mtext><msup><mn mathsize=\"0.900em\">10</mn><mn mathsize=\"0.900em\">5</mn></msup></mrow><annotation encoding=\"application/x-tex\">2.60\\text{\\times}{10}^{5}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">3.19</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">5.47</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "parameters",
            "speech",
            "base",
            "268×105268texttimes105",
            "text",
            "random",
            "bottom",
            "top",
            "scores",
            "ppl",
            "removal",
            "260×105260texttimes105",
            "deactivating",
            "parameter",
            "input",
            "114×105114texttimes105",
            "perplexity",
            "size",
            "model",
            "272×105272texttimes105",
            "after",
            "based",
            "importance"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The results, summarized in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 2.2 Validation of the Parameter Importance Estimation &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, strongly support our hypothesis. Deactivating the top 3% of parameters caused a dramatic increase in PPL and a severe loss of linguistic competence. In contrast, nullifying the bottom 3% had negligible effect, and removing a random 3% resulted in only minor degradation. These findings demonstrates that the observed performance degradation is attributed to the removal of high-importance parameters rather than the deactivation process itself. We therefore conclude that the parameter importance metric is a reliable tool for identifying functionally critical parameters, providing a solid foundation for the subsequent analysis.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The integration of speech into Large Language Models (LLMs) has substantially expanded their capabilities, but often at the cost of weakening their core textual competence. This degradation limits the ability of speech-enabled LLMs to fully exploit their pre-trained text-based knowledge. In this work, we analyze the underlying mechanisms of this issue through a focused study of the widely used encoder&#8211;adaptor paradigm. We propose an analytical framework based on parameter importance estimation, which reveals that fine-tuning for speech introduces a textual importance distribution shift: the layer-wise allocation of parameters critical to textual reasoning is disrupted. Building on this insight, we investigate two mitigation strategies: layer-wise learning rate scheduling and Low-Rank Adaptation (LoRA), both aim to preserve the original parameter distribution. Experimental results show that both approaches better maintain textual competence than full fine-tuning, while also improving downstream spoken question answering performance. Furthermore, our analysis offers a principled explanation for the effectiveness of the proposed mitigation strategies, linking their benefits to the structural properties of textual knowledge in LLMs.</span>\n</p>\n\n",
                "matched_terms": [
                    "parameters",
                    "speech",
                    "parameter",
                    "based",
                    "importance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold ltx_font_italic\" style=\"font-size:90%;\">Index Terms<span class=\"ltx_text ltx_font_upright\">&#8212;&#8201;<span class=\"ltx_text ltx_font_medium\">\nspeech LLM, question answering, parameter importance, textual capability degradation</span></span></span>\n</p>\n\n",
                "matched_terms": [
                    "parameter",
                    "speech",
                    "importance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Early attempts at speech-enabled LLMs often relied on cascaded ASR&#8211;LLM&#8211;TTS pipelines </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib7\" title=\"\">7</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib8\" title=\"\">8</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. While functional, these pipelines introduce non-negligible latency and suffer from error accumulation across components. To overcome these limitations, recent work has shifted toward end-to-end speech LLMs that directly integrate speech abilities. Existing methods generally fall into two paradigms. The first couples a speech encoder with the LLM via an adaptor, aligning speech representations with LLM&#8217;s input space </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib9\" title=\"\">9</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib10\" title=\"\">10</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib11\" title=\"\">11</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The second directly incorporates discrete speech tokens into the LLM by expanding its vocabulary </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib12\" title=\"\">12</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib15\" title=\"\">15</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "speech",
                    "input"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To equip LLMs with speech capabilities, both paradigms typically rely on multi-stage fine-tuning on speech-related tasks </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib16\" title=\"\">16</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. However, the substantial mismatch between speech and text data distributions often leads to catastrophic forgetting, a phenomenon where the LLM loses previously acquired knowledge </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib17\" title=\"\">17</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib18\" title=\"\">18</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. While the LLM gains new speech-related skills, its foundational text-based reasoning and instruction-following abilities significantly degrade</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This trade-off poses a critical bottleneck, as preserving the strong textual intelligence of the base LLM is essential for high-quality spoken interaction. Although this degradation is widely observed, its internal mechanisms remain poorly understood. What exactly is disrupted in the model during speech fine-tuning, and why does this lead to diminished textual competence?</span>\n</p>\n\n",
                "matched_terms": [
                    "base",
                    "speech",
                    "model",
                    "text"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To address these questions, this paper conducts a focused case study of speech LLMs built with the encoder&#8211;adaptor paradigm </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib9\" title=\"\">9</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We select this architecture not only for its widespread adoption but also for its methodological advantage: the adaptor projects speech representations into the textual embedding space while leaving the base LLM unchanged. This structural separation enables a controlled analysis of how fine-tuning affects the model&#8217;s internal parameters, without the confounding input modifications introduced by vocabulary expansion. Building on this setup, we develop an analytical framework based on parameter importance estimation </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib20\" title=\"\">20</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib21\" title=\"\">21</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> to quantify the sensitivity of individual parameters and examine their layer-wise distribution.\nThrough this analysis, we identify a key mechanism underlying textual degradation: fine-tuning with speech induces a shift in the original distribution of parameter importance, thereby disrupting the model&#8217;s textual competence.</span>\n</p>\n\n",
                "matched_terms": [
                    "parameters",
                    "speech",
                    "base",
                    "parameter",
                    "based",
                    "importance",
                    "input"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Building on this analysis, we adopt two strategies to mitigate textual degradation: layer-wise learning rate scheduling </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which adjusts updates across layers to better preserve textually important parameters, and Low-Rank Adaptation (LoRA) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which constrains updates within a low-rank subspace to minimize disruption to pre-trained parameters.\nExtensive experiments on dual-modality question answering benchmarks </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib24\" title=\"\">24</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib25\" title=\"\">25</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrate that both methods outperform full fine-tuning in maintaining textual competence while simultaneously improving speech comprehension. Furthermore, our analysis explains why these strategies are effective: layer-wise scheduling reduces distribution shifts, while LoRA aligns with the inherent low-rank structure of textual knowledge.</span>\n</p>\n\n",
                "matched_terms": [
                    "speech",
                    "parameters"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">For this study, implemented the architecture with two different base models: LLaMA-3.2-1B and LLaMA-3.1-8B. Our analysis concentrates on the first stage of the LLaMA-Omni training pipeline, which fine-tunes the LLM for speech understanding. This stage is most critical for our research question, as the subsequent speech generation stage freezes the LLM parameters and thus does not affect its intrinsic textual knowledge.\nTo probe the internal changes that occur during this stage, we employ parameter importance estimation </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib20\" title=\"\">20</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib21\" title=\"\">21</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This method measures the contribution of each parameter to the model&#8217;s linguistic performance by quantifying the sensitivity of the loss to that parameter. Specifically, the importance </span>\n  <math alttext=\"I_{i}(\\theta)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p2.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <msub>\n          <mi mathsize=\"0.900em\">I</mi>\n          <mi mathsize=\"0.900em\">i</mi>\n        </msub>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\">&#952;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">I_{i}(\\theta)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> of a parameter </span>\n  <math alttext=\"\\theta_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p2.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#952;</mi>\n        <mi mathsize=\"0.900em\">i</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\theta_{i}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is formally defined as the absolute change in model loss when </span>\n  <math alttext=\"\\theta_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p2.m3\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#952;</mi>\n        <mi mathsize=\"0.900em\">i</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\theta_{i}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is nullified (i.e., set to zero):</span>\n</p>\n\n",
                "matched_terms": [
                    "parameters",
                    "speech",
                    "base",
                    "parameter",
                    "model",
                    "importance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">where </span>\n  <math alttext=\"L(D,\\theta)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p2.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">L</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\">D</mi>\n          <mo mathsize=\"0.900em\">,</mo>\n          <mi mathsize=\"0.900em\">&#952;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">L(D,\\theta)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> denotes the loss over a given dataset </span>\n  <math alttext=\"D\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p2.m5\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">D</mi>\n      <annotation encoding=\"application/x-tex\">D</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. As calculating this value for every parameter across a large model is computationally infeasible, we approximate it using a first-order Taylor expansion, yielding the widely used gradient-based estimate </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib20\" title=\"\">20</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">:</span>\n</p>\n\n",
                "matched_terms": [
                    "parameter",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This approximation provides a reliable estimate of parameter importance and serves as the foundation for our subsequent analysis.</span>\n</p>\n\n",
                "matched_terms": [
                    "parameter",
                    "importance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To validate the reliability of parameter importance estimation, we conducted a deactivation experiment using both the LLaMA-Omni-1B and LLaMA-Omni-8B model. Our hypothesis was that parameters with high importance scores would be disproportionately critical to the model&#8217;s linguistic functions.\nThe models were trained on first-turn dialogues from the VoiceAssistant-400K </span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\">\n    <sup class=\"ltx_note_mark\">1</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">1</sup>\n        <span class=\"ltx_tag ltx_tag_note\">1</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/gpt-omni/VoiceAssistant-400K\" title=\"\">https://huggingface.co/datasets/gpt-omni/VoiceAssistant-400K</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Spoken-Alpaca-GPT4 </span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\">\n    <sup class=\"ltx_note_mark\">2</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">2</sup>\n        <span class=\"ltx_tag ltx_tag_note\">2</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/GSQA/spoken-alpaca-gpt4\" title=\"\">https://huggingface.co/datasets/GSQA/spoken-alpaca-gpt4</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> datasets, where each spoken query was paired with its textual transcription to enable controlled comparison across modalities. For evaluation, we constructed a test set of 500 randomly sampled examples that were disjoint from the training data.\nAs our focus is on the impact of speech integration on textual ability, the model was evaluated by generating text responses from both speech and text inputs.\nTo assess the effect of parameter removal, we compared text generation performance under three conditions: the top 3% with the highest importance scores, the bottom 3% with the lowest scores, and a randomly selected 3%. Parameter importance scores were computed using a 1/30 subset of the training data, and model perplexity (PPL) on the test set was used as the evaluation metric.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "removal",
                    "parameters",
                    "perplexity",
                    "speech",
                    "bottom",
                    "top",
                    "parameter",
                    "model",
                    "scores",
                    "importance",
                    "ppl"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">With the parameter importance metric validated, we applied it to analyze the distribution of parameters in speech LLMs. This analysis yields two key findings. First, we observe a consistent structural pattern in the organization of important parameters. Second, we identify a shift in this distribution caused by fine-tuning with speech inputs, which we regard as the primary mechanism of textual degradation.</span>\n</p>\n\n",
                "matched_terms": [
                    "parameter",
                    "importance",
                    "speech",
                    "parameters"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">When visualized as heatmaps of Transformer weight matrices, parameter importance exhibits a structural pattern: important parameters cluster along certain rows and columns, a phenomenon we term </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">rank clustering</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. As shown in Figure </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S1.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, important parameters are not randomly scattered but concentrated along specific rows and columns. This distribution is consistent with the importance patterns observed in text LLMs </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib21\" title=\"\">21</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. The non-uniform allocation suggests that the model&#8217;s linguistic competence is encoded in a low-rank structure, rather than being evenly spread across parameters.</span>\n</p>\n\n",
                "matched_terms": [
                    "text",
                    "importance",
                    "parameter",
                    "parameters"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">While rank clustering captures the static structure of parameter importance, our central question concerns how this structure changes during speech adaptation. To this end, we compared the layer-wise distribution of textual parameter importance before and after fine-tuning with speech inputs. The results, illustrated in Figure </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 2.3.2 Textual Importance Distribution Shift &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, reveal a consistent distribution shift. In the 1B base model, textual importance is concentrated in the later-middle layers, which are typically associated with higher-level semantic processing. In the 8B model, the peak importance lies in the earlier-middle layers and gradually decreases in deeper layers. After fine-tuning on speech input, this distribution is disrupted. In the 1B model, the shift is particularly severe: the peak of importance moves to much earlier layers, followed by a sharp decline. In the 8B model, the shape of the distribution is better preserved, but the overall magnitude of importance is suppressed across all layers. Despite these scale-dependent differences, the outcome is consistent: the relative importance of middle and last few layers is significantly diminished in both models.\nWe posit that this layer-wise distribution shift is the primary internal mechanism responsible for the degradation of textual performance when LLMs are fine-tuned to incorporate speech.</span>\n</p>\n\n",
                "matched_terms": [
                    "speech",
                    "base",
                    "after",
                    "parameter",
                    "model",
                    "importance",
                    "input"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Based on our analysis in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2\" style=\"font-size:90%;\" title=\"2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which identifies the textual importance distribution shift as the primary cause of degradation, we propose and evaluate two mitigation strategies designed to preserve the model&#8217;s original knowledge structure during speech adaptation.</span>\n</p>\n\n",
                "matched_terms": [
                    "importance",
                    "speech",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our first approach directly targets the distribution shift observed in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS3.SSS2\" style=\"font-size:90%;\" title=\"2.3.2 Textual Importance Distribution Shift &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.3.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We hypothesize that preserving the importance of critical layers can be achieved by reducing the magnitude of their updates during fine-tuning. Therefore, we implement a layer-wise learning rate scheduling strategy </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> where layers with higher textual parameter importance (as measured on the pre-trained model) are assigned lower learning rates. The learning rate for each layer is scaled by a coefficient calculated as follows:</span>\n</p>\n\n",
                "matched_terms": [
                    "parameter",
                    "model",
                    "importance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">where </span>\n  <math alttext=\"I_{\\text{layer}}(i)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS1.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <msub>\n          <mi mathsize=\"0.900em\">I</mi>\n          <mtext mathsize=\"0.900em\">layer</mtext>\n        </msub>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\">i</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">I_{\\text{layer}}(i)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is the sum of the absolute importance values of all parameters in layer </span>\n  <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS1.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">i</mi>\n      <annotation encoding=\"application/x-tex\">i</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and </span>\n  <math alttext=\"\\lambda\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS1.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#955;</mi>\n      <annotation encoding=\"application/x-tex\">\\lambda</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is a scaling factor empirically set to 0.4.</span>\n</p>\n\n",
                "matched_terms": [
                    "importance",
                    "parameters"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The rank clustering phenomenon identified in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS3.SSS1\" style=\"font-size:90%;\" title=\"2.3.1 Structural Pattern: Rank Clustering &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.3.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> offers a principled explanation for the effectiveness of LoRA </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in the context of speech LLMs. Our finding that important parameters are concentrated in a low-rank structure suggests that an ideal adaptation method should respect this inherent structure to avoid catastrophic forgetting. LoRA, which constrains parameter updates to low-rank decomposition matrices, aligns perfectly with this principle. Therefore, we leverage LoRA not merely as a parameter-efficient fine-tuning technique, but as a method whose core mechanism is uniquely suited to preserving the essential textual knowledge structure we have identified. For our experiments, we apply LoRA to all MLP and self-attention modules, with a rank </span>\n  <math alttext=\"r=8\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">8</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=8</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> for the 1B model and </span>\n  <math alttext=\"r=16\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">16</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=16</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> for the 8B model, and the scaling factor </span>\n  <math alttext=\"\\alpha\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#945;</mi>\n      <annotation encoding=\"application/x-tex\">\\alpha</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> set to </span>\n  <math alttext=\"2r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">2</mn>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">2r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "parameter",
                    "speech",
                    "model",
                    "parameters"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">All models were trained on the datasets introduced in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS2\" style=\"font-size:90%;\" title=\"2.2 Validation of the Parameter Importance Estimation &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Except for the parameter configurations specified in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.SS1\" style=\"font-size:90%;\" title=\"3.1 Mitigation Strategies &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">3.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, all other settings followed the Stage 1 setup of the original LLaMA-Omni paper </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib9\" title=\"\">9</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This ensures that any performance differences can be attributed to the proposed strategies rather than unrelated implementation details. Evaluation was conducted on two spoken question answering (QA) benchmarks: LLaMA Questions</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\">\n    <sup class=\"ltx_note_mark\">3</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">3</sup>\n        <span class=\"ltx_tag ltx_tag_note\">3</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/fixie-ai/llama-questions\" title=\"\">https://huggingface.co/datasets/fixie-ai/llama-questions</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib24\" title=\"\">24</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Web Questions</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote4\">\n    <sup class=\"ltx_note_mark\">4</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">4</sup>\n        <span class=\"ltx_tag ltx_tag_note\">4</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/chiyuanhsiao/spoken-web-questions\" title=\"\">https://huggingface.co/datasets/chiyuanhsiao/spoken-web-questions</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib25\" title=\"\">25</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We evaluated the models on two tasks with identical question&#8211;answering content. The </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Text-to-Text (T2T)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> task corresponds to standard text-based QA, which measures the preservation of textual competence. The </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Speech-to-Text (S2T)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> task corresponds to spoken QA, where the model receives speech as input and generates textual answers, thereby assessing speech comprehension. The fully fine-tuned model (</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Full-FT</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) and the text-only LLM without speech adaptation (</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">No-FT</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) were used as the primary baselines. In addition, we include S2T results from several open-source speech LLMs, such as Moshi </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and GLM-4-Voice </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib15\" title=\"\">15</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, as well as the results reported by the authors of </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib9\" title=\"\">9</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, with all numbers directly taken from </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. These comparisons provide a broader context for assessing the performance of our models.</span>\n</p>\n\n",
                "matched_terms": [
                    "parameter",
                    "speech",
                    "model",
                    "input"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The results, presented in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3.1.2 Low Rank Adaptation &#8227; 3.1 Mitigation Strategies &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, demonstrate the effectiveness of both the Layer-LR and LoRA strategies. Compared with the Full-FT baseline, both strategies substantially mitigate textual degradation while simultaneously improving speech performance. For example, on the Web Questions benchmark, the 8B model trained with full fine-tuning shows a decrease in T2T accuracy from 58.7% to 55.7. In contrast, the models trained with layer-wise learning rate scheduling and LoRA both achieve higher accuracies of 57.6% and 56.7%, respectively, confirming their superior ability to preserve the model&#8217;s original textual competence.\nThis preservation of textual knowledge translates directly to improved spoken QA performance. On the Web-Questions benchmark, the 8B model trained with LoRA achieves the highest accuracy of 42.9%. These results strongly suggest that retaining the foundational textual abilities of the base LLM is essential for enhancing its speech comprehension capabilities.</span>\n</p>\n\n",
                "matched_terms": [
                    "base",
                    "speech",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We also observe a noteworthy trade-off: compared to the model fine-tuned with LoRA, the one using the layer-wise learning rate scheduling exhibits a greater improvement in T2T accuracy, while the LoRA-based model achieves higher accuracy on S2T. This indicates that layer-wise learning rate scheduling is more effective at preserving the base model&#8217;s textual knowledge, but its conservative updates limit adaptation to speech inputs, leading to smaller improvements in spoken QA. In contrast, LoRA facilitates more efficient transfer of knowledge from text to speech, yielding superior spoken QA performance at the cost of weaker textual preservation. Overall, these findings highlight that different strategies strike different balances between textual competence and speech adaptation.</span>\n</p>\n\n",
                "matched_terms": [
                    "base",
                    "speech",
                    "model",
                    "text"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To examine why the proposed strategies are effective, we analyzed their impact on model&#8217;s importance distribution.\nAs shown in Figure </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.F3\" style=\"font-size:90%;\" title=\"Figure 3 &#8227; 3.2 Results &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">,\nboth layer-wise learning rate scheduling and LoRA produce distributions closely resembling those of the original pre-trained model, whereas full fine-tuning substantially distorts them. This confirms that both strategies mitigate the distribution shift identified in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS3.SSS2\" style=\"font-size:90%;\" title=\"2.3.2 Textual Importance Distribution Shift &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.3.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, thereby preserving the model&#8217;s textual competence.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "importance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We further compared the two strategies by visualizing the parameter changes induced by each method. As illustrated in Figure </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.F4\" style=\"font-size:90%;\" title=\"Figure 4 &#8227; 3.3.3 Ablation Study on LoRA Rank &#8227; 3.3 Analysis &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, LoRA&#8217;s updates exhibit a more pronounced row-and-column clustering pattern, consistent with the rank clustering phenomenon observed in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS3.SSS1\" style=\"font-size:90%;\" title=\"2.3.1 Structural Pattern: Rank Clustering &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.3.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This supports that LoRA adapts more efficiently to the model&#8217;s inherent low-rank knowledge structure, which explains its superior performance on spoken QA. In contrast, layer-wise learning rate scheduling applies more conservative updates that effectively preserve textual knowledge but yield less efficient transfer to the speech modality, accounting for its comparatively weaker performance on S2T tasks.</span>\n</p>\n\n",
                "matched_terms": [
                    "parameter",
                    "speech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We also conducted an ablation study on the LoRA rank parameter </span>\n  <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">r</mi>\n      <annotation encoding=\"application/x-tex\">r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. As shown in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 3.3.3 Ablation Study on LoRA Rank &#8227; 3.3 Analysis &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, increasing </span>\n  <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">r</mi>\n      <annotation encoding=\"application/x-tex\">r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> from 8 to 16 consistently improves S2T performance while maintaining stable T2T results. However, a further increase to </span>\n  <math alttext=\"r=24\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">24</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=24</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> leads to a noticeable drop in both T2T and S2T accuracy, likely due to overfitting or excessive disruption of pre-trained knowledge. These results indicate that moderate ranks (e.g., </span>\n  <math alttext=\"r=16\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">16</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=16</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) strike a better balance between preserving textual competence and enabling effective speech adaptation.</span>\n</p>\n\n",
                "matched_terms": [
                    "parameter",
                    "speech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This paper investigated the degradation of textual capabilities in speech LLMs through a parameter-level analysis. We identified the primary mechanism as a textual importance distribution shift, where fine-tuning for speech disrupts the model&#8217;s original knowledge structure. Based on this finding, we adopted two mitigation strategies: layer-wise learning rate scheduling and LoRA. Experimental results confirmed that both methods effectively preserve textual competence by alleviating this distribution shift, which in turn leads to notable improvements in spoken QA performance. For future work, we plan to extend our analytical framework to other speech LLM paradigms, such as those based on vocabulary expansion, to assess the generality of our findings.</span>\n</p>\n\n",
                "matched_terms": [
                    "importance",
                    "speech",
                    "based"
                ]
            }
        ]
    },
    "S3.T2": {
        "source_file": "Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis",
        "caption": "Table 2: Results on spoken QA benchmarks. * indicates the original results reported in [9]. Bold numbers indicate the best performance, and underlined numbers indicate the suboptimal.",
        "body": "Model\nSize\nMethods\nLlama Q\nWeb Q\n\n\nT2T\nS2T\nT2T\nS2T\n\n\nMoshi\n7B\nFull-FT\n-\n62.3\n-\n26.6\n\n\nGLM-4-Voice\n9B\n-\n64.7\n-\n32.2\n\n\nLLaMA-Omni*\n8B\n-\n67.7\n-\n33.4\n\n\nLLaMA-Omni\n1B\nNo-FT\n74.0\n-\n44.5\n-\n\n\nFull-FT\n73.3\n66.7\n42.1\n29.1\n\n\nLayer-LR\n73.7\n68.3\n43.8\n30.2\n\n\nLoRA\n73.7\n70.3\n42.9\n33.5\n\n\nLLaMA-Omni\n8B\nNo-FT\n84.7\n-\n58.7\n-\n\n\nFull-FT\n80.0\n72.0\n55.7\n38.7\n\n\nLayer-LR\n81.3\n73.3\n57.6\n39.6\n\n\nLoRA\n81.0\n75.0\n56.7\n42.9",
        "html_code": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">Model</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">Size</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">Methods</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">Llama Q</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">Web Q</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">T2T</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">S2T</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">T2T</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">S2T</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">Moshi</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">7B</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"3\"><span class=\"ltx_text\" style=\"font-size:90%;\">Full-FT</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">62.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">26.6</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">GLM-4-Voice</span></th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">9B</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">64.7</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">32.2</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">LLaMA-Omni*</span></th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">8B</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">67.7</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">33.4</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"4\"><span class=\"ltx_text\" style=\"font-size:90%;\">LLaMA-Omni</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"4\"><span class=\"ltx_text\" style=\"font-size:90%;\">1B</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">No-FT</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">74.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">44.5</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">Full-FT</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">73.3</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">66.7</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">42.1</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">29.1</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">Layer-LR</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">73.7</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">68.3</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">43.8</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">30.2</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">LoRA</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">73.7</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">70.3</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">42.9</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">33.5</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t\" rowspan=\"4\"><span class=\"ltx_text\" style=\"font-size:90%;\">LLaMA-Omni</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" rowspan=\"4\"><span class=\"ltx_text\" style=\"font-size:90%;\">8B</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">No-FT</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">84.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">58.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">Full-FT</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">80.0</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">72.0</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">55.7</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">38.7</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">Layer-LR</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">81.3</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">73.3</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">57.6</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">39.6</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">LoRA</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">75.0</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">56.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">42.9</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "original",
            "underlined",
            "reported",
            "spoken",
            "best",
            "methods",
            "llama",
            "results",
            "numbers",
            "fullft",
            "t2t",
            "bold",
            "indicates",
            "glm4voice",
            "s2t",
            "performance",
            "web",
            "lora",
            "noft",
            "layerlr",
            "indicate",
            "benchmarks",
            "size",
            "llamaomni",
            "moshi",
            "model",
            "suboptimal"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The results, presented in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3.1.2 Low Rank Adaptation &#8227; 3.1 Mitigation Strategies &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, demonstrate the effectiveness of both the Layer-LR and LoRA strategies. Compared with the Full-FT baseline, both strategies substantially mitigate textual degradation while simultaneously improving speech performance. For example, on the Web Questions benchmark, the 8B model trained with full fine-tuning shows a decrease in T2T accuracy from 58.7% to 55.7. In contrast, the models trained with layer-wise learning rate scheduling and LoRA both achieve higher accuracies of 57.6% and 56.7%, respectively, confirming their superior ability to preserve the model&#8217;s original textual competence.\nThis preservation of textual knowledge translates directly to improved spoken QA performance. On the Web-Questions benchmark, the 8B model trained with LoRA achieves the highest accuracy of 42.9%. These results strongly suggest that retaining the foundational textual abilities of the base LLM is essential for enhancing its speech comprehension capabilities.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The integration of speech into Large Language Models (LLMs) has substantially expanded their capabilities, but often at the cost of weakening their core textual competence. This degradation limits the ability of speech-enabled LLMs to fully exploit their pre-trained text-based knowledge. In this work, we analyze the underlying mechanisms of this issue through a focused study of the widely used encoder&#8211;adaptor paradigm. We propose an analytical framework based on parameter importance estimation, which reveals that fine-tuning for speech introduces a textual importance distribution shift: the layer-wise allocation of parameters critical to textual reasoning is disrupted. Building on this insight, we investigate two mitigation strategies: layer-wise learning rate scheduling and Low-Rank Adaptation (LoRA), both aim to preserve the original parameter distribution. Experimental results show that both approaches better maintain textual competence than full fine-tuning, while also improving downstream spoken question answering performance. Furthermore, our analysis offers a principled explanation for the effectiveness of the proposed mitigation strategies, linking their benefits to the structural properties of textual knowledge in LLMs.</span>\n</p>\n\n",
                "matched_terms": [
                    "original",
                    "performance",
                    "results",
                    "spoken",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To equip LLMs with speech capabilities, both paradigms typically rely on multi-stage fine-tuning on speech-related tasks </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib16\" title=\"\">16</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. However, the substantial mismatch between speech and text data distributions often leads to catastrophic forgetting, a phenomenon where the LLM loses previously acquired knowledge </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib17\" title=\"\">17</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib18\" title=\"\">18</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. While the LLM gains new speech-related skills, its foundational text-based reasoning and instruction-following abilities significantly degrade</span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This trade-off poses a critical bottleneck, as preserving the strong textual intelligence of the base LLM is essential for high-quality spoken interaction. Although this degradation is widely observed, its internal mechanisms remain poorly understood. What exactly is disrupted in the model during speech fine-tuning, and why does this lead to diminished textual competence?</span>\n</p>\n\n",
                "matched_terms": [
                    "spoken",
                    "model"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Building on this analysis, we adopt two strategies to mitigate textual degradation: layer-wise learning rate scheduling </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which adjusts updates across layers to better preserve textually important parameters, and Low-Rank Adaptation (LoRA) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which constrains updates within a low-rank subspace to minimize disruption to pre-trained parameters.\nExtensive experiments on dual-modality question answering benchmarks </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib24\" title=\"\">24</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib25\" title=\"\">25</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrate that both methods outperform full fine-tuning in maintaining textual competence while simultaneously improving speech comprehension. Furthermore, our analysis explains why these strategies are effective: layer-wise scheduling reduces distribution shifts, while LoRA aligns with the inherent low-rank structure of textual knowledge.</span>\n</p>\n\n",
                "matched_terms": [
                    "benchmarks",
                    "methods",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">For this study, implemented the architecture with two different base models: LLaMA-3.2-1B and LLaMA-3.1-8B. Our analysis concentrates on the first stage of the LLaMA-Omni training pipeline, which fine-tunes the LLM for speech understanding. This stage is most critical for our research question, as the subsequent speech generation stage freezes the LLM parameters and thus does not affect its intrinsic textual knowledge.\nTo probe the internal changes that occur during this stage, we employ parameter importance estimation </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib20\" title=\"\">20</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib21\" title=\"\">21</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This method measures the contribution of each parameter to the model&#8217;s linguistic performance by quantifying the sensitivity of the loss to that parameter. Specifically, the importance </span>\n  <math alttext=\"I_{i}(\\theta)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p2.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <msub>\n          <mi mathsize=\"0.900em\">I</mi>\n          <mi mathsize=\"0.900em\">i</mi>\n        </msub>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\">&#952;</mi>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">I_{i}(\\theta)</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> of a parameter </span>\n  <math alttext=\"\\theta_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p2.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#952;</mi>\n        <mi mathsize=\"0.900em\">i</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\theta_{i}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is formally defined as the absolute change in model loss when </span>\n  <math alttext=\"\\theta_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p2.m3\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#952;</mi>\n        <mi mathsize=\"0.900em\">i</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\theta_{i}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is nullified (i.e., set to zero):</span>\n</p>\n\n",
                "matched_terms": [
                    "llamaomni",
                    "model",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To validate the reliability of parameter importance estimation, we conducted a deactivation experiment using both the LLaMA-Omni-1B and LLaMA-Omni-8B model. Our hypothesis was that parameters with high importance scores would be disproportionately critical to the model&#8217;s linguistic functions.\nThe models were trained on first-turn dialogues from the VoiceAssistant-400K </span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\">\n    <sup class=\"ltx_note_mark\">1</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">1</sup>\n        <span class=\"ltx_tag ltx_tag_note\">1</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/gpt-omni/VoiceAssistant-400K\" title=\"\">https://huggingface.co/datasets/gpt-omni/VoiceAssistant-400K</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Spoken-Alpaca-GPT4 </span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote2\">\n    <sup class=\"ltx_note_mark\">2</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">2</sup>\n        <span class=\"ltx_tag ltx_tag_note\">2</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/GSQA/spoken-alpaca-gpt4\" title=\"\">https://huggingface.co/datasets/GSQA/spoken-alpaca-gpt4</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> datasets, where each spoken query was paired with its textual transcription to enable controlled comparison across modalities. For evaluation, we constructed a test set of 500 randomly sampled examples that were disjoint from the training data.\nAs our focus is on the impact of speech integration on textual ability, the model was evaluated by generating text responses from both speech and text inputs.\nTo assess the effect of parameter removal, we compared text generation performance under three conditions: the top 3% with the highest importance scores, the bottom 3% with the lowest scores, and a randomly selected 3%. Parameter importance scores were computed using a 1/30 subset of the training data, and model perplexity (PPL) on the test set was used as the evaluation metric.</span>\n</p>\n\n",
                "matched_terms": [
                    "spoken",
                    "model",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The results, summarized in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.T1\" style=\"font-size:90%;\" title=\"Table 1 &#8227; 2.2 Validation of the Parameter Importance Estimation &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, strongly support our hypothesis. Deactivating the top 3% of parameters caused a dramatic increase in PPL and a severe loss of linguistic competence. In contrast, nullifying the bottom 3% had negligible effect, and removing a random 3% resulted in only minor degradation. These findings demonstrates that the observed performance degradation is attributed to the removal of high-importance parameters rather than the deactivation process itself. We therefore conclude that the parameter importance metric is a reliable tool for identifying functionally critical parameters, providing a solid foundation for the subsequent analysis.</span>\n</p>\n\n",
                "matched_terms": [
                    "results",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">While rank clustering captures the static structure of parameter importance, our central question concerns how this structure changes during speech adaptation. To this end, we compared the layer-wise distribution of textual parameter importance before and after fine-tuning with speech inputs. The results, illustrated in Figure </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 2.3.2 Textual Importance Distribution Shift &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, reveal a consistent distribution shift. In the 1B base model, textual importance is concentrated in the later-middle layers, which are typically associated with higher-level semantic processing. In the 8B model, the peak importance lies in the earlier-middle layers and gradually decreases in deeper layers. After fine-tuning on speech input, this distribution is disrupted. In the 1B model, the shift is particularly severe: the peak of importance moves to much earlier layers, followed by a sharp decline. In the 8B model, the shape of the distribution is better preserved, but the overall magnitude of importance is suppressed across all layers. Despite these scale-dependent differences, the outcome is consistent: the relative importance of middle and last few layers is significantly diminished in both models.\nWe posit that this layer-wise distribution shift is the primary internal mechanism responsible for the degradation of textual performance when LLMs are fine-tuned to incorporate speech.</span>\n</p>\n\n",
                "matched_terms": [
                    "results",
                    "model",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The rank clustering phenomenon identified in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS3.SSS1\" style=\"font-size:90%;\" title=\"2.3.1 Structural Pattern: Rank Clustering &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.3.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> offers a principled explanation for the effectiveness of LoRA </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in the context of speech LLMs. Our finding that important parameters are concentrated in a low-rank structure suggests that an ideal adaptation method should respect this inherent structure to avoid catastrophic forgetting. LoRA, which constrains parameter updates to low-rank decomposition matrices, aligns perfectly with this principle. Therefore, we leverage LoRA not merely as a parameter-efficient fine-tuning technique, but as a method whose core mechanism is uniquely suited to preserving the essential textual knowledge structure we have identified. For our experiments, we apply LoRA to all MLP and self-attention modules, with a rank </span>\n  <math alttext=\"r=8\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">8</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=8</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> for the 1B model and </span>\n  <math alttext=\"r=16\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">16</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=16</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> for the 8B model, and the scaling factor </span>\n  <math alttext=\"\\alpha\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#945;</mi>\n      <annotation encoding=\"application/x-tex\">\\alpha</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> set to </span>\n  <math alttext=\"2r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">2</mn>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">2r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "model",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">All models were trained on the datasets introduced in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS2\" style=\"font-size:90%;\" title=\"2.2 Validation of the Parameter Importance Estimation &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Except for the parameter configurations specified in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.SS1\" style=\"font-size:90%;\" title=\"3.1 Mitigation Strategies &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">3.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, all other settings followed the Stage 1 setup of the original LLaMA-Omni paper </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib9\" title=\"\">9</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This ensures that any performance differences can be attributed to the proposed strategies rather than unrelated implementation details. Evaluation was conducted on two spoken question answering (QA) benchmarks: LLaMA Questions</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\">\n    <sup class=\"ltx_note_mark\">3</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">3</sup>\n        <span class=\"ltx_tag ltx_tag_note\">3</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/fixie-ai/llama-questions\" title=\"\">https://huggingface.co/datasets/fixie-ai/llama-questions</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib24\" title=\"\">24</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Web Questions</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote4\">\n    <sup class=\"ltx_note_mark\">4</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">4</sup>\n        <span class=\"ltx_tag ltx_tag_note\">4</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/chiyuanhsiao/spoken-web-questions\" title=\"\">https://huggingface.co/datasets/chiyuanhsiao/spoken-web-questions</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib25\" title=\"\">25</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We evaluated the models on two tasks with identical question&#8211;answering content. The </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Text-to-Text (T2T)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> task corresponds to standard text-based QA, which measures the preservation of textual competence. The </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Speech-to-Text (S2T)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> task corresponds to spoken QA, where the model receives speech as input and generates textual answers, thereby assessing speech comprehension. The fully fine-tuned model (</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Full-FT</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) and the text-only LLM without speech adaptation (</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">No-FT</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) were used as the primary baselines. In addition, we include S2T results from several open-source speech LLMs, such as Moshi </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and GLM-4-Voice </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib15\" title=\"\">15</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, as well as the results reported by the authors of </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib9\" title=\"\">9</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, with all numbers directly taken from </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. These comparisons provide a broader context for assessing the performance of our models.</span>\n</p>\n\n",
                "matched_terms": [
                    "original",
                    "s2t",
                    "performance",
                    "benchmarks",
                    "web",
                    "reported",
                    "llama",
                    "results",
                    "spoken",
                    "llamaomni",
                    "numbers",
                    "fullft",
                    "noft",
                    "t2t",
                    "moshi",
                    "model",
                    "glm4voice"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We also observe a noteworthy trade-off: compared to the model fine-tuned with LoRA, the one using the layer-wise learning rate scheduling exhibits a greater improvement in T2T accuracy, while the LoRA-based model achieves higher accuracy on S2T. This indicates that layer-wise learning rate scheduling is more effective at preserving the base model&#8217;s textual knowledge, but its conservative updates limit adaptation to speech inputs, leading to smaller improvements in spoken QA. In contrast, LoRA facilitates more efficient transfer of knowledge from text to speech, yielding superior spoken QA performance at the cost of weaker textual preservation. Overall, these findings highlight that different strategies strike different balances between textual competence and speech adaptation.</span>\n</p>\n\n",
                "matched_terms": [
                    "s2t",
                    "performance",
                    "spoken",
                    "lora",
                    "t2t",
                    "model",
                    "indicates"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To examine why the proposed strategies are effective, we analyzed their impact on model&#8217;s importance distribution.\nAs shown in Figure </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.F3\" style=\"font-size:90%;\" title=\"Figure 3 &#8227; 3.2 Results &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">,\nboth layer-wise learning rate scheduling and LoRA produce distributions closely resembling those of the original pre-trained model, whereas full fine-tuning substantially distorts them. This confirms that both strategies mitigate the distribution shift identified in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS3.SSS2\" style=\"font-size:90%;\" title=\"2.3.2 Textual Importance Distribution Shift &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.3.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, thereby preserving the model&#8217;s textual competence.</span>\n</p>\n\n",
                "matched_terms": [
                    "original",
                    "model",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We further compared the two strategies by visualizing the parameter changes induced by each method. As illustrated in Figure </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.F4\" style=\"font-size:90%;\" title=\"Figure 4 &#8227; 3.3.3 Ablation Study on LoRA Rank &#8227; 3.3 Analysis &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, LoRA&#8217;s updates exhibit a more pronounced row-and-column clustering pattern, consistent with the rank clustering phenomenon observed in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS3.SSS1\" style=\"font-size:90%;\" title=\"2.3.1 Structural Pattern: Rank Clustering &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.3.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This supports that LoRA adapts more efficiently to the model&#8217;s inherent low-rank knowledge structure, which explains its superior performance on spoken QA. In contrast, layer-wise learning rate scheduling applies more conservative updates that effectively preserve textual knowledge but yield less efficient transfer to the speech modality, accounting for its comparatively weaker performance on S2T tasks.</span>\n</p>\n\n",
                "matched_terms": [
                    "s2t",
                    "spoken",
                    "lora",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We also conducted an ablation study on the LoRA rank parameter </span>\n  <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">r</mi>\n      <annotation encoding=\"application/x-tex\">r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. As shown in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 3.3.3 Ablation Study on LoRA Rank &#8227; 3.3 Analysis &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, increasing </span>\n  <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">r</mi>\n      <annotation encoding=\"application/x-tex\">r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> from 8 to 16 consistently improves S2T performance while maintaining stable T2T results. However, a further increase to </span>\n  <math alttext=\"r=24\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">24</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=24</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> leads to a noticeable drop in both T2T and S2T accuracy, likely due to overfitting or excessive disruption of pre-trained knowledge. These results indicate that moderate ranks (e.g., </span>\n  <math alttext=\"r=16\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">16</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=16</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) strike a better balance between preserving textual competence and enabling effective speech adaptation.</span>\n</p>\n\n",
                "matched_terms": [
                    "s2t",
                    "indicate",
                    "performance",
                    "results",
                    "lora",
                    "t2t"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This paper investigated the degradation of textual capabilities in speech LLMs through a parameter-level analysis. We identified the primary mechanism as a textual importance distribution shift, where fine-tuning for speech disrupts the model&#8217;s original knowledge structure. Based on this finding, we adopted two mitigation strategies: layer-wise learning rate scheduling and LoRA. Experimental results confirmed that both methods effectively preserve textual competence by alleviating this distribution shift, which in turn leads to notable improvements in spoken QA performance. For future work, we plan to extend our analytical framework to other speech LLM paradigms, such as those based on vocabulary expansion, to assess the generality of our findings.</span>\n</p>\n\n",
                "matched_terms": [
                    "original",
                    "performance",
                    "methods",
                    "results",
                    "spoken",
                    "lora"
                ]
            }
        ]
    },
    "S3.T3": {
        "source_file": "Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis",
        "caption": "Table 3: Results on the Llama Questions and Web Questions benchmarks under different LoRA rank settings.",
        "body": "Rank\nLlama Questions\nWeb Questions\n\n\nT2T\nS2T\nT2T\nS2T\n\n\n\n\n8\n81.3\n74.7\n56.3\n41.7\n\n\n16\n81.0\n75.0\n56.7\n42.9\n\n\n24\n79.3\n75.3\n54.7\n40.1",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" rowspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">Rank</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">Llama Questions</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"2\"><span class=\"ltx_text\" style=\"font-size:90%;\">Web Questions</span></th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span class=\"ltx_text\" style=\"font-size:90%;\">T2T</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span class=\"ltx_text\" style=\"font-size:90%;\">S2T</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span class=\"ltx_text\" style=\"font-size:90%;\">T2T</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span class=\"ltx_text\" style=\"font-size:90%;\">S2T</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">8</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">74.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">56.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text\" style=\"font-size:90%;\">41.7</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row\"><span class=\"ltx_text\" style=\"font-size:90%;\">16</span></th>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">81.0</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">75.0</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">56.7</span></td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"font-size:90%;\">42.9</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">24</span></th>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">79.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">75.3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">54.7</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"font-size:90%;\">40.1</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "rank",
            "s2t",
            "benchmarks",
            "web",
            "under",
            "settings",
            "llama",
            "results",
            "different",
            "lora",
            "t2t",
            "questions"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We also conducted an ablation study on the LoRA rank parameter </span>\n  <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">r</mi>\n      <annotation encoding=\"application/x-tex\">r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. As shown in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.T3\" style=\"font-size:90%;\" title=\"Table 3 &#8227; 3.3.3 Ablation Study on LoRA Rank &#8227; 3.3 Analysis &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, increasing </span>\n  <math alttext=\"r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">r</mi>\n      <annotation encoding=\"application/x-tex\">r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> from 8 to 16 consistently improves S2T performance while maintaining stable T2T results. However, a further increase to </span>\n  <math alttext=\"r=24\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">24</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=24</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> leads to a noticeable drop in both T2T and S2T accuracy, likely due to overfitting or excessive disruption of pre-trained knowledge. These results indicate that moderate ranks (e.g., </span>\n  <math alttext=\"r=16\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.SSS3.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">16</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=16</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) strike a better balance between preserving textual competence and enabling effective speech adaptation.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The integration of speech into Large Language Models (LLMs) has substantially expanded their capabilities, but often at the cost of weakening their core textual competence. This degradation limits the ability of speech-enabled LLMs to fully exploit their pre-trained text-based knowledge. In this work, we analyze the underlying mechanisms of this issue through a focused study of the widely used encoder&#8211;adaptor paradigm. We propose an analytical framework based on parameter importance estimation, which reveals that fine-tuning for speech introduces a textual importance distribution shift: the layer-wise allocation of parameters critical to textual reasoning is disrupted. Building on this insight, we investigate two mitigation strategies: layer-wise learning rate scheduling and Low-Rank Adaptation (LoRA), both aim to preserve the original parameter distribution. Experimental results show that both approaches better maintain textual competence than full fine-tuning, while also improving downstream spoken question answering performance. Furthermore, our analysis offers a principled explanation for the effectiveness of the proposed mitigation strategies, linking their benefits to the structural properties of textual knowledge in LLMs.</span>\n</p>\n\n",
                "matched_terms": [
                    "results",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Building on this analysis, we adopt two strategies to mitigate textual degradation: layer-wise learning rate scheduling </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib22\" title=\"\">22</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which adjusts updates across layers to better preserve textually important parameters, and Low-Rank Adaptation (LoRA) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which constrains updates within a low-rank subspace to minimize disruption to pre-trained parameters.\nExtensive experiments on dual-modality question answering benchmarks </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib24\" title=\"\">24</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib25\" title=\"\">25</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> demonstrate that both methods outperform full fine-tuning in maintaining textual competence while simultaneously improving speech comprehension. Furthermore, our analysis explains why these strategies are effective: layer-wise scheduling reduces distribution shifts, while LoRA aligns with the inherent low-rank structure of textual knowledge.</span>\n</p>\n\n",
                "matched_terms": [
                    "benchmarks",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">While rank clustering captures the static structure of parameter importance, our central question concerns how this structure changes during speech adaptation. To this end, we compared the layer-wise distribution of textual parameter importance before and after fine-tuning with speech inputs. The results, illustrated in Figure </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.F2\" style=\"font-size:90%;\" title=\"Figure 2 &#8227; 2.3.2 Textual Importance Distribution Shift &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, reveal a consistent distribution shift. In the 1B base model, textual importance is concentrated in the later-middle layers, which are typically associated with higher-level semantic processing. In the 8B model, the peak importance lies in the earlier-middle layers and gradually decreases in deeper layers. After fine-tuning on speech input, this distribution is disrupted. In the 1B model, the shift is particularly severe: the peak of importance moves to much earlier layers, followed by a sharp decline. In the 8B model, the shape of the distribution is better preserved, but the overall magnitude of importance is suppressed across all layers. Despite these scale-dependent differences, the outcome is consistent: the relative importance of middle and last few layers is significantly diminished in both models.\nWe posit that this layer-wise distribution shift is the primary internal mechanism responsible for the degradation of textual performance when LLMs are fine-tuned to incorporate speech.</span>\n</p>\n\n",
                "matched_terms": [
                    "results",
                    "rank"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The rank clustering phenomenon identified in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS3.SSS1\" style=\"font-size:90%;\" title=\"2.3.1 Structural Pattern: Rank Clustering &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.3.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> offers a principled explanation for the effectiveness of LoRA </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in the context of speech LLMs. Our finding that important parameters are concentrated in a low-rank structure suggests that an ideal adaptation method should respect this inherent structure to avoid catastrophic forgetting. LoRA, which constrains parameter updates to low-rank decomposition matrices, aligns perfectly with this principle. Therefore, we leverage LoRA not merely as a parameter-efficient fine-tuning technique, but as a method whose core mechanism is uniquely suited to preserving the essential textual knowledge structure we have identified. For our experiments, we apply LoRA to all MLP and self-attention modules, with a rank </span>\n  <math alttext=\"r=8\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">8</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=8</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> for the 1B model and </span>\n  <math alttext=\"r=16\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">r</mi>\n        <mo mathsize=\"0.900em\">=</mo>\n        <mn mathsize=\"0.900em\">16</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">r=16</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> for the 8B model, and the scaling factor </span>\n  <math alttext=\"\\alpha\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#945;</mi>\n      <annotation encoding=\"application/x-tex\">\\alpha</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> set to </span>\n  <math alttext=\"2r\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.SSS2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">2</mn>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mi mathsize=\"0.900em\">r</mi>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">2r</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "rank",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">All models were trained on the datasets introduced in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS2\" style=\"font-size:90%;\" title=\"2.2 Validation of the Parameter Importance Estimation &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. Except for the parameter configurations specified in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.SS1\" style=\"font-size:90%;\" title=\"3.1 Mitigation Strategies &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">3.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, all other settings followed the Stage 1 setup of the original LLaMA-Omni paper </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib9\" title=\"\">9</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This ensures that any performance differences can be attributed to the proposed strategies rather than unrelated implementation details. Evaluation was conducted on two spoken question answering (QA) benchmarks: LLaMA Questions</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\">\n    <sup class=\"ltx_note_mark\">3</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">3</sup>\n        <span class=\"ltx_tag ltx_tag_note\">3</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/fixie-ai/llama-questions\" title=\"\">https://huggingface.co/datasets/fixie-ai/llama-questions</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib24\" title=\"\">24</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Web Questions</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote4\">\n    <sup class=\"ltx_note_mark\">4</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">4</sup>\n        <span class=\"ltx_tag ltx_tag_note\">4</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/chiyuanhsiao/spoken-web-questions\" title=\"\">https://huggingface.co/datasets/chiyuanhsiao/spoken-web-questions</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib25\" title=\"\">25</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. We evaluated the models on two tasks with identical question&#8211;answering content. The </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Text-to-Text (T2T)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> task corresponds to standard text-based QA, which measures the preservation of textual competence. The </span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Speech-to-Text (S2T)</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> task corresponds to spoken QA, where the model receives speech as input and generates textual answers, thereby assessing speech comprehension. The fully fine-tuned model (</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Full-FT</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) and the text-only LLM without speech adaptation (</span>\n  <span class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">No-FT</span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) were used as the primary baselines. In addition, we include S2T results from several open-source speech LLMs, such as Moshi </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib12\" title=\"\">12</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and GLM-4-Voice </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib15\" title=\"\">15</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, as well as the results reported by the authors of </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib9\" title=\"\">9</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, with all numbers directly taken from </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. These comparisons provide a broader context for assessing the performance of our models.</span>\n</p>\n\n",
                "matched_terms": [
                    "s2t",
                    "benchmarks",
                    "web",
                    "settings",
                    "llama",
                    "results",
                    "t2t"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The results, presented in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3.1.2 Low Rank Adaptation &#8227; 3.1 Mitigation Strategies &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, demonstrate the effectiveness of both the Layer-LR and LoRA strategies. Compared with the Full-FT baseline, both strategies substantially mitigate textual degradation while simultaneously improving speech performance. For example, on the Web Questions benchmark, the 8B model trained with full fine-tuning shows a decrease in T2T accuracy from 58.7% to 55.7. In contrast, the models trained with layer-wise learning rate scheduling and LoRA both achieve higher accuracies of 57.6% and 56.7%, respectively, confirming their superior ability to preserve the model&#8217;s original textual competence.\nThis preservation of textual knowledge translates directly to improved spoken QA performance. On the Web-Questions benchmark, the 8B model trained with LoRA achieves the highest accuracy of 42.9%. These results strongly suggest that retaining the foundational textual abilities of the base LLM is essential for enhancing its speech comprehension capabilities.</span>\n</p>\n\n",
                "matched_terms": [
                    "web",
                    "results",
                    "lora",
                    "t2t",
                    "questions"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We also observe a noteworthy trade-off: compared to the model fine-tuned with LoRA, the one using the layer-wise learning rate scheduling exhibits a greater improvement in T2T accuracy, while the LoRA-based model achieves higher accuracy on S2T. This indicates that layer-wise learning rate scheduling is more effective at preserving the base model&#8217;s textual knowledge, but its conservative updates limit adaptation to speech inputs, leading to smaller improvements in spoken QA. In contrast, LoRA facilitates more efficient transfer of knowledge from text to speech, yielding superior spoken QA performance at the cost of weaker textual preservation. Overall, these findings highlight that different strategies strike different balances between textual competence and speech adaptation.</span>\n</p>\n\n",
                "matched_terms": [
                    "t2t",
                    "s2t",
                    "lora",
                    "different"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We further compared the two strategies by visualizing the parameter changes induced by each method. As illustrated in Figure </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S3.F4\" style=\"font-size:90%;\" title=\"Figure 4 &#8227; 3.3.3 Ablation Study on LoRA Rank &#8227; 3.3 Analysis &#8227; 3 Mitigation of Textual Capability Degradation &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, LoRA&#8217;s updates exhibit a more pronounced row-and-column clustering pattern, consistent with the rank clustering phenomenon observed in Section </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.23755v1#S2.SS3.SSS1\" style=\"font-size:90%;\" title=\"2.3.1 Structural Pattern: Rank Clustering &#8227; 2.3 Core Findings &#8227; 2 A Parameter-Level Analysis of Textual Capability Degradation in Speech LLMs &#8227; Understanding Textual Capability Degradation in Speech LLMs via Parameter Importance Analysis\">\n    <span class=\"ltx_text ltx_ref_tag\">2.3.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">. This supports that LoRA adapts more efficiently to the model&#8217;s inherent low-rank knowledge structure, which explains its superior performance on spoken QA. In contrast, layer-wise learning rate scheduling applies more conservative updates that effectively preserve textual knowledge but yield less efficient transfer to the speech modality, accounting for its comparatively weaker performance on S2T tasks.</span>\n</p>\n\n",
                "matched_terms": [
                    "s2t",
                    "rank",
                    "lora"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This paper investigated the degradation of textual capabilities in speech LLMs through a parameter-level analysis. We identified the primary mechanism as a textual importance distribution shift, where fine-tuning for speech disrupts the model&#8217;s original knowledge structure. Based on this finding, we adopted two mitigation strategies: layer-wise learning rate scheduling and LoRA. Experimental results confirmed that both methods effectively preserve textual competence by alleviating this distribution shift, which in turn leads to notable improvements in spoken QA performance. For future work, we plan to extend our analytical framework to other speech LLM paradigms, such as those based on vocabulary expansion, to assess the generality of our findings.</span>\n</p>\n\n",
                "matched_terms": [
                    "results",
                    "lora"
                ]
            }
        ]
    }
}