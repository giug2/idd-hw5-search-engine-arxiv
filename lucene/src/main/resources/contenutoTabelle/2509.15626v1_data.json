{
    "S3.T2": {
        "caption": "Table 1: Krippendorff’s alpha for the annotated VI dimensions.",
        "body": "<table class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">A</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">B</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">C</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">D</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">E</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">F</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">G</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">H</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">I</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">J</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_tt\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">K</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">A</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1.00</span></td>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_nopad_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">B</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">-0.89</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1.00</span></td>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_nopad_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">C</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.67</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.54</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1.00</span></td>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_nopad_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">D</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.48</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.34</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.27</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1.00</span></td>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_nopad_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">E</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.10</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.03</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.38</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.35</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1.00</span></td>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">F</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.67</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.58</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.69</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.34</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.05</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1.00</span></td>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_nopad_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">G</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">-0.78</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.69</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.46</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.36</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.26</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.63</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1.00</span></td>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_nopad_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">H</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.22</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.10</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.51</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.33</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.83</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.18</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.10</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1.00</span></td>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_nopad_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">I</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.44</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.23</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.64</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.31</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.46</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.43</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.21</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.66</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1.00</span></td>\n<td class=\"ltx_td\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n<td class=\"ltx_td ltx_nopad_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">J</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.24</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.37</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.04</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.22</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.05</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.10</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.31</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.16</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.38</span></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1.00</span></td>\n<td class=\"ltx_td ltx_nopad_r\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"/>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">K</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.07</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.17</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.17</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.08</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.21</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.08</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.14</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.18</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.17</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.02</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_right ltx_border_bb\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">1.00</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "dimensions",
            "krippendorff’s",
            "annotated",
            "alpha"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To validate our new manual annotations, we analyzed both the inter-annotator agreement and the inter-scale correlations.\nThe inter-annotator agreement, measured by Krippendorff&#8217;s alpha (</span>\n  <math alttext=\"\\alpha\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#945;</mi>\n      <annotation encoding=\"application/x-tex\">\\alpha</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">), is reported in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3 LibriTTS-VI: A Public Dataset for VIC &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nWhile many of our scales fall below the conventional threshold for reliability (</span>\n  <math alttext=\"\\alpha\\geq 0.667\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">&#945;</mi>\n        <mo mathsize=\"0.900em\">&#8805;</mo>\n        <mn mathsize=\"0.900em\">0.667</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">\\alpha\\geq 0.667</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib28\" title=\"\">28</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, this result aligns with other studies involving subjective audio perception, such as speech emotion in </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib29\" title=\"\">29</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (0.22&#8211;0.58) and singing voice in </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib30\" title=\"\">30</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (0.10&#8211;0.26).\nOur average alpha (0.464) is notably higher than these reported values.\nAs shown in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3 LibriTTS-VI: A Public Dataset for VIC &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, our inter-scale correlations are consistent with the original VIC study </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, with some discrepancies, such as an inverted correlation between C) Clear-Hoarse and F) Youthful-Aged.\nWe hypothesize this discrepancy is due to the different characteristics of the LibriTTS-R corpus versus the in-house data used in </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Voice Impression Control (VIC) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> pioneered the use of VI for controlling speaker characteristics in TTS.\nThe original VIC study established a set of 11 non-expert perceptual dimensions, validated their controllability in TTS, and linked these perceptual vectors with natural language (e.g., &#8220;sleepy&#8221;) via large language models.\nHowever, the study faces two key limitations.\nFirst, in the process of reimplementing the VIC, we observed the problem of impression leakage: despite being able to specify the reference audio and target VI independently, the synthesized voice is often undesirably biased toward the impression of the reference audio itself.\nSecond, no public annotated VI corpus is available, making follow-up studies and reproducible research difficult.</span>\n</p>\n\n",
                "matched_terms": [
                    "dimensions",
                    "annotated"
                ]
            }
        ]
    },
    "S4.T4": {
        "caption": "Table 3: Summary of objective evaluation results. We measured intelligibility with CER and WER, audio quality with UTMOS, speaker similarity with SECS, and VI control error with VI-MSE, RVI-MSE, and impression leakage with their difference (ΔV\\Delta_{\\text{V}}).",
        "body": "<table class=\"ltx_tabular ltx_align_left ltx_centering ltx_figure_panel ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">VI</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">base</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">sep</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">rfg</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">VI</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">base</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">sep</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">rfg</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">A) L-H</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.002</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">0.091</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.163</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">G) T-T</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.042</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">0.050</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.058</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">B) M-F</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">0.604</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.600</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.625</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">H) F-R</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.067</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">0.099</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.137</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">C) C-H</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.037</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">0.070</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.072</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">I) D-B</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.036</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">0.058</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.107</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">D) C-R</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.064</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">0.140</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.165</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">J) C-W</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.046</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">0.098</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.169</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">E) P-W</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">-0.048</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">-0.030</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.000</span></td>\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">K) S-F</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.015</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">0.047</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.170</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_b\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">F) Y-A</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.188</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">0.256</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.283</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Avg</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">0.096</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:80%;\">0.135</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">0.177</span></td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "utmos",
            "summary",
            "sep",
            "wer",
            "their",
            "evaluation",
            "control",
            "error",
            "similarity",
            "difference",
            "vimse",
            "audio",
            "base",
            "objective",
            "speaker",
            "leakage",
            "impression",
            "avg",
            "rvimse",
            "results",
            "measured",
            "δvdeltatextv",
            "rfg",
            "secs",
            "cer",
            "intelligibility",
            "quality"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The full results are listed in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T4\" style=\"font-size:90%;\" title=\"Table 4 &#8227; 4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nAll systems achieved high speech intelligibility (CERs/WERs) and audio quality (UTMOS), confirming that our methods do not degrade synthesis quality.\nFor speaker similarity (SECS), the reference-based VIC-base and VIC-sep achieved high scores (0.84 and 0.82).\nOn the other hand, VIC-rfg&#8217;s score was noticeably lower (0.76), reflecting the expected trade-off of its reference-free design in reconstructing speaker identity.\nNext, we analyzed VI controllability and impression leakage.\nWhile the VI-MSE scores show only a slight improvement in control precision for the proposed methods (0.37 for VIC-sep, 0.36 for VIC-rfg) compared to the baseline (0.39), the impression leakage gap, </span>\n  <math alttext=\"\\Delta_{\\text{V}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n        <mtext mathsize=\"0.900em\">V</mtext>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\Delta_{\\text{V}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, reveals a more significant difference.\nThe baseline exhibits a large gap (</span>\n  <math alttext=\"\\Delta_{\\text{V}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n        <mtext mathsize=\"0.900em\">V</mtext>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\Delta_{\\text{V}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) of 0.22.\nIn contrast, our proposed methods narrow this gap to 0.14 for VIC-sep and a minimal 0.05 for VIC-rfg, demonstrating their superior robustness against impression leakage.</span>\n</p>\n\n",
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To further probe control precision, we conducted a modulation experiment, following </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nFor each of the 39 unseen speakers in the test-clean set, we modulated each VI dimension of an anchor VI vector from -3 to +3, synthesized 50 sentences per condition, and predicted the VI using our VIE.\nWe then quantified the fidelity of VI control via the slope of the linear fit between target and predicted VIs, where a larger positive slope indicates more responsive control in the intended direction.\nAs shown in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T4\" style=\"font-size:90%;\" title=\"Table 4 &#8227; 4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while the slopes were generally mild, they were consistently positive for all dimensions except for E) Powerful-Weak, which was not learned effectively by any system.\nAmong the systems, the average slope consistently increased from VIC-base (0.096) to VIC-sep (0.135), and finally to VIC-rfg (0.177), offering the most responsive control.</span>\n</p>\n\n",
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We conducted subjective evaluations for both controllability and audio quality under two distinct VI modulation conditions: single VI modulation and multiple VI modulation.\nFor the single VI modulation, we followed the evaluation in the original VIC study </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nSpecifically, we evaluated four representative VIs: A) Low-High</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote4\">\n    <sup class=\"ltx_note_mark\">4</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">4</sup><span class=\"ltx_tag ltx_tag_note\">4</span>We replaced the Powerful-Weak dimension from the original VIC study with Low-High, as our models struggled to learn the former (see Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T4\" title=\"Table 4 &#8227; 4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>).</span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, B) Masculine-Feminine, F) Youthful-Aged, and I) Dark-Bright.\nWe used the same audio generated for the VI modulation experiment described in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.SS2\" style=\"font-size:90%;\" title=\"4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T4\" style=\"font-size:90%;\" title=\"Table 4 &#8227; 4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThe multiple VI modulation was designed to assess how synthesis quality is affected by the simultaneous modulation of multiple VIs.\nWe used the same generated audio from the RVI-MSE evaluation described in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.SS2\" style=\"font-size:90%;\" title=\"4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T4\" style=\"font-size:90%;\" title=\"Table 4 &#8227; 4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nWe focused on two speakers (ID 1089 and ID 8555) and report only the results for speaker 8555 due to similar trends and space limitations.\n</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Fine-grained control over voice impressions (e.g., making a voice brighter or calmer) is a key frontier for creating more controllable text-to-speech.\nHowever, this nascent field faces two key challenges.\nThe first is the problem of impression leakage, where the synthesized voice is undesirably influenced by the speaker&#8217;s reference audio, rather than the separately specified target impression, and the second is the lack of a public, annotated corpus.\nTo mitigate impression leakage, we propose two methods: 1) a training strategy that separately uses an utterance for speaker identity and another utterance of the same speaker for target impression, and 2) a novel reference-free model that generates a speaker embedding solely from the target impression, achieving the benefits of improved robustness against the leakage and the convenience of reference-free generation.\nObjective and subjective evaluations demonstrate a significant improvement in controllability.\nOur best method reduced the mean squared error of 11-dimensional voice impression vectors from 0.61 to 0.41 objectively and from 1.15 to 0.92 subjectively, while maintaining high fidelity.\nTo foster reproducible research, we introduce LibriTTS-VI, the first public voice impression dataset released with clear annotation standards, built upon the LibriTTS-R corpus.<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\"><span class=\"ltx_text\" style=\"font-size:111%;\">1</span></span><span class=\"ltx_text\" style=\"font-size:111%;\">The corpus and demo samples are publicly available at: </span><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/sony/LibriTTS-VI\" style=\"font-size:111%;\" title=\"\">https://github.com/sony/LibriTTS-VI</a></span></span></span></span>\n</p>\n\n",
                "matched_terms": [
                    "impression",
                    "audio",
                    "objective",
                    "speaker",
                    "control",
                    "leakage",
                    "error"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text ltx_font_bold ltx_font_italic\" style=\"font-size:90%;\">Index Terms<span class=\"ltx_text ltx_font_upright\">&#8212;&#8201;<span class=\"ltx_text ltx_font_medium\">\nText-to-speech, voice impression control, zero-shot TTS, disentanglement, corpus</span></span></span>\n</p>\n\n",
                "matched_terms": [
                    "control",
                    "impression"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Modern text-to-speech (TTS) synthesis has achieved near-human parity in quality </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib3\" title=\"\">3</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, shifting the research focus from simple naturalness toward enhancing controllability over speaker identity and speaking styles.\nThe pursuit of this controllability has evolved through several paradigms.\nControl paradigms include direct manipulation of acoustic features such as pitch, energy, and duration </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib4\" title=\"\">4</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and ID-based methods for predefined speakers </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib5\" title=\"\">5</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> or emotional classes </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib6\" title=\"\">6</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib7\" title=\"\">7</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nAnother prominent paradigm involves conditioning on audio exemplars or text descriptions, utilizing reference-based speaker encoders </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib8\" title=\"\">8</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib9\" title=\"\">9</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, unsupervised style transfer </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib10\" title=\"\">10</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, emotion synthesis with intensity control </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib11\" title=\"\">11</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib12\" title=\"\">12</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and the use of natural language prompts to describe prosodic styles </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib15\" title=\"\">15</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as well as speaker characteristics </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib16\" title=\"\">16</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib17\" title=\"\">17</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nHowever, these existing approaches present a trade-off in controllability.\nWhile direct manipulation of acoustic features such as pitch and energy offers precision, it can be too granular and is difficult for humans to control effectively.\nConversely, other intuitive methods using IDs, reference audio, or text prompts typically lack mechanisms for fine-grained numerical adjustment.\n</span>\n</p>\n\n",
                "matched_terms": [
                    "audio",
                    "control",
                    "speaker",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">A key challenge, therefore, is to balance fine-grained control with human-understandable scales, which is crucial for practical applications.\nOne line of research attempts to discover controllable dimensions by analyzing the principal components of speaker embeddings </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib18\" title=\"\">18</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThis concept has been extended to generate artificial speaker embeddings, an approach that not only eliminates the need for a reference audio but also offers potential benefits for user privacy </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nIn contrast, another paradigm starts with explicitly defined perceptual dimensions for voice characteristics.\nOne approach uses perceptual voice qualities (e.g., roughness and breathiness), which are rated by phonetic experts based on clinical protocols </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib20\" title=\"\">20</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nAnother approach targets voice impressions (VI) such as calmness and brightness based on non-expert&#8217;s subjective impressions </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib21\" title=\"\">21</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib22\" title=\"\">22</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which we focus in this paper.</span>\n</p>\n\n",
                "matched_terms": [
                    "audio",
                    "control",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Voice Impression Control (VIC) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> pioneered the use of VI for controlling speaker characteristics in TTS.\nThe original VIC study established a set of 11 non-expert perceptual dimensions, validated their controllability in TTS, and linked these perceptual vectors with natural language (e.g., &#8220;sleepy&#8221;) via large language models.\nHowever, the study faces two key limitations.\nFirst, in the process of reimplementing the VIC, we observed the problem of impression leakage: despite being able to specify the reference audio and target VI independently, the synthesized voice is often undesirably biased toward the impression of the reference audio itself.\nSecond, no public annotated VI corpus is available, making follow-up studies and reproducible research difficult.</span>\n</p>\n\n",
                "matched_terms": [
                    "impression",
                    "audio",
                    "their",
                    "speaker",
                    "control",
                    "leakage"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This paper addresses these two challenges to advance research in VIC.\nWe propose two novel methods to mitigate impression leakage.\nThe first is a training strategy for disentangling speaker and impression information, which uses two separate utterances from the same speaker; one to provide the speaker identity and another for the target VI.\nThe second, inspired by the reference-free approach in </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, generates pseudo speaker embeddings based solely on the target VI, providing both an architectural solution to the leakage and the practical advantages of synthesis without any reference audio.\nOur best method reduced the mean squared error (MSE) of 11-dimensional VI vectors from 0.61 to 0.41 objectively and from 1.15 to 0.92 subjectively, while maintaining high synthesis quality.\nMoreover, to promote reproducibility, we introduce LibriTTS-VI, the first public VI corpus built upon the LibriTTS-R dataset </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib24\" title=\"\">24</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "impression",
                    "audio",
                    "speaker",
                    "leakage",
                    "quality",
                    "error"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">After pre-training this backbone, we enable VI control by inserting a lightweight control module (CM) into the speaker encoder illustrated in Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S2.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 2 VIC SYSTEMS &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nWe then finetune the module on our LibriTTS-VI dataset (detailed in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S3\" style=\"font-size:90%;\" title=\"3 LibriTTS-VI: A Public Dataset for VIC &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">).\nWe evaluate three different variations of the CM: the baseline VIC-base, and our two proposed methods, VIC-sep and VIC-rfg, detailed in the following subsections.</span>\n</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "control"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The original VIC framework </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> provides an interface for VI control by inserting a CM into the speaker encoder before the STL, as shown in the left part of Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S2.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 2 VIC SYSTEMS &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThe CM processes information through two internal paths.\nOne path accepts the target VI vector </span>\n  <math alttext=\"\\mathbf{v}\\in\\mathbb{R}^{11}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">&#119855;</mi>\n        <mo mathsize=\"0.900em\">&#8712;</mo>\n        <msup>\n          <mi mathsize=\"0.900em\">&#8477;</mi>\n          <mn mathsize=\"0.900em\">11</mn>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">\\mathbf{v}\\in\\mathbb{R}^{11}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which is then processed by a linear layer. The other path takes the encoded reference audio </span>\n  <math alttext=\"\\mathbf{x}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119857;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{x}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (defined in Eq.&#160;(</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S2.E1\" style=\"font-size:90%;\" title=\"In 2.1 Backbone TTS model &#8227; 2 VIC SYSTEMS &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">)) and applies a high-ratio dropout with a linear layer, followed by an adversarial VI learning module with a gradient reversal layer (GRL) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib26\" title=\"\">26</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> to extract speaker characteristics while removing the inherent VI.\nThe outputs of these two paths are then concatenated, and a final linear layer projects the result back to the original dimension of </span>\n  <math alttext=\"\\mathbf{x}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119857;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{x}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, producing a modified vector </span>\n  <math alttext=\"\\mathbf{x^{\\prime}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <msup>\n        <mi mathsize=\"0.900em\">&#119857;</mi>\n        <mo mathsize=\"0.900em\">&#8242;</mo>\n      </msup>\n      <annotation encoding=\"application/x-tex\">\\mathbf{x^{\\prime}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">:</span>\n</p>\n\n",
                "matched_terms": [
                    "audio",
                    "control",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The CM is fine-tuned with the backbone frozen, using the original TTS loss to implicitly learn the correspondence between a ground-truth audio utterance and its VI vector.\nDuring the fine-tuning, the target VI vector </span>\n  <math alttext=\"\\mathbf{v}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119855;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{v}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is supplied by a pre-trained voice impression estimator (VIE), which consists of the speech encoder (defined in Eq.&#160;(</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S2.E1\" style=\"font-size:90%;\" title=\"In 2.1 Backbone TTS model &#8227; 2 VIC SYSTEMS &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">)) followed by a linear layer to predict the VI vector </span>\n  <math alttext=\"\\hat{\\mathbf{v}}\\in\\mathbb{R}^{11}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.m6\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mover accent=\"true\">\n          <mi mathsize=\"0.900em\">&#119855;</mi>\n          <mo mathsize=\"0.900em\">^</mo>\n        </mover>\n        <mo mathsize=\"0.900em\">&#8712;</mo>\n        <msup>\n          <mi mathsize=\"0.900em\">&#8477;</mi>\n          <mn mathsize=\"0.900em\">11</mn>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">\\hat{\\mathbf{v}}\\in\\mathbb{R}^{11}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">:</span>\n</p>\n\n",
                "matched_terms": [
                    "audio",
                    "impression"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our baseline, VIC-base, is a reimplementation of this original VIC framework, replacing its FastSpeech2 architecture </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib2\" title=\"\">2</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with VITS for its superior audio quality.\nIn our preliminary experiments, we observed some impression leakage from the reference audio, suggesting that dropout and GRL are insufficient to disentangle the inherent impression from the speaker characteristics.\n</span>\n</p>\n\n",
                "matched_terms": [
                    "impression",
                    "audio",
                    "speaker",
                    "leakage",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our first proposed method, VIC-sep (&#8220;separate&#8221;), illustrated in the middle of Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S2.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 2 VIC SYSTEMS &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, aims to mitigate the impression leakage in VIC-base.\nWe hypothesize that it is difficult to disentangle speaker identity and the target VI when both are sourced from a single utterance </span>\n  <math alttext=\"\\mathbf{r}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119851;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{r}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, even with dropout and GRL.\nTo solve this, we introduce a second, separate utterance </span>\n  <math alttext=\"\\mathbf{r^{\\prime}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p1.m2\" intent=\":literal\">\n    <semantics>\n      <msup>\n        <mi mathsize=\"0.900em\">&#119851;</mi>\n        <mo mathsize=\"0.900em\">&#8242;</mo>\n      </msup>\n      <annotation encoding=\"application/x-tex\">\\mathbf{r^{\\prime}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> from the same speaker, which replaces </span>\n  <math alttext=\"\\mathbf{r}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119851;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{r}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> in Eq.&#160;(</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S2.E1\" style=\"font-size:90%;\" title=\"In 2.1 Backbone TTS model &#8227; 2 VIC SYSTEMS &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">).\nThe original utterance </span>\n  <math alttext=\"\\mathbf{r}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119851;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{r}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> remains the ground-truth synthesis target and the source for the target VI, thus decoupling the two information sources while keeping the model architecture identical to VIC-base.</span>\n</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "impression",
                    "leakage"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our second proposed method, VIC-rfg (&#8220;reference-free generation&#8221;), illustrated on the right of Fig.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S2.F1\" style=\"font-size:90%;\" title=\"Figure 1 &#8227; 2 VIC SYSTEMS &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, architecturally eliminates the impression leakage by removing the reference audio from the synthesis process.\nInspired by the method for generating artificial speaker embeddings for voice privacy </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, the speaker encoder is conditioned solely on the target VI vector.\nThe encoded reference audio </span>\n  <math alttext=\"\\mathbf{x}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS4.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119857;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{x}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is then replaced with a random noise vector sampled from a standard Gaussian distribution.\nThis method is therefore designed to strongly suppress the impression leakage from the reference audio.\nHowever, this architectural change introduced a challenge during training.\nWe found that fine-tuning only the CM resulted in an unstable speaking rate.\nTo stabilize it, we also jointly fine-tune the stochastic duration predictor (SDP) from the VITS backbone.</span>\n</p>\n\n",
                "matched_terms": [
                    "audio",
                    "speaker",
                    "leakage",
                    "impression"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The process for creating the manual annotations is as follows.\nFirst, we created the set of 100 utterances to be annotated. This was done by randomly selecting 100 speakers from the LibriTTS-R training set and then choosing one random utterance from each speaker.\nTo guide the annotation, we established standards for the ten subjective VIs (all except K) Slow-Fast).\nThese standards included a written description of each VI and a reference audio sample from LibriTTS-R representing the neutral position.\nFollowing these standards, four annotators with professional experience in speech synthesis evaluation rated the 100 utterances on a seven-point Likert scale, yielding 400 independent annotations.\nThe remaining scale, K) Slow&#8211;Fast, was derived objectively by using a timestamped automatic speech recognition (ASR) model </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> to calculate words per unit of time, and rescaling the values to a 1&#8211;7 range across the dataset.\nThe comprehensive annotation standards are included in our release.</span>\n</p>\n\n",
                "matched_terms": [
                    "audio",
                    "evaluation",
                    "speaker"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To validate our new manual annotations, we analyzed both the inter-annotator agreement and the inter-scale correlations.\nThe inter-annotator agreement, measured by Krippendorff&#8217;s alpha (</span>\n  <math alttext=\"\\alpha\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#945;</mi>\n      <annotation encoding=\"application/x-tex\">\\alpha</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">), is reported in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3 LibriTTS-VI: A Public Dataset for VIC &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nWhile many of our scales fall below the conventional threshold for reliability (</span>\n  <math alttext=\"\\alpha\\geq 0.667\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p3.m2\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">&#945;</mi>\n        <mo mathsize=\"0.900em\">&#8805;</mo>\n        <mn mathsize=\"0.900em\">0.667</mn>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">\\alpha\\geq 0.667</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib28\" title=\"\">28</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, this result aligns with other studies involving subjective audio perception, such as speech emotion in </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib29\" title=\"\">29</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (0.22&#8211;0.58) and singing voice in </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib30\" title=\"\">30</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> (0.10&#8211;0.26).\nOur average alpha (0.464) is notably higher than these reported values.\nAs shown in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S3.T2\" style=\"font-size:90%;\" title=\"Table 2 &#8227; 3 LibriTTS-VI: A Public Dataset for VIC &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, our inter-scale correlations are consistent with the original VIC study </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, with some discrepancies, such as an inverted correlation between C) Clear-Hoarse and F) Youthful-Aged.\nWe hypothesize this discrepancy is due to the different characteristics of the LibriTTS-R corpus versus the in-house data used in </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "audio",
                    "measured"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Finally, using our manual annotations, we trained a VIE with </span>\n  <math alttext=\"\\mathcal{L}_{\\text{VIE}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m1\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi class=\"ltx_font_mathcaligraphic\" mathsize=\"0.900em\">&#8466;</mi>\n        <mtext mathsize=\"0.900em\">VIE</mtext>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\text{VIE}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, described in Eq.&#160;(</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S2.E5\" style=\"font-size:90%;\" title=\"In 2.2 Baseline Implementation (VIC-base) &#8227; 2 VIC SYSTEMS &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">5</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">).\nThe original study&#8217;s training strategy assumed a constant VI vector per speaker, which is unsuitable for the LibriTTS-R audiobook corpus, which contains a mixture of narration and expressive utterances.\nWe therefore adopted a new data augmentation strategy.\nFor each of the 100 manually annotated utterances, we found up to 100 acoustically similar utterances from the same speaker.\nWe calculated similarities based on L1-norms of pitch and energy, and cosine similarity of embeddings from WavLM </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib31\" title=\"\">31</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nWe then selected the top 100 utterances based on the averaged similarity scores.\nThese selected utterances were then assigned the same VI vector, </span>\n  <math alttext=\"\\mathbf{v_{\\text{manual}}}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.p4.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#119855;</mi>\n        <mtext mathsize=\"0.900em\">manual</mtext>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\mathbf{v_{\\text{manual}}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, for training.</span>\n</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "similarity"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Our implementation followed the original VIC study </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, but some hyperparameters were adapted for our VITS-based backbone. The VITS model was based on a publicly available implementation</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote3\">\n    <sup class=\"ltx_note_mark\">3</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\">\n        <sup class=\"ltx_note_mark\">3</sup>\n        <span class=\"ltx_tag ltx_tag_note\">3</span>\n        <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/daniilrobnikov/vits2\" title=\"\">https://github.com/daniilrobnikov/vits2</a>\n      </span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nTo improve synthesis quality, we enhanced the architecture with a Conformer-based text encoder </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib32\" title=\"\">32</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib33\" title=\"\">33</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and applied a connectionist temporal classification auxiliary loss and an adaptive layer-norm zero Transformer </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib34\" title=\"\">34</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib35\" title=\"\">35</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib36\" title=\"\">36</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nWe set both the dimensions of </span>\n  <math alttext=\"\\mathbf{x}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119857;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{x}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"\\mathbf{g}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119840;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{g}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, as defined in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S2.SS1\" style=\"font-size:90%;\" title=\"2.1 Backbone TTS model &#8227; 2 VIC SYSTEMS &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">2.1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, to 256.\nThe base VITS model was pre-trained for 600k steps.\nInside the CM, the target VI vector </span>\n  <math alttext=\"\\mathbf{v}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m3\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119855;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{v}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and the intermediate vector </span>\n  <math alttext=\"\\mathbf{x}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m4\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119857;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{x}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> from Eq.&#160;(</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S2.E1\" style=\"font-size:90%;\" title=\"In 2.1 Backbone TTS model &#8227; 2 VIC SYSTEMS &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">1</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) were each projected to 32 dimensions; for VIC-rfg, the </span>\n  <math alttext=\"\\mathbf{x}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119857;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{x}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> was replaced by a 32-dimensional Gaussian noise vector.\nThe CM was fine-tuned for 60k steps.\nWe used eight NVIDIA A100 GPUs, a batch size of 20, and the AdamW optimizer with an initial learning rate of </span>\n  <math alttext=\"2\\times 10^{-4}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m6\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mn mathsize=\"0.900em\">2</mn>\n        <mo lspace=\"0.222em\" mathsize=\"0.900em\" rspace=\"0.222em\">&#215;</mo>\n        <msup>\n          <mn mathsize=\"0.900em\">10</mn>\n          <mrow>\n            <mo mathsize=\"0.900em\">&#8722;</mo>\n            <mn mathsize=\"0.900em\">4</mn>\n          </mrow>\n        </msup>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">2\\times 10^{-4}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "base",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">For the objective evaluation, we measured speech intelligibility with character/word error rates (CER/WER) via Whisper large-v3 </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib37\" title=\"\">37</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, audio quality with UTMOS </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib38\" title=\"\">38</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and speaker similarity with speaker encoder cosine similarity (SECS) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib39\" title=\"\">39</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nTo assess controllability, we introduce two variants of VI-based MSE.\nLet </span>\n  <math alttext=\"\\mathbf{s}(\\mathbf{r},\\mathbf{v_{r}})\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">&#119852;</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\">&#119851;</mi>\n          <mo mathsize=\"0.900em\">,</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">&#119855;</mi>\n            <mi mathsize=\"0.900em\">&#119851;</mi>\n          </msub>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">\\mathbf{s}(\\mathbf{r},\\mathbf{v_{r}})</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> denote the audio synthesized from the speech encoder&#8217;s reference </span>\n  <math alttext=\"\\mathbf{r}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119851;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{r}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with its VI vector </span>\n  <math alttext=\"\\mathbf{v_{r}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#119855;</mi>\n        <mi mathsize=\"0.900em\">&#119851;</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\mathbf{v_{r}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThe standard VI-MSE measures the MSE of </span>\n  <math alttext=\"\\mathbf{v_{r}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#119855;</mi>\n        <mi mathsize=\"0.900em\">&#119851;</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\mathbf{v_{r}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"\\text{VIE}(\\mathbf{s}(\\mathbf{r},\\mathbf{v_{r}}))\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mtext mathsize=\"0.900em\">VIE</mtext>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mrow>\n            <mi mathsize=\"0.900em\">&#119852;</mi>\n            <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n            <mrow>\n              <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n              <mi mathsize=\"0.900em\">&#119851;</mi>\n              <mo mathsize=\"0.900em\">,</mo>\n              <msub>\n                <mi mathsize=\"0.900em\">&#119855;</mi>\n                <mi mathsize=\"0.900em\">&#119851;</mi>\n              </msub>\n              <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n            </mrow>\n          </mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">\\text{VIE}(\\mathbf{s}(\\mathbf{r},\\mathbf{v_{r}}))</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nIn contrast, RVI-MSE is calculated with the target VI </span>\n  <math alttext=\"\\mathbf{v}_{*}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m6\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#119855;</mi>\n        <mo mathsize=\"0.900em\">&#8727;</mo>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\mathbf{v}_{*}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which is sourced from a random, unrelated utterance </span>\n  <math alttext=\"\\mathbf{r}_{*}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m7\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#119851;</mi>\n        <mo mathsize=\"0.900em\">&#8727;</mo>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\mathbf{r}_{*}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">:</span>\n</p>\n\n",
                "matched_terms": [
                    "utmos",
                    "similarity",
                    "secs",
                    "rvimse",
                    "quality",
                    "vimse",
                    "audio",
                    "objective",
                    "evaluation",
                    "speaker",
                    "measured",
                    "intelligibility",
                    "error"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We then quantified the impression leakage gap, </span>\n  <math alttext=\"\\Delta_{\\text{V}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m8\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n        <mtext mathsize=\"0.900em\">V</mtext>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\Delta_{\\text{V}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, as the difference between these two metrics:</span>\n</p>\n\n",
                "matched_terms": [
                    "δvdeltatextv",
                    "impression",
                    "leakage",
                    "difference"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">A large value of </span>\n  <math alttext=\"\\Delta_{\\text{V}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m9\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n        <mtext mathsize=\"0.900em\">V</mtext>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\Delta_{\\text{V}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> indicates the impression leakage gap, as </span>\n  <math alttext=\"\\mathbf{v_{*}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m10\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#119855;</mi>\n        <mo mathsize=\"0.900em\">&#8727;</mo>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\mathbf{v_{*}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> is sourced from an utterance independent of the speech encoder&#8217;s reference </span>\n  <math alttext=\"\\mathbf{r}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m11\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119851;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{r}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "δvdeltatextv",
                    "impression",
                    "leakage"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Second, we conducted a Mean Opinion Score (MOS) test for audio quality, where 30 native or native-level English speakers rated samples on a five-point scale (1: Bad &#8211; 5: Excellent).\nThe experimental setup was similar to that of the preceding controllability test in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T6\" style=\"font-size:90%;\" title=\"Table 6 &#8227; 4.3 Subjective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">6</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, but it also included the neutral modulation level (0) and used 12 sentences per condition. Each of the 30 participants rated all stimuli, resulting in 30 evaluations for each synthesized speech.\nThe results (Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T6\" style=\"font-size:90%;\" title=\"Table 6 &#8227; 4.3 Subjective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">6</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) reveal several key findings.\nIn the single VI modulation conditions, the proposed methods showed no consistent trend of audio quality degradation compared to the baseline, with VIC-sep having five significant improvements versus four degradations, and VIC-rfg having four of each.\nMoreover, with no significant quality differences observed in the challenging multiple VI condition, we conclude that our proposed methods achieve high controllability while maintaining audio quality comparable to the baseline.\n</span>\n</p>\n\n",
                "matched_terms": [
                    "audio",
                    "results",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">In this paper, we addressed two key challenges in VIC: the issue of impression leakage and the lack of a public corpus.\nTo mitigate impression leakage, we proposed two novel methods: a training strategy using separate utterances for disentanglement, and a reference-free generation model that structurally eliminates the leakage.\nOur experiments showed that these methods improve controllability while maintaining high synthesis quality.\nFor reproducible research, we introduced LibriTTS-VI, a new public corpus for VIC.\n</span>\n</p>\n\n",
                "matched_terms": [
                    "impression",
                    "leakage",
                    "quality"
                ]
            }
        ]
    },
    "S4.T6": {
        "caption": "Table 5: Subjective controllability results for speaker 8555, in terms of MSE (Mean ±\\pm 95% CI). Bold: best, underline: second-best.",
        "body": "<table class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">VI</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Condition</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">base</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">sep</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">rfg</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">A</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. -3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.31 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m32\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.10</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.42 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m33\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">3.75 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m34\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.11</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. +0</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.31 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m35\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.12</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">3.46 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m36\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.11</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">3.44 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m37\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.12</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. +3</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.44 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m38\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.12</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.21 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m39\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span><sup class=\"ltx_sup\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8224;</span></sup>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">2.85 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m41\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span><sup class=\"ltx_sup\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8224;</span></sup>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">B</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. -3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.64 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m43\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.42 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m44\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.13</span><sup class=\"ltx_sup\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8224;</span></sup>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.46 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m46\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span><sup class=\"ltx_sup\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8224;</span></sup>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. +0</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.37 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m48\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.12</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">3.68 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m49\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.11</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">3.52 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m50\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.11</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. +3</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.44 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m51\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.48 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m52\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.12</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.34 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m53\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">F</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. -3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.44 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m54\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.10</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.54 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m55\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.43 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m56\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. +0</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.34 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m57\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.13</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">3.73 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m58\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.10</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">3.62 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m59\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.11</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. +3</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.46 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m60\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.12</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.18 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m61\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.13</span><sup class=\"ltx_sup\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8224;</span></sup>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.42 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m63\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.10</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"3\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">I</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. -3</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.51 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m64\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.10</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.34 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m65\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span><sup class=\"ltx_sup\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8224;</span></sup>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.29 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m67\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span><sup class=\"ltx_sup\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8224;</span></sup>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. +0</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.49 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m69\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">3.68 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m70\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.10</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.26 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m71\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span><sup class=\"ltx_sup\"><span class=\"ltx_text\" style=\"font-size:80%;\">&#8224;</span></sup>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text\" style=\"font-size:80%;\">Mod. +3</span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.26 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m73\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.12</span>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">3.59 <math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m74\" intent=\":literal\"><semantics><mo>&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math> 0.11</span></td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.18 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m75\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.13</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" colspan=\"2\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Multiple VIs</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.71 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m76\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.11</span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.28 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m77\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.12</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">\n<span class=\"ltx_text\" style=\"font-size:80%;\">3.60 </span><math alttext=\"\\pm\" class=\"ltx_Math\" display=\"inline\" id=\"S4.T6.m78\" intent=\":literal\"><semantics><mo mathsize=\"0.800em\">&#177;</mo><annotation encoding=\"application/x-tex\">\\pm</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:80%;\"> 0.12</span>\n</td>\n</tr>\n</table>\n\n",
        "informative_terms_identified": [
            "sep",
            "013†",
            "vis",
            "underline",
            "base",
            "speaker",
            "terms",
            "mod",
            "condition",
            "bold",
            "multiple",
            "mean",
            "results",
            "rfg",
            "secondbest",
            "011†",
            "mse",
            "best",
            "±pm",
            "subjective",
            "controllability"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">First, we conducted a controllability evaluation.\nFor all three systems and both speakers, we selected 10 sentences for each of two conditions: single VI modulation (at levels -3 and +3) and the multiple VI modulation.\nWe asked the same four annotators in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S3\" style=\"font-size:90%;\" title=\"3 LibriTTS-VI: A Public Dataset for VIC &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">3</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> to rate the VI of the synthesized speech.\nTable&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T6\" style=\"font-size:90%;\" title=\"Table 6 &#8227; 4.3 Subjective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">6</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> shows the MSE between the specified target VI vector and the scores provided by the annotators.\nWhile VIC-rfg struggled in the Mod.&#160;+3 setting for dimension I, the proposed methods generally outperformed the baseline in the single VI modulation conditions.\nIn the challenging multiple VI condition, the proposed methods also demonstrated superior robustness, reducing the MSE from 1.15 for the baseline to 1.04 for VIC-sep and 0.92 for VIC-rfg.\n</span>\n</p>\n\n",
            "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Second, we conducted a Mean Opinion Score (MOS) test for audio quality, where 30 native or native-level English speakers rated samples on a five-point scale (1: Bad &#8211; 5: Excellent).\nThe experimental setup was similar to that of the preceding controllability test in Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T6\" style=\"font-size:90%;\" title=\"Table 6 &#8227; 4.3 Subjective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">6</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, but it also included the neutral modulation level (0) and used 12 sentences per condition. Each of the 30 participants rated all stimuli, resulting in 30 evaluations for each synthesized speech.\nThe results (Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T6\" style=\"font-size:90%;\" title=\"Table 6 &#8227; 4.3 Subjective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">6</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) reveal several key findings.\nIn the single VI modulation conditions, the proposed methods showed no consistent trend of audio quality degradation compared to the baseline, with VIC-sep having five significant improvements versus four degradations, and VIC-rfg having four of each.\nMoreover, with no significant quality differences observed in the challenging multiple VI condition, we conclude that our proposed methods achieve high controllability while maintaining audio quality comparable to the baseline.\n</span>\n</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Fine-grained control over voice impressions (e.g., making a voice brighter or calmer) is a key frontier for creating more controllable text-to-speech.\nHowever, this nascent field faces two key challenges.\nThe first is the problem of impression leakage, where the synthesized voice is undesirably influenced by the speaker&#8217;s reference audio, rather than the separately specified target impression, and the second is the lack of a public, annotated corpus.\nTo mitigate impression leakage, we propose two methods: 1) a training strategy that separately uses an utterance for speaker identity and another utterance of the same speaker for target impression, and 2) a novel reference-free model that generates a speaker embedding solely from the target impression, achieving the benefits of improved robustness against the leakage and the convenience of reference-free generation.\nObjective and subjective evaluations demonstrate a significant improvement in controllability.\nOur best method reduced the mean squared error of 11-dimensional voice impression vectors from 0.61 to 0.41 objectively and from 1.15 to 0.92 subjectively, while maintaining high fidelity.\nTo foster reproducible research, we introduce LibriTTS-VI, the first public voice impression dataset released with clear annotation standards, built upon the LibriTTS-R corpus.<span class=\"ltx_note ltx_role_footnote\" id=\"footnote1\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">1</sup><span class=\"ltx_tag ltx_tag_note\"><span class=\"ltx_text\" style=\"font-size:111%;\">1</span></span><span class=\"ltx_text\" style=\"font-size:111%;\">The corpus and demo samples are publicly available at: </span><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/sony/LibriTTS-VI\" style=\"font-size:111%;\" title=\"\">https://github.com/sony/LibriTTS-VI</a></span></span></span></span>\n</p>\n\n",
                "matched_terms": [
                    "best",
                    "speaker",
                    "mean",
                    "subjective",
                    "controllability"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Modern text-to-speech (TTS) synthesis has achieved near-human parity in quality </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib1\" title=\"\">1</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib3\" title=\"\">3</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, shifting the research focus from simple naturalness toward enhancing controllability over speaker identity and speaking styles.\nThe pursuit of this controllability has evolved through several paradigms.\nControl paradigms include direct manipulation of acoustic features such as pitch, energy, and duration </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib2\" title=\"\">2</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib4\" title=\"\">4</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and ID-based methods for predefined speakers </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib3\" title=\"\">3</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib5\" title=\"\">5</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> or emotional classes </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib6\" title=\"\">6</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib7\" title=\"\">7</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nAnother prominent paradigm involves conditioning on audio exemplars or text descriptions, utilizing reference-based speaker encoders </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib8\" title=\"\">8</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib9\" title=\"\">9</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, unsupervised style transfer </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib10\" title=\"\">10</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, emotion synthesis with intensity control </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib11\" title=\"\">11</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib12\" title=\"\">12</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and the use of natural language prompts to describe prosodic styles </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib15\" title=\"\">15</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> as well as speaker characteristics </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib16\" title=\"\">16</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib17\" title=\"\">17</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nHowever, these existing approaches present a trade-off in controllability.\nWhile direct manipulation of acoustic features such as pitch and energy offers precision, it can be too granular and is difficult for humans to control effectively.\nConversely, other intuitive methods using IDs, reference audio, or text prompts typically lack mechanisms for fine-grained numerical adjustment.\n</span>\n</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "controllability"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">A key challenge, therefore, is to balance fine-grained control with human-understandable scales, which is crucial for practical applications.\nOne line of research attempts to discover controllable dimensions by analyzing the principal components of speaker embeddings </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib18\" title=\"\">18</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThis concept has been extended to generate artificial speaker embeddings, an approach that not only eliminates the need for a reference audio but also offers potential benefits for user privacy </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nIn contrast, another paradigm starts with explicitly defined perceptual dimensions for voice characteristics.\nOne approach uses perceptual voice qualities (e.g., roughness and breathiness), which are rated by phonetic experts based on clinical protocols </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib20\" title=\"\">20</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nAnother approach targets voice impressions (VI) such as calmness and brightness based on non-expert&#8217;s subjective impressions </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text\" style=\"font-size:90%;\">[</span><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib21\" title=\"\">21</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib22\" title=\"\">22</a><span class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which we focus in this paper.</span>\n</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "subjective"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">Voice Impression Control (VIC) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> pioneered the use of VI for controlling speaker characteristics in TTS.\nThe original VIC study established a set of 11 non-expert perceptual dimensions, validated their controllability in TTS, and linked these perceptual vectors with natural language (e.g., &#8220;sleepy&#8221;) via large language models.\nHowever, the study faces two key limitations.\nFirst, in the process of reimplementing the VIC, we observed the problem of impression leakage: despite being able to specify the reference audio and target VI independently, the synthesized voice is often undesirably biased toward the impression of the reference audio itself.\nSecond, no public annotated VI corpus is available, making follow-up studies and reproducible research difficult.</span>\n</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "controllability"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">This paper addresses these two challenges to advance research in VIC.\nWe propose two novel methods to mitigate impression leakage.\nThe first is a training strategy for disentangling speaker and impression information, which uses two separate utterances from the same speaker; one to provide the speaker identity and another for the target VI.\nThe second, inspired by the reference-free approach in </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib19\" title=\"\">19</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, generates pseudo speaker embeddings based solely on the target VI, providing both an architectural solution to the leakage and the practical advantages of synthesis without any reference audio.\nOur best method reduced the mean squared error (MSE) of 11-dimensional VI vectors from 0.61 to 0.41 objectively and from 1.15 to 0.92 subjectively, while maintaining high synthesis quality.\nMoreover, to promote reproducibility, we introduce LibriTTS-VI, the first public VI corpus built upon the LibriTTS-R dataset </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib24\" title=\"\">24</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.</span>\n</p>\n\n",
                "matched_terms": [
                    "best",
                    "speaker",
                    "mean",
                    "mse"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The process for creating the manual annotations is as follows.\nFirst, we created the set of 100 utterances to be annotated. This was done by randomly selecting 100 speakers from the LibriTTS-R training set and then choosing one random utterance from each speaker.\nTo guide the annotation, we established standards for the ten subjective VIs (all except K) Slow-Fast).\nThese standards included a written description of each VI and a reference audio sample from LibriTTS-R representing the neutral position.\nFollowing these standards, four annotators with professional experience in speech synthesis evaluation rated the 100 utterances on a seven-point Likert scale, yielding 400 independent annotations.\nThe remaining scale, K) Slow&#8211;Fast, was derived objectively by using a timestamped automatic speech recognition (ASR) model </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib27\" title=\"\">27</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> to calculate words per unit of time, and rescaling the values to a 1&#8211;7 range across the dataset.\nThe comprehensive annotation standards are included in our release.</span>\n</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "subjective",
                    "vis"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">For the objective evaluation, we measured speech intelligibility with character/word error rates (CER/WER) via Whisper large-v3 </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib37\" title=\"\">37</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, audio quality with UTMOS </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib38\" title=\"\">38</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, and speaker similarity with speaker encoder cosine similarity (SECS) </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib39\" title=\"\">39</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nTo assess controllability, we introduce two variants of VI-based MSE.\nLet </span>\n  <math alttext=\"\\mathbf{s}(\\mathbf{r},\\mathbf{v_{r}})\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m1\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mi mathsize=\"0.900em\">&#119852;</mi>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mi mathsize=\"0.900em\">&#119851;</mi>\n          <mo mathsize=\"0.900em\">,</mo>\n          <msub>\n            <mi mathsize=\"0.900em\">&#119855;</mi>\n            <mi mathsize=\"0.900em\">&#119851;</mi>\n          </msub>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">\\mathbf{s}(\\mathbf{r},\\mathbf{v_{r}})</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> denote the audio synthesized from the speech encoder&#8217;s reference </span>\n  <math alttext=\"\\mathbf{r}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m2\" intent=\":literal\">\n    <semantics>\n      <mi mathsize=\"0.900em\">&#119851;</mi>\n      <annotation encoding=\"application/x-tex\">\\mathbf{r}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> with its VI vector </span>\n  <math alttext=\"\\mathbf{v_{r}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m3\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#119855;</mi>\n        <mi mathsize=\"0.900em\">&#119851;</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\mathbf{v_{r}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThe standard VI-MSE measures the MSE of </span>\n  <math alttext=\"\\mathbf{v_{r}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m4\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#119855;</mi>\n        <mi mathsize=\"0.900em\">&#119851;</mi>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\mathbf{v_{r}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and </span>\n  <math alttext=\"\\text{VIE}(\\mathbf{s}(\\mathbf{r},\\mathbf{v_{r}}))\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m5\" intent=\":literal\">\n    <semantics>\n      <mrow>\n        <mtext mathsize=\"0.900em\">VIE</mtext>\n        <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n        <mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n          <mrow>\n            <mi mathsize=\"0.900em\">&#119852;</mi>\n            <mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo>\n            <mrow>\n              <mo maxsize=\"0.900em\" minsize=\"0.900em\">(</mo>\n              <mi mathsize=\"0.900em\">&#119851;</mi>\n              <mo mathsize=\"0.900em\">,</mo>\n              <msub>\n                <mi mathsize=\"0.900em\">&#119855;</mi>\n                <mi mathsize=\"0.900em\">&#119851;</mi>\n              </msub>\n              <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n            </mrow>\n          </mrow>\n          <mo maxsize=\"0.900em\" minsize=\"0.900em\">)</mo>\n        </mrow>\n      </mrow>\n      <annotation encoding=\"application/x-tex\">\\text{VIE}(\\mathbf{s}(\\mathbf{r},\\mathbf{v_{r}}))</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nIn contrast, RVI-MSE is calculated with the target VI </span>\n  <math alttext=\"\\mathbf{v}_{*}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m6\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#119855;</mi>\n        <mo mathsize=\"0.900em\">&#8727;</mo>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\mathbf{v}_{*}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, which is sourced from a random, unrelated utterance </span>\n  <math alttext=\"\\mathbf{r}_{*}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m7\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\">&#119851;</mi>\n        <mo mathsize=\"0.900em\">&#8727;</mo>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\mathbf{r}_{*}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">:</span>\n</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "controllability",
                    "mse"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">The full results are listed in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T4\" style=\"font-size:90%;\" title=\"Table 4 &#8227; 4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nAll systems achieved high speech intelligibility (CERs/WERs) and audio quality (UTMOS), confirming that our methods do not degrade synthesis quality.\nFor speaker similarity (SECS), the reference-based VIC-base and VIC-sep achieved high scores (0.84 and 0.82).\nOn the other hand, VIC-rfg&#8217;s score was noticeably lower (0.76), reflecting the expected trade-off of its reference-free design in reconstructing speaker identity.\nNext, we analyzed VI controllability and impression leakage.\nWhile the VI-MSE scores show only a slight improvement in control precision for the proposed methods (0.37 for VIC-sep, 0.36 for VIC-rfg) compared to the baseline (0.39), the impression leakage gap, </span>\n  <math alttext=\"\\Delta_{\\text{V}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n        <mtext mathsize=\"0.900em\">V</mtext>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\Delta_{\\text{V}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, reveals a more significant difference.\nThe baseline exhibits a large gap (</span>\n  <math alttext=\"\\Delta_{\\text{V}}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m2\" intent=\":literal\">\n    <semantics>\n      <msub>\n        <mi mathsize=\"0.900em\" mathvariant=\"normal\">&#916;</mi>\n        <mtext mathsize=\"0.900em\">V</mtext>\n      </msub>\n      <annotation encoding=\"application/x-tex\">\\Delta_{\\text{V}}</annotation>\n    </semantics>\n  </math>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">) of 0.22.\nIn contrast, our proposed methods narrow this gap to 0.14 for VIC-sep and a minimal 0.05 for VIC-rfg, demonstrating their superior robustness against impression leakage.</span>\n</p>\n\n",
                "matched_terms": [
                    "speaker",
                    "controllability",
                    "results"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">To further probe control precision, we conducted a modulation experiment, following </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nFor each of the 39 unseen speakers in the test-clean set, we modulated each VI dimension of an anchor VI vector from -3 to +3, synthesized 50 sentences per condition, and predicted the VI using our VIE.\nWe then quantified the fidelity of VI control via the slope of the linear fit between target and predicted VIs, where a larger positive slope indicates more responsive control in the intended direction.\nAs shown in Table </span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T4\" style=\"font-size:90%;\" title=\"Table 4 &#8227; 4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, while the slopes were generally mild, they were consistently positive for all dimensions except for E) Powerful-Weak, which was not learned effectively by any system.\nAmong the systems, the average slope consistently increased from VIC-base (0.096) to VIC-sep (0.135), and finally to VIC-rfg (0.177), offering the most responsive control.</span>\n</p>\n\n",
                "matched_terms": [
                    "condition",
                    "vis"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">\n  <span class=\"ltx_text\" style=\"font-size:90%;\">We conducted subjective evaluations for both controllability and audio quality under two distinct VI modulation conditions: single VI modulation and multiple VI modulation.\nFor the single VI modulation, we followed the evaluation in the original VIC study </span>\n  <cite class=\"ltx_cite ltx_citemacro_cite\">\n    <span class=\"ltx_text\" style=\"font-size:90%;\">[</span>\n    <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#bib.bib23\" title=\"\">23</a>\n    <span class=\"ltx_text\" style=\"font-size:90%;\">]</span>\n  </cite>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nSpecifically, we evaluated four representative VIs: A) Low-High</span>\n  <span class=\"ltx_note ltx_role_footnote\" id=\"footnote4\">\n    <sup class=\"ltx_note_mark\">4</sup>\n    <span class=\"ltx_note_outer\">\n      <span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">4</sup><span class=\"ltx_tag ltx_tag_note\">4</span>We replaced the Powerful-Weak dimension from the original VIC study with Low-High, as our models struggled to learn the former (see Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T4\" title=\"Table 4 &#8227; 4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>).</span>\n    </span>\n  </span>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">, B) Masculine-Feminine, F) Youthful-Aged, and I) Dark-Bright.\nWe used the same audio generated for the VI modulation experiment described in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.SS2\" style=\"font-size:90%;\" title=\"4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T4\" style=\"font-size:90%;\" title=\"Table 4 &#8227; 4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nThe multiple VI modulation was designed to assess how synthesis quality is affected by the simultaneous modulation of multiple VIs.\nWe used the same generated audio from the RVI-MSE evaluation described in Sec.&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.SS2\" style=\"font-size:90%;\" title=\"4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4.2</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\"> and Table&#160;</span>\n  <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.15626v1#S4.T4\" style=\"font-size:90%;\" title=\"Table 4 &#8227; 4.2 Objective Evaluation &#8227; 4 Experiments &#8227; LibriTTS-VI: A Public Corpus and Novel Methods for Efficient Voice Impression Control\">\n    <span class=\"ltx_text ltx_ref_tag\">4</span>\n  </a>\n  <span class=\"ltx_text\" style=\"font-size:90%;\">.\nWe focused on two speakers (ID 1089 and ID 8555) and report only the results for speaker 8555 due to similar trends and space limitations.\n</span>\n</p>\n\n",
                "matched_terms": [
                    "multiple",
                    "speaker",
                    "vis",
                    "results",
                    "subjective",
                    "controllability"
                ]
            }
        ]
    }
}