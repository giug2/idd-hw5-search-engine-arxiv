{
    "S2.T1": {
        "caption": "Table 1: Performance on the AudioCaps test set. Scheme indicates the reward strategy. ğ–¢\\mathsf{C} and ğ–¯\\mathsf{P} indicate the CLAP and PQ rewards, respectively. AQA denotes AQAScore. Î±\\alpha is the combination weight in SCORE. â†‘\\uparrow higher is better; â†“\\downarrow lower is better.",
        "body": "<table class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Methods</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Scheme</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\" rowspan=\"2\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Setup</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Generation quality</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Text-Consistency</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Audiobox-Aesthetics</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">FD </span><math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m11\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">IS </span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m12\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">CLAP </span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m13\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">AQA (%) </span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m14\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">PQ </span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m15\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">CU </span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m16\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">CE </span><math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m17\" intent=\":literal\"><semantics><mo mathsize=\"0.900em\" stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Naive sampling</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">18.87</span><math alttext=\"\\pm 0.37\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m18\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.37</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.37</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">11.32</span><math alttext=\"\\pm 0.24\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m19\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.24</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.24</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">0.65</span><math alttext=\"\\pm 0.04\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m20\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.04</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.04</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">90.05</span><math alttext=\"\\pm 0.47\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m21\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.47</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.47</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">5.73</span><math alttext=\"\\pm 0.24\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m22\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.24</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.24</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">5.02</span><math alttext=\"\\pm 0.21\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m23\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.21</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.21</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">3.51</span><math alttext=\"\\pm 0.12\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m24\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.12</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.12</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"4\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Best-of-N</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Single reward</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><math alttext=\"\\mathsf{C}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m25\" intent=\":literal\"><semantics><mi mathsize=\"0.900em\">&#120226;</mi><annotation encoding=\"application/x-tex\">\\mathsf{C}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">15.75</span><math alttext=\"\\pm 0.55\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m26\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.55</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.55</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">11.63</span><math alttext=\"\\pm 0.14\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m27\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.14</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.14</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">0.72</span><math alttext=\"\\pm 0.01\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m28\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.01</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">91.57</span><math alttext=\"\\pm 1.36\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m29\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">1.36</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 1.36</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">5.81</span><math alttext=\"\\pm 0.01\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m30\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.01</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">5.07</span><math alttext=\"\\pm 0.02\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m31\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.02</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.02</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">3.65</span><math alttext=\"\\pm 0.03\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m32\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.03</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.03</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Single reward</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><math alttext=\"\\mathsf{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m33\" intent=\":literal\"><semantics><mi mathsize=\"0.900em\">&#120239;</mi><annotation encoding=\"application/x-tex\">\\mathsf{P}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">17.74</span><math alttext=\"\\pm 0.78\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m34\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.78</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.78</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">11.71</span><math alttext=\"\\pm 0.22\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m35\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.22</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.22</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">0.67</span><math alttext=\"\\pm 0.01\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m36\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.01</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">89.49</span><math alttext=\"\\pm 0.45\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m37\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.45</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.45</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">6.32</span><math alttext=\"\\pm 0.02\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m38\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.02</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.02</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">5.55</span><math alttext=\"\\pm 0.05\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m39\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.05</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.05</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">3.84</span><math alttext=\"\\pm 0.02\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m40\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.02</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.02</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Rank aggregation</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><math alttext=\"\\mathsf{C}+\\mathsf{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m41\" intent=\":literal\"><semantics><mrow><mi mathsize=\"0.900em\">&#120226;</mi><mo mathsize=\"0.900em\">+</mo><mi mathsize=\"0.900em\">&#120239;</mi></mrow><annotation encoding=\"application/x-tex\">\\mathsf{C}+\\mathsf{P}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">16.89</span><math alttext=\"\\pm 0.75\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m42\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.75</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.75</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">11.85</span><math alttext=\"\\pm 0.08\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m43\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.08</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.08</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">0.70</span><math alttext=\"\\pm 0.02\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m44\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.02</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.02</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">91.11</span><math alttext=\"\\pm 0.75\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m45\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.75</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.75</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">6.21</span><math alttext=\"\\pm 0.01\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m46\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.01</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">5.45</span><math alttext=\"\\pm 0.08\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m47\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.08</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.08</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">3.81</span><math alttext=\"\\pm 0.03\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m48\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.03</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.03</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">SCORE (</span><math alttext=\"\\alpha{=}0.50\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m49\" intent=\":literal\"><semantics><mrow><mi mathsize=\"0.900em\">&#945;</mi><mo mathsize=\"0.900em\">=</mo><mn mathsize=\"0.900em\">0.50</mn></mrow><annotation encoding=\"application/x-tex\">\\alpha{=}0.50</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\">)</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><math alttext=\"\\mathsf{C}+\\mathsf{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m50\" intent=\":literal\"><semantics><mrow><mi mathsize=\"0.900em\">&#120226;</mi><mo mathsize=\"0.900em\">+</mo><mi mathsize=\"0.900em\">&#120239;</mi></mrow><annotation encoding=\"application/x-tex\">\\mathsf{C}+\\mathsf{P}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">17.24</span><math alttext=\"\\pm 0.63\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m51\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.63</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.63</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">11.86</span><math alttext=\"\\pm 0.13\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m52\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.13</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.13</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">0.71</span><math alttext=\"\\pm 0.01\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m53\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.01</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">91.43</span><math alttext=\"\\pm 0.24\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m54\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.24</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.24</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">6.21</span><math alttext=\"\\pm 0.02\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m55\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.02</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.02</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">5.44</span><math alttext=\"\\pm 0.04\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m56\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.04</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.04</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">3.81</span><math alttext=\"\\pm 0.03\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m57\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.03</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.03</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" rowspan=\"4\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Evosearch</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text\" style=\"font-size:90%;\">Rank aggregation</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><math alttext=\"\\mathsf{C}+\\mathsf{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m58\" intent=\":literal\"><semantics><mrow><mi mathsize=\"0.900em\">&#120226;</mi><mo mathsize=\"0.900em\">+</mo><mi mathsize=\"0.900em\">&#120239;</mi></mrow><annotation encoding=\"application/x-tex\">\\mathsf{C}+\\mathsf{P}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">15.92</span><math alttext=\"\\pm 0.30\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m59\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.30</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.30</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">12.03</span><math alttext=\"\\pm 0.12\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m60\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.12</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.12</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">0.71</span><math alttext=\"\\pm 0.00\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m61\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.00</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.00</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">91.23</span><math alttext=\"\\pm 0.52\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m62\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.52</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.52</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">6.16</span><math alttext=\"\\pm 0.06\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m63\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.06</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.06</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">5.35</span><math alttext=\"\\pm 0.05\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m64\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.05</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.05</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">3.73</span><math alttext=\"\\pm 0.02\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m65\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.02</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.02</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">SCORE (</span><math alttext=\"\\alpha{=}0.50\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m66\" intent=\":literal\"><semantics><mrow><mi mathsize=\"0.900em\">&#945;</mi><mo mathsize=\"0.900em\">=</mo><mn mathsize=\"0.900em\">0.50</mn></mrow><annotation encoding=\"application/x-tex\">\\alpha{=}0.50</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\">)</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><math alttext=\"\\mathsf{C}+\\mathsf{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m67\" intent=\":literal\"><semantics><mrow><mi mathsize=\"0.900em\">&#120226;</mi><mo mathsize=\"0.900em\">+</mo><mi mathsize=\"0.900em\">&#120239;</mi></mrow><annotation encoding=\"application/x-tex\">\\mathsf{C}+\\mathsf{P}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">15.75</span><math alttext=\"\\pm 0.40\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m68\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.40</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.40</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">11.93</span><math alttext=\"\\pm 0.21\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m69\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.21</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.21</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">0.72</span><math alttext=\"\\pm 0.00\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m70\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.00</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.00</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">91.63</span><math alttext=\"\\pm 0.53\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m71\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.53</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.53</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"font-size:90%;\">6.34</span><math alttext=\"\\pm 0.02\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m72\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.02</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.02</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">5.53</span><math alttext=\"\\pm 0.01\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m73\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.01</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">3.82</span><math alttext=\"\\pm 0.01\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m74\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.01</annotation></semantics></math>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">SCORE (</span><math alttext=\"\\alpha{=}0.25\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m75\" intent=\":literal\"><semantics><mrow><mi mathsize=\"0.900em\">&#945;</mi><mo mathsize=\"0.900em\">=</mo><mn mathsize=\"0.900em\">0.25</mn></mrow><annotation encoding=\"application/x-tex\">\\alpha{=}0.25</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\">)</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><math alttext=\"\\mathsf{C}+\\mathsf{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m76\" intent=\":literal\"><semantics><mrow><mi mathsize=\"0.900em\">&#120226;</mi><mo mathsize=\"0.900em\">+</mo><mi mathsize=\"0.900em\">&#120239;</mi></mrow><annotation encoding=\"application/x-tex\">\\mathsf{C}+\\mathsf{P}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">16.54</span><math alttext=\"\\pm 0.10\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m77\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.10</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.10</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">12.04<math alttext=\"\\pm 0.30\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m78\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.780em\">&#177;</mo><mn mathsize=\"0.780em\">0.30</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.30</annotation></semantics></math></span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">0.69</span><math alttext=\"\\pm 0.00\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m79\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.00</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.00</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">90.61</span><math alttext=\"\\pm 0.40\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m80\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.40</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.40</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">6.47<math alttext=\"\\pm 0.02\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m81\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.780em\">&#177;</mo><mn mathsize=\"0.780em\">0.02</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.02</annotation></semantics></math></span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">5.66<math alttext=\"\\pm 0.01\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m82\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.780em\">&#177;</mo><mn mathsize=\"0.780em\">0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.01</annotation></semantics></math></span></td>\n<td class=\"ltx_td ltx_align_center\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.86<math alttext=\"\\pm 0.01\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m83\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.780em\">&#177;</mo><mn mathsize=\"0.780em\">0.01</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.01</annotation></semantics></math></span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">SCORE (</span><math alttext=\"\\alpha{=}0.75\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m84\" intent=\":literal\"><semantics><mrow><mi mathsize=\"0.900em\">&#945;</mi><mo mathsize=\"0.900em\">=</mo><mn mathsize=\"0.900em\">0.75</mn></mrow><annotation encoding=\"application/x-tex\">\\alpha{=}0.75</annotation></semantics></math><span class=\"ltx_text\" style=\"font-size:90%;\">)</span>\n</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><math alttext=\"\\mathsf{C}+\\mathsf{P}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m85\" intent=\":literal\"><semantics><mrow><mi mathsize=\"0.900em\">&#120226;</mi><mo mathsize=\"0.900em\">+</mo><mi mathsize=\"0.900em\">&#120239;</mi></mrow><annotation encoding=\"application/x-tex\">\\mathsf{C}+\\mathsf{P}</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">15.16<math alttext=\"\\pm 0.26\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m86\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.780em\">&#177;</mo><mn mathsize=\"0.780em\">0.26</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.26</annotation></semantics></math></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">11.86</span><math alttext=\"\\pm 0.26\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m87\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.26</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.26</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.74<math alttext=\"\\pm 0.00\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m88\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.780em\">&#177;</mo><mn mathsize=\"0.780em\">0.00</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.00</annotation></semantics></math></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:5.5pt;padding-right:5.5pt;\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">92.35<math alttext=\"\\pm 0.63\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m89\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.780em\">&#177;</mo><mn mathsize=\"0.780em\">0.63</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.63</annotation></semantics></math></span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">6.09</span><math alttext=\"\\pm 0.04\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m90\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.04</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.04</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">5.29</span><math alttext=\"\\pm 0.04\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m91\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.04</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.04</annotation></semantics></math>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:5.5pt;padding-right:5.5pt;\">\n<span class=\"ltx_text\" style=\"font-size:90%;\">3.70</span><math alttext=\"\\pm 0.02\" class=\"ltx_Math\" display=\"inline\" id=\"S2.T1.m92\" intent=\":literal\"><semantics><mrow><mo mathsize=\"0.700em\">&#177;</mo><mn mathsize=\"0.700em\">0.02</mn></mrow><annotation encoding=\"application/x-tex\">\\pm 0.02</annotation></semantics></math>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "ğ–¢mathsfc",
            "382Â±001pm",
            "9111Â±075pm",
            "combination",
            "scheme",
            "1516Â±026pm",
            "074Â±000pm",
            "065Â±004pm",
            "ğ–¢ğ–¯mathsfcmathsfp",
            "545Â±008pm",
            "higher",
            "621Â±001pm",
            "lower",
            "1774Â±078pm",
            "ğ–¯mathsfp",
            "581Â±001pm",
            "507Â±002pm",
            "rank",
            "aggregation",
            "1204Â±030pm",
            "audiocaps",
            "1185Â±008pm",
            "denotes",
            "573Â±024pm",
            "1186Â±013pm",
            "502Â±021pm",
            "aqa",
            "9061Â±040pm",
            "609Â±004pm",
            "Î±050alpha050",
            "1163Â±014pm",
            "071Â±000pm",
            "generation",
            "351Â±012pm",
            "8949Â±045pm",
            "audioboxaesthetics",
            "Î±075alpha075",
            "072Â±000pm",
            "067Â±001pm",
            "indicates",
            "070Â±002pm",
            "370Â±002pm",
            "respectively",
            "069Â±000pm",
            "1203Â±012pm",
            "better",
            "1132Â±024pm",
            "553Â±001pm",
            "setup",
            "strategy",
            "1575Â±055pm",
            "647Â±002pm",
            "529Â±004pm",
            "072Â±001pm",
            "â†“downarrow",
            "Î±alpha",
            "sampling",
            "555Â±005pm",
            "Î±025alpha025",
            "test",
            "methods",
            "621Â±002pm",
            "rewards",
            "9157Â±136pm",
            "performance",
            "1887Â±037pm",
            "reward",
            "naive",
            "1689Â±075pm",
            "9123Â±052pm",
            "weight",
            "set",
            "textconsistency",
            "score",
            "â†‘uparrow",
            "9005Â±047pm",
            "bestofn",
            "aqascore",
            "9143Â±024pm",
            "544Â±004pm",
            "616Â±006pm",
            "9163Â±053pm",
            "566Â±001pm",
            "634Â±002pm",
            "1575Â±040pm",
            "1171Â±022pm",
            "365Â±003pm",
            "single",
            "evosearch",
            "381Â±003pm",
            "373Â±002pm",
            "9235Â±063pm",
            "1186Â±026pm",
            "indicate",
            "clap",
            "535Â±005pm",
            "1654Â±010pm",
            "386Â±001pm",
            "1592Â±030pm",
            "1193Â±021pm",
            "632Â±002pm",
            "071Â±001pm",
            "1724Â±063pm",
            "384Â±002pm",
            "quality"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Limitations on Single-Objective Guidance.</span>\nWe first compare the performance of different rewarding schemes with BON method. As shown in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#S2.T1\" title=\"Table 1 &#8227; 2 Method &#8227; SCORE: Scaling audio generation using Standardized COmposite REwards\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, ITS utilizing a single reward model shows a clear trade-off across different quality attributes.\nCompared to naive sampling, using the CLAP model as a reward improves the CLAP score by <math alttext=\"10.8\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m1\" intent=\":literal\"><semantics><mrow><mn>10.8</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">10.8\\%</annotation></semantics></math> but increases the PQ score by only <math alttext=\"1.4\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m2\" intent=\":literal\"><semantics><mrow><mn>1.4</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">1.4\\%</annotation></semantics></math>.\nOn the other hand, using the PQ model as a single reward improves all Audiobox-Aesthetics metrics by approximately <math alttext=\"10\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m3\" intent=\":literal\"><semantics><mrow><mn>10</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">10\\%</annotation></semantics></math>, but marginally improves CLAP metric by <math alttext=\"3\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m4\" intent=\":literal\"><semantics><mrow><mn>3</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">3\\%</annotation></semantics></math>.\nThis clearly shows the over-reliance on a single reward model, and the issue is effectively addressed by utilizing multiple reward models.\nUsing rank aggregation and the proposed SCORE, the generation not only improves both CLAP by <math alttext=\"9.2\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m5\" intent=\":literal\"><semantics><mrow><mn>9.2</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">9.2\\%</annotation></semantics></math> and PQ by <math alttext=\"8.4\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p1.m6\" intent=\":literal\"><semantics><mrow><mn>8.4</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">8.4\\%</annotation></semantics></math>, but also clearly enhances all other metrics.\nThis demonstrates that &#8220;verifier hacking&#8221; can be effectively addressed with multiple reward models.</p>\n\n",
            "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Effectiveness of Standardized Composite Reward.</span>\nThe effect of the proposed SCORE is more pronounced in Evosearch framework.\nAs detailed in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#S2.T1\" title=\"Table 1 &#8227; 2 Method &#8227; SCORE: Scaling audio generation using Standardized COmposite REwards\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, SCORE with equal weights on the two reward models (<math alttext=\"\\alpha=0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m1\" intent=\":literal\"><semantics><mrow><mi>&#945;</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\alpha=0.5</annotation></semantics></math>) improves CLAP by <math alttext=\"10.8\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m2\" intent=\":literal\"><semantics><mrow><mn>10.8</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">10.8\\%</annotation></semantics></math> and PQ by <math alttext=\"10.6\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m3\" intent=\":literal\"><semantics><mrow><mn>10.6</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">10.6\\%</annotation></semantics></math> over naive sampling.\nMoreover, the improvement is demonstrated beyond the scope of the rewards, resulting in <math alttext=\"10.2\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m4\" intent=\":literal\"><semantics><mrow><mn>10.2</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">10.2\\%</annotation></semantics></math> relative increase in CU and <math alttext=\"8.8\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS1.p2.m5\" intent=\":literal\"><semantics><mrow><mn>8.8</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">8.8\\%</annotation></semantics></math> in CE.\nWe verify the advantage of our method against existing rank aggregation by consistently outperforming it across all evaluation metrics.\nThis is attributed to the utilization of full-precision scores, which provides more granular guidance than simple ordinal ranking.\nThe influence of SCORE is diminished in BON framework since the method can only be applied once at the last selection stage.\nWe note that SCORE is more effective in frameworks similar to EvoSearch because the iterative refinement of intermediate latents can provide strong positive guidance towards multiple aspects of audio.</p>\n\n",
            "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Effectiveness of Combination Weight.</span> \nWe further investigate the effect of the combination weight <math alttext=\"\\alpha\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m1\" intent=\":literal\"><semantics><mi>&#945;</mi><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math> in the generation process, and demonstrate that it enables an intuitive control over inference towards desired attributes.\nAs shown in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#S2.T1\" title=\"Table 1 &#8227; 2 Method &#8227; SCORE: Scaling audio generation using Standardized COmposite REwards\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, setting <math alttext=\"\\alpha=0.25\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m2\" intent=\":literal\"><semantics><mrow><mi>&#945;</mi><mo>=</mo><mn>0.25</mn></mrow><annotation encoding=\"application/x-tex\">\\alpha=0.25</annotation></semantics></math> to prioritize audio quality significantly boosts all quality-related metrics (PQ, CU, CE) at only a slight expense to textual alignment.\nConversely, prioritizing text alignment by setting <math alttext=\"\\alpha=0.75\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m3\" intent=\":literal\"><semantics><mrow><mi>&#945;</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding=\"application/x-tex\">\\alpha=0.75</annotation></semantics></math> achieves the highest CLAP score among all methods, while the PQ score remains highly competitive, successfully avoiding the quality collapse observed in the single-objective case.\nFinally, a balanced weight of <math alttext=\"\\alpha=0.5\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p1.m4\" intent=\":literal\"><semantics><mrow><mi>&#945;</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">\\alpha=0.5</annotation></semantics></math> produces a faithful equilibrium between the two objectives, as demonstrated by its strong performance across all metrics.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">The goal of this paper is to enhance Text-to-Audio generation at inference, focusing on generating realistic audio that precisely aligns with text prompts.\nDespite the rapid advancements, existing models often fail to achieve a reliable balance between perceptual quality and textual alignment.\nTo address this, we adopt Inference-Time Scaling, a training-free method that improves performance by increasing inference computation.\nWe establish its unexplored application to audio generation and propose a novel multi-reward guidance that equally signifies each component essential in perception.\nBy normalizing each reward value into a common scale and combining them with a weighted summation, the method not only enforces stable guidance but also enables explicit control to reach desired aspects.\nMoreover, we introduce a new audio-text alignment metric using an audio language model for more robust evaluation.\nEmpirically, our method improves both semantic alignment and perceptual quality, significantly outperforming naive generation and existing reward guidance techniques.\nSynthesized samples are available on our demo page: <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://mm.kaist.ac.kr/projects/score/\" title=\"\">https://mm.kaist.ac.kr/projects/score/</a></p>\n\n",
                "matched_terms": [
                    "reward",
                    "naive",
                    "generation",
                    "performance",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">However, even advanced T2A models often fail to reliably satisfy the two key aspects: audio-text alignment and perceptual quality. This issue is particularly pronounced for diffusion models due to their stochastic nature in the generation process.\nDiffusion-based T2A models generate audio by iteratively denoising a random noise vector, resulting in high output variance for a single prompt.\nThis variance, while beneficial for creative diversity, significantly hinders the ability to reliably generate a specific, desired sound.</p>\n\n",
                "matched_terms": [
                    "generation",
                    "single",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">A promising, training-free solution is Inference-Time Scaling (ITS), which allocates additional computation at inference to guide the generation towards superior outputs, such as higher sample quality and alignment with text&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib11\" title=\"\">11</a>]</cite>.\nMany approaches have introduced different ITS techniques, including Best-of-N (BON) selection&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib12\" title=\"\">12</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib13\" title=\"\">13</a>]</cite>, reward-guided particle sampling&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib14\" title=\"\">14</a>]</cite>, and evolutionary search (EvoSearch)&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib15\" title=\"\">15</a>]</cite>, all of which effectively improve the output of a naive generation with increased inference computation.\nHowever, while the method was first explored in large language models&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib16\" title=\"\">16</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib17\" title=\"\">17</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib18\" title=\"\">18</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib19\" title=\"\">19</a>]</cite> and extended to image and video domains&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib20\" title=\"\">20</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib12\" title=\"\">12</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib21\" title=\"\">21</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib22\" title=\"\">22</a>]</cite>, its application to audio generation is yet to be discovered.\nMoreover, most methods provide limited advancements in reward guidance, a crucial component that guides the overall ITS process.\nMost existing methods leverage a single reward model as guidance which introduces &#8220;verifier hacking&#8221;, a decrease in performance due to over-reliance on a single objective&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib11\" title=\"\">11</a>]</cite>.\nOthers utilize an aggregation of multiple rewards by converting different values into ranks&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib11\" title=\"\">11</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib23\" title=\"\">23</a>]</cite>, but treating criteria with equal importance under-utilizes the complementary strengths of distinct rewards.</p>\n\n",
                "matched_terms": [
                    "aggregation",
                    "sampling",
                    "single",
                    "reward",
                    "naive",
                    "bestofn",
                    "generation",
                    "higher",
                    "methods",
                    "quality",
                    "evosearch",
                    "rewards",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we pioneer the application of ITS to T2A generation and conduct comprehensive empirical study of different methods in this domain.\nFurthermore, to address the limitations of prior techniques that rely on single rewards or rank aggregation, we propose Standardized Composite Reward (SCORE), a novel reward guidance designed to effectively configure and balance two rewards specifically for T2A tasks: audio quality and audio-text alignment.\nSpecifically, we normalize each reward with zero mean and unit variance to establish equal influence, and combine them with weighted summation where the weight can be controlled to effectively steer the generation to achieve desired aspect.\nMoreover, we assess the text-audio alignment beyond the scope of the reward model by introducing AQAScore, an evaluation metric based on audio language model Audio Flamingo 3&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib24\" title=\"\">24</a>]</cite>.\nMotivated by VQAScore&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib25\" title=\"\">25</a>]</cite>, we ask the model with the generated audio and its text prompt and obtain the probability of producing &#8220;yes&#8221; token, serving as a quantitative measure of alignment.</p>\n\n",
                "matched_terms": [
                    "score",
                    "aggregation",
                    "rank",
                    "reward",
                    "generation",
                    "aqascore",
                    "methods",
                    "quality",
                    "single",
                    "rewards",
                    "weight"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Our experiments demonstrate that SCORE significantly enhances the generation quality of T2A model compared to naive generation, improving both CLAP and PQ metric by <math alttext=\"11\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p5.m1\" intent=\":literal\"><semantics><mrow><mn>11</mn><mo>%</mo></mrow><annotation encoding=\"application/x-tex\">11\\%</annotation></semantics></math>.\nWe further verify that SCORE effectively avoids &#8220;verifier hacking&#8221; and outperforms existing rank aggregation method in both audio-text alignment and audio quality.\nFinally, we show that the generation quality faithfully reflects the adjustment of combination weights, offering a principled approach to prioritize specific attributes of interest.</p>\n\n",
                "matched_terms": [
                    "combination",
                    "score",
                    "aggregation",
                    "clap",
                    "rank",
                    "naive",
                    "generation",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We augment T2A generation with established ITS methods: BON&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib11\" title=\"\">11</a>]</cite> and EvoSearch&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib15\" title=\"\">15</a>]</cite>.\nBoth methods initialize multiple noise latents to denoise, and select the best performing sample from the finally produced audios.\nTo successfully evaluate the samples, they utilize pretrained audio evaluation models as reward models and obtain the reward values.\nAs shown in Fig.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; SCORE: Scaling audio generation using Standardized COmposite REwards\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, while BON applies reward guidance only at the end, EvoSearch enforces additional guidance the intermediate denoising stages.\nSpecifically, when diffusion timesteps lie in predefined evolution steps <math alttext=\"\\mathcal{T}_{evo}=\\{t_{1},\\dots,t_{j},\\dots,t_{k}\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p1.m1\" intent=\":literal\"><semantics><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><mrow><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>v</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>t</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><msub><mi>t</mi><mi>j</mi></msub><mo>,</mo><mi mathvariant=\"normal\">&#8230;</mi><mo>,</mo><msub><mi>t</mi><mi>k</mi></msub><mo stretchy=\"false\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{T}_{evo}=\\{t_{1},\\dots,t_{j},\\dots,t_{k}\\}</annotation></semantics></math>, the intermediate latents are decoded to audio and fed to reward models for evaluation.\nBased on the obtained rewards, high-performing &#8220;elite&#8221; latents are selected and copied with a slight mutation to replace the rejected ones.\nThis mutation involves adding subtle noise to the latents, increasing the diversity while preserving the core quality.\nThe evolution process (evaluation, selection, and mutation) occurs in every evolution step in <math alttext=\"\\mathcal{T}_{evo}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p1.m2\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><mrow><mi>e</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>v</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>o</mi></mrow></msub><annotation encoding=\"application/x-tex\">\\mathcal{T}_{evo}</annotation></semantics></math> to iteratively refine the latent candidates, and the final best audio is selected identical to BON.\nAs EvoSearch utilizes reward models more frequently and applies guidance in the middle of denoising, the method can provide more distinct effect of reward guidance than BON sampling.</p>\n\n",
                "matched_terms": [
                    "sampling",
                    "reward",
                    "generation",
                    "methods",
                    "evosearch",
                    "rewards",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">As mentioned earlier, guiding inference with a single reward leads to &#8220;verifier hacking,&#8221; causing the generation to over-adapt to the reward and fail to achieve high overall quality&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib11\" title=\"\">11</a>]</cite>.\nTo this end, the objective of the proposed method covers two aspects of audio generation: audio-text alignment and high-quality generation.\nWe select the CLAP&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib26\" title=\"\">26</a>]</cite> score as a reward for audio-text alignment, and PQ from Audiobox-Aesthetics&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib27\" title=\"\">27</a>]</cite> for general audio quality.\nHowever, utilizing multiple reward models poses a critical challenge, because each signal originates from a unique distribution.\nFor instance, the CLAP score ranges from 0 to 1, whereas the PQ score ranges from 0 to 10, with a high concentration of values around 5 to 7&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib27\" title=\"\">27</a>]</cite>.\nThis mismatch in distribution can easily bias the reward guidance.\nTherefore, we normalize each distribution to provide equal influence for each reward, which is further elaborated in the next section.</p>\n\n",
                "matched_terms": [
                    "score",
                    "clap",
                    "reward",
                    "generation",
                    "audioboxaesthetics",
                    "single",
                    "quality"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Existing methods mitigate imbalances across different scales to minimize bias by converting the reward values into ranks&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib11\" title=\"\">11</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib28\" title=\"\">28</a>]</cite> or by applying a weighted summation&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib29\" title=\"\">29</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib30\" title=\"\">30</a>]</cite>.\nIn this work, we aim to eliminate the need for a heuristic weight search while utilizing the full-precision values of the rewards, rather than their ranks.\nAs illustrated in Fig&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#S2.F2\" title=\"Figure 2 &#8227; 2.1 Inference-Time Scaling &#8227; 2 Method &#8227; SCORE: Scaling audio generation using Standardized COmposite REwards\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, even when different reward scores are normalized to the same range, their underlying distributions can differ significantly.\nThis distributional mismatch can disturb the combined reward guidance, necessitating a heuristic search for appropriate weights to counteract this effect.</p>\n\n",
                "matched_terms": [
                    "reward",
                    "rewards",
                    "weight",
                    "methods"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address this, we propose Standardized Composite Reward (SCORE), a method that combines each reward signal by normalizing to a zero mean and unit variance, followed by a weighted summation.\nThis process ensures that multiple reward values can be combined without bias from disparate scales or distributions, and the weight parameter enables the controllability to shift the direction of generation.\nSpecifically, we first obtain the raw reward scores using each reward model at evolution timestep <math alttext=\"t_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m1\" intent=\":literal\"><semantics><msub><mi>t</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">t_{i}</annotation></semantics></math>\nFollowing EvoSearch, raw reward score is defined as:</p>\n\n",
                "matched_terms": [
                    "score",
                    "reward",
                    "generation",
                    "evosearch",
                    "weight"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where <math alttext=\"x_{0}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m2\" intent=\":literal\"><semantics><msub><mi>x</mi><mn>0</mn></msub><annotation encoding=\"application/x-tex\">x_{0}</annotation></semantics></math> is the denoised audio from intermediate latent <math alttext=\"x_{t_{i}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m3\" intent=\":literal\"><semantics><msub><mi>x</mi><msub><mi>t</mi><mi>i</mi></msub></msub><annotation encoding=\"application/x-tex\">x_{t_{i}}</annotation></semantics></math> and <math alttext=\"r(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m4\" intent=\":literal\"><semantics><mrow><mi>r</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">r(\\cdot)</annotation></semantics></math> is the reward function.\nNext, we normalize the raw score using the mean (<math alttext=\"\\mu\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m5\" intent=\":literal\"><semantics><mi>&#956;</mi><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math>) and standard deviation (<math alttext=\"\\sigma\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m6\" intent=\":literal\"><semantics><mi>&#963;</mi><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math>) calculated from the training dataset:</p>\n\n",
                "matched_terms": [
                    "reward",
                    "score"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The normalized scores are then combined via a weighted sum to produce the final reward score for the intermediate state:</p>\n\n",
                "matched_terms": [
                    "score",
                    "reward"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where the weight <math alttext=\"\\alpha\\in[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m7\" intent=\":literal\"><semantics><mrow><mi>&#945;</mi><mo>&#8712;</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\alpha\\in[0,1]</annotation></semantics></math> can be adjusted to explicitly control the guidance process towards the direction of interest.\nFor example, if one desires a generation with high audio-text alignment, one can simply increase <math alttext=\"\\alpha\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p2.m8\" intent=\":literal\"><semantics><mi>&#945;</mi><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math> to assign greater weight to the CLAP reward.\nWe note that this normalization and combination process is not limited to two rewards; any additional model with a distinct reward attribute can be incorporated and play as another axis of guidance for various applications. The effect of different weight values is further discussed in Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#S4.SS2\" title=\"4.2 Ablation Study &#8227; 4 Results &#8227; SCORE: Scaling audio generation using Standardized COmposite REwards\"><span class=\"ltx_text ltx_ref_tag\">4.2</span></a>.</p>\n\n",
                "matched_terms": [
                    "Î±alpha",
                    "combination",
                    "clap",
                    "reward",
                    "generation",
                    "rewards",
                    "weight"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Despite the growing interest in matching the generated audio to the text prompt, there are a limited number of relevant evaluation metrics. To gauge the performance of the proposed method from different perspectives, we introduce AQAScore, a novel audio-text alignment metric leveraging a pre-trained Audio Language Model named Audio Flamingo 3&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib24\" title=\"\">24</a>]</cite>.\nSpecifically, we adopt the method used in VQAScore&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib25\" title=\"\">25</a>]</cite>, where the image-text alignment is measured by asking a Vision Language Model a query <span class=\"ltx_text ltx_font_italic\">&#8220;Does this image contain </span>{<span class=\"ltx_text ltx_font_italic\">prompt</span>}<span class=\"ltx_text ltx_font_italic\">?&#8221;</span> and calculating the probability of generating <span class=\"ltx_text ltx_font_italic\">&#8220;yes&#8221;</span>.\nFor audio-text alignment evaluation, we feed Audio Flamingo 3 model an audio with a prompt <span class=\"ltx_text ltx_font_italic\">&#8220;Does this audio contain </span>{<span class=\"ltx_text ltx_font_italic\">prompt</span>}<span class=\"ltx_text ltx_font_italic\">?&#8221;</span> and obtain the <span class=\"ltx_text ltx_font_italic\">&#8220;yes&#8221;</span> probability.</p>\n\n",
                "matched_terms": [
                    "aqascore",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Implementation Details.</span>\nWe conduct experiments using EzAudio&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib7\" title=\"\">7</a>]</cite>, a T2A model.\nFor reward models, we utilize pretrained CLAP&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib26\" title=\"\">26</a>]</cite> and Audiobox Aesthetics&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib27\" title=\"\">27</a>]</cite> models.\nWe use the test split of AudioCaps&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib31\" title=\"\">31</a>]</cite> dataset, consisting of 944 audio files with their textual descriptions.\nThe evaluation is conducted within two distinct sampling frameworks, BON and EvoSearch.\nWe report the average performance and standard deviation over three runs with distinct random seeds for reliability.\nAll experiments are conducted on NVIDIA RTX 4090 GPUs.</p>\n\n",
                "matched_terms": [
                    "audiocaps",
                    "sampling",
                    "clap",
                    "reward",
                    "test",
                    "evosearch",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Evaluation Metrics.</span>\nAudio samples are evaluated with various metrics to gauge the performance in different aspects.\nFor generation quality, we use Frechet Distance (FD)&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib32\" title=\"\">32</a>]</cite> and Inception Score (IS)&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib33\" title=\"\">33</a>]</cite>.\nIn addition, three metrics proposed in Audiobox-Aesthetics&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib27\" title=\"\">27</a>]</cite> are measured to further analyze the audio quality: Production Quality (PQ), Content Usage (CU), and Content Enjoyment (CE).\nWe do not report Production Complexity (PC) since evaluating the complexity of the generated audio is not our main objective.\nWe use CLAP similarity&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#bib.bib26\" title=\"\">26</a>]</cite> as well as the aforementioned AQAScore for audio-text alignment.</p>\n\n",
                "matched_terms": [
                    "score",
                    "clap",
                    "generation",
                    "aqascore",
                    "audioboxaesthetics",
                    "quality",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Evaluation with AQAScore.</span>\nTo evaluate the audio-text alignment without potential bias introduced by CLAP reward, we gauge the performance with the proposed AQAScore.\nWhile AQAScore broadly follows the trend of CLAP, it reveals discrepancies. For example, BON with PQ reward attains a lower AQAScore than naive sampling despite a higher CLAP score, an evidence of verifier hacking.\nSuch observation provides an additional perspective on alignment evaluation, and we validate that AQAScore faithfully reflects the effectiveness of SCORE.</p>\n\n",
                "matched_terms": [
                    "score",
                    "sampling",
                    "clap",
                    "reward",
                    "naive",
                    "aqascore",
                    "higher",
                    "lower",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Effect of Number of Function Evaluations.</span>\nTo verify the scalability of the proposed method, we conduct experiments by applying SCORE to two different ITS methods with an incremental number of function evaluations (NFE).\nAs shown in Fig.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.19831v1#S4.F3\" title=\"Figure 3 &#8227; 4.2 Ablation Study &#8227; 4 Results &#8227; SCORE: Scaling audio generation using Standardized COmposite REwards\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>, both methods show that the performance on CLAP and PQ metrics is proportional to the increase in NFE.\nAs indicated by the decreasing variance of the metrics, increasing computation makes the generation more robust to randomness and consistently produces favorable results.\nNote that the population size <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S4.SS2.p2.m1\" intent=\":literal\"><semantics><mi>N</mi><annotation encoding=\"application/x-tex\">N</annotation></semantics></math>, the number of noise candidates in one inference, for EvoSearch is set lower than that of BON to match the NFE, and yet it shows a more stable increase in performance and mostly outperforms BON when scaled.</p>\n\n",
                "matched_terms": [
                    "set",
                    "score",
                    "clap",
                    "generation",
                    "lower",
                    "methods",
                    "evosearch",
                    "performance"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This paper pioneers the extension of Inference-Time Scaling to Text-to-Audio generation and presents a novel standardized composite reward framework named SCORE.\nBy normalizing and combining multiple reward signals, SCORE effectively balances audio&#8211;text alignment and perceptual quality while avoiding verifier hacking. Extensive experiments show consistent improvements across CLAP, PQ, and other evaluation metrics, with controllable trade-offs enabled through adjustable weighting. These results highlight SCORE as a principled and flexible approach for enhancing audio generation, setting a foundation for future work on multi-objective guidance in diffusion-based generative models.</p>\n\n",
                "matched_terms": [
                    "score",
                    "clap",
                    "reward",
                    "generation",
                    "quality"
                ]
            }
        ]
    }
}