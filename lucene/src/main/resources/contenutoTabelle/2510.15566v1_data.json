{
    "S3.T1": {
        "source_file": "SpikeVox: Towards Energy-Efficient Speech Therapy Framework with Spike-driven Generative Language Models",
        "caption": "TABLE I: Mapping speech disorder categories based on the neuron activation patterns of SpikeGPT.",
        "body": "Disorder\nPrimary\nTypical\nThreshold\nWeight\n\n\nCategory\nNeurons\nSiS_{i}\n\n(α\\alpha, β\\beta, γ\\gamma)\n\n\n\n\nR-sound issues\n\nN1-64\n\n0.15-0.35\n0.25\n(0.5, 0.3, 0.2)\n\n\nS-sound issues\n\nN65-128\n\n0.20-0.40\n0.30\n(0.4, 0.4, 0.2)\n\n\nTh-sound issues\n\nN129-192\n\n0.25-0.45\n0.35\n(0.4, 0.3, 0.3)\n\n\nL-sound issues\n\nN193-256\n\n0.15-0.30\n0.20\n(0.5, 0.3, 0.2)\n\n\nConsonant clusters\n\nN257-320\n\n0.30-0.50\n0.40\n(0.3, 0.5, 0.2)\n\n\nVowel distortions\n\nN321-384\n\n0.20-0.35\n0.25\n(0.4, 0.3, 0.3)",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Disorder</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Primary</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Typical</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Threshold</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Weight</span></th>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Category</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Neurons</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><math alttext=\"S_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m1\" intent=\":literal\"><semantics><msub><mi mathsize=\"0.700em\">S</mi><mi mathsize=\"0.700em\">i</mi></msub><annotation encoding=\"application/x-tex\">S_{i}</annotation></semantics></math></th>\n<th class=\"ltx_td ltx_th ltx_th_column ltx_border_r\"/>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">(<math alttext=\"\\alpha\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m2\" intent=\":literal\"><semantics><mi>&#945;</mi><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math>, <math alttext=\"\\beta\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m3\" intent=\":literal\"><semantics><mi>&#946;</mi><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math>, <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m4\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math>)</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:70%;\">R-sound issues</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt\">\n<span class=\"ltx_text\" style=\"font-size:70%;\">N</span><sub class=\"ltx_sub\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:70%;\">1-64</span></sub>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.15-0.35</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.25</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span class=\"ltx_text\" style=\"font-size:70%;\">(0.5, 0.3, 0.2)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">S-sound issues</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">\n<span class=\"ltx_text\" style=\"font-size:70%;\">N</span><sub class=\"ltx_sub\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:70%;\">65-128</span></sub>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.20-0.40</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.30</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">(0.4, 0.4, 0.2)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">Th-sound issues</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">\n<span class=\"ltx_text\" style=\"font-size:70%;\">N</span><sub class=\"ltx_sub\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:70%;\">129-192</span></sub>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.25-0.45</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.35</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">(0.4, 0.3, 0.3)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">L-sound issues</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">\n<span class=\"ltx_text\" style=\"font-size:70%;\">N</span><sub class=\"ltx_sub\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:70%;\">193-256</span></sub>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.15-0.30</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.20</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">(0.5, 0.3, 0.2)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">Consonant clusters</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">\n<span class=\"ltx_text\" style=\"font-size:70%;\">N</span><sub class=\"ltx_sub\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:70%;\">257-320</span></sub>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.30-0.50</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.40</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">(0.3, 0.5, 0.2)</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">Vowel distortions</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\">\n<span class=\"ltx_text\" style=\"font-size:70%;\">N</span><sub class=\"ltx_sub\"><span class=\"ltx_text ltx_font_italic\" style=\"font-size:70%;\">321-384</span></sub>\n</th>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.20-0.35</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">0.25</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span class=\"ltx_text\" style=\"font-size:70%;\">(0.4, 0.3, 0.3)</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "n129192",
            "consonant",
            "mapping",
            "threshold",
            "categories",
            "n193256",
            "speech",
            "issues",
            "neuron",
            "ssound",
            "n65128",
            "αalpha",
            "n257320",
            "spikegpt",
            "neurons",
            "vowel",
            "typical",
            "weight",
            "sisi",
            "thsound",
            "n321384",
            "clusters",
            "disorder",
            "primary",
            "patterns",
            "n164",
            "activation",
            "γgamma",
            "lsound",
            "category",
            "βbeta",
            "distortions",
            "based",
            "rsound"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">Once the confidence score is calculated, it will be mapped to a specific disorder based on the neuron activation patterns; see Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#S3.T1\" title=\"TABLE I &#8227; III-B Speech Pattern Analysis &#8227; III The SpikeVox Framework &#8227; SpikeVox: Towards Energy-Efficient Speech Therapy Framework with Spike-driven Generative Language Models\"><span class=\"ltx_text ltx_ref_tag\">I</span></a>.</p>\n\n",
            "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Issue Categorization and Phoneme Detection.</span>\nOne of the most critical aspect of speech therapy systems is correctly categorizing the speech issues (i.e., R-sound, S-sound, Th-sound, L-sound, consonant cluster, and vowel) based on the phoneme pronunciation, as this aspect identifies the necessary treatments to do.\nFor issue categorization, our SpikeVox achieves high confidence level with 89% for R-sound (rhotacism), 91% for S-sound (lisping), 87% for Th-sound, 89% for L-sound, 85% for consonant cluster, and 87% for vowel (i.e., 88% on average), as shown in Fig.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#S5.F3\" title=\"Figure 3 &#8227; V-A Speech Analysis Performance &#8227; V Results and Discussion &#8227; SpikeVox: Towards Energy-Efficient Speech Therapy Framework with Spike-driven Generative Language Models\"><span class=\"ltx_text ltx_ref_tag\">3</span></a>(b).\nSuch high performance from SpikeVox is attributed to its effective speech-to-text conversion, and effective categorization criteria presented in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#S3.T1\" title=\"TABLE I &#8227; III-B Speech Pattern Analysis &#8227; III The SpikeVox Framework &#8227; SpikeVox: Towards Energy-Efficient Speech Therapy Framework with Spike-driven Generative Language Models\"><span class=\"ltx_text ltx_ref_tag\">I</span></a>.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Speech disorders can significantly affect the patients&#8217; capability to communicate, learn, and socialize.\nHowever, existing speech therapy solutions (e.g., therapist or tools) are still limited and costly, hence such solutions remain inadequate for serving millions of patients worldwide.\nTo address this, state-of-the-art methods employ neural network (NN) algorithms to help accurately detecting speech disorders.\nHowever, these methods do not provide therapy recommendation as feedback, hence providing partial solution for patients.\nMoreover, these methods incur high energy consumption due to their complex and resource-intensive NN processing, hence hindering their deployments on low-power/energy platforms (e.g., smartphones).\nToward this, we propose <span class=\"ltx_text ltx_font_italic\">SpikeVox</span>, a novel framework for enabling energy-efficient speech therapy solutions through spike-driven generative language model.\nSpecifically, SpikeVox employs a speech recognition module to perform highly accurate speech-to-text conversion; leverages a spike-driven generative language model to efficiently perform pattern analysis for speech disorder detection and generates suitable exercises for therapy; provides guidance on correct pronunciation as feedback; as well as utilizes the REST API to enable seamless interaction for users.\nExperimental results demonstrate that SpikeVox achieves 88% confidence level on average in speech disorder recognition, while providing a complete feedback for therapy exercises.\nTherefore, SpikeVox provides a comprehensive framework for energy-efficient speech therapy solutions, and potentially addresses the significant global speech therapy access gap.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "disorder"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Targeted Research Problem:</span>\n<span class=\"ltx_text ltx_font_italic\">How can we develop an automated speech therapy solution that provides highly accurate speech disorder detection and suggests suitable treatments?</span>\nAn efficient solution to this problem may enable a low-cost speech therapy solution that is accessible for patients worldwide.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "disorder"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Currently, state-of-the-art methods employ neural network (NN) algorithms to accurately detect speech disorders, thereby helping human SLPs to identify different types of speech disorders&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib6\" title=\"\">6</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib7\" title=\"\">7</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib8\" title=\"\">8</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib9\" title=\"\">9</a>]</cite>.\nFor instance, recent works proposed stuttering detection techniques by leveraging the wav2vec 2.0 library&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib7\" title=\"\">7</a>]</cite><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib10\" title=\"\">10</a>]</cite>, keyword recognition using a trained deep learning model&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib8\" title=\"\">8</a>]</cite>, and dysarthria detection using convolutional neural networks (CNNs)&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib9\" title=\"\">9</a>]</cite>.\nHowever, these methods provide partial solution for patients, as they only focus on the speech disorder detection aspect and do not provide recommended treatments as feedback.\nTherefore, they still involve SLPs in the loop to guide the patients with necessary treatments, which limit the accessibility of the solution worldwide.\nMoreover, these methods incur high energy consumption due to their complex and resource-intensive NN processing, hence hindering their deployments for low-power/energy platforms (e.g., smartphones, embedded platforms, or wearable devices), which are especially important if patients require offline processing due to better efficiency and better privacy.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "disorder"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The above-discussed limitations expose several characteristics that are expected from speech therapy solutions, as follows.\nThe solution should (1) detect speech disorders and categorize them with high accuracy, (2) provide feedback of recommended treatments/exercises based on the detected speech patterns, and (3) process NN algorithms efficiently to enable its adoption in low-power/energy systems, such as smartphones, embedded platforms, or wearable devices.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "patterns",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To address the challenges, we propose <span class=\"ltx_text ltx_font_italic\">SpikeVox</span>, <span class=\"ltx_text ltx_font_italic\">a novel framework for enabling energy-efficient speech therapy solutions by leveraging spike-driven generative language model.</span>\nThis paper is also the first work that provides a complete speech disorder detection, analysis, and feedback for speech therapy in a single spiking-based framework.\nTo achieve this, SpikeVox employs the following key design steps (an overview shown in Fig.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#S1.F1\" title=\"Figure 1 &#8227; I-C Our Novel Contributions &#8227; I Introduction &#8227; SpikeVox: Towards Energy-Efficient Speech Therapy Framework with Spike-driven Generative Language Models\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>).</p>\n\n",
                "matched_terms": [
                    "speech",
                    "disorder"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Speech Pattern Analysis (Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#S3.SS2\" title=\"III-B Speech Pattern Analysis &#8227; III The SpikeVox Framework &#8227; SpikeVox: Towards Energy-Efficient Speech Therapy Framework with Spike-driven Generative Language Models\"><span class=\"ltx_text ltx_ref_tag\">III-B</span></a>):</span>\nIt identifies errors in speech patterns using binary spike activations, then classifies them into the correct disorder categories.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "categories",
                    "patterns",
                    "disorder"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Speech Therapy Generation (Section&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#S3.SS3\" title=\"III-C Speech Therapy Generation &#8227; III The SpikeVox Framework &#8227; SpikeVox: Towards Energy-Efficient Speech Therapy Framework with Spike-driven Generative Language Models\"><span class=\"ltx_text ltx_ref_tag\">III-C</span></a>):</span>\nIt generates customized exercises based on the detected disorder categories, hence providing effective therapy for the observed disorder.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "categories",
                    "disorder",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Key Results:</span>\nIn evaluation, we realize our SpikeVox framework using Python-based implementation, and then run it on the Apple M4 10-core CPU with 16GB memory.\nExperimental results show that, SpikeVox obtains high confidence level (88% on average) in speech disorder recognition, while providing therapy exercises as feedback.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "disorder"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Spiking Neural Networks (SNNs):</span>\nAn SNN model comprises several components, i.e., spiking neurons, network architecture, neural coding, and learning rule&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib11\" title=\"\">11</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib12\" title=\"\">12</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib13\" title=\"\">13</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib14\" title=\"\">14</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib15\" title=\"\">15</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib16\" title=\"\">16</a>]</cite>.\nRecently, SNNs have emerged as the alternate low-power/energy NN algorithms due to their sparse spike-driven operations&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib17\" title=\"\">17</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib18\" title=\"\">18</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib19\" title=\"\">19</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib20\" title=\"\">20</a>]</cite> and hardware advancements&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib21\" title=\"\">21</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib22\" title=\"\">22</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib23\" title=\"\">23</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib24\" title=\"\">24</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib25\" title=\"\">25</a>]</cite>.\nTherefore, <span class=\"ltx_text ltx_font_italic\">in this work, we leverage SNNs to perform speech disorder recognition and generate suitable exercises for therapy.</span></p>\n\n",
                "matched_terms": [
                    "speech",
                    "disorder",
                    "neurons"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Spike-driven Generative Language Models:</span>\nIn this work, we use the spike-driven generative model called <span class=\"ltx_text ltx_font_italic\">SpikeGPT</span>&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib26\" title=\"\">26</a>]</cite>, and employ its pre-trained model based on the OpenWebText2 dataset&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib27\" title=\"\">27</a>]</cite>.\nThis model considers the Leaky Integrate-and-Fire (LIF) as the spiking neuron model, since it is commonly adopted in the SNN community due to its low computational complexity&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib28\" title=\"\">28</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib29\" title=\"\">29</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib30\" title=\"\">30</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib31\" title=\"\">31</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib32\" title=\"\">32</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib33\" title=\"\">33</a>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib34\" title=\"\">34</a>]</cite>.\nFor neural coding and learning rule, it employs rate coding&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib35\" title=\"\">35</a>]</cite> and surrogate gradient learning&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib36\" title=\"\">36</a>]</cite>, respectively.\nFor network architecture, SpikeGPT uses Spiking Receptance Weighted Key Value (Spiking RWKV) and Spiking Receptance Feed-Forward Networks (Spiking RFFN) modules.</p>\n\n",
                "matched_terms": [
                    "spikegpt",
                    "neuron",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This step captures the speech sound from the patient, and then perform speech-to-text conversion while preserving pronunciation information.\nUnlike conventional speech-to-text techniques which only focus on semantic accuracy, SpikeVox captures both the transcription and confidence scores for individual phoneme.\nThis speech recognition module leverages the wav2vec 2.0 library&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib10\" title=\"\">10</a>]</cite> for phoneme-level analysis.\nBy examining the softmax output of the model, we identify potential pronunciation issues where confidence is low.\nThis information is then passed to the pattern analysis step.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "issues"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This step identifies disorders in speech patterns using binary spike activations.\nSpecifically, it leverages the pre-trained SpikeGPT model to analyze articulation, fluency, and pronunciation of the input sound, and then categorize the detected issues based on common speech therapy classification:\n(1) <span class=\"ltx_text ltx_font_italic\">R-sound issues (rhotacism)</span>, (2) <span class=\"ltx_text ltx_font_italic\">S-sound issues (lisping)</span>, (3) <span class=\"ltx_text ltx_font_italic\">Th-sound issues</span>, (4) <span class=\"ltx_text ltx_font_italic\">L-sound issues</span>, (5) <span class=\"ltx_text ltx_font_italic\">consonant cluster simplification</span>, and (6) <span class=\"ltx_text ltx_font_italic\">vowel distortions</span>&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib37\" title=\"\">37</a>]</cite>.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "issues",
                    "rsound",
                    "lsound",
                    "consonant",
                    "ssound",
                    "thsound",
                    "distortions",
                    "patterns",
                    "spikegpt",
                    "based",
                    "vowel"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For each category, the system assigns a confidence score, creating a comprehensive profile of the patient&#8217;s speech patterns. This profile serves as the basis for generating personalized therapy exercises.\nThe confidence score <math alttext=\"C_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m1\" intent=\":literal\"><semantics><msub><mi>C</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">C_{i}</annotation></semantics></math> for speech disorder category <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m2\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math> is defined as:</p>\n\n",
                "matched_terms": [
                    "speech",
                    "patterns",
                    "disorder",
                    "category"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Here, <math alttext=\"\\mathcal{P}_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m3\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{P}_{i}</annotation></semantics></math> is the set of phonemes associated with category <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m4\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>; <math alttext=\"p_{j}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m5\" intent=\":literal\"><semantics><msub><mi>p</mi><mi>j</mi></msub><annotation encoding=\"application/x-tex\">p_{j}</annotation></semantics></math> is the confidence score from the wav2vec 2.0 for phoneme <math alttext=\"j\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m6\" intent=\":literal\"><semantics><mi>j</mi><annotation encoding=\"application/x-tex\">j</annotation></semantics></math>; <math alttext=\"S_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m7\" intent=\":literal\"><semantics><msub><mi>S</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">S_{i}</annotation></semantics></math> is the spike density for neurons associated with category <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m8\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>; <math alttext=\"S_{max}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m9\" intent=\":literal\"><semantics><msub><mi>S</mi><mrow><mi>m</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>a</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>x</mi></mrow></msub><annotation encoding=\"application/x-tex\">S_{max}</annotation></semantics></math> is the maximum possible spike density; <math alttext=\"M_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m10\" intent=\":literal\"><semantics><msub><mi>M</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">M_{i}</annotation></semantics></math> is the pattern matching score derived from membrane potential of SpikeGPT model; while <math alttext=\"\\alpha\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m11\" intent=\":literal\"><semantics><mi>&#945;</mi><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math>, <math alttext=\"\\beta\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m12\" intent=\":literal\"><semantics><mi>&#946;</mi><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math>, and <math alttext=\"\\gamma\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m13\" intent=\":literal\"><semantics><mi>&#947;</mi><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math> are weighting factors with <math alttext=\"\\alpha+\\beta+\\gamma=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p2.m14\" intent=\":literal\"><semantics><mrow><mrow><mi>&#945;</mi><mo>+</mo><mi>&#946;</mi><mo>+</mo><mi>&#947;</mi></mrow><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\alpha+\\beta+\\gamma=1</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "γgamma",
                    "sisi",
                    "category",
                    "βbeta",
                    "αalpha",
                    "spikegpt",
                    "neurons"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The contribution of SpikeGPT to confidence scoring is realized through the spike density (<math alttext=\"S_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m1\" intent=\":literal\"><semantics><msub><mi>S</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">S_{i}</annotation></semantics></math>) and the pattern matching score (<math alttext=\"M_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m2\" intent=\":literal\"><semantics><msub><mi>M</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">M_{i}</annotation></semantics></math>).\nSpike density <math alttext=\"S_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m3\" intent=\":literal\"><semantics><msub><mi>S</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">S_{i}</annotation></semantics></math> measures how frequently category-specific neurons activate when processing problematic phonemes, and it is defined as:</p>\n\n",
                "matched_terms": [
                    "spikegpt",
                    "neurons",
                    "sisi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Here, <math alttext=\"s_{n,t}\\in\\{0,1\\}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m4\" intent=\":literal\"><semantics><mrow><msub><mi>s</mi><mrow><mi>n</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>&#8712;</mo><mrow><mo stretchy=\"false\">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">s_{n,t}\\in\\{0,1\\}</annotation></semantics></math> is the binary spike output of neuron <math alttext=\"n\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m5\" intent=\":literal\"><semantics><mi>n</mi><annotation encoding=\"application/x-tex\">n</annotation></semantics></math> at time step <math alttext=\"t\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m6\" intent=\":literal\"><semantics><mi>t</mi><annotation encoding=\"application/x-tex\">t</annotation></semantics></math>; <math alttext=\"\\mathcal{N}_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m7\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#119977;</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{N}_{i}</annotation></semantics></math> is the set of neurons associated with category <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m8\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math>; and <math alttext=\"T\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m9\" intent=\":literal\"><semantics><mi>T</mi><annotation encoding=\"application/x-tex\">T</annotation></semantics></math> is the total number of time steps.\nMeanwhile, pattern matching score <math alttext=\"M_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m10\" intent=\":literal\"><semantics><msub><mi>M</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">M_{i}</annotation></semantics></math> leverages the membrane potential patterns in SpikeGPT by comparing them to known disorder patterns, and it can be expressed as:</p>\n\n",
                "matched_terms": [
                    "neuron",
                    "category",
                    "disorder",
                    "patterns",
                    "spikegpt",
                    "neurons"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Here, <math alttext=\"U_{n}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m11\" intent=\":literal\"><semantics><msub><mi>U</mi><mi>n</mi></msub><annotation encoding=\"application/x-tex\">U_{n}</annotation></semantics></math> is the membrane potential sequence for neuron <math alttext=\"n\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m12\" intent=\":literal\"><semantics><mi>n</mi><annotation encoding=\"application/x-tex\">n</annotation></semantics></math>; <math alttext=\"\\hat{U}_{i,n}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m13\" intent=\":literal\"><semantics><msub><mover accent=\"true\"><mi>U</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>n</mi></mrow></msub><annotation encoding=\"application/x-tex\">\\hat{U}_{i,n}</annotation></semantics></math> is the reference membrane potential pattern for disorder category <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m14\" intent=\":literal\"><semantics><mi>i</mi><annotation encoding=\"application/x-tex\">i</annotation></semantics></math> and neuron <math alttext=\"n\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m15\" intent=\":literal\"><semantics><mi>n</mi><annotation encoding=\"application/x-tex\">n</annotation></semantics></math>; and <math alttext=\"\\mathrm{sim}(\\cdot)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p3.m16\" intent=\":literal\"><semantics><mrow><mi>sim</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mo lspace=\"0em\" rspace=\"0em\">&#8901;</mo><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathrm{sim}(\\cdot)</annotation></semantics></math> is a similarity function such as cosine similarity.</p>\n\n",
                "matched_terms": [
                    "category",
                    "neuron",
                    "disorder"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This step leverages language generation features in the SpikeGPT to produces contextually appropriate practice sentences that focus on problematic phonemes and sound combinations.\nThis step considers:\n(1) severity of each identified issue; (2) phonetic context in which errors occur; (3) progression from simpler to more complex exercises; and (4) personalization based on patient history and progress.</p>\n\n",
                "matched_terms": [
                    "spikegpt",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The exercise generation process is formulated as an optimization problem over a set of candidate sentences. For a given speech disorder category <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m1\" intent=\":literal\"><semantics><mi>c</mi><annotation encoding=\"application/x-tex\">c</annotation></semantics></math>, difficulty level <math alttext=\"d\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m2\" intent=\":literal\"><semantics><mi>d</mi><annotation encoding=\"application/x-tex\">d</annotation></semantics></math>, and patient history vector <math alttext=\"\\mathbf{h}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m3\" intent=\":literal\"><semantics><mi>&#119841;</mi><annotation encoding=\"application/x-tex\">\\mathbf{h}</annotation></semantics></math>, we define the optimal exercise selection function <math alttext=\"\\mathcal{E}(c,d,\\mathbf{h})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m4\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#8496;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>&#119841;</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{E}(c,d,\\mathbf{h})</annotation></semantics></math> as:</p>\n\n",
                "matched_terms": [
                    "speech",
                    "disorder",
                    "category"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Here, <math alttext=\"\\mathcal{S}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m5\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119982;</mi><annotation encoding=\"application/x-tex\">\\mathcal{S}</annotation></semantics></math> represents the set of potential exercise sentences; <math alttext=\"\\mathcal{R}(s,c)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m6\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#8475;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo>,</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{R}(s,c)</annotation></semantics></math> is the relevance function measuring how well sentence <math alttext=\"s\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m7\" intent=\":literal\"><semantics><mi>s</mi><annotation encoding=\"application/x-tex\">s</annotation></semantics></math> targets disorder category <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m8\" intent=\":literal\"><semantics><mi>c</mi><annotation encoding=\"application/x-tex\">c</annotation></semantics></math>; <math alttext=\"\\mathcal{D}(s,d)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m9\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119967;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo>,</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{D}(s,d)</annotation></semantics></math> is the difficulty alignment function for difficulty level <math alttext=\"d\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m10\" intent=\":literal\"><semantics><mi>d</mi><annotation encoding=\"application/x-tex\">d</annotation></semantics></math>; <math alttext=\"\\mathcal{P}(s,\\mathbf{h})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m11\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119979;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo>,</mo><mi>&#119841;</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{P}(s,\\mathbf{h})</annotation></semantics></math> is the personalization function based on patient history <math alttext=\"\\mathbf{h}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m12\" intent=\":literal\"><semantics><mi>&#119841;</mi><annotation encoding=\"application/x-tex\">\\mathbf{h}</annotation></semantics></math>; while <math alttext=\"\\omega_{1},\\omega_{2}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m13\" intent=\":literal\"><semantics><mrow><msub><mi>&#969;</mi><mn>1</mn></msub><mo>,</mo><msub><mi>&#969;</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\omega_{1},\\omega_{2}</annotation></semantics></math>, and <math alttext=\"\\omega_{3}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m14\" intent=\":literal\"><semantics><msub><mi>&#969;</mi><mn>3</mn></msub><annotation encoding=\"application/x-tex\">\\omega_{3}</annotation></semantics></math> are weighting parameters where <math alttext=\"\\omega_{1}+\\omega_{2}+\\omega_{3}=1\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p2.m15\" intent=\":literal\"><semantics><mrow><mrow><msub><mi>&#969;</mi><mn>1</mn></msub><mo>+</mo><msub><mi>&#969;</mi><mn>2</mn></msub><mo>+</mo><msub><mi>&#969;</mi><mn>3</mn></msub></mrow><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\omega_{1}+\\omega_{2}+\\omega_{3}=1</annotation></semantics></math>.</p>\n\n",
                "matched_terms": [
                    "category",
                    "disorder",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The relevance function <math alttext=\"\\mathcal{R}(s,c)\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p3.m1\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#8475;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo>,</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{R}(s,c)</annotation></semantics></math> quantifies how effectively a sentence targets the specific speech disorder category:</p>\n\n",
                "matched_terms": [
                    "speech",
                    "disorder",
                    "category"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Here, <math alttext=\"\\psi(s_{i},\\Phi_{c})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p3.m2\" intent=\":literal\"><semantics><mrow><mi>&#968;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>s</mi><mi>i</mi></msub><mo>,</mo><msub><mi mathvariant=\"normal\">&#934;</mi><mi>c</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\psi(s_{i},\\Phi_{c})</annotation></semantics></math> is an indicator function that equals 1 if phoneme <math alttext=\"s_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p3.m3\" intent=\":literal\"><semantics><msub><mi>s</mi><mi>i</mi></msub><annotation encoding=\"application/x-tex\">s_{i}</annotation></semantics></math> belongs to the target phoneme set <math alttext=\"\\Phi_{c}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p3.m4\" intent=\":literal\"><semantics><msub><mi mathvariant=\"normal\">&#934;</mi><mi>c</mi></msub><annotation encoding=\"application/x-tex\">\\Phi_{c}</annotation></semantics></math> for category <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p3.m5\" intent=\":literal\"><semantics><mi>c</mi><annotation encoding=\"application/x-tex\">c</annotation></semantics></math>, and 0 otherwise; <math alttext=\"\\mathcal{Q}(s_{i},s_{i-1},s_{i+1})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p3.m6\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119980;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>s</mi><mi>i</mi></msub><mo>,</mo><msub><mi>s</mi><mrow><mi>i</mi><mo>&#8722;</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{Q}(s_{i},s_{i-1},s_{i+1})</annotation></semantics></math> is a contextual difficulty factor that increases the score when the target phoneme appears in challenging phonetic contexts; <math alttext=\"\\lambda_{c}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p3.m7\" intent=\":literal\"><semantics><msub><mi>&#955;</mi><mi>c</mi></msub><annotation encoding=\"application/x-tex\">\\lambda_{c}</annotation></semantics></math> is a category-specific normalization constant; while <math alttext=\"\\eta\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS3.p3.m8\" intent=\":literal\"><semantics><mi>&#951;</mi><annotation encoding=\"application/x-tex\">\\eta</annotation></semantics></math> is a context weighting parameter.</p>\n\n",
                "matched_terms": [
                    "category",
                    "sisi"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This step provides personalized guidance on the correct pronunciation based on the generated exercises, and thereby enabling the user to perform treatments without personal assistant.\nIt generates three types of feedback: (1) specific phoneme-level guidance for detected issues, (2) visual pronunciation guides showing tongue and lip positions, and (3) general practice recommendations to improve overall articulation.</p>\n\n",
                "matched_terms": [
                    "issues",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The feedback generation process takes two primary inputs: speech analysis results (<math alttext=\"\\mathcal{A}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#119964;</mi><annotation encoding=\"application/x-tex\">\\mathcal{A}</annotation></semantics></math>), and exercise performance results (<math alttext=\"\\mathcal{E}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m2\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#8496;</mi><annotation encoding=\"application/x-tex\">\\mathcal{E}</annotation></semantics></math>) when available.\nThe feedback function (<math alttext=\"\\mathcal{F}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m3\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#8497;</mi><annotation encoding=\"application/x-tex\">\\mathcal{F}</annotation></semantics></math>) can be formally defined as:</p>\n\n",
                "matched_terms": [
                    "speech",
                    "primary"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><math alttext=\"\\mathcal{F}_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m4\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8497;</mi><mi>s</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{F}_{s}</annotation></semantics></math>, <math alttext=\"\\mathcal{F}_{g}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m5\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8497;</mi><mi>g</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{F}_{g}</annotation></semantics></math>, <math alttext=\"\\mathcal{F}_{v}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m6\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8497;</mi><mi>v</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{F}_{v}</annotation></semantics></math>, <math alttext=\"\\mathcal{F}_{o}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m7\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8497;</mi><mi>o</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{F}_{o}</annotation></semantics></math>, and <math alttext=\"\\mathcal{F}_{e}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m8\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8497;</mi><mi>e</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{F}_{e}</annotation></semantics></math> denote specific guidance, general tips, visual guides, overall assessment, and exercise-specific feedback, respectively.\nTo generate <math alttext=\"\\mathcal{F}_{s}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m9\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8497;</mi><mi>s</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{F}_{s}</annotation></semantics></math>, we select from category-specific templates (<math alttext=\"\\mathcal{T}_{c}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m10\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><mi>c</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{T}_{c}</annotation></semantics></math>) based on the detected issues (<math alttext=\"\\mathcal{I}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m11\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#8464;</mi><annotation encoding=\"application/x-tex\">\\mathcal{I}</annotation></semantics></math>), stated as:</p>\n\n",
                "matched_terms": [
                    "issues",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Here, <math alttext=\"\\text{select}(\\mathcal{T}_{c})\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m12\" intent=\":literal\"><semantics><mrow><mtext>select</mtext><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><mi>c</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\text{select}(\\mathcal{T}_{c})</annotation></semantics></math> is a selection function that chooses an appropriate guidance from the set of templates <math alttext=\"\\mathcal{T}_{c}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m13\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#119983;</mi><mi>c</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{T}_{c}</annotation></semantics></math> for category <math alttext=\"c\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m14\" intent=\":literal\"><semantics><mi>c</mi><annotation encoding=\"application/x-tex\">c</annotation></semantics></math>.\nVisual guides <math alttext=\"\\mathcal{F}_{v}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p2.m15\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8497;</mi><mi>v</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{F}_{v}</annotation></semantics></math> are generated based on the phonetic categories requiring attention:</p>\n\n",
                "matched_terms": [
                    "category",
                    "categories",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">SpikeVox integrates confidence-weighted guidance, hence its feedback is prioritized based on the severity of disorder and the confidence in system&#8217;s detection, ensuring that patients receive the most effective guidance.\nWhen exercise performance data <math alttext=\"\\mathcal{E}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m1\" intent=\":literal\"><semantics><mi class=\"ltx_font_mathcaligraphic\">&#8496;</mi><annotation encoding=\"application/x-tex\">\\mathcal{E}</annotation></semantics></math> is available, the system calculates an accuracy score (<math alttext=\"\\mathcal{A}_{c}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS4.p3.m2\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#119964;</mi><mi>c</mi></msub><annotation encoding=\"application/x-tex\">\\mathcal{A}_{c}</annotation></semantics></math>) for each exercise category:</p>\n\n",
                "matched_terms": [
                    "category",
                    "disorder",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_typewriter\">/api/speech-analyze</span>:\nIt processes audio input and returns a detailed analysis of speech patterns.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "patterns"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The resulting text and phoneme confidence scores are analyzed by the pattern analysis module, which identifies speech issues.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "issues"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Then, the client requests personalized exercises for therapy by sending the analysis identifier of detected speech issues to the &#8220;<span class=\"ltx_text ltx_font_typewriter\">/api/generate-therapy</span>&#8221; endpoint.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "issues"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Afterward, the server generates exercises tailored to the detected speech patterns and returns them to the client.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "patterns"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We evaluate the SpikeVox framework using PyTorch-based implementation, and then run it on the Apple M4 10-core CPU with 16GB memory.\nSpikeVox employs the SpikeGPT model with 216M parameters&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib26\" title=\"\">26</a>]</cite>, that has been trained with 5B tokens from the OpenWebText dataset&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib38\" title=\"\">38</a>]</cite>.\nTo evaluate speech analysis performance of SpikeVox, we use an open-sourced dysfluency corpus (i.e., Libri-Dys dataset&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib39\" title=\"\">39</a>]</cite>), and consider standard metrics, such as transcription accuracy, issue categorization, and phoneme detection.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "spikegpt"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To illustrate the data processing flow in SpikeVox, we perform an experimental case study, as shown in Fig.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#S3.F2\" title=\"Figure 2 &#8227; III-E Implementation using the REST API &#8227; III The SpikeVox Framework &#8227; SpikeVox: Towards Energy-Efficient Speech Therapy Framework with Spike-driven Generative Language Models\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>.\nLabel  <span class=\"ltx_inline-block\"><svg class=\"ltx_picture\" height=\"15.74\" id=\"S5.SS2.p1.pic1\" overflow=\"visible\" style=\"vertical-align:-3.41px\" version=\"1.1\" viewbox=\"0 0 15.74 15.74\" width=\"15.74\"><g transform=\"translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,3.41)\"><g fill=\"#BF8040\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#BF8040;\"><path d=\"M 7.59 4.46 C 7.59 8.65 4.19 12.05 0 12.05 C -4.19 12.05 -7.59 8.65 -7.59 4.46 C -7.59 0.27 -4.19 -3.13 0 -3.13 C 4.19 -3.13 7.59 0.27 7.59 4.46 Z M 0 4.46\"/></g><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#000000;\" transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 0)\"><foreignobject color=\"#000000\" height=\"8.92\" overflow=\"visible\" style=\"--ltx-fg-color:#000000;--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;\" transform=\"matrix(1 0 0 -1 0 8.92)\" width=\"6.92\"><span class=\"ltx_foreignobject_container\"><span class=\"ltx_foreignobject_content\">1</span></span></foreignobject></g></g></svg></span> indicates the pages that SpikeVox GUI provides, namely <span class=\"ltx_text ltx_font_italic\">recording</span>, <span class=\"ltx_text ltx_font_italic\">analysis</span>, <span class=\"ltx_text ltx_font_italic\">therapy</span>, and <span class=\"ltx_text ltx_font_italic\">feedback</span>.\nIn the recording page, the user can record the speech sound, which will be analyzed for its transcription and phoneme pronunciation in the analysis page.\nFor instance, the input sound of &#8220;hello good morning&#8221; is transcribed to &#8220;HELLO GOOD MORNING&#8221;, showing no differences in transcription  <span class=\"ltx_inline-block\"><svg class=\"ltx_picture\" height=\"15.74\" id=\"S5.SS2.p1.pic2\" overflow=\"visible\" style=\"vertical-align:-3.41px\" version=\"1.1\" viewbox=\"0 0 15.74 15.74\" width=\"15.74\"><g transform=\"translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,3.41)\"><g fill=\"#BF8040\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#BF8040;\"><path d=\"M 7.59 4.46 C 7.59 8.65 4.19 12.05 0 12.05 C -4.19 12.05 -7.59 8.65 -7.59 4.46 C -7.59 0.27 -4.19 -3.13 0 -3.13 C 4.19 -3.13 7.59 0.27 7.59 4.46 Z M 0 4.46\"/></g><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#000000;\" transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 0)\"><foreignobject color=\"#000000\" height=\"8.92\" overflow=\"visible\" style=\"--ltx-fg-color:#000000;--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;\" transform=\"matrix(1 0 0 -1 0 8.92)\" width=\"6.92\"><span class=\"ltx_foreignobject_container\"><span class=\"ltx_foreignobject_content\">2</span></span></foreignobject></g></g></svg></span>.\nHowever, when we observe the pronunciation using Eq.&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#S3.E1\" title=\"In III-B Speech Pattern Analysis &#8227; III The SpikeVox Framework &#8227; SpikeVox: Towards Energy-Efficient Speech Therapy Framework with Spike-driven Generative Language Models\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, SpikeVox identifies phonemes issues for &#8216;H&#8217;, &#8216;E&#8217;, &#8216;L&#8217; with 70.5%, 41.7%, and 73.8%, respectively; see  <span class=\"ltx_inline-block\"><svg class=\"ltx_picture\" height=\"15.74\" id=\"S5.SS2.p1.pic3\" overflow=\"visible\" style=\"vertical-align:-3.41px\" version=\"1.1\" viewbox=\"0 0 15.74 15.74\" width=\"15.74\"><g transform=\"translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,3.41)\"><g fill=\"#BF8040\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#BF8040;\"><path d=\"M 7.59 4.46 C 7.59 8.65 4.19 12.05 0 12.05 C -4.19 12.05 -7.59 8.65 -7.59 4.46 C -7.59 0.27 -4.19 -3.13 0 -3.13 C 4.19 -3.13 7.59 0.27 7.59 4.46 Z M 0 4.46\"/></g><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#000000;\" transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 0)\"><foreignobject color=\"#000000\" height=\"8.92\" overflow=\"visible\" style=\"--ltx-fg-color:#000000;--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;\" transform=\"matrix(1 0 0 -1 0 8.92)\" width=\"6.92\"><span class=\"ltx_foreignobject_container\"><span class=\"ltx_foreignobject_content\">3</span></span></foreignobject></g></g></svg></span>.\nThis shows that, despite no transcription errors, there is a possibility for the existence of phoneme issues.\nBased on this observation, an overall assessment (including severity level and primary issues) is provided as summary, which will be used as basis of therapy exercises generation; see  <span class=\"ltx_inline-block\"><svg class=\"ltx_picture\" height=\"15.74\" id=\"S5.SS2.p1.pic4\" overflow=\"visible\" style=\"vertical-align:-3.41px\" version=\"1.1\" viewbox=\"0 0 15.74 15.74\" width=\"15.74\"><g transform=\"translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,3.41)\"><g fill=\"#BF8040\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#BF8040;\"><path d=\"M 7.59 4.46 C 7.59 8.65 4.19 12.05 0 12.05 C -4.19 12.05 -7.59 8.65 -7.59 4.46 C -7.59 0.27 -4.19 -3.13 0 -3.13 C 4.19 -3.13 7.59 0.27 7.59 4.46 Z M 0 4.46\"/></g><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#000000;\" transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 0)\"><foreignobject color=\"#000000\" height=\"8.92\" overflow=\"visible\" style=\"--ltx-fg-color:#000000;--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;\" transform=\"matrix(1 0 0 -1 0 8.92)\" width=\"6.92\"><span class=\"ltx_foreignobject_container\"><span class=\"ltx_foreignobject_content\">4</span></span></foreignobject></g></g></svg></span>.\nIn the therapy page, SpikeVox generates multiple exercises based on previous results to train specific sounds (e.g., &#8216;L&#8217; and &#8216;vowel&#8217;), which are accompanied with the textual description and correct sound examples; see  <span class=\"ltx_inline-block\"><svg class=\"ltx_picture\" height=\"15.74\" id=\"S5.SS2.p1.pic5\" overflow=\"visible\" style=\"vertical-align:-3.41px\" version=\"1.1\" viewbox=\"0 0 15.74 15.74\" width=\"15.74\"><g transform=\"translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,3.41)\"><g fill=\"#BF8040\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#BF8040;\"><path d=\"M 7.59 4.46 C 7.59 8.65 4.19 12.05 0 12.05 C -4.19 12.05 -7.59 8.65 -7.59 4.46 C -7.59 0.27 -4.19 -3.13 0 -3.13 C 4.19 -3.13 7.59 0.27 7.59 4.46 Z M 0 4.46\"/></g><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#000000;\" transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 0)\"><foreignobject color=\"#000000\" height=\"8.92\" overflow=\"visible\" style=\"--ltx-fg-color:#000000;--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;\" transform=\"matrix(1 0 0 -1 0 8.92)\" width=\"6.92\"><span class=\"ltx_foreignobject_container\"><span class=\"ltx_foreignobject_content\">5</span></span></foreignobject></g></g></svg></span>.\nResults from this page will be used as basis of the feedback generation.\nIn the feedback page, SpikeVox provides an assessment summary based on the user&#8217;s current speech quality; see  <span class=\"ltx_inline-block\"><svg class=\"ltx_picture\" height=\"15.74\" id=\"S5.SS2.p1.pic6\" overflow=\"visible\" style=\"vertical-align:-3.41px\" version=\"1.1\" viewbox=\"0 0 15.74 15.74\" width=\"15.74\"><g transform=\"translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,3.41)\"><g fill=\"#BF8040\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#BF8040;\"><path d=\"M 7.59 4.46 C 7.59 8.65 4.19 12.05 0 12.05 C -4.19 12.05 -7.59 8.65 -7.59 4.46 C -7.59 0.27 -4.19 -3.13 0 -3.13 C 4.19 -3.13 7.59 0.27 7.59 4.46 Z M 0 4.46\"/></g><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#000000;\" transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 0)\"><foreignobject color=\"#000000\" height=\"8.92\" overflow=\"visible\" style=\"--ltx-fg-color:#000000;--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;\" transform=\"matrix(1 0 0 -1 0 8.92)\" width=\"6.92\"><span class=\"ltx_foreignobject_container\"><span class=\"ltx_foreignobject_content\">6</span></span></foreignobject></g></g></svg></span>.\nIt also provides specific guidance based on the observed issues (e.g., &#8216;L&#8217; and &#8216;vowel&#8217;), visual pronunciation guides, and general tips for improving the quality of exercises; see  <span class=\"ltx_inline-block\"><svg class=\"ltx_picture\" height=\"15.74\" id=\"S5.SS2.p1.pic7\" overflow=\"visible\" style=\"vertical-align:-3.41px\" version=\"1.1\" viewbox=\"0 0 15.74 15.74\" width=\"15.74\"><g transform=\"translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,3.41)\"><g fill=\"#BF8040\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#BF8040;\"><path d=\"M 7.59 4.46 C 7.59 8.65 4.19 12.05 0 12.05 C -4.19 12.05 -7.59 8.65 -7.59 4.46 C -7.59 0.27 -4.19 -3.13 0 -3.13 C 4.19 -3.13 7.59 0.27 7.59 4.46 Z M 0 4.46\"/></g><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#000000;\" transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 0)\"><foreignobject color=\"#000000\" height=\"8.92\" overflow=\"visible\" style=\"--ltx-fg-color:#000000;--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;\" transform=\"matrix(1 0 0 -1 0 8.92)\" width=\"6.92\"><span class=\"ltx_foreignobject_container\"><span class=\"ltx_foreignobject_content\">7</span></span></foreignobject></g></g></svg></span>.\nSpikeVox also keeps the progress of the user&#8217;s speech quality over time for improving the exercise quality; see  <span class=\"ltx_inline-block\"><svg class=\"ltx_picture\" height=\"15.74\" id=\"S5.SS2.p1.pic8\" overflow=\"visible\" style=\"vertical-align:-3.41px\" version=\"1.1\" viewbox=\"0 0 15.74 15.74\" width=\"15.74\"><g transform=\"translate(0,15.74) matrix(1 0 0 -1 0 0) translate(7.87,0) translate(0,3.41)\"><g fill=\"#BF8040\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#BF8040;\"><path d=\"M 7.59 4.46 C 7.59 8.65 4.19 12.05 0 12.05 C -4.19 12.05 -7.59 8.65 -7.59 4.46 C -7.59 0.27 -4.19 -3.13 0 -3.13 C 4.19 -3.13 7.59 0.27 7.59 4.46 Z M 0 4.46\"/></g><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#000000;\" transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 0)\"><foreignobject color=\"#000000\" height=\"8.92\" overflow=\"visible\" style=\"--ltx-fg-color:#000000;--fo_width :0.5em;--fo_height:0.64em;--fo_depth :0em;\" transform=\"matrix(1 0 0 -1 0 8.92)\" width=\"6.92\"><span class=\"ltx_foreignobject_container\"><span class=\"ltx_foreignobject_content\">8</span></span></foreignobject></g></g></svg></span>.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "issues",
                    "primary",
                    "based"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In speech therapy tools, the employment of generative NN models is important for analyzing disorders and providing proper feedback.\nHowever, such generative models often rely on the transformer&#8217;s attention mechanism which operates with quadratic computational complexity <math alttext=\"\\mathcal{O}(T^{2})\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS3.p1.m1\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>T</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T^{2})</annotation></semantics></math>.\nTo address this, we employ SpikeGPT which replaces the self-attention matrix multiplication with recurrent structure, that processes tokens sequentially and accumulates context through hidden states&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib26\" title=\"\">26</a>]</cite>, leading to lower complexity <math alttext=\"\\mathcal{O}(T)\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS3.p1.m2\" intent=\":literal\"><semantics><mrow><mi class=\"ltx_font_mathcaligraphic\">&#119978;</mi><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{O}(T)</annotation></semantics></math>.\nMoreover, this approach also results in significant reduction of energy consumption due to: (1) reduced elementary operation energy, <math alttext=\"\\sim\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS3.p1.m3\" intent=\":literal\"><semantics><mo>&#8764;</mo><annotation encoding=\"application/x-tex\">\\sim</annotation></semantics></math>5x energy saving is obtained by replacing multiplication-and-accumulation with accumulation only)&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib26\" title=\"\">26</a>]</cite><cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib40\" title=\"\">40</a>]</cite>; and (2) higher sparsity of operations, <math alttext=\"\\sim\" class=\"ltx_Math\" display=\"inline\" id=\"S5.SS3.p1.m4\" intent=\":literal\"><semantics><mo>&#8764;</mo><annotation encoding=\"application/x-tex\">\\sim</annotation></semantics></math>0.15x fewer operations is obtained by employing spiking neurons&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2510.15566v1#bib.bib26\" title=\"\">26</a>]</cite>.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "spikegpt",
                    "neurons"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">In this paper, we propose a novel SpikeVox framework for enabling energy-efficient speech therapy solutions based on spike-driven generative language model.\nIts key steps include speech recognition, pattern analysis for disorder detection, exercises and guidance generation as therapy feedback.\nIt also enable seamless interaction for users through REST API implementation.\nThe experimental results show that SpikeVox is a promising framework that may provide accessible and energy efficient speech therapy solutions worldwide.</p>\n\n",
                "matched_terms": [
                    "speech",
                    "disorder",
                    "based"
                ]
            }
        ]
    }
}