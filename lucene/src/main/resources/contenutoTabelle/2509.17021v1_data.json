{
    "S3.T1": {
        "source_file": "Bridging the Gap between Training and Inference in LM-based TTS models",
        "caption": "Table 1: Comparison results with existing methods.",
        "body": "System\nLibriSpeech\nSeed-TTS\n\n\n\n\n\nWER ↓\\downarrow\n\n\n\n\nSIM↑\\uparrow\n\n\n\n\nWER ↓\\downarrow\n\n\n\n\nSIM↑\\uparrow\n\n\n\n\nGT\n\n\n1.94\n\n\n\n\n0.82\n\n\n\n\n2.14\n\n\n\n\n0.89\n\n\n\n\nIndexTTS\n\n\n8.30\n\n\n\n\n0.68\n\n\n\n\n6.53\n\n\n\n\n0.84\n\n\n\n\nCosyVoice - TF\n\n\n8.17\n\n\n\n\n0.67\n\n\n\n\n6.54\n\n\n\n\n0.78\n\n\n\n\nCosyVoice2 - TF\n\n\n6.23\n\n\n\n\n0.74\n\n\n\n\n4.83\n\n\n\n\n0.83\n\n\n\n\nCosyVoice - Ours\n\n\n5.38\n\n\n\n\n0.68\n\n\n\n\n6.34\n\n\n\n\n0.85\n\n\n\n\nCosyVoice2 - Ours\n\n\n4.21\n\n\n\n\n0.78\n\n\n\n\n4.64\n\n\n\n\n0.84",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">System</th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">LibriSpeech</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">Seed-TTS</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_row\" style=\"padding-left:3.5pt;padding-right:3.5pt;\"/>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">WER <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m1\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">SIM<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m2\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">WER <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">SIM<math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T1.m4\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">GT</th>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">1.94</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.82</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">2.14</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.89</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">IndexTTS</th>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">8.30</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.68</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">6.53</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.84</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">CosyVoice - TF</th>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">8.17</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.67</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">6.54</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.78</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">CosyVoice2 - TF</th>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">6.23</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.74</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">4.83</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.83</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">CosyVoice - Ours</th>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">5.38</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.68</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">6.34</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_border_t\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">0.85</span></span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">CosyVoice2 - Ours</th>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">4.21</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">0.78</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">4.64</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_nopad_r ltx_align_justify ltx_border_bb\" style=\"padding-left:3.5pt;padding-right:3.5pt;\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.84</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "system",
            "cosyvoice2",
            "indextts",
            "ours",
            "existing",
            "librispeech",
            "wer",
            "↓downarrow",
            "methods",
            "comparison",
            "results",
            "seedtts",
            "cosyvoice",
            "sim↑uparrow"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">As shown in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#S3.T1\" title=\"Table 1 &#8227; 3.2 Subjective evaluation &#8227; 3 Experiments &#8227; Bridging the Gap between Training and Inference in LM-based TTS models\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, we compare against the baselines IndexTTS<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#bib.bib20\" title=\"\">20</a>]</cite>, CosyVoice and CosyVoice2. CosyVoice-TF denotes fine-tuning the pretrained CosyVoice model using the standard teacher forcing scheme. CosyVoice2-TF is defined analogously. On CosyVoice2, our prompt-guided hybrid training strategy achieves the best overall performance. It yields superior Word Error Rate (WER) and speaker smilarity performance over baselines on LibriSpeech and relatively smaller improvement on Seed-TTS (where utterances are <math alttext=\"&lt;10s\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\"><semantics><mrow><mi/><mo>&lt;</mo><mrow><mn>10</mn><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi></mrow></mrow><annotation encoding=\"application/x-tex\">&lt;10s</annotation></semantics></math>). The relatively small improvement on Seed-TTS dataset may be attributed to the shorter duration of its speech samples, as our method tends to perform better on longer speech samples by mitigating the accumulated error caused by exposure bias. It is also quite intuitive that longer sequence is easier to suffer from accumulated error in the process of autoregressive generation.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">The proposed prompt-guided hybrid training scheme is employed to fine-tuning the CosyVoice <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#bib.bib16\" title=\"\">16</a>]</cite> and CosyVoice2<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#bib.bib17\" title=\"\">17</a>]</cite> on the LibriSpeech corpus<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#bib.bib18\" title=\"\">18</a>]</cite>, which contains approximately 40K hours of transcribed speech data. For evaluation, we adopt two test sets, LibriSpeech test-clean and SeedTTS <cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#bib.bib19\" title=\"\">19</a>]</cite>, which includes 1,000 utterances sampled from the common voice corpus to reflect more diverse acoustic conditions.\nDuring training, we adopt the AdamW optimizer with a constant learning rate of <math alttext=\"1\\times 10^{-5}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS1.p1.m1\" intent=\":literal\"><semantics><mrow><mn>1</mn><mo lspace=\"0.222em\" rspace=\"0.222em\">&#215;</mo><msup><mn>10</mn><mrow><mo>&#8722;</mo><mn>5</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">1\\times 10^{-5}</annotation></semantics></math>. Speech signals are discretized into token sequences using a vector quantizer with a single codebook of 4096 entries. We apply 10k warm-up steps before introducing the proposed hybrid training strategy.</p>\n\n",
                "matched_terms": [
                    "cosyvoice",
                    "seedtts",
                    "librispeech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For objective evaluation, we evaluate our method using both mean opinion score (MOS) and A/B preference tests with human listeners.\nThirty samples are obtained from the LibriSpeech test-clean set, and the MOS results are shown in Figure &#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#S3.F2\" title=\"Figure 2 &#8227; 3.3 Objective evaluation &#8227; 3 Experiments &#8227; Bridging the Gap between Training and Inference in LM-based TTS models\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. Our method outperforms teacher forcing training and yield comparable results with GT speech samples.</p>\n\n",
                "matched_terms": [
                    "results",
                    "librispeech"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">As summarized in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#S3.T2\" title=\"Table 2 &#8227; 3.6 Ablation Study &#8227; 3 Experiments &#8227; Bridging the Gap between Training and Inference in LM-based TTS models\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, we conduct an ablation study to validate the effectiveness. The results show that removing either prompt protection or EOS adaptive leads to higher WER and lower speaker similarity. The degradation is more pronounced when Prompt Protection is removed.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "results"
                ]
            }
        ]
    },
    "S3.T2": {
        "source_file": "Bridging the Gap between Training and Inference in LM-based TTS models",
        "caption": "Table 2: Ablation Study. w refers to our training framework with all method enabled.",
        "body": "systems\n\n\nWER ↓\\downarrow\n\n\n\n\nSIM ↑\\uparrow\n\n\n\n\n\n\nw/o Prompt Protection\n\n\n7.25\n\n\n\n\n0.65\n\n\n\n\nw/o EOS Adaptive\n\n\n4.98\n\n\n\n\n0.72\n\n\n\n\nw\n\n\n4.21\n\n\n\n\n0.80",
        "html_code": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">systems</span></th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">WER <math alttext=\"\\downarrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.m1\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8595;</mo><annotation encoding=\"application/x-tex\">\\downarrow</annotation></semantics></math></span>\n</span>\n</th>\n<th class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">SIM <math alttext=\"\\uparrow\" class=\"ltx_Math\" display=\"inline\" id=\"S3.T2.m2\" intent=\":literal\"><semantics><mo stretchy=\"false\">&#8593;</mo><annotation encoding=\"application/x-tex\">\\uparrow</annotation></semantics></math></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">w/o Prompt Protection</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">7.25</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.65</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span class=\"ltx_text ltx_font_bold\">w/o EOS Adaptive</span></th>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">4.98</span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\">0.72</span>\n</span>\n</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\"><span class=\"ltx_text ltx_font_bold\">w</span></th>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">4.21</span></span>\n</span>\n</td>\n<td class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span class=\"ltx_inline-block ltx_align_top\">\n<span class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">0.80</span></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "informative_terms_identified": [
            "protection",
            "method",
            "systems",
            "ablation",
            "all",
            "wer",
            "↓downarrow",
            "prompt",
            "eos",
            "study",
            "sim",
            "adaptive",
            "framework",
            "training",
            "refers",
            "our",
            "↑uparrow",
            "enabled"
        ],
        "citing_paragraphs": [
            "<p class=\"ltx_p\">As summarized in Table <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#S3.T2\" title=\"Table 2 &#8227; 3.6 Ablation Study &#8227; 3 Experiments &#8227; Bridging the Gap between Training and Inference in LM-based TTS models\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, we conduct an ablation study to validate the effectiveness. The results show that removing either prompt protection or EOS adaptive leads to higher WER and lower speaker similarity. The degradation is more pronounced when Prompt Protection is removed.</p>\n\n"
        ],
        "contextual_paragraphs": [
            {
                "html": "<p class=\"ltx_p\">Recent advancements in text-to-speech (TTS) have shown that language model (LM) based systems offer competitive performance compared to traditional approaches. However, in training, TTS models use ground-truth (GT) tokens as prefixes to predict the next token, while in inference these tokens are not available, a gap between training and inference that is often neglected. In this study, we propose a prompt-guided hybrid training scheme to mitigate exposure bias in popular LM-based TTS systems. Our core idea is to adopt a hybrid training paradigm that combines teacher forcing with free running, thereby introducing self-generated tokens into the training process. This makes the training mode more consistent with inference, reducing the training&#8211;inference gap. In addition, we incorporate an EOS prediction mechanism during training to detect incorrect sequence termination and adaptively control the free running process. Experimental results provide a comprehensive evaluation of the impact of exposure bias on LM-based TTS, and demonstrate that our method effectively narrows the training&#8211;inference gap, thereby improving the quality of synthesized long-form speech.</p>\n\n",
                "matched_terms": [
                    "method",
                    "eos",
                    "systems",
                    "study",
                    "training",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To mitigate exposure bias, we propose a prompt-guided hybrid training scheme that gradually transitions from fully guided supervision to self-conditioned generation. As illustrated in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Bridging the Gap between Training and Inference in LM-based TTS models\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, our approach operates iteratively within each training step. First, it replaces a portion of the GT input tokens with self-generated tokens in a previous pass. Concurrently, we use a prompt protection strategy to ensure a specific part of the GT tokens is always preserved. This controlled exposure not only maintains training stability but also enhances generalization. We further introduce an adaptive free running strategy guided by End-of-Sequence (EOS) prediction. If the EOS is mispredicted, we end free running early by masking subsequent steps and proceed directly to gradient updates.\nOur experimental results demonstrate that the iterative hybrid training strategy enhances the model&#8217;s dependency on its token history, compensating for the absence of GT tokens during inference. This approach also narrows the gap between training and inference modes, leading to more stable and coherent sequence modeling.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "eos",
                    "adaptive",
                    "prompt",
                    "training",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Figure &#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Bridging the Gap between Training and Inference in LM-based TTS models\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>(right) illustrates our training framework in comparison with standard teacher forcing training (left). We propose a prompt-guided hybrid training scheme that integrates teacher forcing with free running. The basic idea of our training strategy is to iteratively put the self-generated tokens into the LLM being trained to simulate auto-regressive inference process and back propagate both teacher forcing loss and accumulated free running loss in a single training step. To further strengthen its prompt following ability, we randomly replace the starting speech tokens with GT tokens in later iterations. This design leverages the stability of teacher forcing while gradually introducing self-generated prefixes, thereby improving robustness against exposure bias.</p>\n\n",
                "matched_terms": [
                    "our",
                    "prompt",
                    "framework",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Moreover, when prompt protection strategy is enabled and the first few speech tokens of input sequence is replaced by GT tokens, the replaced portion also provides an additional teacher forcing loss to further stabilize training process. As training progresses, we increase the number of replaced tokens to make a smooth shift from initial teacher forcing dominated training to self-generated token dominated training. This fosters a smooth transition, guiding the model toward robust and reliable self-generation.</p>\n\n",
                "matched_terms": [
                    "enabled",
                    "prompt",
                    "protection",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">Earlier studies have found that teacher forcing demonstrates greater stability and faster convergence compared to free running. Therefore, too many iterations of free running may interfere with model convergence. To address this issue, adaptive free running scheduling via EOS prediction is introduced as a compensatory solution.\n</p>\n\n",
                "matched_terms": [
                    "eos",
                    "adaptive"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We observe that the predicted EOS token serves as a reliable indicator of exposure bias and training stability, allowing dynamic adjustment of free running iterations. When the EOS token is not correctly predicted, it suggests potential exposure bias or model degradation during training. In such cases, the model should increase its reliance on ground-truth supervision to correct its learning trajectory in subsequent steps. Conversely, when EOS token is successfully predicted in several consecutive training steps, the model increases the number of free running iterations to better align the inference procedure. This adaptive mechanism dynamically adjusts the number of free running iterations based on output quality, thereby improving both training efficiency and generation stability.</p>\n\n",
                "matched_terms": [
                    "eos",
                    "adaptive",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">The overall training objective is influenced by two components: teacher forcing loss, which provides stable supervision using GT tokens, and a weighted sum of free running losses, which improves prediction quality under autoregressive conditions. As depicted in Figure&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#S1.F1\" title=\"Figure 1 &#8227; 1 Introduction &#8227; Bridging the Gap between Training and Inference in LM-based TTS models\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>(right), the first iteration of our training framework involves computing the teacher forcing loss <math alttext=\"\\mathcal{L}_{\\text{TF}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p1.m1\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8466;</mi><mtext>TF</mtext></msub><annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\text{TF}}</annotation></semantics></math>, identical to the cross-entropy loss in conventional LLM training. <math alttext=\"\\mathcal{L}_{\\text{TF}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p1.m2\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8466;</mi><mtext>TF</mtext></msub><annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\text{TF}}</annotation></semantics></math> can be described as follow:</p>\n\n",
                "matched_terms": [
                    "our",
                    "framework",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">where, <math alttext=\"y_{t}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p3.m1\" intent=\":literal\"><semantics><msub><mi>y</mi><mi>t</mi></msub><annotation encoding=\"application/x-tex\">y_{t}</annotation></semantics></math> denotes the <math alttext=\"t_{\\text{th}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p3.m2\" intent=\":literal\"><semantics><msub><mi>t</mi><mtext>th</mtext></msub><annotation encoding=\"application/x-tex\">t_{\\text{th}}</annotation></semantics></math> speech token generated from its GT prefixes <math alttext=\"y_{i&lt;t}^{\\text{gt}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p3.m3\" intent=\":literal\"><semantics><msubsup><mi>y</mi><mrow><mi>i</mi><mo>&lt;</mo><mi>t</mi></mrow><mtext>gt</mtext></msubsup><annotation encoding=\"application/x-tex\">y_{i&lt;t}^{\\text{gt}}</annotation></semantics></math>. <math alttext=\"\\mathbf{X}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p3.m4\" intent=\":literal\"><semantics><mi>&#119831;</mi><annotation encoding=\"application/x-tex\">\\mathbf{X}</annotation></semantics></math> refers to the input prompt tokens, including SOS token, text embeddings, speaker embedding and other prompt tokens.</p>\n\n",
                "matched_terms": [
                    "prompt",
                    "refers"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">This free running loss <math alttext=\"\\mathcal{L}_{\\text{FR}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p5.m1\" intent=\":literal\"><semantics><msub><mi class=\"ltx_font_mathcaligraphic\">&#8466;</mi><mtext>FR</mtext></msub><annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\text{FR}}</annotation></semantics></math> is a sum of two terms. The first term refers to the cross entropy between GT and the first <math alttext=\"T_{1}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p5.m2\" intent=\":literal\"><semantics><msub><mi>T</mi><mn>1</mn></msub><annotation encoding=\"application/x-tex\">T_{1}</annotation></semantics></math> speech tokens of model output. These tokens are generated based on GT prefixes <math alttext=\"y_{i&lt;t}^{\\text{gt}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p5.m3\" intent=\":literal\"><semantics><msubsup><mi>y</mi><mrow><mi>i</mi><mo>&lt;</mo><mi>t</mi></mrow><mtext>gt</mtext></msubsup><annotation encoding=\"application/x-tex\">y_{i&lt;t}^{\\text{gt}}</annotation></semantics></math> and <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p5.m4\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math>. The second term refers to the cross entropy between GT and the rest of the speech tokens which is generated based on GT tokens <math alttext=\"y_{i&lt;T_{1}}^{\\text{gt}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p5.m5\" intent=\":literal\"><semantics><msubsup><mi>y</mi><mrow><mi>i</mi><mo>&lt;</mo><msub><mi>T</mi><mn>1</mn></msub></mrow><mtext>gt</mtext></msubsup><annotation encoding=\"application/x-tex\">y_{i&lt;T_{1}}^{\\text{gt}}</annotation></semantics></math>, predicted tokens <math alttext=\"y_{T_{1}&lt;i&lt;t}^{\\text{pred}}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p5.m6\" intent=\":literal\"><semantics><msubsup><mi>y</mi><mrow><msub><mi>T</mi><mn>1</mn></msub><mo>&lt;</mo><mi>i</mi><mo>&lt;</mo><mi>t</mi></mrow><mtext>pred</mtext></msubsup><annotation encoding=\"application/x-tex\">y_{T_{1}&lt;i&lt;t}^{\\text{pred}}</annotation></semantics></math>, and <math alttext=\"X\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS3.p5.m7\" intent=\":literal\"><semantics><mi>X</mi><annotation encoding=\"application/x-tex\">X</annotation></semantics></math>. Our overall training objective can be formulated as follow:</p>\n\n",
                "matched_terms": [
                    "our",
                    "training",
                    "refers"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">As shown in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#S3.T1\" title=\"Table 1 &#8227; 3.2 Subjective evaluation &#8227; 3 Experiments &#8227; Bridging the Gap between Training and Inference in LM-based TTS models\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, we compare against the baselines IndexTTS<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#bib.bib20\" title=\"\">20</a>]</cite>, CosyVoice and CosyVoice2. CosyVoice-TF denotes fine-tuning the pretrained CosyVoice model using the standard teacher forcing scheme. CosyVoice2-TF is defined analogously. On CosyVoice2, our prompt-guided hybrid training strategy achieves the best overall performance. It yields superior Word Error Rate (WER) and speaker smilarity performance over baselines on LibriSpeech and relatively smaller improvement on Seed-TTS (where utterances are <math alttext=\"&lt;10s\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.p1.m1\" intent=\":literal\"><semantics><mrow><mi/><mo>&lt;</mo><mrow><mn>10</mn><mo lspace=\"0em\" rspace=\"0em\">&#8203;</mo><mi>s</mi></mrow></mrow><annotation encoding=\"application/x-tex\">&lt;10s</annotation></semantics></math>). The relatively small improvement on Seed-TTS dataset may be attributed to the shorter duration of its speech samples, as our method tends to perform better on longer speech samples by mitigating the accumulated error caused by exposure bias. It is also quite intuitive that longer sequence is easier to suffer from accumulated error in the process of autoregressive generation.</p>\n\n",
                "matched_terms": [
                    "wer",
                    "method",
                    "training",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">For objective evaluation, we evaluate our method using both mean opinion score (MOS) and A/B preference tests with human listeners.\nThirty samples are obtained from the LibriSpeech test-clean set, and the MOS results are shown in Figure &#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#S3.F2\" title=\"Figure 2 &#8227; 3.3 Objective evaluation &#8227; 3 Experiments &#8227; Bridging the Gap between Training and Inference in LM-based TTS models\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>. Our method outperforms teacher forcing training and yield comparable results with GT speech samples.</p>\n\n",
                "matched_terms": [
                    "our",
                    "method",
                    "training"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">To validate EOS guided adaptive iteration introduced in Section <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#S2.SS2\" title=\"2.2 Adaptive free running scheduling via EOS prediction &#8227; 2 proposed approach &#8227; Bridging the Gap between Training and Inference in LM-based TTS models\"><span class=\"ltx_text ltx_ref_tag\">2.2</span></a>, we track the number of iterations before the model incorrectly predicts a premature EOS token.\nExperiments are conducted under different maximum iteration settings (2, 4, and 6). As shown in Figure &#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2509.17021v1#S3.F4\" title=\"Figure 4 &#8227; 3.5 Validation of EOS-guided scheduling &#8227; 3 Experiments &#8227; Bridging the Gap between Training and Inference in LM-based TTS models\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>, during the early phase of hybrid training, premature EOS often occurs within the first few iterations, suggesting that the model is not fully prepared for free running. As training goes on, the occurrence of premature EOS shifts to later steps, suggesting improved robustness under free running conditions. Based on this observation, we increase the number of free running iterations when premature EOS predictions are less frequent. Notably, despite the gradual increase in iterations during training, our method requires only 1.5&#215; the computation of the baseline and converges in fewer steps.\nThis training efficiency attributed to the fact that we only do backward pass once in a training step.</p>\n\n",
                "matched_terms": [
                    "method",
                    "eos",
                    "adaptive",
                    "training",
                    "our"
                ]
            },
            {
                "html": "<p class=\"ltx_p\">We propose a novel training framework for LM-based TTS to align the training process with autoregressive inference. By constructing a hybrid input that mixes GT tokens with the model&#8217;s self-generated tokens, our method effectively mitigates exposure bias. This strategy effectively simulates the data distribution encountered during inference. The prompt protection mechanism guides the model to gradually shift from supervised guidance to self-sufficient autoregressive generation. Concurrently, it offers a reliable feedback EOS signal for dynamically tng the free-running scheduling strategy.\nIn our experiments, we first visualize the significant exposure bias between the training and inference stages. Furthermore, the framework alleviates the problem of the model struggling to predict the EOS token during free running generation, a classic symptom of exposure bias. The results demonstrate that our proposed training framework significantly improves speech synthesis quality, especially for long-form speech synthesis.</p>\n\n",
                "matched_terms": [
                    "protection",
                    "method",
                    "eos",
                    "prompt",
                    "framework",
                    "training",
                    "our"
                ]
            }
        ]
    }
}